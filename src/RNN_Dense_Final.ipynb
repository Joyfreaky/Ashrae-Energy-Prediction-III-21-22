{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tT3oRvEFUtYK"
      },
      "outputs": [],
      "source": [
        "# Energy prediction 3 (ASHRAE)\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from scipy.signal import savgol_filter as sg\n",
        "import holidays\n",
        "from pandas.api.types import is_categorical_dtype\n",
        "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import numpy as np  # linear algebra\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import os\n",
        "import gc\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "black_day = 10\n",
        "\n",
        "debug = False\n",
        "num_rounds = 200\n",
        "\n",
        "folds = 3  # 3, 6, 12\n",
        "\n",
        "ucf_year = [2017, 2018]  # ucf data year used in train\n",
        "\n",
        "predmode = 'all'  \n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras import backend as k\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras.layers as layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, Activation\n",
        "from keras.optimizers import *\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Original code from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage by @gemartin\n",
        "# Modified to support timestamp type, categorical type\n",
        "# Modified to add option to use float16 or not. feather format does not support float16.\n",
        "\n",
        "\n",
        "def reduce_mem_usage(df, use_float16=False):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "\n",
        "    for col in df.columns:\n",
        "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
        "            # skip datetime type or categorical type\n",
        "            continue\n",
        "        col_type = df[col].dtype\n",
        "\n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "            else:\n",
        "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(\n",
        "        100 * (start_mem - end_mem) / start_mem))\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "zone_dict = {0: 4, 1: 0, 2: 7, 3: 4, 4: 7, 5: 0, 6: 4, 7: 4,\n",
        "             8: 4, 9: 5, 10: 7, 11: 4, 12: 0, 13: 5, 14: 4, 15: 4}\n",
        "\n",
        "\n",
        "def set_local(df):\n",
        "    for sid, zone in zone_dict.items():\n",
        "        sids = df.site_id == sid\n",
        "        df.loc[sids, 'timestamp'] = df[sids].timestamp - pd.offsets.Hour(zone)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "root = Path('/home/joydipb/Documents/CMT307-Coursework-2-Group-19') # Change the path to the source file path, use Memory_Management.py to generate files in feather format \n",
        "train_df = pd.read_feather(root/'train.feather')\n",
        "weather_train_df = pd.read_feather(root/'weather_train.feather')\n",
        "building_meta_df = pd.read_feather(root/'building_metadata.feather')\n",
        "\n",
        "building_meta_df = building_meta_df.merge(\n",
        "    train_df[['building_id', 'meter']].drop_duplicates(), on='building_id')\n",
        "\n",
        "# Set group  (site-meter) for training models\n",
        "\n",
        "building_meta_df['groupNum_train'] = building_meta_df['site_id'].astype(\n",
        "    'int')*10 + building_meta_df['meter'].astype('int')\n",
        "\n",
        "building_meta_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "building_meta_df['floor_area'] = building_meta_df.square_feet / \\\n",
        "    building_meta_df.floor_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Site Specific Holiday\n",
        "\n",
        "\n",
        "en_holidays = holidays.England()\n",
        "ir_holidays = holidays.Ireland()\n",
        "ca_holidays = holidays.Canada()\n",
        "us_holidays = holidays.UnitedStates()\n",
        "\n",
        "\n",
        "def add_holiyday(df_weather):\n",
        "    en_idx = df_weather.query('site_id == 1 or site_id == 5').index\n",
        "    ir_idx = df_weather.query('site_id == 12').index\n",
        "    ca_idx = df_weather.query('site_id == 7 or site_id == 11').index\n",
        "    us_idx = df_weather.query(\n",
        "        'site_id == 0 or site_id == 2 or site_id == 3 or site_id == 4 or site_id == 6 or site_id == 8 or site_id == 9 or site_id == 10 or site_id == 13 or site_id == 14 or site_id == 15').index\n",
        "\n",
        "    df_weather['IsHoliday'] = 0\n",
        "    df_weather.loc[en_idx, 'IsHoliday'] = df_weather.loc[en_idx,\n",
        "                                                         'timestamp'].apply(lambda x: en_holidays.get(x, default=0))\n",
        "    df_weather.loc[ir_idx, 'IsHoliday'] = df_weather.loc[ir_idx,\n",
        "                                                         'timestamp'].apply(lambda x: ir_holidays.get(x, default=0))\n",
        "    df_weather.loc[ca_idx, 'IsHoliday'] = df_weather.loc[ca_idx,\n",
        "                                                         'timestamp'].apply(lambda x: ca_holidays.get(x, default=0))\n",
        "    df_weather.loc[us_idx, 'IsHoliday'] = df_weather.loc[us_idx,\n",
        "                                                         'timestamp'].apply(lambda x: us_holidays.get(x, default=0))\n",
        "\n",
        "    holiday_idx = df_weather['IsHoliday'] != 0\n",
        "    df_weather.loc[holiday_idx, 'IsHoliday'] = 1\n",
        "    df_weather['IsHoliday'] = df_weather['IsHoliday'].astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "set_local(weather_train_df)\n",
        "add_holiyday(weather_train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = train_df.query('not (building_id == 954 & meter_reading == 0)')\n",
        "train_df = train_df.query('not (building_id == 1221 & meter_reading == 0)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Removing buildings with meter == 0 before first initial reading.\n",
        "train_df = train_df.query(\n",
        "    'not (building_id <= 104 & meter == 0 & timestamp <= \"2016-05-20 18\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 681 & meter == 0 & timestamp <= \"2016-04-27\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 761 & meter == 0 & timestamp <= \"2016-09-02\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 799 & meter == 0 & timestamp <= \"2016-09-02\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 802 & meter == 0 & timestamp <= \"2016-08-24\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1073 & meter == 0 & timestamp <= \"2016-10-26\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1094 & meter == 0 & timestamp <= \"2016-09-08\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 29 & meter == 0 & timestamp <= \"2016-08-10\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 40 & meter == 0 & timestamp <= \"2016-06-04\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 45 & meter == 0 & timestamp <= \"2016-07\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 106 & meter == 0 & timestamp <= \"2016-11\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 107 & meter == 0 & timestamp >= \"2016-11-10\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 112 & meter == 0 & timestamp < \"2016-10-31 15\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 144 & meter == 0 & timestamp > \"2016-05-14\" & timestamp < \"2016-10-31\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 147 & meter == 0 & timestamp > \"2016-06-05 19\" & timestamp < \"2016-07-18 15\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 171 & meter == 0 & timestamp <= \"2016-07-05\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 177 & meter == 0 & timestamp > \"2016-06-04\" & timestamp < \"2016-06-25\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 258 & meter == 0 & timestamp > \"2016-09-26\" & timestamp < \"2016-12-12\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 258 & meter == 0 & timestamp > \"2016-08-30\" & timestamp < \"2016-09-08\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 258 & meter == 0 & timestamp > \"2016-09-18\" & timestamp < \"2016-09-25\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 260 & meter == 0 & timestamp <= \"2016-05-11\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 269 & meter == 0 & timestamp > \"2016-06-04\" & timestamp < \"2016-06-25\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 304 & meter == 0 & timestamp >= \"2016-11-20\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 545 & meter == 0 & timestamp > \"2016-01-17\" & timestamp < \"2016-02-10\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 604 & meter == 0 & timestamp < \"2016-11-21\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 693 & meter == 0 & timestamp > \"2016-09-07\" & timestamp < \"2016-11-23\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 693 & meter == 0 & timestamp > \"2016-07-12\" & timestamp < \"2016-05-29\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 723 & meter == 0 & timestamp > \"2016-10-06\" & timestamp < \"2016-11-22\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 733 & meter == 0 & timestamp > \"2016-05-29\" & timestamp < \"2016-06-22\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 733 & meter == 0 & timestamp > \"2016-05-19\" & timestamp < \"2016-05-20\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 803 & meter == 0 & timestamp > \"2016-9-25\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 815 & meter == 0 & timestamp > \"2016-05-17\" & timestamp < \"2016-11-17\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 848 & meter == 0 & timestamp > \"2016-01-15\" & timestamp < \"2016-03-20\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 857 & meter == 0 & timestamp > \"2016-04-13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 909 & meter == 0 & timestamp < \"2016-02-02\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 909 & meter == 0 & timestamp < \"2016-06-23\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1008 & meter == 0 & timestamp > \"2016-10-30\" & timestamp < \"2016-11-21\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1113 & meter == 0 & timestamp < \"2016-07-27\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1153 & meter == 0 & timestamp < \"2016-01-20\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1169 & meter == 0 & timestamp < \"2016-08-03\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1170 & meter == 0 & timestamp > \"2016-06-30\" & timestamp < \"2016-07-05\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1221 & meter == 0 & timestamp < \"2016-11-04\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1225 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1234 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1233 & building_id <= 1234 & meter == 0 & timestamp > \"2016-01-13 22\" & timestamp < \"2016-03-08 12\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1241 & meter == 0 & timestamp > \"2016-07-14\" & timestamp < \"2016-11-19\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1250 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1255 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1264 & meter == 0 & timestamp > \"2016-08-23\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1265 & meter == 0 & timestamp > \"2016-05-06\" & timestamp < \"2016-05-26\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1272 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1275 & building_id <= 1280 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1283 & meter == 0 & timestamp > \"2016-07-08\" & timestamp < \"2016-08-03\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1291 & building_id <= 1302 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1303 & meter == 0 & timestamp > \"2016-07-25 22\" & timestamp < \"2016-07-27 16\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1303 & meter == 0 & timestamp > \"2016-01-26\" & timestamp < \"2016-06-02 12\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1319 & meter == 0 & timestamp > \"2016-05-17 16\" & timestamp < \"2016-06-07 12\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1319 & meter == 0 & timestamp > \"2016-08-18 14\" & timestamp < \"2016-09-02 14\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1322 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "\n",
        "# 2nd cleaning\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 0 & timestamp > \"2016-10-14 22\" & timestamp < \"2016-10-17 08\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 0 & timestamp > \"2016-07-01 14\" & timestamp < \"2016-07-05 06\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 1 & timestamp > \"2016-10-14 22\" & timestamp < \"2016-10-17 08\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 1 & timestamp > \"2016-07-01 14\" & timestamp < \"2016-07-05 06\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 2 & timestamp > \"2016-10-14 22\" & timestamp < \"2016-10-17 08\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 2 & timestamp > \"2016-07-01 14\" & timestamp < \"2016-07-05 06\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1272 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1291 & building_id <= 1297 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1300 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1302 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1291 & building_id <= 1299 & meter == 2 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1221 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1225 & building_id <= 1226 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1233 & building_id <= 1234 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1241 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1223 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1226 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1233 & building_id <= 1234 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1225 & building_id <= 1226 & meter == 2 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1305 & meter == 2 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1307 & meter == 2 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1223 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1231 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1233 & building_id <= 1234 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1272 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1275 & building_id <= 1297 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1300 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1302 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1293 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-25 12\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1302 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-25 12\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1223 & meter == 0 & timestamp > \"2016-9-28 07\" & timestamp < \"2016-10-11 18\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1225 & meter == 1 & timestamp > \"2016-8-22 23\" & timestamp < \"2016-10-11 14\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1230 & meter == 1 & timestamp > \"2016-8-22 08\" & timestamp < \"2016-10-05 18\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 904 & meter == 0 & timestamp < \"2016-02-17 08\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 986 & meter == 0 & timestamp < \"2016-02-17 08\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 954 & meter == 0 & timestamp < \"2016-08-08 11\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 954 & meter == 0 & timestamp < \"2016-06-23 08\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 745 & building_id <= 770 & meter == 1 & timestamp > \"2016-10-05 01\" & timestamp < \"2016-10-10 09\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 774 & building_id <= 787 & meter == 1 & timestamp > \"2016-10-05 01\" & timestamp < \"2016-10-10 09\")')\n",
        "\n",
        "# 3rd cleaning hourly spikes\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 0 & timestamp > \"2016-05-11 09\" & timestamp < \"2016-05-12 01\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 1 & timestamp > \"2016-05-11 09\" & timestamp < \"2016-05-12 01\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 2 & timestamp > \"2016-05-11 09\" & timestamp < \"2016-05-12 01\")')\n",
        "\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 0 & timestamp == \"2016-02-26 01\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 1 & timestamp == \"2016-02-26 01\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 2 & timestamp == \"2016-02-26 01\")')\n",
        "\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 0 & timestamp > \"2016-03-29 10\" & timestamp < \"2016-03-30 12\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 1 & timestamp > \"2016-03-29 10\" & timestamp < \"2016-03-30 12\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 2 & timestamp > \"2016-03-29 10\" & timestamp < \"2016-03-30 12\")')\n",
        "\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 0 & timestamp > \"2016-01-19 23\" & timestamp < \"2016-01-28 15\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 1 & timestamp > \"2016-01-19 23\" & timestamp < \"2016-01-28 15\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 2 & timestamp > \"2016-01-19 23\" & timestamp < \"2016-01-28 15\")')\n",
        "\n",
        "train_df = train_df.query(\n",
        "    'not (building_id != 1227 & building_id != 1281 & building_id != 1314 & building_id >=1223 & building_id < 1335 & meter==0 & meter_reading==0)')\n",
        "\n",
        "# 4th cleaning\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1223 & building_id <= 1324 & meter==1 & timestamp > \"2016-07-16 04\" & timestamp < \"2016-07-19 11\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 107 & meter == 0 & timestamp <= \"2016-07-06\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 180 & timestamp >= \"2016-02-17 12\")')\n",
        "train_df = train_df.query('not (building_id == 182 & meter == 0)')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 191 & meter == 0 & timestamp >= \"2016-12-22 09\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 192 & meter == 1 & timestamp >= \"2016-05-09 18\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 192 & meter == 3 & timestamp >= \"2016-03-29 05\" & timestamp <= \"2016-04-04 08\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 207 & meter == 1 & timestamp > \"2016-07-02 20\" & timestamp < \"2016-08-25 12\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 258 & timestamp > \"2016-09-18\" & timestamp < \"2016-12-12 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 258 & timestamp > \"2016-08-29 08\" & timestamp < \"2016-09-08 14\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 257 & meter == 1 & timestamp < \"2016-03-25 16\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 260 & meter == 1 & timestamp > \"2016-05-10 17\" & timestamp < \"2016-08-17 11\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 260 & meter == 1 & timestamp > \"2016-08-28 01\" & timestamp < \"2016-10-31 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 220 & meter == 1 & timestamp > \"2016-09-23 01\" & timestamp < \"2016-09-23 12\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 281 & meter == 1 & timestamp > \"2016-10-25 08\" & timestamp < \"2016-11-04 15\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 273 & meter == 1 & timestamp > \"2016-04-03 04\" & timestamp < \"2016-04-29 15\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 28 & meter == 0 & timestamp < \"2016-10-14 20\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 71 & meter == 0 & timestamp < \"2016-08-18 20\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 76 & meter == 0 & timestamp > \"2016-06-04 09\" & timestamp < \"2016-06-04 14\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 101 & meter == 0 & timestamp > \"2016-10-12 13\" & timestamp < \"2016-10-12 18\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 7 & meter == 1 & timestamp > \"2016-11-03 09\" & timestamp < \"2016-11-28 14\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 9 & meter == 1 & timestamp > \"2016-12-06 08\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 43 & meter == 1 & timestamp > \"2016-04-03 08\" & timestamp < \"2016-06-06 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 60 & meter == 1 & timestamp > \"2016-05-01 17\" & timestamp < \"2016-05-01 21\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 75 & meter == 1 & timestamp > \"2016-08-05 13\" & timestamp < \"2016-08-26 12\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 95 & meter == 1 & timestamp > \"2016-08-08 10\" & timestamp < \"2016-08-26 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 97 & meter == 1 & timestamp > \"2016-08-08 14\" & timestamp < \"2016-08-25 14\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1232 & meter == 1 & timestamp > \"2016-06-23 16\" & timestamp < \"2016-08-31 20\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1236 & meter == 1 & meter_reading >= 3000)')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1239 & meter == 1 & timestamp > \"2016-03-11 16\" & timestamp < \"2016-03-27 17\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1264 & meter == 1 & timestamp > \"2016-08-22 17\" & timestamp < \"2016-09-22 20\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1264 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1269 & meter == 1 & meter_reading >= 2000)')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1272 & meter == 1 & timestamp > \"2016-08-11 12\" & timestamp < \"2016-08-30 19\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1273 & meter == 1 & timestamp > \"2016-05-31 14\" & timestamp < \"2016-06-17\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1276 & meter == 1 & timestamp < \"2016-02-03 23\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1280 & meter == 1 & timestamp > \"2016-05-18\" & timestamp < \"2016-05-26 09\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1280 & meter == 1 & timestamp > \"2016-02-28 23\" & timestamp < \"2016-05-02 05\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1280 & meter == 1 & timestamp > \"2016-06-12 01\" & timestamp < \"2016-7-07 06\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1288 & meter == 1 & timestamp > \"2016-07-07 15\" & timestamp < \"2016-08-12 17\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1311 & meter == 1 & timestamp > \"2016-04-25 18\" & timestamp < \"2016-05-13 14\")')\n",
        "train_df = train_df.query('not (building_id == 1099 & meter == 2)')\n",
        "\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1329 & meter == 0 & timestamp > \"2016-04-28 00\" & timestamp < \"2016-04-28 07\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1331 & meter == 0 & timestamp > \"2016-04-28 00\" & timestamp < \"2016-04-28 07\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1427 & meter == 0 & timestamp > \"2016-04-11 10\" & timestamp < \"2016-04-11 14\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1426 & meter == 2 & timestamp > \"2016-05-03 09\" & timestamp < \"2016-05-03 14\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1345 & meter == 0 & timestamp < \"2016-03-01\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1346 & timestamp < \"2016-03-01\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1359 & meter == 0 & timestamp > \"2016-04-25 17\" & timestamp < \"2016-07-22 14\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1365 & meter == 0 & timestamp > \"2016-08-19 00\" & timestamp < \"2016-08-19 07\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1365 & meter == 0 & timestamp > \"2016-06-18 22\" & timestamp < \"2016-06-19 06\")')\n",
        "\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 18 & meter == 0 & timestamp > \"2016-06-04 09\" & timestamp < \"2016-06-04 16\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 18 & meter == 0 & timestamp > \"2016-11-05 05\" & timestamp < \"2016-11-05 15\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 101 & meter == 0 & meter_reading > 800)')\n",
        "\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1384 & meter == 0 & meter_reading == 0 )')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1289 & building_id <= 1301 & meter == 2 & meter_reading == 0)')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1243 & meter == 2 & meter_reading == 0)')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1263 & meter == 2 & meter_reading == 0)')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1284 & meter == 2 & meter_reading == 0)')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1286 & meter == 2 & meter_reading == 0)')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1263 & meter == 0 & timestamp > \"2016-11-10 11\" & timestamp < \"2016-11-10 15\")')\n",
        "\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1238 & meter == 2 & meter_reading == 0)')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1329 & meter == 2 & timestamp > \"2016-11-21 12\" & timestamp < \"2016-11-29 12\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1249 & meter == 2 & meter_reading == 0)')\n",
        "\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1250 & meter == 2 & meter_reading == 0)')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1256 & meter == 2 & timestamp > \"2016-03-05 18\" & timestamp < \"2016-03-05 22\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1256 & meter == 2 & timestamp > \"2016-03-27 00\" & timestamp < \"2016-03-27 23\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1256 & meter == 2 & timestamp > \"2016-04-11 09\" & timestamp < \"2016-04-13 03\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1256 & meter == 2 & timestamp > \"2016-04-29 00\" & timestamp < \"2016-04-30 15\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1303 & meter == 2 & timestamp < \"2016-06-06 19\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1223 & building_id <= 1324 & meter == 1 & timestamp > \"2016-08-11 17\" & timestamp < \"2016-08-12 17\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1223 & building_id <= 1324 & building_id != 1296 & building_id != 129 & building_id != 1298 & building_id != 1299 & meter == 2 & timestamp > \"2016-08-11 17\" & timestamp < \"2016-08-12 17\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1223 & building_id <= 1324 & meter == 3 & timestamp > \"2016-08-11 17\" & timestamp < \"2016-08-12 17\")')\n",
        "\n",
        "train_df = train_df.reset_index()\n",
        "\n",
        "print('after', len(train_df))\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Site-0 Correction¶\n",
        "# https://www.kaggle.com/c/ashrae-energy-prediction/discussion/119261#latest-684102\n",
        "site_0_bids = building_meta_df[building_meta_df.site_id ==\n",
        "                               0].building_id.unique()\n",
        "print(len(site_0_bids), len(\n",
        "    train_df[train_df.building_id.isin(site_0_bids)].building_id.unique()))\n",
        "train_df[train_df.building_id.isin(\n",
        "    site_0_bids) & (train_df.meter == 0)].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df.loc[(train_df.building_id.isin(site_0_bids)) & (train_df.meter == 0), 'meter_reading'] = train_df[(\n",
        "    train_df.building_id.isin(site_0_bids)) & (train_df.meter == 0)]['meter_reading'] * 0.2931"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df[(train_df.building_id.isin(site_0_bids))\n",
        "         & (train_df.meter == 0)].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df['date'] = train_df['timestamp'].dt.date\n",
        "train_df['meter_reading_log1p'] = np.log1p(train_df['meter_reading'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess(df):\n",
        "    df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
        "    df[\"day\"] = df[\"timestamp\"].dt.day\n",
        "    df[\"weekend\"] = df[\"timestamp\"].dt.weekday\n",
        "    df[\"month\"] = df[\"timestamp\"].dt.month\n",
        "    df[\"dayofweek\"] = df[\"timestamp\"].dt.dayofweek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "preprocess(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "weather_train_df = weather_train_df.groupby('site_id').apply(\n",
        "    lambda group: group.interpolate(method='ffill', limit_direction='forward'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Adding some lag feature\n",
        "\n",
        "def add_lag_feature(weather_df, window=3):\n",
        "    group_df = weather_df.groupby('site_id')\n",
        "    cols = ['air_temperature', 'cloud_coverage', 'dew_temperature',\n",
        "            'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction', 'wind_speed']\n",
        "    rolled = group_df[cols].rolling(window=window, min_periods=0)\n",
        "    lag_mean = rolled.mean().reset_index().astype(np.float16)\n",
        "    lag_max = rolled.max().reset_index().astype(np.float16)\n",
        "    lag_min = rolled.min().reset_index().astype(np.float16)\n",
        "    lag_std = rolled.std().reset_index().astype(np.float16)\n",
        "    for col in cols:\n",
        "        weather_df[f'{col}_mean_lag{window}'] = lag_mean[col]\n",
        "        weather_df[f'{col}_max_lag{window}'] = lag_max[col]\n",
        "        weather_df[f'{col}_min_lag{window}'] = lag_min[col]\n",
        "        weather_df[f'{col}_std_lag{window}'] = lag_std[col]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "add_lag_feature(weather_train_df, window=3)\n",
        "add_lag_feature(weather_train_df, window=72)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "year_map = building_meta_df.year_built.value_counts()\n",
        "building_meta_df['year_cnt'] = building_meta_df.year_built.map(year_map)\n",
        "\n",
        "bid_map = train_df.building_id.value_counts()\n",
        "train_df['bid_cnt'] = train_df.building_id.map(bid_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "primary_use_list = building_meta_df['primary_use'].unique()\n",
        "primary_use_dict = {key: value for value, key in enumerate(primary_use_list)}\n",
        "print('primary_use_dict: ', primary_use_dict)\n",
        "building_meta_df['primary_use'] = building_meta_df['primary_use'].map(\n",
        "    primary_use_dict)\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = reduce_mem_usage(train_df, use_float16=True)\n",
        "building_meta_df = reduce_mem_usage(building_meta_df, use_float16=True)\n",
        "weather_train_df = reduce_mem_usage(weather_train_df, use_float16=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SG Filter for Weather\n",
        "\n",
        "def add_sg(df):\n",
        "    w = 11\n",
        "    p = 2\n",
        "    for si in df.site_id.unique():\n",
        "        index = df.site_id == si\n",
        "        df.loc[index, 'air_smooth'] = sg(df[index].air_temperature, w, p)\n",
        "        df.loc[index, 'dew_smooth'] = sg(df[index].dew_temperature, w, p)\n",
        "\n",
        "        df.loc[index, 'air_diff'] = sg(df[index].air_temperature, w, p, 1)\n",
        "        df.loc[index, 'dew_diff'] = sg(df[index].dew_temperature, w, p, 1)\n",
        "\n",
        "        df.loc[index, 'air_diff2'] = sg(df[index].air_temperature, w, p, 2)\n",
        "        df.loc[index, 'dew_diff2'] = sg(df[index].dew_temperature, w, p, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "add_sg(weather_train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Selection\n",
        "\n",
        "category_cols = ['building_id', 'site_id', 'primary_use',\n",
        "                 'IsHoliday', 'groupNum_train']  # , 'meter'\n",
        "feature_cols = ['square_feet_np_log1p', 'year_built'] + [\n",
        "    'hour', 'weekend',\n",
        "    #    'day', # 'month' ,\n",
        "    #    'dayofweek',\n",
        "    #    'building_median'\n",
        "    #    'square_feet'\n",
        "] + [\n",
        "    'air_temperature', 'cloud_coverage',\n",
        "    'dew_temperature', 'precip_depth_1_hr',\n",
        "    'sea_level_pressure',\n",
        "    #'wind_direction', 'wind_speed',\n",
        "    'air_temperature_mean_lag72',\n",
        "    'air_temperature_max_lag72', 'air_temperature_min_lag72',\n",
        "    'air_temperature_std_lag72', 'cloud_coverage_mean_lag72',\n",
        "    'dew_temperature_mean_lag72', 'precip_depth_1_hr_mean_lag72',\n",
        "    'sea_level_pressure_mean_lag72',\n",
        "    # 'wind_direction_mean_lag72',\n",
        "    'wind_speed_mean_lag72',\n",
        "    'air_temperature_mean_lag3',\n",
        "    'air_temperature_max_lag3',\n",
        "    'air_temperature_min_lag3', 'cloud_coverage_mean_lag3',\n",
        "    'dew_temperature_mean_lag3',\n",
        "    'precip_depth_1_hr_mean_lag3',\n",
        "    'sea_level_pressure_mean_lag3',\n",
        "    #    'wind_direction_mean_lag3', 'wind_speed_mean_lag3',\n",
        "    #    'floor_area',\n",
        "    'year_cnt', 'bid_cnt',\n",
        "    'dew_smooth', 'air_smooth',\n",
        "    'dew_diff', 'air_diff',\n",
        "    'dew_diff2', 'air_diff2'\n",
        " ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = train_df.merge(building_meta_df, on=[\n",
        "                          'building_id', 'meter'], how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = reduce_mem_usage(train_df, use_float16=True)\n",
        "weather_train_df = reduce_mem_usage(weather_train_df, use_float16=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = train_df.merge(weather_train_df, on=[\n",
        "                          'site_id', 'timestamp'], how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df['square_feet_np_log1p'] = np.log1p(train_df['square_feet'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = reduce_mem_usage(train_df, use_float16=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "del weather_train_df\n",
        "gc.collect() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "iyt_1Xg7cg1X",
        "outputId": "daf36014-f11c-4cda-f7ca-d6040a35353c"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "--------------------------------------------------------------------------------\n",
        "IMPLEMENTATION\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVLutpqjcuoo"
      },
      "outputs": [],
      "source": [
        "# Get X_train and y_train\n",
        "def create_X_y(train_df, groupNum_train):\n",
        "\n",
        "    target_train_df = train_df[train_df['groupNum_train']\n",
        "                               == groupNum_train].copy()\n",
        "    \n",
        "    X_train = target_train_df[feature_cols + category_cols]\n",
        "    y_train = target_train_df['meter_reading_log1p'].values\n",
        "\n",
        "    del target_train_df\n",
        "    return X_train, y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBX5P0Phedaw"
      },
      "outputs": [],
      "source": [
        "# # Define RMSLE specifically for neural network\n",
        "def NN_RMSLE(y_act, y_pred):\n",
        "  return k.sqrt(k.mean(k.square(y_pred - y_act)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vV-tpC9pfegY"
      },
      "outputs": [],
      "source": [
        "# Split into train and validation sets\n",
        "# train_xx, val_xx, train_yy, val_yy = train_test_split(train_x, train_y, test_size = 0.2, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Method to train LSTM model\n",
        "def RNN_LSTM(train, val ):\n",
        "       X_train, y_train = train\n",
        "       X_valid, y_valid = val\n",
        "       metric= 'val_loss'\n",
        "       model = Sequential()\n",
        "       early_stop = EarlyStopping(monitor = metric, mode = 'min', patience = 3)\n",
        "       model_checkpoint = ModelCheckpoint(\"model_\" + str(groupNum_train) + \"[]\",\n",
        "                                          save_best_only=True, verbose=1, monitor=metric, mode='min')\n",
        "\n",
        "       # Add LSTM Layers, etc\n",
        "       # Add layers, etc\n",
        "       model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
        "       model.add(Dropout(0.2))\n",
        "       model.add(Dense(units=32, activation='relu'))\n",
        "       model.add(Dropout(0.2))\n",
        "       model.add(Dense(units=16, activation='relu'))\n",
        "       model.add(Dropout(0.2))\n",
        "       model.add(Dense(units=1, activation='linear'))\n",
        "\n",
        "       model.compile(loss='mse', optimizer='adam', metrics=[NN_RMSLE])\n",
        "       model.summary()\n",
        "       \n",
        "       \n",
        "\n",
        "       # Fit model\n",
        "       model.fit(X_train, y_train, epochs=100, batch_size=64,\n",
        "             validation_data=(X_valid, y_valid),\n",
        "             callbacks=[early_stop, model_checkpoint], verbose=1)\n",
        "       model.summary()\n",
        "\n",
        "       y_pred_valid = model.predict(X_valid)\n",
        "\n",
        "       print('---------- Evaluation on Training Data ----------')\n",
        "       print(\"MSE: \", mean_squared_error(y_valid, y_pred_valid))\n",
        "       print(\"\")\n",
        "       \n",
        "       return model, y_pred_valid\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
        "seed = 666\n",
        "shuffle = False\n",
        "kf = StratifiedKFold(n_splits=folds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for groupNum_train in building_meta_df['groupNum_train'].unique():\n",
        "    X_train, y_train = create_X_y(train_df, groupNum_train=groupNum_train)\n",
        "    y_valid_pred_total = np.zeros(X_train.shape[0])\n",
        "    gc.collect()\n",
        "    print('groupNum_train', groupNum_train, X_train.shape)\n",
        "\n",
        "    cat_features = [X_train.columns.get_loc(\n",
        "        cat_col) for cat_col in category_cols]\n",
        "    print('cat_features', cat_features)\n",
        "\n",
        "    exec('models' + str(groupNum_train) + '=[]')\n",
        "\n",
        "    train_df_site = train_df[train_df['groupNum_train']\n",
        "                             == groupNum_train].copy()\n",
        "\n",
        "    \n",
        "    for train_idx, valid_idx in kf.split(train_df_site, train_df_site['building_id']):\n",
        "        train_data = X_train.iloc[train_idx, :], y_train[train_idx]\n",
        "        valid_data = X_train.iloc[valid_idx, :], y_train[valid_idx]\n",
        "\n",
        "        mindex = train_df_site.iloc[valid_idx, :].month.unique()\n",
        "        print(mindex)\n",
        "\n",
        "        print('train', len(train_idx), 'valid', len(valid_idx))\n",
        "    \n",
        "        model, y_pred_valid= RNN_LSTM(train_data, valid_data) # How to pass and train the categorical data\n",
        "        \n",
        "        \n",
        "        y_valid_pred_total[valid_idx] = y_pred_valid.reshape(-1)\n",
        "        exec('models' + str(groupNum_train) + '.append([mindex, model])')\n",
        "        gc.collect()\n",
        "        if debug:\n",
        "            break\n",
        "\n",
        "    try:\n",
        "        sns.distplot(y_train)\n",
        "        sns.distplot(y_valid_pred_total)\n",
        "        plt.show()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    del X_train, y_train\n",
        "    gc.collect()\n",
        "\n",
        "    print('-------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prediction on test data¶\n",
        "\n",
        "print('loading...')\n",
        "test_df = pd.read_feather(root/'test.feather')\n",
        "weather_test_df = pd.read_feather(root/'weather_test.feather')\n",
        "\n",
        "print('Before Preprocessing ....')\n",
        "print('Shape of test data: ', test_df.shape)\n",
        "print('Shape of Weather test data: ', weather_test_df.shape)\n",
        "\n",
        "weather_test_df = weather_test_df.drop_duplicates(['timestamp', 'site_id'])\n",
        "set_local(weather_test_df)\n",
        "add_holiyday(weather_test_df)\n",
        "\n",
        "print('preprocessing building...')\n",
        "test_df['date'] = test_df['timestamp'].dt.date\n",
        "preprocess(test_df)\n",
        "\n",
        "\n",
        "print('preprocessing weather...')\n",
        "weather_test_df = weather_test_df.groupby('site_id').apply(\n",
        "    lambda group: group.interpolate(method='ffill', limit_direction='forward'))\n",
        "weather_test_df.groupby('site_id').apply(lambda group: group.isna().sum())\n",
        "\n",
        "add_sg(weather_test_df)\n",
        "\n",
        "add_lag_feature(weather_test_df, window=3)\n",
        "add_lag_feature(weather_test_df, window=72)\n",
        "\n",
        "test_df['bid_cnt'] = test_df.building_id.map(bid_map)\n",
        "\n",
        "test_df = test_df.merge(building_meta_df[['building_id', 'meter', 'groupNum_train','square_feet']], on=[\n",
        "                        'building_id', 'meter'], how='left')\n",
        "\n",
        "test_df['square_feet_np_log1p'] = np.log1p(test_df['square_feet'])\n",
        "\n",
        "print('reduce mem usage...')\n",
        "test_df = reduce_mem_usage(test_df, use_float16=True)\n",
        "weather_test_df = reduce_mem_usage(weather_test_df, use_float16=True)\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %% [code]\n",
        "sample_submission = pd.read_feather(\n",
        "    os.path.join(root, 'sample_submission.feather'))\n",
        "reduce_mem_usage(sample_submission)\n",
        "\n",
        "print(sample_submission.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_X(test_df, groupNum_train):\n",
        "\n",
        "    target_test_df = test_df[test_df['groupNum_train']\n",
        "                             == groupNum_train].copy()\n",
        "    # target_test_df = target_test_df.merge(df_groupNum_median, on=['timestamp'], how='left')\n",
        "    target_test_df = target_test_df.merge(\n",
        "        building_meta_df, on=['building_id', 'meter', 'groupNum_train'], how='left')\n",
        "    target_test_df = target_test_df.merge(\n",
        "        weather_test_df, on=['site_id', 'timestamp'], how='left')\n",
        "    #target_test_df['group_median_'+str(groupNum_train)] = np.nan\n",
        "\n",
        "    X_test = target_test_df[feature_cols + category_cols]\n",
        "\n",
        "    return X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def pred_all(X_test, models, batch_size=10000):\n",
        "    iterations = (X_test.shape[1] + batch_size - 1) // batch_size\n",
        "    print('iterations', iterations)\n",
        "\n",
        "    y_test_pred_total = np.zeros(X_test.shape[0])\n",
        "    for i, (mindex, model) in enumerate(models):\n",
        "        print(f'predicting {i}-th model')\n",
        "        for k in tqdm(range(iterations)):\n",
        "            y_pred_test = model.predict(\n",
        "                X_test[k*batch_size:(k+1)*batch_size]) #num_iteration=model.best_iteration\n",
        "            y_test_pred_total[k*batch_size:(k+1)*batch_size] += y_pred_test.reshape(-1)\n",
        "\n",
        "    y_test_pred_total /= len(models)\n",
        "    return y_test_pred_total\n",
        "\n",
        "\n",
        "def pred(X_test, models, batch_size=10000):\n",
        "        print('all pred')\n",
        "        return pred_all(X_test, models, batch_size=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for groupNum_train in building_meta_df['groupNum_train'].unique():\n",
        "    print('groupNum_train: ', groupNum_train)\n",
        "    X_test = create_X(test_df, groupNum_train=groupNum_train)\n",
        "    gc.collect()\n",
        "\n",
        "    exec('y_test= pred(X_test, models' + str(groupNum_train) + ')')\n",
        "\n",
        "    sns.distplot(y_test)\n",
        "    plt.show()\n",
        "\n",
        "    print(X_test.shape, y_test.shape)\n",
        "    sample_submission.loc[test_df[\"groupNum_train\"] ==\n",
        "                          groupNum_train, \"meter_reading\"] = np.expm1(y_test)\n",
        "\n",
        "    del X_test, y_test\n",
        "    gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Site-0 Correction "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://www.kaggle.com/c/ashrae-energy-prediction/discussion/119261#latest-684102\n",
        "sample_submission.loc[(test_df.building_id.isin(site_0_bids)) & (test_df.meter == 0), 'meter_reading'] = sample_submission[(\n",
        "    test_df.building_id.isin(site_0_bids)) & (test_df.meter == 0)]['meter_reading'] * 3.4118"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.log1p(sample_submission['meter_reading']).hist(bins=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not debug:\n",
        "    sample_submission.to_csv(\n",
        "        'submission_LSTM_RNN_firstRun.csv', index=False, float_format='%.4f')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not debug:\n",
        "\n",
        "  ! mkdir -p ~/.kaggle/ && \\\n",
        "    echo '{\"username\":\"joydipbhowmick\",\"key\":\"5bd4e6a1fec9fc7f8a93def26785a6d2\"}' > ~/.kaggle/kaggle.json && \\\n",
        "    chmod 600 ~/.kaggle/kaggle.json # Create a new direcory use the kaggle token key in that and make it read only to current user.\n",
        "  ! kaggle competitions submit -c ashrae-energy-prediction -f submission_RNN_Dense_layer.csv -m \"LSTM RNN Model No Blend First test run - still in debug mode\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ML_Final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
