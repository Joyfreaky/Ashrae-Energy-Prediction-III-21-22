{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tT3oRvEFUtYK"
      },
      "outputs": [],
      "source": [
        "# Energy prediction 3 (ASHRAE)\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from scipy.signal import savgol_filter as sg\n",
        "import holidays\n",
        "from pandas.api.types import is_categorical_dtype\n",
        "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import numpy as np  # linear algebra\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import os\n",
        "import gc\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "black_day = 10\n",
        "\n",
        "debug = False\n",
        "num_rounds = 200\n",
        "\n",
        "folds = 3  # 3, 6, 12\n",
        "\n",
        "ucf_year = [2017, 2018]  # ucf data year used in train\n",
        "\n",
        "predmode = 'all'  \n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras import backend as k\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras.layers as layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, Activation\n",
        "from keras.optimizers import *\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Original code from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage by @gemartin\n",
        "# Modified to support timestamp type, categorical type\n",
        "# Modified to add option to use float16 or not. feather format does not support float16.\n",
        "\n",
        "\n",
        "def reduce_mem_usage(df, use_float16=False):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "\n",
        "    for col in df.columns:\n",
        "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
        "            # skip datetime type or categorical type\n",
        "            continue\n",
        "        col_type = df[col].dtype\n",
        "\n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "            else:\n",
        "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(\n",
        "        100 * (start_mem - end_mem) / start_mem))\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "zone_dict = {0: 4, 1: 0, 2: 7, 3: 4, 4: 7, 5: 0, 6: 4, 7: 4,\n",
        "             8: 4, 9: 5, 10: 7, 11: 4, 12: 0, 13: 5, 14: 4, 15: 4}\n",
        "\n",
        "\n",
        "def set_local(df):\n",
        "    for sid, zone in zone_dict.items():\n",
        "        sids = df.site_id == sid\n",
        "        df.loc[sids, 'timestamp'] = df[sids].timestamp - pd.offsets.Hour(zone)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>site_id</th>\n",
              "      <th>building_id</th>\n",
              "      <th>primary_use</th>\n",
              "      <th>square_feet</th>\n",
              "      <th>year_built</th>\n",
              "      <th>floor_count</th>\n",
              "      <th>meter</th>\n",
              "      <th>groupNum_train</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Education</td>\n",
              "      <td>7432</td>\n",
              "      <td>2008.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Education</td>\n",
              "      <td>2720</td>\n",
              "      <td>2004.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Education</td>\n",
              "      <td>5376</td>\n",
              "      <td>1991.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Education</td>\n",
              "      <td>23685</td>\n",
              "      <td>2002.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Education</td>\n",
              "      <td>116607</td>\n",
              "      <td>1975.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2375</th>\n",
              "      <td>15</td>\n",
              "      <td>1444</td>\n",
              "      <td>Entertainment/public assembly</td>\n",
              "      <td>19619</td>\n",
              "      <td>1914.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2376</th>\n",
              "      <td>15</td>\n",
              "      <td>1445</td>\n",
              "      <td>Education</td>\n",
              "      <td>4298</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2377</th>\n",
              "      <td>15</td>\n",
              "      <td>1446</td>\n",
              "      <td>Entertainment/public assembly</td>\n",
              "      <td>11265</td>\n",
              "      <td>1997.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2378</th>\n",
              "      <td>15</td>\n",
              "      <td>1447</td>\n",
              "      <td>Lodging/residential</td>\n",
              "      <td>29775</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2379</th>\n",
              "      <td>15</td>\n",
              "      <td>1448</td>\n",
              "      <td>Office</td>\n",
              "      <td>92271</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2380 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      site_id  building_id                    primary_use  square_feet  \\\n",
              "0           0            0                      Education         7432   \n",
              "1           0            1                      Education         2720   \n",
              "2           0            2                      Education         5376   \n",
              "3           0            3                      Education        23685   \n",
              "4           0            4                      Education       116607   \n",
              "...       ...          ...                            ...          ...   \n",
              "2375       15         1444  Entertainment/public assembly        19619   \n",
              "2376       15         1445                      Education         4298   \n",
              "2377       15         1446  Entertainment/public assembly        11265   \n",
              "2378       15         1447            Lodging/residential        29775   \n",
              "2379       15         1448                         Office        92271   \n",
              "\n",
              "      year_built  floor_count  meter  groupNum_train  \n",
              "0         2008.0          NaN      0               0  \n",
              "1         2004.0          NaN      0               0  \n",
              "2         1991.0          NaN      0               0  \n",
              "3         2002.0          NaN      0               0  \n",
              "4         1975.0          NaN      0               0  \n",
              "...          ...          ...    ...             ...  \n",
              "2375      1914.0          NaN      0             150  \n",
              "2376         NaN          NaN      0             150  \n",
              "2377      1997.0          NaN      0             150  \n",
              "2378      2001.0          NaN      0             150  \n",
              "2379      2001.0          NaN      0             150  \n",
              "\n",
              "[2380 rows x 8 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "root = Path('/home/joydipb/Documents/CMT307-Coursework-2-Group-19') # Change the path to the source file path, use Memory_Management.py to generate files in feather format \n",
        "train_df = pd.read_feather(root/'train.feather')\n",
        "weather_train_df = pd.read_feather(root/'weather_train.feather')\n",
        "building_meta_df = pd.read_feather(root/'building_metadata.feather')\n",
        "\n",
        "building_meta_df = building_meta_df.merge(\n",
        "    train_df[['building_id', 'meter']].drop_duplicates(), on='building_id')\n",
        "\n",
        "# Set group  (site-meter) for training models\n",
        "\n",
        "building_meta_df['groupNum_train'] = building_meta_df['site_id'].astype(\n",
        "    'int')*10 + building_meta_df['meter'].astype('int')\n",
        "\n",
        "building_meta_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "building_meta_df['floor_area'] = building_meta_df.square_feet / \\\n",
        "    building_meta_df.floor_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Site Specific Holiday\n",
        "\n",
        "\n",
        "en_holidays = holidays.England()\n",
        "ir_holidays = holidays.Ireland()\n",
        "ca_holidays = holidays.Canada()\n",
        "us_holidays = holidays.UnitedStates()\n",
        "\n",
        "\n",
        "def add_holiyday(df_weather):\n",
        "    en_idx = df_weather.query('site_id == 1 or site_id == 5').index\n",
        "    ir_idx = df_weather.query('site_id == 12').index\n",
        "    ca_idx = df_weather.query('site_id == 7 or site_id == 11').index\n",
        "    us_idx = df_weather.query(\n",
        "        'site_id == 0 or site_id == 2 or site_id == 3 or site_id == 4 or site_id == 6 or site_id == 8 or site_id == 9 or site_id == 10 or site_id == 13 or site_id == 14 or site_id == 15').index\n",
        "\n",
        "    df_weather['IsHoliday'] = 0\n",
        "    df_weather.loc[en_idx, 'IsHoliday'] = df_weather.loc[en_idx,\n",
        "                                                         'timestamp'].apply(lambda x: en_holidays.get(x, default=0))\n",
        "    df_weather.loc[ir_idx, 'IsHoliday'] = df_weather.loc[ir_idx,\n",
        "                                                         'timestamp'].apply(lambda x: ir_holidays.get(x, default=0))\n",
        "    df_weather.loc[ca_idx, 'IsHoliday'] = df_weather.loc[ca_idx,\n",
        "                                                         'timestamp'].apply(lambda x: ca_holidays.get(x, default=0))\n",
        "    df_weather.loc[us_idx, 'IsHoliday'] = df_weather.loc[us_idx,\n",
        "                                                         'timestamp'].apply(lambda x: us_holidays.get(x, default=0))\n",
        "\n",
        "    holiday_idx = df_weather['IsHoliday'] != 0\n",
        "    df_weather.loc[holiday_idx, 'IsHoliday'] = 1\n",
        "    df_weather['IsHoliday'] = df_weather['IsHoliday'].astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "set_local(weather_train_df)\n",
        "add_holiyday(weather_train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = train_df.query('not (building_id == 954 & meter_reading == 0)')\n",
        "train_df = train_df.query('not (building_id == 1221 & meter_reading == 0)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "after 19456584\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "261"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Removing buildings with meter == 0 before first initial reading.\n",
        "train_df = train_df.query(\n",
        "    'not (building_id <= 104 & meter == 0 & timestamp <= \"2016-05-20 18\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 681 & meter == 0 & timestamp <= \"2016-04-27\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 761 & meter == 0 & timestamp <= \"2016-09-02\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 799 & meter == 0 & timestamp <= \"2016-09-02\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 802 & meter == 0 & timestamp <= \"2016-08-24\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1073 & meter == 0 & timestamp <= \"2016-10-26\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1094 & meter == 0 & timestamp <= \"2016-09-08\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 29 & meter == 0 & timestamp <= \"2016-08-10\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 40 & meter == 0 & timestamp <= \"2016-06-04\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 45 & meter == 0 & timestamp <= \"2016-07\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 106 & meter == 0 & timestamp <= \"2016-11\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 107 & meter == 0 & timestamp >= \"2016-11-10\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 112 & meter == 0 & timestamp < \"2016-10-31 15\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 144 & meter == 0 & timestamp > \"2016-05-14\" & timestamp < \"2016-10-31\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 147 & meter == 0 & timestamp > \"2016-06-05 19\" & timestamp < \"2016-07-18 15\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 171 & meter == 0 & timestamp <= \"2016-07-05\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 177 & meter == 0 & timestamp > \"2016-06-04\" & timestamp < \"2016-06-25\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 258 & meter == 0 & timestamp > \"2016-09-26\" & timestamp < \"2016-12-12\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 258 & meter == 0 & timestamp > \"2016-08-30\" & timestamp < \"2016-09-08\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 258 & meter == 0 & timestamp > \"2016-09-18\" & timestamp < \"2016-09-25\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 260 & meter == 0 & timestamp <= \"2016-05-11\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 269 & meter == 0 & timestamp > \"2016-06-04\" & timestamp < \"2016-06-25\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 304 & meter == 0 & timestamp >= \"2016-11-20\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 545 & meter == 0 & timestamp > \"2016-01-17\" & timestamp < \"2016-02-10\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 604 & meter == 0 & timestamp < \"2016-11-21\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 693 & meter == 0 & timestamp > \"2016-09-07\" & timestamp < \"2016-11-23\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 693 & meter == 0 & timestamp > \"2016-07-12\" & timestamp < \"2016-05-29\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 723 & meter == 0 & timestamp > \"2016-10-06\" & timestamp < \"2016-11-22\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 733 & meter == 0 & timestamp > \"2016-05-29\" & timestamp < \"2016-06-22\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 733 & meter == 0 & timestamp > \"2016-05-19\" & timestamp < \"2016-05-20\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 803 & meter == 0 & timestamp > \"2016-9-25\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 815 & meter == 0 & timestamp > \"2016-05-17\" & timestamp < \"2016-11-17\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 848 & meter == 0 & timestamp > \"2016-01-15\" & timestamp < \"2016-03-20\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 857 & meter == 0 & timestamp > \"2016-04-13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 909 & meter == 0 & timestamp < \"2016-02-02\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 909 & meter == 0 & timestamp < \"2016-06-23\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1008 & meter == 0 & timestamp > \"2016-10-30\" & timestamp < \"2016-11-21\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1113 & meter == 0 & timestamp < \"2016-07-27\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1153 & meter == 0 & timestamp < \"2016-01-20\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1169 & meter == 0 & timestamp < \"2016-08-03\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1170 & meter == 0 & timestamp > \"2016-06-30\" & timestamp < \"2016-07-05\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1221 & meter == 0 & timestamp < \"2016-11-04\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1225 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1234 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1233 & building_id <= 1234 & meter == 0 & timestamp > \"2016-01-13 22\" & timestamp < \"2016-03-08 12\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1241 & meter == 0 & timestamp > \"2016-07-14\" & timestamp < \"2016-11-19\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1250 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1255 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1264 & meter == 0 & timestamp > \"2016-08-23\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1265 & meter == 0 & timestamp > \"2016-05-06\" & timestamp < \"2016-05-26\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1272 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1275 & building_id <= 1280 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1283 & meter == 0 & timestamp > \"2016-07-08\" & timestamp < \"2016-08-03\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1291 & building_id <= 1302 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1303 & meter == 0 & timestamp > \"2016-07-25 22\" & timestamp < \"2016-07-27 16\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1303 & meter == 0 & timestamp > \"2016-01-26\" & timestamp < \"2016-06-02 12\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1319 & meter == 0 & timestamp > \"2016-05-17 16\" & timestamp < \"2016-06-07 12\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1319 & meter == 0 & timestamp > \"2016-08-18 14\" & timestamp < \"2016-09-02 14\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1322 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "\n",
        "# 2nd cleaning\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 0 & timestamp > \"2016-10-14 22\" & timestamp < \"2016-10-17 08\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 0 & timestamp > \"2016-07-01 14\" & timestamp < \"2016-07-05 06\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 1 & timestamp > \"2016-10-14 22\" & timestamp < \"2016-10-17 08\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 1 & timestamp > \"2016-07-01 14\" & timestamp < \"2016-07-05 06\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 2 & timestamp > \"2016-10-14 22\" & timestamp < \"2016-10-17 08\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 2 & timestamp > \"2016-07-01 14\" & timestamp < \"2016-07-05 06\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1272 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1291 & building_id <= 1297 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1300 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1302 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1291 & building_id <= 1299 & meter == 2 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1221 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1225 & building_id <= 1226 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1233 & building_id <= 1234 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1241 & meter == 0 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1223 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1226 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1233 & building_id <= 1234 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1225 & building_id <= 1226 & meter == 2 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1305 & meter == 2 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1307 & meter == 2 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1223 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1231 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1233 & building_id <= 1234 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1272 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1275 & building_id <= 1297 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1300 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1302 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1293 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-25 12\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1302 & meter == 3 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-25 12\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1223 & meter == 0 & timestamp > \"2016-9-28 07\" & timestamp < \"2016-10-11 18\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1225 & meter == 1 & timestamp > \"2016-8-22 23\" & timestamp < \"2016-10-11 14\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1230 & meter == 1 & timestamp > \"2016-8-22 08\" & timestamp < \"2016-10-05 18\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 904 & meter == 0 & timestamp < \"2016-02-17 08\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 986 & meter == 0 & timestamp < \"2016-02-17 08\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 954 & meter == 0 & timestamp < \"2016-08-08 11\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 954 & meter == 0 & timestamp < \"2016-06-23 08\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 745 & building_id <= 770 & meter == 1 & timestamp > \"2016-10-05 01\" & timestamp < \"2016-10-10 09\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 774 & building_id <= 787 & meter == 1 & timestamp > \"2016-10-05 01\" & timestamp < \"2016-10-10 09\")')\n",
        "\n",
        "# 3rd cleaning hourly spikes\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 0 & timestamp > \"2016-05-11 09\" & timestamp < \"2016-05-12 01\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 1 & timestamp > \"2016-05-11 09\" & timestamp < \"2016-05-12 01\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 2 & timestamp > \"2016-05-11 09\" & timestamp < \"2016-05-12 01\")')\n",
        "\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 0 & timestamp == \"2016-02-26 01\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 1 & timestamp == \"2016-02-26 01\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 2 & timestamp == \"2016-02-26 01\")')\n",
        "\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 0 & timestamp > \"2016-03-29 10\" & timestamp < \"2016-03-30 12\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 1 & timestamp > \"2016-03-29 10\" & timestamp < \"2016-03-30 12\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 2 & timestamp > \"2016-03-29 10\" & timestamp < \"2016-03-30 12\")')\n",
        "\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 0 & timestamp > \"2016-01-19 23\" & timestamp < \"2016-01-28 15\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 1 & timestamp > \"2016-01-19 23\" & timestamp < \"2016-01-28 15\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 874 & building_id <= 997 & meter == 2 & timestamp > \"2016-01-19 23\" & timestamp < \"2016-01-28 15\")')\n",
        "\n",
        "train_df = train_df.query(\n",
        "    'not (building_id != 1227 & building_id != 1281 & building_id != 1314 & building_id >=1223 & building_id < 1335 & meter==0 & meter_reading==0)')\n",
        "\n",
        "# 4th cleaning\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1223 & building_id <= 1324 & meter==1 & timestamp > \"2016-07-16 04\" & timestamp < \"2016-07-19 11\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 107 & meter == 0 & timestamp <= \"2016-07-06\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 180 & timestamp >= \"2016-02-17 12\")')\n",
        "train_df = train_df.query('not (building_id == 182 & meter == 0)')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 191 & meter == 0 & timestamp >= \"2016-12-22 09\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 192 & meter == 1 & timestamp >= \"2016-05-09 18\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 192 & meter == 3 & timestamp >= \"2016-03-29 05\" & timestamp <= \"2016-04-04 08\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 207 & meter == 1 & timestamp > \"2016-07-02 20\" & timestamp < \"2016-08-25 12\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 258 & timestamp > \"2016-09-18\" & timestamp < \"2016-12-12 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 258 & timestamp > \"2016-08-29 08\" & timestamp < \"2016-09-08 14\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 257 & meter == 1 & timestamp < \"2016-03-25 16\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 260 & meter == 1 & timestamp > \"2016-05-10 17\" & timestamp < \"2016-08-17 11\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 260 & meter == 1 & timestamp > \"2016-08-28 01\" & timestamp < \"2016-10-31 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 220 & meter == 1 & timestamp > \"2016-09-23 01\" & timestamp < \"2016-09-23 12\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 281 & meter == 1 & timestamp > \"2016-10-25 08\" & timestamp < \"2016-11-04 15\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 273 & meter == 1 & timestamp > \"2016-04-03 04\" & timestamp < \"2016-04-29 15\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 28 & meter == 0 & timestamp < \"2016-10-14 20\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 71 & meter == 0 & timestamp < \"2016-08-18 20\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 76 & meter == 0 & timestamp > \"2016-06-04 09\" & timestamp < \"2016-06-04 14\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 101 & meter == 0 & timestamp > \"2016-10-12 13\" & timestamp < \"2016-10-12 18\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 7 & meter == 1 & timestamp > \"2016-11-03 09\" & timestamp < \"2016-11-28 14\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 9 & meter == 1 & timestamp > \"2016-12-06 08\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 43 & meter == 1 & timestamp > \"2016-04-03 08\" & timestamp < \"2016-06-06 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 60 & meter == 1 & timestamp > \"2016-05-01 17\" & timestamp < \"2016-05-01 21\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 75 & meter == 1 & timestamp > \"2016-08-05 13\" & timestamp < \"2016-08-26 12\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 95 & meter == 1 & timestamp > \"2016-08-08 10\" & timestamp < \"2016-08-26 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 97 & meter == 1 & timestamp > \"2016-08-08 14\" & timestamp < \"2016-08-25 14\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1232 & meter == 1 & timestamp > \"2016-06-23 16\" & timestamp < \"2016-08-31 20\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1236 & meter == 1 & meter_reading >= 3000)')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1239 & meter == 1 & timestamp > \"2016-03-11 16\" & timestamp < \"2016-03-27 17\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1264 & meter == 1 & timestamp > \"2016-08-22 17\" & timestamp < \"2016-09-22 20\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1264 & meter == 1 & timestamp > \"2016-09-28 07\" & timestamp < \"2016-10-20 13\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1269 & meter == 1 & meter_reading >= 2000)')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1272 & meter == 1 & timestamp > \"2016-08-11 12\" & timestamp < \"2016-08-30 19\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1273 & meter == 1 & timestamp > \"2016-05-31 14\" & timestamp < \"2016-06-17\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1276 & meter == 1 & timestamp < \"2016-02-03 23\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1280 & meter == 1 & timestamp > \"2016-05-18\" & timestamp < \"2016-05-26 09\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1280 & meter == 1 & timestamp > \"2016-02-28 23\" & timestamp < \"2016-05-02 05\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1280 & meter == 1 & timestamp > \"2016-06-12 01\" & timestamp < \"2016-7-07 06\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1288 & meter == 1 & timestamp > \"2016-07-07 15\" & timestamp < \"2016-08-12 17\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1311 & meter == 1 & timestamp > \"2016-04-25 18\" & timestamp < \"2016-05-13 14\")')\n",
        "train_df = train_df.query('not (building_id == 1099 & meter == 2)')\n",
        "\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1329 & meter == 0 & timestamp > \"2016-04-28 00\" & timestamp < \"2016-04-28 07\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1331 & meter == 0 & timestamp > \"2016-04-28 00\" & timestamp < \"2016-04-28 07\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1427 & meter == 0 & timestamp > \"2016-04-11 10\" & timestamp < \"2016-04-11 14\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1426 & meter == 2 & timestamp > \"2016-05-03 09\" & timestamp < \"2016-05-03 14\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1345 & meter == 0 & timestamp < \"2016-03-01\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1346 & timestamp < \"2016-03-01\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1359 & meter == 0 & timestamp > \"2016-04-25 17\" & timestamp < \"2016-07-22 14\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1365 & meter == 0 & timestamp > \"2016-08-19 00\" & timestamp < \"2016-08-19 07\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1365 & meter == 0 & timestamp > \"2016-06-18 22\" & timestamp < \"2016-06-19 06\")')\n",
        "\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 18 & meter == 0 & timestamp > \"2016-06-04 09\" & timestamp < \"2016-06-04 16\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 18 & meter == 0 & timestamp > \"2016-11-05 05\" & timestamp < \"2016-11-05 15\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 101 & meter == 0 & meter_reading > 800)')\n",
        "\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1384 & meter == 0 & meter_reading == 0 )')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1289 & building_id <= 1301 & meter == 2 & meter_reading == 0)')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1243 & meter == 2 & meter_reading == 0)')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1263 & meter == 2 & meter_reading == 0)')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1284 & meter == 2 & meter_reading == 0)')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1286 & meter == 2 & meter_reading == 0)')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1263 & meter == 0 & timestamp > \"2016-11-10 11\" & timestamp < \"2016-11-10 15\")')\n",
        "\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1238 & meter == 2 & meter_reading == 0)')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1329 & meter == 2 & timestamp > \"2016-11-21 12\" & timestamp < \"2016-11-29 12\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1249 & meter == 2 & meter_reading == 0)')\n",
        "\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1250 & meter == 2 & meter_reading == 0)')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1256 & meter == 2 & timestamp > \"2016-03-05 18\" & timestamp < \"2016-03-05 22\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1256 & meter == 2 & timestamp > \"2016-03-27 00\" & timestamp < \"2016-03-27 23\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1256 & meter == 2 & timestamp > \"2016-04-11 09\" & timestamp < \"2016-04-13 03\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1256 & meter == 2 & timestamp > \"2016-04-29 00\" & timestamp < \"2016-04-30 15\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id == 1303 & meter == 2 & timestamp < \"2016-06-06 19\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1223 & building_id <= 1324 & meter == 1 & timestamp > \"2016-08-11 17\" & timestamp < \"2016-08-12 17\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1223 & building_id <= 1324 & building_id != 1296 & building_id != 129 & building_id != 1298 & building_id != 1299 & meter == 2 & timestamp > \"2016-08-11 17\" & timestamp < \"2016-08-12 17\")')\n",
        "train_df = train_df.query(\n",
        "    'not (building_id >= 1223 & building_id <= 1324 & meter == 3 & timestamp > \"2016-08-11 17\" & timestamp < \"2016-08-12 17\")')\n",
        "\n",
        "train_df = train_df.reset_index()\n",
        "\n",
        "print('after', len(train_df))\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "105 105\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>building_id</th>\n",
              "      <th>meter</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>meter_reading</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7054137</th>\n",
              "      <td>7579069</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05-20 19:00:00</td>\n",
              "      <td>277.802002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7054138</th>\n",
              "      <td>7579070</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05-20 19:00:00</td>\n",
              "      <td>125.863998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7054139</th>\n",
              "      <td>7579071</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05-20 19:00:00</td>\n",
              "      <td>32.762901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7054140</th>\n",
              "      <td>7579072</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05-20 19:00:00</td>\n",
              "      <td>336.843994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7054141</th>\n",
              "      <td>7579073</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05-20 19:00:00</td>\n",
              "      <td>1625.859985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7054142</th>\n",
              "      <td>7579074</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05-20 19:00:00</td>\n",
              "      <td>45.390301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7054143</th>\n",
              "      <td>7579075</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05-20 19:00:00</td>\n",
              "      <td>83.545403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7054144</th>\n",
              "      <td>7579076</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05-20 19:00:00</td>\n",
              "      <td>511.920013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7054146</th>\n",
              "      <td>7579078</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05-20 19:00:00</td>\n",
              "      <td>348.787994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7054147</th>\n",
              "      <td>7579079</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05-20 19:00:00</td>\n",
              "      <td>120.813004</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           index  building_id  meter           timestamp  meter_reading\n",
              "7054137  7579069            0      0 2016-05-20 19:00:00     277.802002\n",
              "7054138  7579070            1      0 2016-05-20 19:00:00     125.863998\n",
              "7054139  7579071            2      0 2016-05-20 19:00:00      32.762901\n",
              "7054140  7579072            3      0 2016-05-20 19:00:00     336.843994\n",
              "7054141  7579073            4      0 2016-05-20 19:00:00    1625.859985\n",
              "7054142  7579074            5      0 2016-05-20 19:00:00      45.390301\n",
              "7054143  7579075            6      0 2016-05-20 19:00:00      83.545403\n",
              "7054144  7579076            7      0 2016-05-20 19:00:00     511.920013\n",
              "7054146  7579078            8      0 2016-05-20 19:00:00     348.787994\n",
              "7054147  7579079            9      0 2016-05-20 19:00:00     120.813004"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Site-0 Correction¶\n",
        "# https://www.kaggle.com/c/ashrae-energy-prediction/discussion/119261#latest-684102\n",
        "site_0_bids = building_meta_df[building_meta_df.site_id ==\n",
        "                               0].building_id.unique()\n",
        "print(len(site_0_bids), len(\n",
        "    train_df[train_df.building_id.isin(site_0_bids)].building_id.unique()))\n",
        "train_df[train_df.building_id.isin(\n",
        "    site_0_bids) & (train_df.meter == 0)].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df.loc[(train_df.building_id.isin(site_0_bids)) & (train_df.meter == 0), 'meter_reading'] = train_df[(\n",
        "    train_df.building_id.isin(site_0_bids)) & (train_df.meter == 0)]['meter_reading'] * 0.2931"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>building_id</th>\n",
              "      <th>meter</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>meter_reading</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7054137</th>\n",
              "      <td>7579069</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05-20 19:00:00</td>\n",
              "      <td>81.423767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7054138</th>\n",
              "      <td>7579070</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05-20 19:00:00</td>\n",
              "      <td>36.890739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7054139</th>\n",
              "      <td>7579071</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05-20 19:00:00</td>\n",
              "      <td>9.602806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7054140</th>\n",
              "      <td>7579072</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05-20 19:00:00</td>\n",
              "      <td>98.728973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7054141</th>\n",
              "      <td>7579073</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05-20 19:00:00</td>\n",
              "      <td>476.539551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7054142</th>\n",
              "      <td>7579074</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05-20 19:00:00</td>\n",
              "      <td>13.303897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7054143</th>\n",
              "      <td>7579075</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05-20 19:00:00</td>\n",
              "      <td>24.487158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7054144</th>\n",
              "      <td>7579076</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05-20 19:00:00</td>\n",
              "      <td>150.043762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7054146</th>\n",
              "      <td>7579078</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05-20 19:00:00</td>\n",
              "      <td>102.229759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7054147</th>\n",
              "      <td>7579079</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05-20 19:00:00</td>\n",
              "      <td>35.410290</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           index  building_id  meter           timestamp  meter_reading\n",
              "7054137  7579069            0      0 2016-05-20 19:00:00      81.423767\n",
              "7054138  7579070            1      0 2016-05-20 19:00:00      36.890739\n",
              "7054139  7579071            2      0 2016-05-20 19:00:00       9.602806\n",
              "7054140  7579072            3      0 2016-05-20 19:00:00      98.728973\n",
              "7054141  7579073            4      0 2016-05-20 19:00:00     476.539551\n",
              "7054142  7579074            5      0 2016-05-20 19:00:00      13.303897\n",
              "7054143  7579075            6      0 2016-05-20 19:00:00      24.487158\n",
              "7054144  7579076            7      0 2016-05-20 19:00:00     150.043762\n",
              "7054146  7579078            8      0 2016-05-20 19:00:00     102.229759\n",
              "7054147  7579079            9      0 2016-05-20 19:00:00      35.410290"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df[(train_df.building_id.isin(site_0_bids))\n",
        "         & (train_df.meter == 0)].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df['date'] = train_df['timestamp'].dt.date\n",
        "train_df['meter_reading_log1p'] = np.log1p(train_df['meter_reading'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess(df):\n",
        "    df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
        "    df[\"day\"] = df[\"timestamp\"].dt.day\n",
        "    df[\"weekend\"] = df[\"timestamp\"].dt.weekday\n",
        "    df[\"month\"] = df[\"timestamp\"].dt.month\n",
        "    df[\"dayofweek\"] = df[\"timestamp\"].dt.dayofweek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "preprocess(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "weather_train_df = weather_train_df.groupby('site_id').apply(\n",
        "    lambda group: group.interpolate(method='ffill', limit_direction='forward'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Adding some lag feature\n",
        "\n",
        "def add_lag_feature(weather_df, window=3):\n",
        "    group_df = weather_df.groupby('site_id')\n",
        "    cols = ['air_temperature', 'cloud_coverage', 'dew_temperature',\n",
        "            'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction', 'wind_speed']\n",
        "    rolled = group_df[cols].rolling(window=window, min_periods=0)\n",
        "    lag_mean = rolled.mean().reset_index().astype(np.float16)\n",
        "    lag_max = rolled.max().reset_index().astype(np.float16)\n",
        "    lag_min = rolled.min().reset_index().astype(np.float16)\n",
        "    lag_std = rolled.std().reset_index().astype(np.float16)\n",
        "    for col in cols:\n",
        "        weather_df[f'{col}_mean_lag{window}'] = lag_mean[col]\n",
        "        weather_df[f'{col}_max_lag{window}'] = lag_max[col]\n",
        "        weather_df[f'{col}_min_lag{window}'] = lag_min[col]\n",
        "        weather_df[f'{col}_std_lag{window}'] = lag_std[col]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "add_lag_feature(weather_train_df, window=3)\n",
        "add_lag_feature(weather_train_df, window=72)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "year_map = building_meta_df.year_built.value_counts()\n",
        "building_meta_df['year_cnt'] = building_meta_df.year_built.map(year_map)\n",
        "\n",
        "bid_map = train_df.building_id.value_counts()\n",
        "train_df['bid_cnt'] = train_df.building_id.map(bid_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "primary_use_dict:  {'Education': 0, 'Lodging/residential': 1, 'Office': 2, 'Entertainment/public assembly': 3, 'Other': 4, 'Retail': 5, 'Parking': 6, 'Public services': 7, 'Warehouse/storage': 8, 'Food sales and service': 9, 'Religious worship': 10, 'Healthcare': 11, 'Utility': 12, 'Technology/science': 13, 'Manufacturing/industrial': 14, 'Services': 15}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "primary_use_list = building_meta_df['primary_use'].unique()\n",
        "primary_use_dict = {key: value for value, key in enumerate(primary_use_list)}\n",
        "print('primary_use_dict: ', primary_use_dict)\n",
        "building_meta_df['primary_use'] = building_meta_df['primary_use'].map(\n",
        "    primary_use_dict)\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 1540.09 MB\n",
            "Memory usage after optimization is: 593.78 MB\n",
            "Decreased by 61.4%\n",
            "Memory usage of dataframe is 0.11 MB\n",
            "Memory usage after optimization is: 0.07 MB\n",
            "Decreased by 40.6%\n",
            "Memory usage of dataframe is 21.06 MB\n",
            "Memory usage after optimization is: 19.33 MB\n",
            "Decreased by 8.2%\n"
          ]
        }
      ],
      "source": [
        "train_df = reduce_mem_usage(train_df, use_float16=True)\n",
        "building_meta_df = reduce_mem_usage(building_meta_df, use_float16=True)\n",
        "weather_train_df = reduce_mem_usage(weather_train_df, use_float16=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SG Filter for Weather\n",
        "\n",
        "def add_sg(df):\n",
        "    w = 11\n",
        "    p = 2\n",
        "    for si in df.site_id.unique():\n",
        "        index = df.site_id == si\n",
        "        df.loc[index, 'air_smooth'] = sg(df[index].air_temperature, w, p)\n",
        "        df.loc[index, 'dew_smooth'] = sg(df[index].dew_temperature, w, p)\n",
        "\n",
        "        df.loc[index, 'air_diff'] = sg(df[index].air_temperature, w, p, 1)\n",
        "        df.loc[index, 'dew_diff'] = sg(df[index].dew_temperature, w, p, 1)\n",
        "\n",
        "        df.loc[index, 'air_diff2'] = sg(df[index].air_temperature, w, p, 2)\n",
        "        df.loc[index, 'dew_diff2'] = sg(df[index].dew_temperature, w, p, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "add_sg(weather_train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Selection\n",
        "\n",
        "category_cols = ['building_id', 'site_id', 'primary_use',\n",
        "                 'IsHoliday', 'groupNum_train']  # , 'meter'\n",
        "feature_cols = ['square_feet_np_log1p', 'year_built'] + [\n",
        "    'hour', 'weekend',\n",
        "    #    'day', # 'month' ,\n",
        "    #    'dayofweek',\n",
        "    #    'building_median'\n",
        "    #    'square_feet'\n",
        "] + [\n",
        "    'air_temperature', 'cloud_coverage',\n",
        "    'dew_temperature', 'precip_depth_1_hr',\n",
        "    'sea_level_pressure',\n",
        "    #'wind_direction', 'wind_speed',\n",
        "    'air_temperature_mean_lag72',\n",
        "    'air_temperature_max_lag72', 'air_temperature_min_lag72',\n",
        "    'air_temperature_std_lag72', 'cloud_coverage_mean_lag72',\n",
        "    'dew_temperature_mean_lag72', 'precip_depth_1_hr_mean_lag72',\n",
        "    'sea_level_pressure_mean_lag72',\n",
        "    # 'wind_direction_mean_lag72',\n",
        "    'wind_speed_mean_lag72',\n",
        "    'air_temperature_mean_lag3',\n",
        "    'air_temperature_max_lag3',\n",
        "    'air_temperature_min_lag3', 'cloud_coverage_mean_lag3',\n",
        "    'dew_temperature_mean_lag3',\n",
        "    'precip_depth_1_hr_mean_lag3',\n",
        "    'sea_level_pressure_mean_lag3',\n",
        "    #    'wind_direction_mean_lag3', 'wind_speed_mean_lag3',\n",
        "    #    'floor_area',\n",
        "    'year_cnt', 'bid_cnt',\n",
        "    'dew_smooth', 'air_smooth',\n",
        "    'dew_diff', 'air_diff',\n",
        "    'dew_diff2', 'air_diff2'\n",
        " ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = train_df.merge(building_meta_df, on=[\n",
        "                          'building_id', 'meter'], how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 1076.22 MB\n",
            "Memory usage after optimization is: 1076.22 MB\n",
            "Decreased by 0.0%\n",
            "Memory usage of dataframe is 25.73 MB\n",
            "Memory usage after optimization is: 20.93 MB\n",
            "Decreased by 18.7%\n"
          ]
        }
      ],
      "source": [
        "train_df = reduce_mem_usage(train_df, use_float16=True)\n",
        "weather_train_df = reduce_mem_usage(weather_train_df, use_float16=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = train_df.merge(weather_train_df, on=[\n",
        "                          'site_id', 'timestamp'], how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df['square_feet_np_log1p'] = np.log1p(train_df['square_feet'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 3822.39 MB\n",
            "Memory usage after optimization is: 3711.06 MB\n",
            "Decreased by 2.9%\n"
          ]
        }
      ],
      "source": [
        "train_df = reduce_mem_usage(train_df, use_float16=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "del weather_train_df\n",
        "gc.collect() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "iyt_1Xg7cg1X",
        "outputId": "daf36014-f11c-4cda-f7ca-d6040a35353c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n--------------------------------------------------------------------------------\\nIMPLEMENTATION\\n'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "--------------------------------------------------------------------------------\n",
        "IMPLEMENTATION\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "KVLutpqjcuoo"
      },
      "outputs": [],
      "source": [
        "# Get X_train and y_train\n",
        "def create_X_y(train_df, groupNum_train):\n",
        "\n",
        "    target_train_df = train_df[train_df['groupNum_train']\n",
        "                               == groupNum_train].copy()\n",
        "    \n",
        "    X_train = target_train_df[feature_cols + category_cols]\n",
        "    y_train = target_train_df['meter_reading_log1p'].values\n",
        "\n",
        "    del target_train_df\n",
        "    return X_train, y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "kBX5P0Phedaw"
      },
      "outputs": [],
      "source": [
        "# # Define RMSLE specifically for neural network\n",
        "def NN_RMSLE(y_act, y_pred):\n",
        "  return k.sqrt(k.mean(k.square(y_pred - y_act)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "vV-tpC9pfegY"
      },
      "outputs": [],
      "source": [
        "# Split into train and validation sets\n",
        "# train_xx, val_xx, train_yy, val_yy = train_test_split(train_x, train_y, test_size = 0.2, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Method to train LSTM model\n",
        "def RNN_LSTM(train, val ):\n",
        "       X_train, y_train = train\n",
        "       X_valid, y_valid = val\n",
        "       metric= 'val_loss'\n",
        "       model = Sequential()\n",
        "       early_stop = EarlyStopping(monitor = metric, mode = 'min', patience = 3)\n",
        "       model_checkpoint = ModelCheckpoint(\"model_\" + str(groupNum_train) + \"[]\",\n",
        "                                          save_best_only=True, verbose=1, monitor=metric, mode='min')\n",
        "\n",
        "       # Add LSTM Layers, etc\n",
        "       # Add layers, etc\n",
        "       model.add(Dense(units=64, activation='relu', input_dim=X_train.shape[1]))\n",
        "       model.add(Dropout(0.2))\n",
        "       model.add(Dense(units=32, activation='relu'))\n",
        "       model.add(Dropout(0.2))\n",
        "       model.add(Dense(units=16, activation='relu'))\n",
        "       model.add(Dropout(0.2))\n",
        "       model.add(Dense(units=1, activation='linear'))\n",
        "\n",
        "       model.compile(loss='mse', optimizer='adam', metrics=[NN_RMSLE])\n",
        "       model.summary()\n",
        "       \n",
        "       \n",
        "\n",
        "       # Fit model\n",
        "       model.fit(X_train, y_train, epochs=100, batch_size=64,\n",
        "             validation_data=(X_valid, y_valid),\n",
        "             callbacks=[early_stop, model_checkpoint], verbose=1)\n",
        "       model.summary()\n",
        "\n",
        "       y_pred_valid = model.predict(X_valid)\n",
        "\n",
        "       print('---------- Evaluation on Training Data ----------')\n",
        "       print(\"MSE: \", mean_squared_error(y_valid, y_pred_valid))\n",
        "       print(\"\")\n",
        "       \n",
        "       return model, y_pred_valid\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
        "seed = 666\n",
        "shuffle = False\n",
        "kf = StratifiedKFold(n_splits=folds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "groupNum_train 0 (553329, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[ 5  6  7  8  9 10 11]\n",
            "train 368886 valid 184443\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-04-25 06:34:43.754202: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-04-25 06:34:43.755208: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5753/5764 [============================>.] - ETA: 0s - loss: 706.1586 - NN_RMSLE: 3.9926\n",
            "Epoch 1: val_loss improved from inf to 1.62218, saving model to model_0[]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-04-25 06:35:00.515077: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_0[]/assets\n",
            "5764/5764 [==============================] - 17s 3ms/step - loss: 704.8348 - NN_RMSLE: 3.9880 - val_loss: 1.6222 - val_NN_RMSLE: 1.2682\n",
            "Epoch 2/100\n",
            "5746/5764 [============================>.] - ETA: 0s - loss: 1.9746 - NN_RMSLE: 1.3976\n",
            "Epoch 2: val_loss improved from 1.62218 to 1.52853, saving model to model_0[]\n",
            "INFO:tensorflow:Assets written to: model_0[]/assets\n",
            "5764/5764 [==============================] - 15s 3ms/step - loss: 1.9740 - NN_RMSLE: 1.3974 - val_loss: 1.5285 - val_NN_RMSLE: 1.2293\n",
            "Epoch 3/100\n",
            "5753/5764 [============================>.] - ETA: 0s - loss: 1.6061 - NN_RMSLE: 1.2617\n",
            "Epoch 3: val_loss did not improve from 1.52853\n",
            "5764/5764 [==============================] - 18s 3ms/step - loss: 1.6062 - NN_RMSLE: 1.2617 - val_loss: 1.5288 - val_NN_RMSLE: 1.2295\n",
            "Epoch 4/100\n",
            "5760/5764 [============================>.] - ETA: 0s - loss: 1.5565 - NN_RMSLE: 1.2421\n",
            "Epoch 4: val_loss did not improve from 1.52853\n",
            "5764/5764 [==============================] - 16s 3ms/step - loss: 1.5565 - NN_RMSLE: 1.2420 - val_loss: 1.5300 - val_NN_RMSLE: 1.2293\n",
            "Epoch 5/100\n",
            "5760/5764 [============================>.] - ETA: 0s - loss: 1.5524 - NN_RMSLE: 1.2404\n",
            "Epoch 5: val_loss improved from 1.52853 to 1.52818, saving model to model_0[]\n",
            "INFO:tensorflow:Assets written to: model_0[]/assets\n",
            "5764/5764 [==============================] - 17s 3ms/step - loss: 1.5524 - NN_RMSLE: 1.2404 - val_loss: 1.5282 - val_NN_RMSLE: 1.2287\n",
            "Epoch 6/100\n",
            "5753/5764 [============================>.] - ETA: 0s - loss: 1.5517 - NN_RMSLE: 1.2401\n",
            "Epoch 6: val_loss did not improve from 1.52818\n",
            "5764/5764 [==============================] - 18s 3ms/step - loss: 1.5518 - NN_RMSLE: 1.2401 - val_loss: 1.5289 - val_NN_RMSLE: 1.2289\n",
            "Epoch 7/100\n",
            "5744/5764 [============================>.] - ETA: 0s - loss: 1.5517 - NN_RMSLE: 1.2402\n",
            "Epoch 7: val_loss improved from 1.52818 to 1.52716, saving model to model_0[]\n",
            "INFO:tensorflow:Assets written to: model_0[]/assets\n",
            "5764/5764 [==============================] - 16s 3ms/step - loss: 1.5516 - NN_RMSLE: 1.2402 - val_loss: 1.5272 - val_NN_RMSLE: 1.2285\n",
            "Epoch 8/100\n",
            "5753/5764 [============================>.] - ETA: 0s - loss: 1.5516 - NN_RMSLE: 1.2399\n",
            "Epoch 8: val_loss did not improve from 1.52716\n",
            "5764/5764 [==============================] - 15s 3ms/step - loss: 1.5516 - NN_RMSLE: 1.2399 - val_loss: 1.5274 - val_NN_RMSLE: 1.2285\n",
            "Epoch 9/100\n",
            "5748/5764 [============================>.] - ETA: 0s - loss: 1.5514 - NN_RMSLE: 1.2399\n",
            "Epoch 9: val_loss did not improve from 1.52716\n",
            "5764/5764 [==============================] - 16s 3ms/step - loss: 1.5515 - NN_RMSLE: 1.2399 - val_loss: 1.5274 - val_NN_RMSLE: 1.2285\n",
            "Epoch 10/100\n",
            "5751/5764 [============================>.] - ETA: 0s - loss: 1.5511 - NN_RMSLE: 1.2399\n",
            "Epoch 10: val_loss did not improve from 1.52716\n",
            "5764/5764 [==============================] - 19s 3ms/step - loss: 1.5515 - NN_RMSLE: 1.2401 - val_loss: 1.5276 - val_NN_RMSLE: 1.2285\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.5275912\n",
            "\n",
            "[ 8  9 10 11 12]\n",
            "train 368886 valid 184443\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "5760/5764 [============================>.] - ETA: 0s - loss: 188.7541 - NN_RMSLE: 2.2961\n",
            "Epoch 1: val_loss improved from inf to 1.62837, saving model to model_0[]\n",
            "INFO:tensorflow:Assets written to: model_0[]/assets\n",
            "5764/5764 [==============================] - 16s 3ms/step - loss: 188.6301 - NN_RMSLE: 2.2957 - val_loss: 1.6284 - val_NN_RMSLE: 1.2721\n",
            "Epoch 2/100\n",
            "5755/5764 [============================>.] - ETA: 0s - loss: 2.0289 - NN_RMSLE: 1.4160\n",
            "Epoch 2: val_loss improved from 1.62837 to 1.46206, saving model to model_0[]\n",
            "INFO:tensorflow:Assets written to: model_0[]/assets\n",
            "5764/5764 [==============================] - 16s 3ms/step - loss: 2.0285 - NN_RMSLE: 1.4159 - val_loss: 1.4621 - val_NN_RMSLE: 1.2041\n",
            "Epoch 3/100\n",
            "5764/5764 [==============================] - ETA: 0s - loss: 1.6444 - NN_RMSLE: 1.2767\n",
            "Epoch 3: val_loss improved from 1.46206 to 1.45555, saving model to model_0[]\n",
            "INFO:tensorflow:Assets written to: model_0[]/assets\n",
            "5764/5764 [==============================] - 16s 3ms/step - loss: 1.6444 - NN_RMSLE: 1.2767 - val_loss: 1.4556 - val_NN_RMSLE: 1.2012\n",
            "Epoch 4/100\n",
            "5757/5764 [============================>.] - ETA: 0s - loss: 1.5944 - NN_RMSLE: 1.2571\n",
            "Epoch 4: val_loss did not improve from 1.45555\n",
            "5764/5764 [==============================] - 17s 3ms/step - loss: 1.5947 - NN_RMSLE: 1.2572 - val_loss: 1.4590 - val_NN_RMSLE: 1.2028\n",
            "Epoch 5/100\n",
            "5752/5764 [============================>.] - ETA: 0s - loss: 1.5883 - NN_RMSLE: 1.2545\n",
            "Epoch 5: val_loss did not improve from 1.45555\n",
            "5764/5764 [==============================] - 16s 3ms/step - loss: 1.5885 - NN_RMSLE: 1.2546 - val_loss: 1.4588 - val_NN_RMSLE: 1.2027\n",
            "Epoch 6/100\n",
            "5754/5764 [============================>.] - ETA: 0s - loss: 1.5875 - NN_RMSLE: 1.2544\n",
            "Epoch 6: val_loss did not improve from 1.45555\n",
            "5764/5764 [==============================] - 17s 3ms/step - loss: 1.5875 - NN_RMSLE: 1.2544 - val_loss: 1.4595 - val_NN_RMSLE: 1.2030\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.4595478\n",
            "\n",
            "[10 11 12]\n",
            "train 368886 valid 184443\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "5763/5764 [============================>.] - ETA: 0s - loss: 754.9438 - NN_RMSLE: 8.6065\n",
            "Epoch 1: val_loss improved from inf to 2.18363, saving model to model_0[]\n",
            "INFO:tensorflow:Assets written to: model_0[]/assets\n",
            "5764/5764 [==============================] - 17s 3ms/step - loss: 754.8337 - NN_RMSLE: 8.6053 - val_loss: 2.1836 - val_NN_RMSLE: 1.4740\n",
            "Epoch 2/100\n",
            "5742/5764 [============================>.] - ETA: 0s - loss: 2.6247 - NN_RMSLE: 1.4865\n",
            "Epoch 2: val_loss improved from 2.18363 to 1.66683, saving model to model_0[]\n",
            "INFO:tensorflow:Assets written to: model_0[]/assets\n",
            "5764/5764 [==============================] - 17s 3ms/step - loss: 2.6203 - NN_RMSLE: 1.4854 - val_loss: 1.6668 - val_NN_RMSLE: 1.2889\n",
            "Epoch 3/100\n",
            "5755/5764 [============================>.] - ETA: 0s - loss: 1.6911 - NN_RMSLE: 1.2285\n",
            "Epoch 3: val_loss improved from 1.66683 to 1.65126, saving model to model_0[]\n",
            "INFO:tensorflow:Assets written to: model_0[]/assets\n",
            "5764/5764 [==============================] - 15s 3ms/step - loss: 1.6907 - NN_RMSLE: 1.2284 - val_loss: 1.6513 - val_NN_RMSLE: 1.2818\n",
            "Epoch 4/100\n",
            "5742/5764 [============================>.] - ETA: 0s - loss: 1.4937 - NN_RMSLE: 1.2162\n",
            "Epoch 4: val_loss improved from 1.65126 to 1.65016, saving model to model_0[]\n",
            "INFO:tensorflow:Assets written to: model_0[]/assets\n",
            "5764/5764 [==============================] - 16s 3ms/step - loss: 1.4939 - NN_RMSLE: 1.2163 - val_loss: 1.6502 - val_NN_RMSLE: 1.2814\n",
            "Epoch 5/100\n",
            "5746/5764 [============================>.] - ETA: 0s - loss: 1.4908 - NN_RMSLE: 1.2157\n",
            "Epoch 5: val_loss improved from 1.65016 to 1.64897, saving model to model_0[]\n",
            "INFO:tensorflow:Assets written to: model_0[]/assets\n",
            "5764/5764 [==============================] - 16s 3ms/step - loss: 1.4907 - NN_RMSLE: 1.2157 - val_loss: 1.6490 - val_NN_RMSLE: 1.2810\n",
            "Epoch 6/100\n",
            "5761/5764 [============================>.] - ETA: 0s - loss: 1.9086 - NN_RMSLE: 1.2254\n",
            "Epoch 6: val_loss did not improve from 1.64897\n",
            "5764/5764 [==============================] - 16s 3ms/step - loss: 1.9082 - NN_RMSLE: 1.2254 - val_loss: 1.6498 - val_NN_RMSLE: 1.2813\n",
            "Epoch 7/100\n",
            "5748/5764 [============================>.] - ETA: 0s - loss: 1.4939 - NN_RMSLE: 1.2162\n",
            "Epoch 7: val_loss did not improve from 1.64897\n",
            "5764/5764 [==============================] - 15s 3ms/step - loss: 1.4941 - NN_RMSLE: 1.2163 - val_loss: 1.6496 - val_NN_RMSLE: 1.2812\n",
            "Epoch 8/100\n",
            "5759/5764 [============================>.] - ETA: 0s - loss: 1.4909 - NN_RMSLE: 1.2157\n",
            "Epoch 8: val_loss did not improve from 1.64897\n",
            "5764/5764 [==============================] - 17s 3ms/step - loss: 1.4908 - NN_RMSLE: 1.2157 - val_loss: 1.6497 - val_NN_RMSLE: 1.2812\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.6497409\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD5CAYAAADItClGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAASDUlEQVR4nO3dfYxld13H8fenDyIUKtQuS91u2AZXTNXYNmNBSwxawfIghUhIGym1AZeYoiBGUxojmGiiRupDoo0LrW55LrSFSipYKgFRC8zWSrdPskLr7mbbHUBoAW3t9usfc+b0dvbOzuzMnHvuvX2/kpt77++cc+9nmu185vzOueemqpAkCeCovgNIksaHpSBJalkKkqSWpSBJalkKkqSWpSBJah3T1Qsn2QxcBWwECtheVX+e5B3ArwBzzaqXVtUNzTZvA14PHAR+vao+ebj3OPHEE2vLli3d/ACSNKV27tz5taraMGxZZ6UAPAL8ZlXdkuRpwM4kNzbL/rSq/mRw5SSnAucBPwL8APCpJD9UVQeXeoMtW7YwOzvbUXxJmk5J7l1qWWfTR1W1v6puaR4/CNwJbDrMJucCH6yqh6rqq8Bu4Myu8kmSDjWSYwpJtgCnA59vht6U5EtJrkzyjGZsE7BnYLO9DCmRJNuSzCaZnZubW7xYkrQGnZdCkqcC1wBvqaoHgMuB5wCnAfuBdx7J61XV9qqaqaqZDRuGTolJklap01JIcizzhfC+qroWoKrur6qDVfUo8C4emyLaB2we2PzkZkySNCKdlUKSAFcAd1bVZQPjJw2s9ipgV/P4euC8JE9KcgqwFfhCV/kkSYfq8uyjs4ALgNuS3NqMXQqcn+Q05k9TvQd4I0BV3Z7kauAO5s9cuvhwZx5JktZfZ6VQVZ8DMmTRDYfZ5g+AP+gqkyTp8PxEsySpZSlIklqWgiSpZSlIklqWgiSpZSlIklqWgiSpZSlIklqWgiSpZSlIklqWgiSpZSlIklqWgiSpZSlIklqWgiSpZSlIklqWgiSpZSlIklqWgiSpZSlIklqWgiSpZSlIklqWgiSpZSlIklqWgiSpZSlIklqWgiSpZSlIklqWgiSpZSlIklqWgiSpZSlIklqWgiSpZSlIklqdlUKSzUk+neSOJLcneXMzfkKSG5N8ubl/RjOeJH+RZHeSLyU5o6tskqThutxTeAT4zao6FXg+cHGSU4FLgJuqaitwU/Mc4CXA1ua2Dbi8w2ySpCE6K4Wq2l9VtzSPHwTuBDYB5wI7mtV2AK9sHp8LXFXzbgaenuSkrvJJkg41kmMKSbYApwOfBzZW1f5m0X3AxubxJmDPwGZ7m7HFr7UtyWyS2bm5ue5CS9ITUOelkOSpwDXAW6rqgcFlVVVAHcnrVdX2qpqpqpkNGzasY1JJUqelkORY5gvhfVV1bTN8/8K0UHN/oBnfB2we2PzkZkySNCJdnn0U4Argzqq6bGDR9cCFzeMLgY8NjL+uOQvp+cC3BqaZJEkjcEyHr30WcAFwW5Jbm7FLgT8Erk7yeuBe4DXNshuAlwK7ge8CF3WYTZI0RGelUFWfA7LE4rOHrF/AxV3lkSQtz080S5JaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqdVZKSS5MsmBJLsGxt6RZF+SW5vbSweWvS3J7iR3J/n5rnJJkpbW5Z7C3wLnDBn/06o6rbndAJDkVOA84Eeabf4qydEdZpMkDdFZKVTVZ4FvrHD1c4EPVtVDVfVVYDdwZlfZJEnD9XFM4U1JvtRMLz2jGdsE7BlYZ28zdogk25LMJpmdm5vrOqskPaGMuhQuB54DnAbsB955pC9QVduraqaqZjZs2LDO8STpiW2kpVBV91fVwap6FHgXj00R7QM2D6x6cjMmSRqhkZZCkpMGnr4KWDgz6XrgvCRPSnIKsBX4wiizSZLgmJWslORa4Arg75u/8leyzQeAFwInJtkLvB14YZLTgALuAd4IUFW3J7kauAN4BLi4qg4e0U8iSVqzVNXyKyU/B1wEPB/4MPA3VXV3x9mWNTMzU7Ozs33HkKSJkmRnVc0MW7ai6aOq+lRV/RJwBvN/4X8qyb8kuSjJsesXVZLUpxUfU0jy/cAvA28A/g34c+ZL4sZOkkmSRm6lxxSuA54LvAf4hara3yz6UBLnbyRpSqyoFIB3LVySYkGSJzWfQB46LyVJmjwrnT76/SFj/7qeQSRJ/TvsnkKSZzF/uYknJzkdSLPoeOApHWeTJI3YctNHP8/8weWTgcsGxh8ELu0okySpJ4ctharaAexI8otVdc2IMkmSerLc9NFrq+q9wJYkb128vKouG7KZJGlCLTd9dFxz/9Sug0iS+rfc9NFfN/e/N5o4kqQ+reiU1CR/nOT4JMcmuSnJXJLXdh1OkjRaK/2cwour6gHg5cxf++gHgd/qKpQkqR8rLYWFaaaXAR+uqm91lEeS1KOVXubi40nuAv4H+NUkG4D/7S6WJKkPK7109iXATwEzVfV/wHeAc7sMJkkavZXuKQD8MPOfVxjc5qp1ziNJ6tFKL539HuA5wK3AwtdkFpaCJE2Vle4pzACn1kq+u1OSNLFWevbRLuBZXQaRJPVvpXsKJwJ3JPkC8NDCYFW9opNUkqRerLQU3tFlCEnSeFhRKVTVZ5I8G9haVZ9K8hTg6G6jSZJGbaXXPvoV4CPAXzdDm4CPdpRJktSTlR5ovhg4C3gAoKq+DDyzq1CSpH6stBQeqqqHF540H2Dz9FRJmjIrLYXPJLkUeHKSFwEfBv6uu1iSpD6stBQuAeaA24A3AjcAv9NVKElSP1Z69tGjST4KfLSq5rqNJEnqy2H3FDLvHUm+BtwN3N1869rvjiaeJGmUlps++g3mzzr6iao6oapOAJ4HnJXkNzpPJ0kaqeVK4QLg/Kr66sJAVX0FeC3wui6DSZJGb7lSOLaqvrZ4sDmucGw3kSRJfVmuFB5e5TJJ0gRarhR+PMkDQ24PAj92uA2TXJnkQJJdA2MnJLkxyZeb+2c040nyF0l2J/lSkjPW/qNJko7UYUuhqo6uquOH3J5WVctNH/0tcM6isUuAm6pqK3BT8xzgJcDW5rYNuPxIfxBJ0tqt9MNrR6yqPgt8Y9HwucCO5vEO4JUD41fVvJuBpyc5qatskqThOiuFJWysqv3N4/uAjc3jTcCegfX2NmOHSLItyWyS2bk5P0cnSetp1KXQar7v+YgvqldV26tqpqpmNmzY0EEySXriGnUp3L8wLdTcH2jG9wGbB9Y7uRmTJI3QqEvheuDC5vGFwMcGxl/XnIX0fOBbA9NMkqQRWel3NB+xJB8AXgicmGQv8HbgD4Grk7weuBd4TbP6DcBLgd3Ad4GLusolSVpaZ6VQVecvsejsIesW89/uJknqUW8HmiVJ48dSkCS1LAVJUstSkCS1LAVJUstSkCS1LAVJUstSkCS1LAVJUstSkCS1LAVJUstSkCS1LAVJUstSkCS1LAVJUstSkCbdQw/Cgbvm73ddC4883HciTbDOvmRH0oi899Ww52Z4yvfDd78OP/EGeNk7+06lCeWegjTp9tw8f//dr8/f79vZXxZNPEtBmjZVfSfQBLMUpKljKWj1LAVp2rinoDWwFCRJLUtBktSyFKSp4/SRVs9SkCS1LAVp2rijoDWwFKRpU4/2nUATzFKQpk0d7DuBJpilIE0bP6egNbAUpGnj9JHWwFKQpo57Clo9S0GaNk4faQ0sBWnqWApaPUtBktTq5ZvXktwDPAgcBB6pqpkkJwAfArYA9wCvqar/7iOfNNGcPtIa9Lmn8DNVdVpVzTTPLwFuqqqtwE3Nc0lHzFLQ6o3T9NG5wI7m8Q7glf1FkSaYp6RqDfoqhQL+IcnOJNuasY1Vtb95fB+wcdiGSbYlmU0yOzc3N4qs0mRxR0Fr0MsxBeAFVbUvyTOBG5PcNbiwqirJ0H/aVbUd2A4wMzPjP3/pEP5vodXrZU+hqvY19weA64AzgfuTnATQ3B/oI5s08TzQrDUYeSkkOS7J0xYeAy8GdgHXAxc2q10IfGzU2aTpYClo9fqYPtoIXJdk4f3fX1WfSPJF4OokrwfuBV7TQzZp8nmgWWsw8lKoqq8APz5k/OvA2aPOI0l6zDidkippPXhMQWtgKUjTxukjrYGlIE0d9xS0epaCNG2cPtIaWArS1LEUtHqWgjRt3FPQGlgK0tSxFLR6loI0bTz7SGtgKUjTxh0FrYGlIElqWQqSpJalIE0d54+0epaCNG08JVVrYClI08azj7QGloI08bLouXsKWj1LQZo2Th9pDSwFSVLLUpCmjnsKWj1LQZp0WXRMwekjrYGlIE0dS0GrZylIE889Ba0fS0GadIunj9xT0BpYCpKklqUgTRunj7QGloI08Zw+0vqxFKRp456C1sBSkKaOpaDVsxSkSXfI2UfS6lkKkqSWpSBJalkK0sRz+kjrx1KQJp4HlrV+LAVp0nkKqtaRpSBNPEtB62fsSiHJOUnuTrI7ySV955HG3qMHH//8Scf3k0NT4Zi+AwxKcjTwl8CLgL3AF5NcX1V39JtsstSi6YTFswuL/65cvP7wdRYvP/x7DM915K+xXNblcg5bqah2vYVFVTXweCBb8bjxYdsvZBp878HXGLru49Yflufx2w977wU/uugH/Mbmn+O/9nzzkJ+JIXkWhMGPO4RkYSyPW5ZmGc3YUs8f22Zg+aLXG9y23X7R8qMyv+FRCUc1y45q3uCoZjzNPTz2fPDnGpSBhXnc+NLrPdGMVSkAZwK7q+orAEk+CJwLrGspfGLXfbz16lvb58N/GR3ZL9Zhe/BH+hqr+eUsfeZ7nsmzjzrQPv/QXf/HH+365x4TTa+1Fk4Wb7XE6x1um4Vlb3jBKbz1xc9dNvORyrBfRH1J8mrgnKp6Q/P8AuB5VfWmgXW2Aduap88F7h5BtBOBr43gfdbKnOvLnOtrEnJOQkZYe85nV9WGYQvGbU9hWVW1Hdg+yvdMMltVM6N8z9Uw5/oy5/qahJyTkBG6zTluB5r3AZsHnp/cjEmSRmDcSuGLwNYkpyT5HuA84PqeM0nSE8ZYTR9V1SNJ3gR8EjgauLKqbu85Fox4umoNzLm+zLm+JiHnJGSEDnOO1YFmSVK/xm36SJLUI0tBktSyFJYxCZfdSHJlkgNJdvWd5XCSbE7y6SR3JLk9yZv7zjRMku9N8oUk/97k/L2+My0lydFJ/i3Jx/vOspQk9yS5LcmtSWb7zrOUJE9P8pEkdyW5M8lP9p1psSTPbf47LtweSPKWdX0Pjyksrbnsxn8wcNkN4Pxxu+xGkp8Gvg1cVVU/2neepSQ5CTipqm5J8jRgJ/DKMfzvGeC4qvp2kmOBzwFvrqqbe452iCRvBWaA46vq5X3nGSbJPcBMVY31h8KS7AD+qare3Zz9+JSq+mbPsZbU/H7ax/wHfO9dr9d1T+Hw2stuVNXDwMJlN8ZKVX0W+EbfOZZTVfur6pbm8YPAncCmflMdquZ9u3l6bHMbu7+ekpwMvAx4d99ZJl2S7wN+GrgCoKoeHudCaJwN/Od6FgJYCsvZBOwZeL6XMfwlNomSbAFOBz7fc5ShmmmZW4EDwI1VNY45/wz4beDRnnMsp4B/SLKzuUzNODoFmAP+ppmOe3eS4/oOtYzzgA+s94taChq5JE8FrgHeUlUP9J1nmKo6WFWnMf+p+jOTjNW0XJKXAweqamffWVbgBVV1BvAS4OJmunPcHAOcAVxeVacD3wHG8hgiQDO99Qrgw+v92pbC4XnZjXXWzNFfA7yvqq7tO89ymimETwPn9BxlsbOAVzTz9R8EfjbJe/uNNFxV7WvuDwDXMT8tO272AnsH9gg/wnxJjKuXALdU1f3r/cKWwuF52Y111BzAvQK4s6ou6zvPUpJsSPL05vGTmT/R4K5eQy1SVW+rqpOragvz/y7/sape23OsQyQ5rjmpgGY65sXA2J0lV1X3AXuSLFyL+mzW+ZL96+x8Opg6gjG7zMW4GePLbjxOkg8ALwROTLIXeHtVXdFvqqHOAi4Abmvm6wEuraob+os01EnAjubsjqOAq6tqbE/5HHMbgeua7xo4Bnh/VX2i30hL+jXgfc0fgF8BLuo5z1BNub4IeGMnr+8pqZKkBU4fSZJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJa/w+IaFWePCG/uQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 1 (164229, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[2 3 4 5 6 7]\n",
            "train 109486 valid 54743\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1709/1711 [============================>.] - ETA: 0s - loss: 1716.7748 - NN_RMSLE: 5.9148\n",
            "Epoch 1: val_loss improved from inf to 6.83867, saving model to model_1[]\n",
            "INFO:tensorflow:Assets written to: model_1[]/assets\n",
            "1711/1711 [==============================] - 6s 3ms/step - loss: 1715.0645 - NN_RMSLE: 5.9124 - val_loss: 6.8387 - val_NN_RMSLE: 2.5970\n",
            "Epoch 2/100\n",
            "1696/1711 [============================>.] - ETA: 0s - loss: 11.8386 - NN_RMSLE: 3.4234\n",
            "Epoch 2: val_loss improved from 6.83867 to 6.28977, saving model to model_1[]\n",
            "INFO:tensorflow:Assets written to: model_1[]/assets\n",
            "1711/1711 [==============================] - 5s 3ms/step - loss: 11.8224 - NN_RMSLE: 3.4209 - val_loss: 6.2898 - val_NN_RMSLE: 2.4758\n",
            "Epoch 3/100\n",
            "1707/1711 [============================>.] - ETA: 0s - loss: 8.6656 - NN_RMSLE: 2.9254\n",
            "Epoch 3: val_loss improved from 6.28977 to 6.00899, saving model to model_1[]\n",
            "INFO:tensorflow:Assets written to: model_1[]/assets\n",
            "1711/1711 [==============================] - 5s 3ms/step - loss: 8.6631 - NN_RMSLE: 2.9250 - val_loss: 6.0090 - val_NN_RMSLE: 2.3973\n",
            "Epoch 4/100\n",
            "1697/1711 [============================>.] - ETA: 0s - loss: 7.0177 - NN_RMSLE: 2.6324\n",
            "Epoch 4: val_loss improved from 6.00899 to 5.98446, saving model to model_1[]\n",
            "INFO:tensorflow:Assets written to: model_1[]/assets\n",
            "1711/1711 [==============================] - 5s 3ms/step - loss: 7.0093 - NN_RMSLE: 2.6307 - val_loss: 5.9845 - val_NN_RMSLE: 2.3767\n",
            "Epoch 5/100\n",
            "1700/1711 [============================>.] - ETA: 0s - loss: 6.2346 - NN_RMSLE: 2.4804\n",
            "Epoch 5: val_loss did not improve from 5.98446\n",
            "1711/1711 [==============================] - 5s 3ms/step - loss: 6.2338 - NN_RMSLE: 2.4804 - val_loss: 6.0194 - val_NN_RMSLE: 2.3741\n",
            "Epoch 6/100\n",
            "1701/1711 [============================>.] - ETA: 0s - loss: 5.4048 - NN_RMSLE: 2.3049\n",
            "Epoch 6: val_loss did not improve from 5.98446\n",
            "1711/1711 [==============================] - 5s 3ms/step - loss: 5.4057 - NN_RMSLE: 2.3051 - val_loss: 6.0804 - val_NN_RMSLE: 2.3778\n",
            "Epoch 7/100\n",
            "1695/1711 [============================>.] - ETA: 0s - loss: 4.9571 - NN_RMSLE: 2.2040\n",
            "Epoch 7: val_loss did not improve from 5.98446\n",
            "1711/1711 [==============================] - 5s 3ms/step - loss: 4.9554 - NN_RMSLE: 2.2036 - val_loss: 6.1078 - val_NN_RMSLE: 2.3804\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  6.107772\n",
            "\n",
            "[ 5  6  7  8  9 10]\n",
            "train 109486 valid 54743\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1707/1711 [============================>.] - ETA: 0s - loss: 4107.9731 - NN_RMSLE: 10.4258\n",
            "Epoch 1: val_loss improved from inf to 18.50002, saving model to model_1[]\n",
            "INFO:tensorflow:Assets written to: model_1[]/assets\n",
            "1711/1711 [==============================] - 6s 3ms/step - loss: 4099.0811 - NN_RMSLE: 10.4112 - val_loss: 18.5000 - val_NN_RMSLE: 4.2877\n",
            "Epoch 2/100\n",
            "1711/1711 [==============================] - ETA: 0s - loss: 11.9524 - NN_RMSLE: 3.4414\n",
            "Epoch 2: val_loss improved from 18.50002 to 7.09014, saving model to model_1[]\n",
            "INFO:tensorflow:Assets written to: model_1[]/assets\n",
            "1711/1711 [==============================] - 6s 3ms/step - loss: 11.9524 - NN_RMSLE: 3.4414 - val_loss: 7.0901 - val_NN_RMSLE: 2.6553\n",
            "Epoch 3/100\n",
            "1705/1711 [============================>.] - ETA: 0s - loss: 9.2731 - NN_RMSLE: 3.0320\n",
            "Epoch 3: val_loss improved from 7.09014 to 5.94859, saving model to model_1[]\n",
            "INFO:tensorflow:Assets written to: model_1[]/assets\n",
            "1711/1711 [==============================] - 6s 3ms/step - loss: 9.2720 - NN_RMSLE: 3.0318 - val_loss: 5.9486 - val_NN_RMSLE: 2.4256\n",
            "Epoch 4/100\n",
            "1706/1711 [============================>.] - ETA: 0s - loss: 7.8593 - NN_RMSLE: 2.7893\n",
            "Epoch 4: val_loss improved from 5.94859 to 5.16268, saving model to model_1[]\n",
            "INFO:tensorflow:Assets written to: model_1[]/assets\n",
            "1711/1711 [==============================] - 6s 3ms/step - loss: 7.8581 - NN_RMSLE: 2.7891 - val_loss: 5.1627 - val_NN_RMSLE: 2.2478\n",
            "Epoch 5/100\n",
            "1707/1711 [============================>.] - ETA: 0s - loss: 6.9414 - NN_RMSLE: 2.6197\n",
            "Epoch 5: val_loss improved from 5.16268 to 4.79634, saving model to model_1[]\n",
            "INFO:tensorflow:Assets written to: model_1[]/assets\n",
            "1711/1711 [==============================] - 5s 3ms/step - loss: 6.9426 - NN_RMSLE: 2.6200 - val_loss: 4.7963 - val_NN_RMSLE: 2.1560\n",
            "Epoch 6/100\n",
            "1697/1711 [============================>.] - ETA: 0s - loss: 6.3488 - NN_RMSLE: 2.5037\n",
            "Epoch 6: val_loss improved from 4.79634 to 4.71665, saving model to model_1[]\n",
            "INFO:tensorflow:Assets written to: model_1[]/assets\n",
            "1711/1711 [==============================] - 6s 3ms/step - loss: 6.3478 - NN_RMSLE: 2.5034 - val_loss: 4.7167 - val_NN_RMSLE: 2.1349\n",
            "Epoch 7/100\n",
            "1705/1711 [============================>.] - ETA: 0s - loss: 5.9663 - NN_RMSLE: 2.4241\n",
            "Epoch 7: val_loss improved from 4.71665 to 4.61015, saving model to model_1[]\n",
            "INFO:tensorflow:Assets written to: model_1[]/assets\n",
            "1711/1711 [==============================] - 5s 3ms/step - loss: 5.9685 - NN_RMSLE: 2.4246 - val_loss: 4.6102 - val_NN_RMSLE: 2.1060\n",
            "Epoch 8/100\n",
            "1696/1711 [============================>.] - ETA: 0s - loss: 5.7507 - NN_RMSLE: 2.3786\n",
            "Epoch 8: val_loss improved from 4.61015 to 4.57465, saving model to model_1[]\n",
            "INFO:tensorflow:Assets written to: model_1[]/assets\n",
            "1711/1711 [==============================] - 6s 3ms/step - loss: 5.7514 - NN_RMSLE: 2.3787 - val_loss: 4.5747 - val_NN_RMSLE: 2.0962\n",
            "Epoch 9/100\n",
            "1710/1711 [============================>.] - ETA: 0s - loss: 5.6184 - NN_RMSLE: 2.3511\n",
            "Epoch 9: val_loss improved from 4.57465 to 4.51333, saving model to model_1[]\n",
            "INFO:tensorflow:Assets written to: model_1[]/assets\n",
            "1711/1711 [==============================] - 5s 3ms/step - loss: 5.6174 - NN_RMSLE: 2.3508 - val_loss: 4.5133 - val_NN_RMSLE: 2.0789\n",
            "Epoch 10/100\n",
            "1704/1711 [============================>.] - ETA: 0s - loss: 5.5295 - NN_RMSLE: 2.3325\n",
            "Epoch 10: val_loss did not improve from 4.51333\n",
            "1711/1711 [==============================] - 5s 3ms/step - loss: 5.5275 - NN_RMSLE: 2.3321 - val_loss: 4.5151 - val_NN_RMSLE: 2.0794\n",
            "Epoch 11/100\n",
            "1708/1711 [============================>.] - ETA: 0s - loss: 5.4733 - NN_RMSLE: 2.3193\n",
            "Epoch 11: val_loss did not improve from 4.51333\n",
            "1711/1711 [==============================] - 5s 3ms/step - loss: 5.4743 - NN_RMSLE: 2.3195 - val_loss: 4.5390 - val_NN_RMSLE: 2.0862\n",
            "Epoch 12/100\n",
            "1687/1711 [============================>.] - ETA: 0s - loss: 5.4183 - NN_RMSLE: 2.3078\n",
            "Epoch 12: val_loss improved from 4.51333 to 4.49887, saving model to model_1[]\n",
            "INFO:tensorflow:Assets written to: model_1[]/assets\n",
            "1711/1711 [==============================] - 6s 3ms/step - loss: 5.4206 - NN_RMSLE: 2.3084 - val_loss: 4.4989 - val_NN_RMSLE: 2.0747\n",
            "Epoch 13/100\n",
            "1711/1711 [==============================] - ETA: 0s - loss: 5.3940 - NN_RMSLE: 2.3025\n",
            "Epoch 13: val_loss improved from 4.49887 to 4.37168, saving model to model_1[]\n",
            "INFO:tensorflow:Assets written to: model_1[]/assets\n",
            "1711/1711 [==============================] - 6s 3ms/step - loss: 5.3940 - NN_RMSLE: 2.3025 - val_loss: 4.3717 - val_NN_RMSLE: 2.0372\n",
            "Epoch 14/100\n",
            "1690/1711 [============================>.] - ETA: 0s - loss: 5.3650 - NN_RMSLE: 2.2961\n",
            "Epoch 14: val_loss did not improve from 4.37168\n",
            "1711/1711 [==============================] - 5s 3ms/step - loss: 5.3647 - NN_RMSLE: 2.2960 - val_loss: 4.3744 - val_NN_RMSLE: 2.0381\n",
            "Epoch 15/100\n",
            "1700/1711 [============================>.] - ETA: 0s - loss: 5.3528 - NN_RMSLE: 2.2921\n",
            "Epoch 15: val_loss did not improve from 4.37168\n",
            "1711/1711 [==============================] - 5s 3ms/step - loss: 5.3522 - NN_RMSLE: 2.2920 - val_loss: 4.4197 - val_NN_RMSLE: 2.0517\n",
            "Epoch 16/100\n",
            "1700/1711 [============================>.] - ETA: 0s - loss: 5.3428 - NN_RMSLE: 2.2908\n",
            "Epoch 16: val_loss did not improve from 4.37168\n",
            "1711/1711 [==============================] - 5s 3ms/step - loss: 5.3408 - NN_RMSLE: 2.2903 - val_loss: 4.4159 - val_NN_RMSLE: 2.0505\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  4.4158645\n",
            "\n",
            "[ 7  8  9 10 11 12]\n",
            "train 109486 valid 54743\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_20 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1706/1711 [============================>.] - ETA: 0s - loss: 23429.5566 - NN_RMSLE: 60.7066\n",
            "Epoch 1: val_loss improved from inf to 10.53182, saving model to model_1[]\n",
            "INFO:tensorflow:Assets written to: model_1[]/assets\n",
            "1711/1711 [==============================] - 6s 3ms/step - loss: 23367.2480 - NN_RMSLE: 60.5961 - val_loss: 10.5318 - val_NN_RMSLE: 3.2209\n",
            "Epoch 2/100\n",
            "1697/1711 [============================>.] - ETA: 0s - loss: 179.5202 - NN_RMSLE: 9.4240\n",
            "Epoch 2: val_loss improved from 10.53182 to 8.27922, saving model to model_1[]\n",
            "INFO:tensorflow:Assets written to: model_1[]/assets\n",
            "1711/1711 [==============================] - 5s 3ms/step - loss: 178.6765 - NN_RMSLE: 9.4081 - val_loss: 8.2792 - val_NN_RMSLE: 2.8570\n",
            "Epoch 3/100\n",
            "1695/1711 [============================>.] - ETA: 0s - loss: 44.2823 - NN_RMSLE: 5.0911\n",
            "Epoch 3: val_loss improved from 8.27922 to 7.92404, saving model to model_1[]\n",
            "INFO:tensorflow:Assets written to: model_1[]/assets\n",
            "1711/1711 [==============================] - 5s 3ms/step - loss: 44.0505 - NN_RMSLE: 5.0839 - val_loss: 7.9240 - val_NN_RMSLE: 2.7950\n",
            "Epoch 4/100\n",
            "1705/1711 [============================>.] - ETA: 0s - loss: 28.2753 - NN_RMSLE: 4.3156\n",
            "Epoch 4: val_loss improved from 7.92404 to 6.61114, saving model to model_1[]\n",
            "INFO:tensorflow:Assets written to: model_1[]/assets\n",
            "1711/1711 [==============================] - 5s 3ms/step - loss: 28.2293 - NN_RMSLE: 4.3138 - val_loss: 6.6111 - val_NN_RMSLE: 2.5494\n",
            "Epoch 5/100\n",
            "1710/1711 [============================>.] - ETA: 0s - loss: 20.9497 - NN_RMSLE: 3.9996\n",
            "Epoch 5: val_loss improved from 6.61114 to 6.51427, saving model to model_1[]\n",
            "INFO:tensorflow:Assets written to: model_1[]/assets\n",
            "1711/1711 [==============================] - 5s 3ms/step - loss: 21.0132 - NN_RMSLE: 4.0050 - val_loss: 6.5143 - val_NN_RMSLE: 2.5307\n",
            "Epoch 6/100\n",
            "1704/1711 [============================>.] - ETA: 0s - loss: 13.8564 - NN_RMSLE: 3.4705\n",
            "Epoch 6: val_loss improved from 6.51427 to 5.32225, saving model to model_1[]\n",
            "INFO:tensorflow:Assets written to: model_1[]/assets\n",
            "1711/1711 [==============================] - 5s 3ms/step - loss: 13.8418 - NN_RMSLE: 3.4693 - val_loss: 5.3223 - val_NN_RMSLE: 2.2688\n",
            "Epoch 7/100\n",
            "1700/1711 [============================>.] - ETA: 0s - loss: 10.0272 - NN_RMSLE: 2.9819\n",
            "Epoch 7: val_loss improved from 5.32225 to 4.61121, saving model to model_1[]\n",
            "INFO:tensorflow:Assets written to: model_1[]/assets\n",
            "1711/1711 [==============================] - 5s 3ms/step - loss: 10.0193 - NN_RMSLE: 2.9816 - val_loss: 4.6112 - val_NN_RMSLE: 2.0376\n",
            "Epoch 8/100\n",
            "1695/1711 [============================>.] - ETA: 0s - loss: 6.7929 - NN_RMSLE: 2.5796\n",
            "Epoch 8: val_loss did not improve from 4.61121\n",
            "1711/1711 [==============================] - 5s 3ms/step - loss: 6.7856 - NN_RMSLE: 2.5783 - val_loss: 4.6160 - val_NN_RMSLE: 2.0453\n",
            "Epoch 9/100\n",
            "1705/1711 [============================>.] - ETA: 0s - loss: 6.5186 - NN_RMSLE: 2.3817\n",
            "Epoch 9: val_loss did not improve from 4.61121\n",
            "1711/1711 [==============================] - 5s 3ms/step - loss: 6.5165 - NN_RMSLE: 2.3818 - val_loss: 4.6256 - val_NN_RMSLE: 2.0407\n",
            "Epoch 10/100\n",
            "1705/1711 [============================>.] - ETA: 0s - loss: 5.5149 - NN_RMSLE: 2.2789\n",
            "Epoch 10: val_loss did not improve from 4.61121\n",
            "1711/1711 [==============================] - 5s 3ms/step - loss: 5.5158 - NN_RMSLE: 2.2793 - val_loss: 4.6514 - val_NN_RMSLE: 2.0277\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_20 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  4.6514215\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 10 (422507, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[ 1  2  3  4  5  7  8 10 11]\n",
            "train 281671 valid 140836\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_24 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4402/4402 [==============================] - ETA: 0s - loss: 9.3312 - NN_RMSLE: 2.9087\n",
            "Epoch 1: val_loss improved from inf to 2.33071, saving model to model_10[]\n",
            "INFO:tensorflow:Assets written to: model_10[]/assets\n",
            "4402/4402 [==============================] - 14s 3ms/step - loss: 9.3312 - NN_RMSLE: 2.9087 - val_loss: 2.3307 - val_NN_RMSLE: 1.5178\n",
            "Epoch 2/100\n",
            "4391/4402 [============================>.] - ETA: 0s - loss: 1.4344 - NN_RMSLE: 1.1894\n",
            "Epoch 2: val_loss improved from 2.33071 to 1.09247, saving model to model_10[]\n",
            "INFO:tensorflow:Assets written to: model_10[]/assets\n",
            "4402/4402 [==============================] - 12s 3ms/step - loss: 1.4344 - NN_RMSLE: 1.1894 - val_loss: 1.0925 - val_NN_RMSLE: 1.0383\n",
            "Epoch 3/100\n",
            "4396/4402 [============================>.] - ETA: 0s - loss: 1.2600 - NN_RMSLE: 1.1193\n",
            "Epoch 3: val_loss improved from 1.09247 to 1.09189, saving model to model_10[]\n",
            "INFO:tensorflow:Assets written to: model_10[]/assets\n",
            "4402/4402 [==============================] - 12s 3ms/step - loss: 1.2599 - NN_RMSLE: 1.1193 - val_loss: 1.0919 - val_NN_RMSLE: 1.0380\n",
            "Epoch 4/100\n",
            "4394/4402 [============================>.] - ETA: 0s - loss: 1.2600 - NN_RMSLE: 1.1195\n",
            "Epoch 4: val_loss did not improve from 1.09189\n",
            "4402/4402 [==============================] - 12s 3ms/step - loss: 1.2600 - NN_RMSLE: 1.1195 - val_loss: 1.0938 - val_NN_RMSLE: 1.0389\n",
            "Epoch 5/100\n",
            "4384/4402 [============================>.] - ETA: 0s - loss: 1.2598 - NN_RMSLE: 1.1192\n",
            "Epoch 5: val_loss did not improve from 1.09189\n",
            "4402/4402 [==============================] - 12s 3ms/step - loss: 1.2599 - NN_RMSLE: 1.1193 - val_loss: 1.0928 - val_NN_RMSLE: 1.0385\n",
            "Epoch 6/100\n",
            "4391/4402 [============================>.] - ETA: 0s - loss: 1.2600 - NN_RMSLE: 1.1193\n",
            "Epoch 6: val_loss did not improve from 1.09189\n",
            "4402/4402 [==============================] - 12s 3ms/step - loss: 1.2599 - NN_RMSLE: 1.1192 - val_loss: 1.0928 - val_NN_RMSLE: 1.0385\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_24 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.0928127\n",
            "\n",
            "[ 3  4  5  6  7  8  9 11 12]\n",
            "train 281671 valid 140836\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_28 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4388/4402 [============================>.] - ETA: 0s - loss: 9.4390 - NN_RMSLE: 2.9241\n",
            "Epoch 1: val_loss improved from inf to 2.35316, saving model to model_10[]\n",
            "INFO:tensorflow:Assets written to: model_10[]/assets\n",
            "4402/4402 [==============================] - 13s 3ms/step - loss: 9.4181 - NN_RMSLE: 2.9197 - val_loss: 2.3532 - val_NN_RMSLE: 1.5245\n",
            "Epoch 2/100\n",
            "4390/4402 [============================>.] - ETA: 0s - loss: 1.3401 - NN_RMSLE: 1.1487\n",
            "Epoch 2: val_loss improved from 2.35316 to 1.30672, saving model to model_10[]\n",
            "INFO:tensorflow:Assets written to: model_10[]/assets\n",
            "4402/4402 [==============================] - 12s 3ms/step - loss: 1.3395 - NN_RMSLE: 1.1484 - val_loss: 1.3067 - val_NN_RMSLE: 1.1255\n",
            "Epoch 3/100\n",
            "4386/4402 [============================>.] - ETA: 0s - loss: 1.1529 - NN_RMSLE: 1.0707\n",
            "Epoch 3: val_loss improved from 1.30672 to 1.30582, saving model to model_10[]\n",
            "INFO:tensorflow:Assets written to: model_10[]/assets\n",
            "4402/4402 [==============================] - 13s 3ms/step - loss: 1.1527 - NN_RMSLE: 1.0706 - val_loss: 1.3058 - val_NN_RMSLE: 1.1253\n",
            "Epoch 4/100\n",
            "4379/4402 [============================>.] - ETA: 0s - loss: 1.1527 - NN_RMSLE: 1.0706\n",
            "Epoch 4: val_loss improved from 1.30582 to 1.30539, saving model to model_10[]\n",
            "INFO:tensorflow:Assets written to: model_10[]/assets\n",
            "4402/4402 [==============================] - 12s 3ms/step - loss: 1.1527 - NN_RMSLE: 1.0705 - val_loss: 1.3054 - val_NN_RMSLE: 1.1251\n",
            "Epoch 5/100\n",
            "4397/4402 [============================>.] - ETA: 0s - loss: 1.1528 - NN_RMSLE: 1.0707\n",
            "Epoch 5: val_loss did not improve from 1.30539\n",
            "4402/4402 [==============================] - 12s 3ms/step - loss: 1.1527 - NN_RMSLE: 1.0706 - val_loss: 1.3065 - val_NN_RMSLE: 1.1255\n",
            "Epoch 6/100\n",
            "4391/4402 [============================>.] - ETA: 0s - loss: 1.1526 - NN_RMSLE: 1.0705\n",
            "Epoch 6: val_loss did not improve from 1.30539\n",
            "4402/4402 [==============================] - 12s 3ms/step - loss: 1.1527 - NN_RMSLE: 1.0706 - val_loss: 1.3066 - val_NN_RMSLE: 1.1255\n",
            "Epoch 7/100\n",
            "4391/4402 [============================>.] - ETA: 0s - loss: 1.1527 - NN_RMSLE: 1.0707\n",
            "Epoch 7: val_loss did not improve from 1.30539\n",
            "4402/4402 [==============================] - 12s 3ms/step - loss: 1.1527 - NN_RMSLE: 1.0707 - val_loss: 1.3066 - val_NN_RMSLE: 1.1255\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_28 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.3066245\n",
            "\n",
            "[ 5  9 10 11 12]\n",
            "train 281672 valid 140835\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_32 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4394/4402 [============================>.] - ETA: 0s - loss: 9.4302 - NN_RMSLE: 2.9237\n",
            "Epoch 1: val_loss improved from inf to 2.30601, saving model to model_10[]\n",
            "INFO:tensorflow:Assets written to: model_10[]/assets\n",
            "4402/4402 [==============================] - 13s 3ms/step - loss: 9.4186 - NN_RMSLE: 2.9212 - val_loss: 2.3060 - val_NN_RMSLE: 1.5088\n",
            "Epoch 2/100\n",
            "4389/4402 [============================>.] - ETA: 0s - loss: 1.3822 - NN_RMSLE: 1.1669\n",
            "Epoch 2: val_loss improved from 2.30601 to 1.21602, saving model to model_10[]\n",
            "INFO:tensorflow:Assets written to: model_10[]/assets\n",
            "4402/4402 [==============================] - 12s 3ms/step - loss: 1.3817 - NN_RMSLE: 1.1666 - val_loss: 1.2160 - val_NN_RMSLE: 1.0978\n",
            "Epoch 3/100\n",
            "4400/4402 [============================>.] - ETA: 0s - loss: 1.1974 - NN_RMSLE: 1.0913\n",
            "Epoch 3: val_loss did not improve from 1.21602\n",
            "4402/4402 [==============================] - 12s 3ms/step - loss: 1.1973 - NN_RMSLE: 1.0913 - val_loss: 1.2162 - val_NN_RMSLE: 1.0978\n",
            "Epoch 4/100\n",
            "4397/4402 [============================>.] - ETA: 0s - loss: 1.1974 - NN_RMSLE: 1.0912\n",
            "Epoch 4: val_loss did not improve from 1.21602\n",
            "4402/4402 [==============================] - 14s 3ms/step - loss: 1.1973 - NN_RMSLE: 1.0911 - val_loss: 1.2170 - val_NN_RMSLE: 1.0981\n",
            "Epoch 5/100\n",
            "4392/4402 [============================>.] - ETA: 0s - loss: 1.1974 - NN_RMSLE: 1.0913\n",
            "Epoch 5: val_loss did not improve from 1.21602\n",
            "4402/4402 [==============================] - 13s 3ms/step - loss: 1.1973 - NN_RMSLE: 1.0912 - val_loss: 1.2161 - val_NN_RMSLE: 1.0978\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_32 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.2160722\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 13 (105375, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[1 2 3 4 5]\n",
            "train 70250 valid 35125\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_36 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1087/1098 [============================>.] - ETA: 0s - loss: 8.2451 - NN_RMSLE: 2.8586\n",
            "Epoch 1: val_loss improved from inf to 12.43781, saving model to model_13[]\n",
            "INFO:tensorflow:Assets written to: model_13[]/assets\n",
            "1098/1098 [==============================] - 5s 4ms/step - loss: 8.2351 - NN_RMSLE: 2.8569 - val_loss: 12.4378 - val_NN_RMSLE: 3.5176\n",
            "Epoch 2/100\n",
            "1098/1098 [==============================] - ETA: 0s - loss: 6.0681 - NN_RMSLE: 2.4576\n",
            "Epoch 2: val_loss improved from 12.43781 to 8.87252, saving model to model_13[]\n",
            "INFO:tensorflow:Assets written to: model_13[]/assets\n",
            "1098/1098 [==============================] - 6s 5ms/step - loss: 6.0681 - NN_RMSLE: 2.4576 - val_loss: 8.8725 - val_NN_RMSLE: 2.9727\n",
            "Epoch 3/100\n",
            "1091/1098 [============================>.] - ETA: 0s - loss: 5.3821 - NN_RMSLE: 2.3168\n",
            "Epoch 3: val_loss improved from 8.87252 to 7.26418, saving model to model_13[]\n",
            "INFO:tensorflow:Assets written to: model_13[]/assets\n",
            "1098/1098 [==============================] - 7s 6ms/step - loss: 5.3828 - NN_RMSLE: 2.3170 - val_loss: 7.2642 - val_NN_RMSLE: 2.6910\n",
            "Epoch 4/100\n",
            "1093/1098 [============================>.] - ETA: 0s - loss: 5.2644 - NN_RMSLE: 2.2923\n",
            "Epoch 4: val_loss improved from 7.26418 to 6.78001, saving model to model_13[]\n",
            "INFO:tensorflow:Assets written to: model_13[]/assets\n",
            "1098/1098 [==============================] - 4s 3ms/step - loss: 5.2651 - NN_RMSLE: 2.2925 - val_loss: 6.7800 - val_NN_RMSLE: 2.6002\n",
            "Epoch 5/100\n",
            "1086/1098 [============================>.] - ETA: 0s - loss: 5.2578 - NN_RMSLE: 2.2910\n",
            "Epoch 5: val_loss improved from 6.78001 to 6.69619, saving model to model_13[]\n",
            "INFO:tensorflow:Assets written to: model_13[]/assets\n",
            "1098/1098 [==============================] - 4s 3ms/step - loss: 5.2582 - NN_RMSLE: 2.2910 - val_loss: 6.6962 - val_NN_RMSLE: 2.5841\n",
            "Epoch 6/100\n",
            "1095/1098 [============================>.] - ETA: 0s - loss: 5.2564 - NN_RMSLE: 2.2908\n",
            "Epoch 6: val_loss improved from 6.69619 to 6.68177, saving model to model_13[]\n",
            "INFO:tensorflow:Assets written to: model_13[]/assets\n",
            "1098/1098 [==============================] - 3s 3ms/step - loss: 5.2581 - NN_RMSLE: 2.2912 - val_loss: 6.6818 - val_NN_RMSLE: 2.5814\n",
            "Epoch 7/100\n",
            "1079/1098 [============================>.] - ETA: 0s - loss: 5.2583 - NN_RMSLE: 2.2910\n",
            "Epoch 7: val_loss improved from 6.68177 to 6.67571, saving model to model_13[]\n",
            "INFO:tensorflow:Assets written to: model_13[]/assets\n",
            "1098/1098 [==============================] - 4s 3ms/step - loss: 5.2581 - NN_RMSLE: 2.2910 - val_loss: 6.6757 - val_NN_RMSLE: 2.5802\n",
            "Epoch 8/100\n",
            "1086/1098 [============================>.] - ETA: 0s - loss: 5.2596 - NN_RMSLE: 2.2915\n",
            "Epoch 8: val_loss did not improve from 6.67571\n",
            "1098/1098 [==============================] - 3s 2ms/step - loss: 5.2581 - NN_RMSLE: 2.2911 - val_loss: 6.6970 - val_NN_RMSLE: 2.5843\n",
            "Epoch 9/100\n",
            "1097/1098 [============================>.] - ETA: 0s - loss: 5.2580 - NN_RMSLE: 2.2910\n",
            "Epoch 9: val_loss improved from 6.67571 to 6.67522, saving model to model_13[]\n",
            "INFO:tensorflow:Assets written to: model_13[]/assets\n",
            "1098/1098 [==============================] - 4s 3ms/step - loss: 5.2581 - NN_RMSLE: 2.2910 - val_loss: 6.6752 - val_NN_RMSLE: 2.5801\n",
            "Epoch 10/100\n",
            "1089/1098 [============================>.] - ETA: 0s - loss: 5.2582 - NN_RMSLE: 2.2911\n",
            "Epoch 10: val_loss did not improve from 6.67522\n",
            "1098/1098 [==============================] - 3s 3ms/step - loss: 5.2580 - NN_RMSLE: 2.2911 - val_loss: 6.7327 - val_NN_RMSLE: 2.5911\n",
            "Epoch 11/100\n",
            "1096/1098 [============================>.] - ETA: 0s - loss: 5.2583 - NN_RMSLE: 2.2912\n",
            "Epoch 11: val_loss did not improve from 6.67522\n",
            "1098/1098 [==============================] - 4s 3ms/step - loss: 5.2581 - NN_RMSLE: 2.2911 - val_loss: 6.7156 - val_NN_RMSLE: 2.5879\n",
            "Epoch 12/100\n",
            "1084/1098 [============================>.] - ETA: 0s - loss: 5.2567 - NN_RMSLE: 2.2908\n",
            "Epoch 12: val_loss did not improve from 6.67522\n",
            "1098/1098 [==============================] - 3s 3ms/step - loss: 5.2581 - NN_RMSLE: 2.2911 - val_loss: 6.7078 - val_NN_RMSLE: 2.5864\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_36 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  6.707759\n",
            "\n",
            "[5 6 7 8 9]\n",
            "train 70250 valid 35125\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_40 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_32 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1094/1098 [============================>.] - ETA: 0s - loss: 12.2978 - NN_RMSLE: 3.4945\n",
            "Epoch 1: val_loss improved from inf to 5.80322, saving model to model_13[]\n",
            "INFO:tensorflow:Assets written to: model_13[]/assets\n",
            "1098/1098 [==============================] - 4s 3ms/step - loss: 12.2921 - NN_RMSLE: 3.4937 - val_loss: 5.8032 - val_NN_RMSLE: 2.3731\n",
            "Epoch 2/100\n",
            "1088/1098 [============================>.] - ETA: 0s - loss: 8.3020 - NN_RMSLE: 2.8732\n",
            "Epoch 2: val_loss improved from 5.80322 to 4.82242, saving model to model_13[]\n",
            "INFO:tensorflow:Assets written to: model_13[]/assets\n",
            "1098/1098 [==============================] - 4s 4ms/step - loss: 8.2878 - NN_RMSLE: 2.8705 - val_loss: 4.8224 - val_NN_RMSLE: 2.1897\n",
            "Epoch 3/100\n",
            "1098/1098 [==============================] - ETA: 0s - loss: 6.2832 - NN_RMSLE: 2.5027\n",
            "Epoch 3: val_loss did not improve from 4.82242\n",
            "1098/1098 [==============================] - 3s 3ms/step - loss: 6.2832 - NN_RMSLE: 2.5027 - val_loss: 5.0138 - val_NN_RMSLE: 2.2374\n",
            "Epoch 4/100\n",
            "1081/1098 [============================>.] - ETA: 0s - loss: 5.5146 - NN_RMSLE: 2.3459\n",
            "Epoch 4: val_loss did not improve from 4.82242\n",
            "1098/1098 [==============================] - 3s 2ms/step - loss: 5.5104 - NN_RMSLE: 2.3450 - val_loss: 5.5944 - val_NN_RMSLE: 2.3567\n",
            "Epoch 5/100\n",
            "1094/1098 [============================>.] - ETA: 0s - loss: 5.3318 - NN_RMSLE: 2.3067\n",
            "Epoch 5: val_loss did not improve from 4.82242\n",
            "1098/1098 [==============================] - 4s 3ms/step - loss: 5.3314 - NN_RMSLE: 2.3066 - val_loss: 5.9624 - val_NN_RMSLE: 2.4290\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_40 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_32 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  5.9624233\n",
            "\n",
            "[ 8  9 10 11 12]\n",
            "train 70250 valid 35125\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_44 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_33 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_34 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_35 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1095/1098 [============================>.] - ETA: 0s - loss: 11.2325 - NN_RMSLE: 3.3391\n",
            "Epoch 1: val_loss improved from inf to 7.61447, saving model to model_13[]\n",
            "INFO:tensorflow:Assets written to: model_13[]/assets\n",
            "1098/1098 [==============================] - 4s 3ms/step - loss: 11.2278 - NN_RMSLE: 3.3384 - val_loss: 7.6145 - val_NN_RMSLE: 2.6821\n",
            "Epoch 2/100\n",
            "1085/1098 [============================>.] - ETA: 0s - loss: 7.6257 - NN_RMSLE: 2.7537\n",
            "Epoch 2: val_loss improved from 7.61447 to 6.00069, saving model to model_13[]\n",
            "INFO:tensorflow:Assets written to: model_13[]/assets\n",
            "1098/1098 [==============================] - 3s 3ms/step - loss: 7.6115 - NN_RMSLE: 2.7510 - val_loss: 6.0007 - val_NN_RMSLE: 2.4250\n",
            "Epoch 3/100\n",
            "1087/1098 [============================>.] - ETA: 0s - loss: 5.9188 - NN_RMSLE: 2.4291\n",
            "Epoch 3: val_loss improved from 6.00069 to 5.65005, saving model to model_13[]\n",
            "INFO:tensorflow:Assets written to: model_13[]/assets\n",
            "1098/1098 [==============================] - 3s 3ms/step - loss: 5.9147 - NN_RMSLE: 2.4282 - val_loss: 5.6500 - val_NN_RMSLE: 2.3738\n",
            "Epoch 4/100\n",
            "1083/1098 [============================>.] - ETA: 0s - loss: 5.3343 - NN_RMSLE: 2.3073\n",
            "Epoch 4: val_loss did not improve from 5.65005\n",
            "1098/1098 [==============================] - 3s 3ms/step - loss: 5.3312 - NN_RMSLE: 2.3067 - val_loss: 5.7925 - val_NN_RMSLE: 2.4032\n",
            "Epoch 5/100\n",
            "1082/1098 [============================>.] - ETA: 0s - loss: 5.2154 - NN_RMSLE: 2.2815\n",
            "Epoch 5: val_loss did not improve from 5.65005\n",
            "1098/1098 [==============================] - 3s 3ms/step - loss: 5.2171 - NN_RMSLE: 2.2819 - val_loss: 5.9293 - val_NN_RMSLE: 2.4285\n",
            "Epoch 6/100\n",
            "1098/1098 [==============================] - ETA: 0s - loss: 5.2087 - NN_RMSLE: 2.2799\n",
            "Epoch 6: val_loss did not improve from 5.65005\n",
            "1098/1098 [==============================] - 3s 3ms/step - loss: 5.2087 - NN_RMSLE: 2.2799 - val_loss: 5.9618 - val_NN_RMSLE: 2.4344\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_44 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_33 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_34 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_35 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  5.9617953\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 20 (1157326, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[1 2 3 4 5 6 7 8 9]\n",
            "train 771550 valid 385776\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_48 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_36 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_38 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12045/12056 [============================>.] - ETA: 0s - loss: 202.7469 - NN_RMSLE: 1.8231\n",
            "Epoch 1: val_loss improved from inf to 1.73413, saving model to model_20[]\n",
            "INFO:tensorflow:Assets written to: model_20[]/assets\n",
            "12056/12056 [==============================] - 33s 3ms/step - loss: 202.5723 - NN_RMSLE: 1.8226 - val_loss: 1.7341 - val_NN_RMSLE: 1.3058\n",
            "Epoch 2/100\n",
            "12048/12056 [============================>.] - ETA: 0s - loss: 1.6648 - NN_RMSLE: 1.2844\n",
            "Epoch 2: val_loss improved from 1.73413 to 1.73235, saving model to model_20[]\n",
            "INFO:tensorflow:Assets written to: model_20[]/assets\n",
            "12056/12056 [==============================] - 38s 3ms/step - loss: 1.6648 - NN_RMSLE: 1.2844 - val_loss: 1.7324 - val_NN_RMSLE: 1.3049\n",
            "Epoch 3/100\n",
            "12045/12056 [============================>.] - ETA: 0s - loss: 1.6360 - NN_RMSLE: 1.2731\n",
            "Epoch 3: val_loss did not improve from 1.73235\n",
            "12056/12056 [==============================] - 36s 3ms/step - loss: 1.6360 - NN_RMSLE: 1.2731 - val_loss: 1.7348 - val_NN_RMSLE: 1.3056\n",
            "Epoch 4/100\n",
            "12049/12056 [============================>.] - ETA: 0s - loss: 1.6347 - NN_RMSLE: 1.2725\n",
            "Epoch 4: val_loss did not improve from 1.73235\n",
            "12056/12056 [==============================] - 34s 3ms/step - loss: 1.6348 - NN_RMSLE: 1.2725 - val_loss: 1.7346 - val_NN_RMSLE: 1.3056\n",
            "Epoch 5/100\n",
            "12049/12056 [============================>.] - ETA: 0s - loss: 1.6346 - NN_RMSLE: 1.2726\n",
            "Epoch 5: val_loss did not improve from 1.73235\n",
            "12056/12056 [==============================] - 35s 3ms/step - loss: 1.6347 - NN_RMSLE: 1.2726 - val_loss: 1.7327 - val_NN_RMSLE: 1.3050\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_48 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_36 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_38 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.732681\n",
            "\n",
            "[ 1  2  3  4  5  6  7  8  9 10 11]\n",
            "train 771551 valid 385775\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_52 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_39 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_40 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12040/12056 [============================>.] - ETA: 0s - loss: 114.1244 - NN_RMSLE: 2.4385\n",
            "Epoch 1: val_loss improved from inf to 1.61087, saving model to model_20[]\n",
            "INFO:tensorflow:Assets written to: model_20[]/assets\n",
            "12056/12056 [==============================] - 39s 3ms/step - loss: 113.9801 - NN_RMSLE: 2.4371 - val_loss: 1.6109 - val_NN_RMSLE: 1.2603\n",
            "Epoch 2/100\n",
            "12042/12056 [============================>.] - ETA: 0s - loss: 1.6958 - NN_RMSLE: 1.2964\n",
            "Epoch 2: val_loss improved from 1.61087 to 1.61055, saving model to model_20[]\n",
            "INFO:tensorflow:Assets written to: model_20[]/assets\n",
            "12056/12056 [==============================] - 37s 3ms/step - loss: 1.6958 - NN_RMSLE: 1.2964 - val_loss: 1.6105 - val_NN_RMSLE: 1.2601\n",
            "Epoch 3/100\n",
            "12045/12056 [============================>.] - ETA: 0s - loss: 1.6958 - NN_RMSLE: 1.2964\n",
            "Epoch 3: val_loss did not improve from 1.61055\n",
            "12056/12056 [==============================] - 34s 3ms/step - loss: 1.6957 - NN_RMSLE: 1.2964 - val_loss: 1.6120 - val_NN_RMSLE: 1.2608\n",
            "Epoch 4/100\n",
            "12037/12056 [============================>.] - ETA: 0s - loss: 1.6958 - NN_RMSLE: 1.2965\n",
            "Epoch 4: val_loss did not improve from 1.61055\n",
            "12056/12056 [==============================] - 33s 3ms/step - loss: 1.6957 - NN_RMSLE: 1.2964 - val_loss: 1.6105 - val_NN_RMSLE: 1.2601\n",
            "Epoch 5/100\n",
            "12047/12056 [============================>.] - ETA: 0s - loss: 1.6958 - NN_RMSLE: 1.2965\n",
            "Epoch 5: val_loss did not improve from 1.61055\n",
            "12056/12056 [==============================] - 39s 3ms/step - loss: 1.6957 - NN_RMSLE: 1.2965 - val_loss: 1.6106 - val_NN_RMSLE: 1.2601\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_52 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_39 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_40 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.6106187\n",
            "\n",
            "[ 2  6  7  8  9 10 11 12]\n",
            "train 771551 valid 385775\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_56 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12044/12056 [============================>.] - ETA: 0s - loss: 349.4206 - NN_RMSLE: 2.0116\n",
            "Epoch 1: val_loss improved from inf to 1.65945, saving model to model_20[]\n",
            "INFO:tensorflow:Assets written to: model_20[]/assets\n",
            "12056/12056 [==============================] - 33s 3ms/step - loss: 349.0893 - NN_RMSLE: 2.0108 - val_loss: 1.6595 - val_NN_RMSLE: 1.2817\n",
            "Epoch 2/100\n",
            "12043/12056 [============================>.] - ETA: 0s - loss: 1.6888 - NN_RMSLE: 1.2938\n",
            "Epoch 2: val_loss improved from 1.65945 to 1.65906, saving model to model_20[]\n",
            "INFO:tensorflow:Assets written to: model_20[]/assets\n",
            "12056/12056 [==============================] - 33s 3ms/step - loss: 1.6887 - NN_RMSLE: 1.2937 - val_loss: 1.6591 - val_NN_RMSLE: 1.2815\n",
            "Epoch 3/100\n",
            "12049/12056 [============================>.] - ETA: 0s - loss: 1.6723 - NN_RMSLE: 1.2876\n",
            "Epoch 3: val_loss did not improve from 1.65906\n",
            "12056/12056 [==============================] - 32s 3ms/step - loss: 1.6723 - NN_RMSLE: 1.2876 - val_loss: 1.6597 - val_NN_RMSLE: 1.2819\n",
            "Epoch 4/100\n",
            "12049/12056 [============================>.] - ETA: 0s - loss: 1.6716 - NN_RMSLE: 1.2871\n",
            "Epoch 4: val_loss did not improve from 1.65906\n",
            "12056/12056 [==============================] - 33s 3ms/step - loss: 1.6716 - NN_RMSLE: 1.2871 - val_loss: 1.6592 - val_NN_RMSLE: 1.2816\n",
            "Epoch 5/100\n",
            "12045/12056 [============================>.] - ETA: 0s - loss: 1.6714 - NN_RMSLE: 1.2869\n",
            "Epoch 5: val_loss improved from 1.65906 to 1.65906, saving model to model_20[]\n",
            "INFO:tensorflow:Assets written to: model_20[]/assets\n",
            "12056/12056 [==============================] - 32s 3ms/step - loss: 1.6715 - NN_RMSLE: 1.2869 - val_loss: 1.6591 - val_NN_RMSLE: 1.2815\n",
            "Epoch 6/100\n",
            "12052/12056 [============================>.] - ETA: 0s - loss: 1.6715 - NN_RMSLE: 1.2871\n",
            "Epoch 6: val_loss did not improve from 1.65906\n",
            "12056/12056 [==============================] - 32s 3ms/step - loss: 1.6714 - NN_RMSLE: 1.2870 - val_loss: 1.6591 - val_NN_RMSLE: 1.2816\n",
            "Epoch 7/100\n",
            "12046/12056 [============================>.] - ETA: 0s - loss: 1.6714 - NN_RMSLE: 1.2869\n",
            "Epoch 7: val_loss did not improve from 1.65906\n",
            "12056/12056 [==============================] - 38s 3ms/step - loss: 1.6714 - NN_RMSLE: 1.2869 - val_loss: 1.6594 - val_NN_RMSLE: 1.2816\n",
            "Epoch 8/100\n",
            "12045/12056 [============================>.] - ETA: 0s - loss: 1.6714 - NN_RMSLE: 1.2870\n",
            "Epoch 8: val_loss did not improve from 1.65906\n",
            "12056/12056 [==============================] - 32s 3ms/step - loss: 1.6714 - NN_RMSLE: 1.2870 - val_loss: 1.6591 - val_NN_RMSLE: 1.2816\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_56 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.6591086\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 21 (840114, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[1 2 3 4 5 6 7]\n",
            "train 560076 valid 280038\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_60 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_45 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_46 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_47 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "8740/8752 [============================>.] - ETA: 0s - loss: 135.2563 - NN_RMSLE: 2.9011\n",
            "Epoch 1: val_loss improved from inf to 4.27053, saving model to model_21[]\n",
            "INFO:tensorflow:Assets written to: model_21[]/assets\n",
            "8752/8752 [==============================] - 25s 3ms/step - loss: 135.0888 - NN_RMSLE: 2.8999 - val_loss: 4.2705 - val_NN_RMSLE: 2.0339\n",
            "Epoch 2/100\n",
            "8741/8752 [============================>.] - ETA: 0s - loss: 4.0720 - NN_RMSLE: 2.0091\n",
            "Epoch 2: val_loss did not improve from 4.27053\n",
            "8752/8752 [==============================] - 29s 3ms/step - loss: 4.0718 - NN_RMSLE: 2.0089 - val_loss: 4.4005 - val_NN_RMSLE: 2.0603\n",
            "Epoch 3/100\n",
            "8741/8752 [============================>.] - ETA: 0s - loss: 3.9510 - NN_RMSLE: 1.9788\n",
            "Epoch 3: val_loss did not improve from 4.27053\n",
            "8752/8752 [==============================] - 25s 3ms/step - loss: 3.9511 - NN_RMSLE: 1.9788 - val_loss: 4.4023 - val_NN_RMSLE: 2.0607\n",
            "Epoch 4/100\n",
            "8741/8752 [============================>.] - ETA: 0s - loss: 3.9325 - NN_RMSLE: 1.9741\n",
            "Epoch 4: val_loss did not improve from 4.27053\n",
            "8752/8752 [==============================] - 28s 3ms/step - loss: 3.9329 - NN_RMSLE: 1.9742 - val_loss: 4.3761 - val_NN_RMSLE: 2.0553\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_60 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_45 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_46 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_47 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  4.376146\n",
            "\n",
            "[ 1  2  3  4  5  6  7  8  9 10]\n",
            "train 560076 valid 280038\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_64 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_48 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_65 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_49 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_66 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_50 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_67 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "8744/8752 [============================>.] - ETA: 0s - loss: 458.6257 - NN_RMSLE: 2.4861\n",
            "Epoch 1: val_loss improved from inf to 4.53608, saving model to model_21[]\n",
            "INFO:tensorflow:Assets written to: model_21[]/assets\n",
            "8752/8752 [==============================] - 27s 3ms/step - loss: 458.2524 - NN_RMSLE: 2.4857 - val_loss: 4.5361 - val_NN_RMSLE: 2.1228\n",
            "Epoch 2/100\n",
            "8743/8752 [============================>.] - ETA: 0s - loss: 4.2769 - NN_RMSLE: 2.0611\n",
            "Epoch 2: val_loss improved from 4.53608 to 4.35869, saving model to model_21[]\n",
            "INFO:tensorflow:Assets written to: model_21[]/assets\n",
            "8752/8752 [==============================] - 25s 3ms/step - loss: 4.2768 - NN_RMSLE: 2.0611 - val_loss: 4.3587 - val_NN_RMSLE: 2.0807\n",
            "Epoch 3/100\n",
            "8740/8752 [============================>.] - ETA: 0s - loss: 4.1114 - NN_RMSLE: 2.0209\n",
            "Epoch 3: val_loss improved from 4.35869 to 4.21739, saving model to model_21[]\n",
            "INFO:tensorflow:Assets written to: model_21[]/assets\n",
            "8752/8752 [==============================] - 25s 3ms/step - loss: 4.1113 - NN_RMSLE: 2.0209 - val_loss: 4.2174 - val_NN_RMSLE: 2.0463\n",
            "Epoch 4/100\n",
            "8737/8752 [============================>.] - ETA: 0s - loss: 4.0783 - NN_RMSLE: 2.0126\n",
            "Epoch 4: val_loss did not improve from 4.21739\n",
            "8752/8752 [==============================] - 23s 3ms/step - loss: 4.0785 - NN_RMSLE: 2.0127 - val_loss: 4.2849 - val_NN_RMSLE: 2.0628\n",
            "Epoch 5/100\n",
            "8735/8752 [============================>.] - ETA: 0s - loss: 4.0704 - NN_RMSLE: 2.0106\n",
            "Epoch 5: val_loss improved from 4.21739 to 4.19612, saving model to model_21[]\n",
            "INFO:tensorflow:Assets written to: model_21[]/assets\n",
            "8752/8752 [==============================] - 24s 3ms/step - loss: 4.0707 - NN_RMSLE: 2.0108 - val_loss: 4.1961 - val_NN_RMSLE: 2.0410\n",
            "Epoch 6/100\n",
            "8746/8752 [============================>.] - ETA: 0s - loss: 4.0687 - NN_RMSLE: 2.0103\n",
            "Epoch 6: val_loss did not improve from 4.19612\n",
            "8752/8752 [==============================] - 26s 3ms/step - loss: 4.0687 - NN_RMSLE: 2.0103 - val_loss: 4.2420 - val_NN_RMSLE: 2.0523\n",
            "Epoch 7/100\n",
            "8738/8752 [============================>.] - ETA: 0s - loss: 4.0679 - NN_RMSLE: 2.0101\n",
            "Epoch 7: val_loss did not improve from 4.19612\n",
            "8752/8752 [==============================] - 30s 3ms/step - loss: 4.0680 - NN_RMSLE: 2.0100 - val_loss: 4.2492 - val_NN_RMSLE: 2.0541\n",
            "Epoch 8/100\n",
            "8746/8752 [============================>.] - ETA: 0s - loss: 4.0677 - NN_RMSLE: 2.0101\n",
            "Epoch 8: val_loss did not improve from 4.19612\n",
            "8752/8752 [==============================] - 28s 3ms/step - loss: 4.0676 - NN_RMSLE: 2.0101 - val_loss: 4.2074 - val_NN_RMSLE: 2.0438\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_64 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_48 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_65 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_49 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_66 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_50 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_67 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  4.207372\n",
            "\n",
            "[ 2  3  4  5  6  7  8  9 10 11 12]\n",
            "train 560076 valid 280038\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_68 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_51 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_69 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_52 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_70 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_53 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_71 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "8742/8752 [============================>.] - ETA: 0s - loss: 336.3048 - NN_RMSLE: 2.7166\n",
            "Epoch 1: val_loss improved from inf to 4.13322, saving model to model_21[]\n",
            "INFO:tensorflow:Assets written to: model_21[]/assets\n",
            "8752/8752 [==============================] - 24s 3ms/step - loss: 335.9560 - NN_RMSLE: 2.7158 - val_loss: 4.1332 - val_NN_RMSLE: 2.0104\n",
            "Epoch 2/100\n",
            "8750/8752 [============================>.] - ETA: 0s - loss: 4.1617 - NN_RMSLE: 2.0314\n",
            "Epoch 2: val_loss did not improve from 4.13322\n",
            "8752/8752 [==============================] - 24s 3ms/step - loss: 4.1617 - NN_RMSLE: 2.0314 - val_loss: 4.1581 - val_NN_RMSLE: 2.0128\n",
            "Epoch 3/100\n",
            "8752/8752 [==============================] - ETA: 0s - loss: 4.0088 - NN_RMSLE: 1.9939\n",
            "Epoch 3: val_loss did not improve from 4.13322\n",
            "8752/8752 [==============================] - 23s 3ms/step - loss: 4.0088 - NN_RMSLE: 1.9939 - val_loss: 4.1534 - val_NN_RMSLE: 2.0122\n",
            "Epoch 4/100\n",
            "8750/8752 [============================>.] - ETA: 0s - loss: 3.9867 - NN_RMSLE: 1.9882\n",
            "Epoch 4: val_loss did not improve from 4.13322\n",
            "8752/8752 [==============================] - 24s 3ms/step - loss: 3.9867 - NN_RMSLE: 1.9882 - val_loss: 4.1711 - val_NN_RMSLE: 2.0145\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_68 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_51 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_69 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_52 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_70 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_53 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_71 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  4.171077\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 23 (481810, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[1 2 3 4 5]\n",
            "train 321206 valid 160604\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_72 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_54 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_55 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_56 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_75 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "5014/5019 [============================>.] - ETA: 0s - loss: 544.7149 - NN_RMSLE: 2.3073\n",
            "Epoch 1: val_loss improved from inf to 4.27239, saving model to model_23[]\n",
            "INFO:tensorflow:Assets written to: model_23[]/assets\n",
            "5019/5019 [==============================] - 15s 3ms/step - loss: 544.1929 - NN_RMSLE: 2.3070 - val_loss: 4.2724 - val_NN_RMSLE: 2.0605\n",
            "Epoch 2/100\n",
            "5019/5019 [==============================] - ETA: 0s - loss: 3.6737 - NN_RMSLE: 1.9143\n",
            "Epoch 2: val_loss improved from 4.27239 to 4.24001, saving model to model_23[]\n",
            "INFO:tensorflow:Assets written to: model_23[]/assets\n",
            "5019/5019 [==============================] - 22s 4ms/step - loss: 3.6737 - NN_RMSLE: 1.9143 - val_loss: 4.2400 - val_NN_RMSLE: 2.0529\n",
            "Epoch 3/100\n",
            "5005/5019 [============================>.] - ETA: 0s - loss: 3.6668 - NN_RMSLE: 1.9126\n",
            "Epoch 3: val_loss improved from 4.24001 to 4.22921, saving model to model_23[]\n",
            "INFO:tensorflow:Assets written to: model_23[]/assets\n",
            "5019/5019 [==============================] - 15s 3ms/step - loss: 3.6669 - NN_RMSLE: 1.9126 - val_loss: 4.2292 - val_NN_RMSLE: 2.0504\n",
            "Epoch 4/100\n",
            "5009/5019 [============================>.] - ETA: 0s - loss: 3.6640 - NN_RMSLE: 1.9118\n",
            "Epoch 4: val_loss improved from 4.22921 to 4.18874, saving model to model_23[]\n",
            "INFO:tensorflow:Assets written to: model_23[]/assets\n",
            "5019/5019 [==============================] - 14s 3ms/step - loss: 3.6642 - NN_RMSLE: 1.9119 - val_loss: 4.1887 - val_NN_RMSLE: 2.0408\n",
            "Epoch 5/100\n",
            "5012/5019 [============================>.] - ETA: 0s - loss: 3.6637 - NN_RMSLE: 1.9117\n",
            "Epoch 5: val_loss did not improve from 4.18874\n",
            "5019/5019 [==============================] - 14s 3ms/step - loss: 3.6636 - NN_RMSLE: 1.9117 - val_loss: 4.2263 - val_NN_RMSLE: 2.0497\n",
            "Epoch 6/100\n",
            "5013/5019 [============================>.] - ETA: 0s - loss: 3.6630 - NN_RMSLE: 1.9116\n",
            "Epoch 6: val_loss did not improve from 4.18874\n",
            "5019/5019 [==============================] - 15s 3ms/step - loss: 3.6630 - NN_RMSLE: 1.9116 - val_loss: 4.2232 - val_NN_RMSLE: 2.0490\n",
            "Epoch 7/100\n",
            "5018/5019 [============================>.] - ETA: 0s - loss: 3.6628 - NN_RMSLE: 1.9116\n",
            "Epoch 7: val_loss did not improve from 4.18874\n",
            "5019/5019 [==============================] - 13s 3ms/step - loss: 3.6629 - NN_RMSLE: 1.9116 - val_loss: 4.2071 - val_NN_RMSLE: 2.0452\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_72 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_54 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_55 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_56 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_75 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  4.2070765\n",
            "\n",
            "[4 5 6 7 8 9]\n",
            "train 321207 valid 160603\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_76 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_57 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_77 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_58 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_78 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_59 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_79 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "5005/5019 [============================>.] - ETA: 0s - loss: 712.8914 - NN_RMSLE: 2.4848\n",
            "Epoch 1: val_loss improved from inf to 3.76731, saving model to model_23[]\n",
            "INFO:tensorflow:Assets written to: model_23[]/assets\n",
            "5019/5019 [==============================] - 14s 3ms/step - loss: 710.9344 - NN_RMSLE: 2.4835 - val_loss: 3.7673 - val_NN_RMSLE: 1.9394\n",
            "Epoch 2/100\n",
            "5008/5019 [============================>.] - ETA: 0s - loss: 3.9943 - NN_RMSLE: 1.9957\n",
            "Epoch 2: val_loss did not improve from 3.76731\n",
            "5019/5019 [==============================] - 15s 3ms/step - loss: 3.9944 - NN_RMSLE: 1.9957 - val_loss: 3.7904 - val_NN_RMSLE: 1.9453\n",
            "Epoch 3/100\n",
            "5006/5019 [============================>.] - ETA: 0s - loss: 3.8655 - NN_RMSLE: 1.9636\n",
            "Epoch 3: val_loss did not improve from 3.76731\n",
            "5019/5019 [==============================] - 13s 3ms/step - loss: 3.8655 - NN_RMSLE: 1.9636 - val_loss: 3.7940 - val_NN_RMSLE: 1.9463\n",
            "Epoch 4/100\n",
            "5008/5019 [============================>.] - ETA: 0s - loss: 3.8210 - NN_RMSLE: 1.9524\n",
            "Epoch 4: val_loss did not improve from 3.76731\n",
            "5019/5019 [==============================] - 18s 4ms/step - loss: 3.8205 - NN_RMSLE: 1.9522 - val_loss: 3.8515 - val_NN_RMSLE: 1.9608\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_76 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_57 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_77 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_58 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_78 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_59 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_79 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  3.8514543\n",
            "\n",
            "[ 8  9 10 11 12]\n",
            "train 321207 valid 160603\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_80 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_60 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_81 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_61 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_82 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_62 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_83 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "5008/5019 [============================>.] - ETA: 0s - loss: 144.2596 - NN_RMSLE: 2.2389\n",
            "Epoch 1: val_loss improved from inf to 3.87205, saving model to model_23[]\n",
            "INFO:tensorflow:Assets written to: model_23[]/assets\n",
            "5019/5019 [==============================] - 15s 3ms/step - loss: 143.9560 - NN_RMSLE: 2.2383 - val_loss: 3.8720 - val_NN_RMSLE: 1.9663\n",
            "Epoch 2/100\n",
            "5002/5019 [============================>.] - ETA: 0s - loss: 3.7818 - NN_RMSLE: 1.9422\n",
            "Epoch 2: val_loss did not improve from 3.87205\n",
            "5019/5019 [==============================] - 14s 3ms/step - loss: 3.7816 - NN_RMSLE: 1.9422 - val_loss: 3.8790 - val_NN_RMSLE: 1.9681\n",
            "Epoch 3/100\n",
            "5006/5019 [============================>.] - ETA: 0s - loss: 3.7374 - NN_RMSLE: 1.9309\n",
            "Epoch 3: val_loss did not improve from 3.87205\n",
            "5019/5019 [==============================] - 16s 3ms/step - loss: 3.7370 - NN_RMSLE: 1.9309 - val_loss: 3.8742 - val_NN_RMSLE: 1.9668\n",
            "Epoch 4/100\n",
            "4997/5019 [============================>.] - ETA: 0s - loss: 3.7236 - NN_RMSLE: 1.9275\n",
            "Epoch 4: val_loss did not improve from 3.87205\n",
            "5019/5019 [==============================] - 14s 3ms/step - loss: 3.7235 - NN_RMSLE: 1.9275 - val_loss: 3.8797 - val_NN_RMSLE: 1.9683\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_80 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_60 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_81 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_61 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_82 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_62 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_83 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  3.879699\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAZO0lEQVR4nO3deZRkZXnH8e9TW/f0LMww044ji6MwQQkamLSYOGAwBAJRAaPHBBXJOmogcUtykCQGl3NichJMThKNbBEVMCqrxIigRMIhoD0DOgsgSwBnHGaaZZiepZeqevLHvVVTXV3VtXS9Vd3c3+ecPrfq3rq3Hsfmd9967lu3zd0REZHkSPW6ABER6S4Fv4hIwij4RUQSRsEvIpIwCn4RkYTJ9LqAZqxYscJXr17d6zJEROaVDRs2POPug9Xr50Xwr169muHh4V6XISIyr5jZk7XWq9UjIpIwCn4RkYRR8IuIJIyCX0QkYRT8IiIJo+AXEUkYBb+ISMIo+EVEEkbBLyKSMAp+EZGEUfCLiCSMgl9EJGEU/CIiCaPgFxFJGAW/iEjCKPhFRBJGwS8ikjAKfhGRhFHwi4gkTLDgN7MjzOxOM9tqZlvM7IPx+kvMbLuZPRD//EaoGkREZLqQf2w9D3zU3Tea2WJgg5ndHm/7rLv/fcD3FhGROoIFv7vvAHbEj0fN7EHgsFDvJyIizelKj9/MVgMnAPfFqy40sx+b2VVmtqzOPuvNbNjMhkdGRrpRpohIIgQPfjNbBFwPfMjd9wCfB44Cjif6RPAPtfZz98vcfcjdhwYHB0OXKSKSGEGD38yyRKF/jbvfAODuO9294O5F4HLgxJA1iIjIVCFn9RhwJfCgu19asX5VxcveBmwOVYOIiEwXclbPOuA8YJOZPRCvuxg418yOBxx4AnhfwBpERKRKyFk9dwNWY9O3Qr2niIg0pm/uiogkjIJfRCRhFPwiIgmj4BcRSRgFv4hIwij4RUQSRsEvIpIwCn4RkYRR8IuIJIyCX0QkYRT8IiIJo+AXEUkYBb+ISMIo+EVEEkbBLyKSMAp+EZGEUfCLiCSMgl9EJGEU/CIiCaPgFxFJGAW/iEjCKPhFRBJGwS8ikjAKfhGRhFHwi4gkjIJfRCRhFPwiIgmj4BcRSRgFv4hIwgQLfjM7wszuNLOtZrbFzD4Yrz/UzG43s0fi5bJQNYiIyHQhR/x54KPufizwS8AFZnYscBHwXXdfA3w3fi4iIl0SLPjdfYe7b4wfjwIPAocBZwNXxy+7GjgnVA0iIjJdV3r8ZrYaOAG4D1jp7jviTU8DK7tRg4iIRIIHv5ktAq4HPuTueyq3ubsDXme/9WY2bGbDIyMjocsUEUmMoMFvZlmi0L/G3W+IV+80s1Xx9lXArlr7uvtl7j7k7kODg4MhyxQRSZSQs3oMuBJ40N0vrdh0C3B+/Ph84OZQNYiIyHSZgMdeB5wHbDKzB+J1FwOfAb5mZr8PPAm8M2ANIiJSJVjwu/vdgNXZfGqo9xURkZnpm7siIgmj4BcRSRgFv4hIwij4RUQSRsEvIpIwCn4RkYRR8IuIJIyCX0QkYRT8IiIJo+AXEUkYBb+ISMIo+EVEEkbBLyKSMAp+EZGEUfCLiCSMgl9EJGEU/CIiCaPgFxFJGAW/iEjCKPhFRBJGwS8ikjAKfhGRhFHwi4gkjIJfRCRhFPwiIgnTVPCb2Q1m9mYz04lCRGSeazbIPwe8C3jEzD5jZscErElERAJqKvjd/Q53fzewFngCuMPM7jGz3zWzbMgCRUSks5pu3ZjZcuB3gD8A7gf+iehEcHuQykREJIhMMy8ysxuBY4AvA2919x3xpv8ws+FQxYmISOc1O+K/3N2Pdfe/KYW+mfUBuPtQrR3M7Coz22VmmyvWXWJm283sgfjnN2b9v0BERFrSbPB/usa6/22wzxeBM2qs/6y7Hx//fKvJ9xcRkQ6ZsdVjZi8FDgMWmNkJgMWblgADM+3r7neZ2epOFCkiIp3TqMf/60QXdA8HLq1YPwpc3OZ7Xmhm7wWGgY+6+/O1XmRm64H1AEceeWSbbyUiItXM3Ru/yOzt7n59ywePRvy3uvtx8fOVwDOAA58CVrn77zU6ztDQkA8P6xqyiEgrzGxDreuwjVo973H3rwCrzewj1dvd/dIau9Xl7jsrjn05cGsr+4uIyOw1avUsjJeLOvFmZraqYiro24DNM71eREQ6b8bgd/cvxMtPtHpgM7sOOAVYYWbbgL8GTjGz44laPU8A72v1uCIiMjvNfoHr74imdB4Avg28Fvhw3Aaqyd3PrbH6ynaKFBGRzml2Hv/p7r4HeAvRSP1o4M9CFSUiIuE0G/ylTwZvBr7u7i8EqkdERAJrqtUD3GpmDxG1ej5gZoPAWLiyREQklGZvy3wR8AZgyN0ngX3A2SELExGRMJod8QO8img+f+U+X+pwPSIiElizs3q+DBwFPAAU4tWOgl9EZN5pdsQ/BBzrzdzfQURE5rRmZ/VsBl4ashAREemOZkf8K4CtZvYDYLy00t3PClKViIgE02zwXxKyCBER6Z6mgt/dv29mLwfWuPsdZjYApMOWJiIiITTV4zezPwS+AXwhXnUYcFOgmkREJKBmL+5eAKwD9gC4+yPAS0IVJSIi4TQb/OPuPlF6En+JS1M7RUTmoWaD//tmdjHRH10/Dfg68M1wZYmISCjNBv9FwAiwieiPp3wL+MtQRYmISDjNzuopmtlNwE3uPhK2JBERCWnGEb9FLjGzZ4CHgYfNbMTMPt6d8kREpNMatXo+TDSb53Xufqi7Hwq8HlhnZh8OXp2IiHRco+A/DzjX3f+vtMLdHwfeA7w3ZGEiIhJGo+DPuvsz1SvjPn82TEkiIhJSo+CfaHObiIjMUY1m9fyCme2psd6A/gD1iIhIYDMGv7vrRmwiIi8yzX6BS0REXiQU/CIiCaPgFxFJGAW/iEjCKPhFRBJGwS8ikjDBgt/MrjKzXWa2uWLdoWZ2u5k9Ei+XhXp/ERGpLeSI/4vAGVXrLgK+6+5rgO/Gz0VEpIuCBb+73wU8V7X6bODq+PHVwDmh3l9ERGrrdo9/pbvviB8/Days90IzW29mw2Y2PDKiv/0iItIpPbu46+7ODH+w3d0vc/chdx8aHBzsYmUiIi9u3Q7+nWa2CiBe7ury+4uIJF63g/8W4Pz48fnAzV1+fxGRxAs5nfM64H+BY8xsm5n9PvAZ4DQzewT4tfi5iIh0UaP78bfN3c+ts+nUUO8pIiKN6Zu7IiIJo+AXEUkYBb+Et20YCvnW9nnyHthf/f2/WGEStm+cfV0iCaXgl7CeeRSuOBW+8xfN71OYhH8/E750du3td1wCl78JRh7uSIkiSaPgl7DGXoiWT97T/D6lkf7TP669ffuGaLlP3+gWaYeCX8Ka2Bst07nm95ncP/N2L05dikhLFPwSVnEyflD37hw19inMvL10Yii2eN1ARAAFv4RWuqjbKMwrlU8WdeQn4mM3eJ2I1KTgl7BKo3JvIfgbBbpZ/LqJ9moSSTgFv4RVGr17K62eBi0ci39tFfwibVHwS1ilFk9LrZ5GvfvSiF+tHpF2KPglrFI4q9UjMmco+CWsUqunkxd3Ffwis6Lgl7DamXKpVo9IUAp+CavVe/Q0s49G/CKzouCXsMqj91Zm9TRq9cS/tnkFv0g7FPwSVqMQr7lPk58S9M1dkbYo+CWsdvrwjVo95W8Dq8cv0g4Fv4TVymye8j4NAr000tfFXZG2KPglrLamczYY8bdzTBEpU/BLWKUQb6UfXzmSr3Wrh9J2tXpE2qLgl7BKId1KW6byJFFrVK9Wj8isKPglrPK9eloI6cpAr/VJoaiLuyKzoeCXsErh3MoXuaaM+GuEe0E9fpHZUPBLWOWQbiX4mxzxq9Uj0hYFv4TVVqsnX/tx+Zhq9YjMhoJfwipWjPib/WMsavWIBKXgl7CmhHizt2JQq0ckJAW/hFUZzs0G9ZRWT9U+xQLlG76p1SPSFgW/hFXZjmk2qKeM+KvaOe18ghCRKTK9eFMzewIYBQpA3t2HelGHdMFMIV53nxl6/MUGF35FpKGeBH/sTe7+TA/fX7qhrVbPDPtM+XKXWj0i7VCrR8JqNEOn4T7VrZ6K57q4K9KWXgW/A98xsw1mtr7WC8xsvZkNm9nwyMhIl8uTjinOcKG2mX2mtXraaB2JyBS9Cv6T3H0tcCZwgZm9sfoF7n6Zuw+5+9Dg4GD3K5TOaOdi7Ez36mnnE4SITNGT4Hf37fFyF3AjcGIv6pAuaKfHP9OnhHY+QYjIFF0PfjNbaGaLS4+B04HN3a5DuqTTI/7STB5LaTqnSJt6MatnJXCjmZXe/1p3/3YP6pBuKOYh0w/5sdYu7loavFC/1ZNZoOAXaVPXg9/dHwd+odvvKz1SmITsgij4m513X4z3mdhbv9WT7VerR6RNms4pYRXz0egcmh/xF/JR8Nfap/RcI36Rtin4JaxiRYg3fXF3siL468zjz/Yr+EXapOCXsAqVId7Cxd1MnZNFZY9frR6Rtij4JazK0XvTI/5CNKKHGrN64mNoxC/SNgW/hDWlX9/Kxd2Bg4+nbCuN+Pujbc3+cRcRKVPwS1gzhXg9hcko2GH6TKDyrJ461wBEpCEFv4RV2eNvaTpn6WRRbx5//8HXikhLFPwSjnv0JayWR/wzTeesHvGrzy/SKgW/hFO6EFtu27QynbPBxd1WjykiZQp+Cac0Wm/54m5+hh5/aR6/Rvwi7VLwSzjlqZd1+vV198tDOhfdr2emWT2tHFNEynr5pxfnlWvve2raune9/sgeVDKPVPfjW2n1pDLRz7SLu1UnE7V6RFqmEb+EM23E38J0znQ2+qk7nVMjfpF2KfglnOoefzPTOUszgVLZOiP+uMefUY9fpF0KfgmnPAOnD7DmRvylIC+3eqr2qbxlQ+VzEWmagl/CqQzxdLa5kC69Jl1nn8qbtIG+wCXSBgW/hFMO8Tptm1pKQV5u9VTflrmqx9/st4FFpEzBL+FMCfFsc8FfCvLyyaJOq0c9fpG2KfglnMoQT2eaa/WUTxZxq2faN3fHo22ZvqmvF5GmKfglnMoQT2WbC+n8eLTM9EX7VZ8s8uOQ7otOCqCLuyJtUPBLOPmxaJnprz0nv+Y+peDvr31dID928KQAui2zSBsU/BJOKcSz/bX79TX3qThZ1Az+8YPbQK0ekTYo+CWcyQPRshTUzbRlKkf86SwUJqZvz+TU6hGZBQV/E9wd15/4a111q6eZGTj50smiL7rVQ+nkUXnMKSN+zeoRaZVu0lbHCwcmueyux/jmj3bw1HP7SRkc/ZJFvG71oRy7aglm1usS575S8GcXND+Pv9weWgC5hbB359TthYnozp2l+/9M7u9cvSIJoeCv4cfbdnPBtRvZ/vwBTlozyDnHv4zhJ59n6449XHPfU/zcykX85gmH97rMuW+yYsSf6TsY6jMpf0rog77FML636pgHouP1L4mej492rl6RhFDwV3B3vnzvk3z61gdZsSjHNz7wBtYeuQyIbst85nGruPfxZ7l9607+9c5HGVq9jKHVh/a46jksX9Hj71sCB55vvE/5usACyC2CiapgHx+FBcuibaXnItIS9fhjo2OTXHjt/Xz85i2ctGYF//knJ5dDvySdMtYdvYIPnHIUuUyKcy+/ly/f+6T6//WMj0bz9zN9sGApjO1uvM/YC9Gy/5Co1TOxb/ox+5dAKh2Fv4JfpGUa8QNbfvYCF1yzkZ8+f4CLznwV609+JalU/R7+yiX9/NEpR3P3oyP81U2b2bRtN588+zj6s+kuVj0PHHg+Cnwz6F8KB3Y33qd0cuhfAn2Lop5+fiKayQNR0Pctjh73LYbxPZ2vW+RFLtEj/nyhyOV3Pc7bPncPByYLfHX9L/H+XzlqxtAvWZBLc+X5r+NPfvVovja8jXf82z1s/ZlCaIoDu6O2DMQj/hei++3PZOyFqM2T6YNcHPATFX3+8T1R2wii4B/Tv7lIq3oy4jezM4B/AtLAFe7+mW6+f75Q5LYtO/nn7z3CQ0+P8muvfgl/+/bXsnxRX0vHSaWMj5x+DMcddggfu2ETZ/3L3bzzdUfw/jcexZHLBwJV31kh/qRk6ZinPr0d84Xccd9TvGoXrPXCwVZNPXtH2Jc5hJvve4qX73DWATfdfT/PDbySt716Ecsm9zOaW8HY6DhLc0tg77Ps3TeBGRiGpaDytF15mplyzvHSwmtun7qfU/SDy6J79FOseBxvL7iTLziFYvS4UDz4PF8sRuuLpeeVyyKFIhSKxar1U1+TLzqFQvS86D7leWl70R0zI5sysukUmXSKXNrIpFNk48f9uTQD2TQDuQwDfWkGcmkWZDMM5OLHuXhbLk1fJqVZbC8yXQ9+M0sD/wqcBmwDfmhmt7j71k6/V7Ho7D4wycjoOCOj4zzx7D4e+OluvvfQLp7bN8ErVyzkc+9ey5nHvXRWv9in//xLOfEVh/L333mYr/1wG9fe9xTHH7GUk45ewbEvW8LKJf28ZHEfyxbmyKaNbCrV1KeKVrk7E4UiByYK7C//5Hl+/yS790/w/L6J8uPn4uVjI3vLry0Wnb5MisvueoxDFmRZvqiP5QtzLF/Ux4pFOZYvyrF0QY5UykhZFJSjY3lGxybZMzbJc/smeW7fOJu2vcC+iQKn7X+Uu/21fPLWLZxBnrVp+K2/+Qo/SR9NOpUikzLSKSOTNgpFZzJf4MrJYUaLy/n4zZs5zidY1wf/9d//w23FMW75z0e5qQ/+9Pbd3HbbHfxDtp9fTm3hDZ+6veP/lnNRuvTvFS9LjyfyRVJmpFKGASkznOgkUnSik0HFiahQbO2aVMqgL5OmL5uiL5OKHmdS8fM02XRUS8riuuJaoiUN15e3pwwzSDe5vnwso/y4qfWp6FiZtJFOpcrbM+no2NX/vukpz1OkUkRLY96eEHsx4j8ReNTdHwcws68CZwMdD/6/uGkT1/3gp1PWLR3IcvKaQd762lWc+uqVpDsUwEsHcnz6nNdw4ZvWcMP92/j25qf5/Pcfq/sfWcogk06VAxQqRplVo9Hq7aWLyQeft1brIQuyLBvIsnQgx+K+LCsX9zOQS5NOGWOTRVYe0s/u/RPs3DPG1p/t4dl940wWGr9JLp1i2cIsKTOWZIvszBzGswOvYe3iZeQLJ1LYmeE/+BjjLMCKjhWKmBdJEf2UXH/Iebxh6XL6Wcy+7Yv5Qu6zTFiOnE9QtAyn/fpZnJRbzuFPncy+J0Y56+cGKcS/yg6ccMRSav33uPGp3dT6f7vef7s25TVR+KSIluVPGHZwm8WvSxvlIE7FAVReX153MMxKJ9Lp6w6GV+nYneDuTBaiQcJkvshEochEvKz3PF9wJotOvhB9qsjH68YmJsnHJ5jqT0aO117vjpc/OU19XWm9+9RPXXNV+cRUZ3v9363aG2q9/gvn/SInrxlsr8A6rNszUszsHcAZ7v4H8fPzgNe7+4VVr1sPrI+fHgM83NVCp1sBPNPjGhqZDzXC/KhTNXbOfKhzPtQIrdf5cnefdtaYs7N63P0y4LJe11FiZsPuPtTrOmYyH2qE+VGnauyc+VDnfKgROldnL2b1bAeOqHh+eLxORES6oBfB/0NgjZm9wsxywG8Dt/SgDhGRROp6q8fd82Z2IXAb0XTOq9x9S7fraMOcaTvNYD7UCPOjTtXYOfOhzvlQI3Sozq5f3BURkd5K9Dd3RUSSSMEvIpIwCv4GzOwMM3vYzB41s4t6XU8tZnaVme0ys829rqUeMzvCzO40s61mtsXMPtjrmmoxs34z+4GZ/Siu8xO9rqkeM0ub2f1mdmuva6nFzJ4ws01m9oCZDfe6nnrMbKmZfcPMHjKzB83sl3tdUyUzOyb+Nyz97DGzD83qmOrx1xffXuInVNxeAjg3xO0lZsPM3gjsBb7k7sf1up5azGwVsMrdN5rZYmADcM4c/Lc0YKG77zWzLHA38EF3v7fHpU1jZh8BhoAl7v6WXtdTzcyeAIbcfU5/McrMrgb+x92viGcaDrj77h6XVVOcSduJvvT6ZLvH0Yh/ZuXbS7j7BFC6vcSc4u53Ac/1uo6ZuPsOd98YPx4FHgQO621V03mkdDvQbPwz50ZHZnY48Gbgil7XMp+Z2SHAG4ErAdx9Yq6GfuxU4LHZhD4o+Bs5DKi82c825mBYzTdmtho4Abivx6XUFLdQHgB2Abe7+1ys8x+BP4eKmxzNPQ58x8w2xLdgmYteAYwA/x63za4ws4W9LmoGvw1cN9uDKPilq8xsEXA98CF3n5M303f3grsfT/St8hPNbE61z8zsLcAud9/Q61oaOMnd1wJnAhfELcm5JgOsBT7v7icA+4C5ei0vB5wFfH22x1Lwz0y3l+iguGd+PXCNu9/Q63oaiT/y3wmc0eNSqq0Dzop76F8FftXMvtLbkqZz9+3xchdwI1HrdK7ZBmyr+FT3DaITwVx0JrDR3XfO9kAK/pnp9hIdEl80vRJ40N0v7XU99ZjZoJktjR8vILqw/1BPi6ri7h9z98PdfTXR7+T33P09PS5rCjNbGF/EJ26dnA7MuVln7v408FMzOyZedSoBbhHfIefSgTYPzOG7c84F8+X2EmZ2HXAKsMLMtgF/7e5X9raqadYB5wGb4v45wMXu/q3elVTTKuDqePZECviau8/J6ZJz3ErgxvhvCGSAa939270tqa4/Bq6JB3ePA7/b43qmiU+epwHv68jxNJ1TRCRZ1OoREUkYBb+ISMIo+EVEEkbBLyKSMAp+EZGEUfCLiCSMgl9EJGH+H+ekRt4HagYRAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 30 (2368873, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[ 1  2  3  4  5  6  7  8 12]\n",
            "train 1579248 valid 789625\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_84 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_63 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_85 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_64 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_86 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_65 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_87 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "24666/24676 [============================>.] - ETA: 0s - loss: 20.3431 - NN_RMSLE: 1.5673\n",
            "Epoch 1: val_loss improved from inf to 1.95915, saving model to model_30[]\n",
            "INFO:tensorflow:Assets written to: model_30[]/assets\n",
            "24676/24676 [==============================] - 82s 3ms/step - loss: 20.3358 - NN_RMSLE: 1.5672 - val_loss: 1.9591 - val_NN_RMSLE: 1.3896\n",
            "Epoch 2/100\n",
            "24671/24676 [============================>.] - ETA: 0s - loss: 1.9702 - NN_RMSLE: 1.3975\n",
            "Epoch 2: val_loss did not improve from 1.95915\n",
            "24676/24676 [==============================] - 80s 3ms/step - loss: 1.9703 - NN_RMSLE: 1.3975 - val_loss: 1.9604 - val_NN_RMSLE: 1.3901\n",
            "Epoch 3/100\n",
            "24665/24676 [============================>.] - ETA: 0s - loss: 1.9693 - NN_RMSLE: 1.3973\n",
            "Epoch 3: val_loss did not improve from 1.95915\n",
            "24676/24676 [==============================] - 69s 3ms/step - loss: 1.9693 - NN_RMSLE: 1.3973 - val_loss: 1.9663 - val_NN_RMSLE: 1.3923\n",
            "Epoch 4/100\n",
            "24665/24676 [============================>.] - ETA: 0s - loss: 1.9693 - NN_RMSLE: 1.3972\n",
            "Epoch 4: val_loss did not improve from 1.95915\n",
            "24676/24676 [==============================] - 70s 3ms/step - loss: 1.9693 - NN_RMSLE: 1.3972 - val_loss: 1.9653 - val_NN_RMSLE: 1.3919\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_84 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_63 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_85 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_64 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_86 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_65 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_87 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.9652711\n",
            "\n",
            "[ 2  3  4  5  6  7  8  9 10 12]\n",
            "train 1579249 valid 789624\n",
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_88 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_66 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_89 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_67 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_90 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_68 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_91 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "24675/24676 [============================>.] - ETA: 0s - loss: 30.4273 - NN_RMSLE: 1.5671\n",
            "Epoch 1: val_loss improved from inf to 1.96484, saving model to model_30[]\n",
            "INFO:tensorflow:Assets written to: model_30[]/assets\n",
            "24676/24676 [==============================] - 66s 3ms/step - loss: 30.4265 - NN_RMSLE: 1.5671 - val_loss: 1.9648 - val_NN_RMSLE: 1.3937\n",
            "Epoch 2/100\n",
            "24665/24676 [============================>.] - ETA: 0s - loss: 1.9733 - NN_RMSLE: 1.3987\n",
            "Epoch 2: val_loss did not improve from 1.96484\n",
            "24676/24676 [==============================] - 75s 3ms/step - loss: 1.9732 - NN_RMSLE: 1.3987 - val_loss: 1.9689 - val_NN_RMSLE: 1.3952\n",
            "Epoch 3/100\n",
            "24665/24676 [============================>.] - ETA: 0s - loss: 1.9731 - NN_RMSLE: 1.3986\n",
            "Epoch 3: val_loss improved from 1.96484 to 1.96463, saving model to model_30[]\n",
            "INFO:tensorflow:Assets written to: model_30[]/assets\n",
            "24676/24676 [==============================] - 97s 4ms/step - loss: 1.9731 - NN_RMSLE: 1.3986 - val_loss: 1.9646 - val_NN_RMSLE: 1.3937\n",
            "Epoch 4/100\n",
            "24665/24676 [============================>.] - ETA: 0s - loss: 1.9731 - NN_RMSLE: 1.3986\n",
            "Epoch 4: val_loss did not improve from 1.96463\n",
            "24676/24676 [==============================] - 100s 4ms/step - loss: 1.9731 - NN_RMSLE: 1.3986 - val_loss: 1.9661 - val_NN_RMSLE: 1.3942\n",
            "Epoch 5/100\n",
            "24662/24676 [============================>.] - ETA: 0s - loss: 1.9731 - NN_RMSLE: 1.3987\n",
            "Epoch 5: val_loss did not improve from 1.96463\n",
            "24676/24676 [==============================] - 104s 4ms/step - loss: 1.9732 - NN_RMSLE: 1.3987 - val_loss: 1.9716 - val_NN_RMSLE: 1.3961\n",
            "Epoch 6/100\n",
            "24665/24676 [============================>.] - ETA: 0s - loss: 1.9731 - NN_RMSLE: 1.3986\n",
            "Epoch 6: val_loss did not improve from 1.96463\n",
            "24676/24676 [==============================] - 100s 4ms/step - loss: 1.9731 - NN_RMSLE: 1.3986 - val_loss: 1.9743 - val_NN_RMSLE: 1.3971\n",
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_88 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_66 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_89 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_67 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_90 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_68 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_91 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.9743325\n",
            "\n",
            "[ 3  4  6  7  8  9 10 11 12]\n",
            "train 1579249 valid 789624\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_92 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_69 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_93 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_70 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_94 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_71 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_95 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "24674/24676 [============================>.] - ETA: 0s - loss: 48.8735 - NN_RMSLE: 1.5852\n",
            "Epoch 1: val_loss improved from inf to 1.99985, saving model to model_30[]\n",
            "INFO:tensorflow:Assets written to: model_30[]/assets\n",
            "24676/24676 [==============================] - 107s 4ms/step - loss: 48.8702 - NN_RMSLE: 1.5852 - val_loss: 1.9999 - val_NN_RMSLE: 1.4053\n",
            "Epoch 2/100\n",
            "24665/24676 [============================>.] - ETA: 0s - loss: 1.9514 - NN_RMSLE: 1.3907\n",
            "Epoch 2: val_loss improved from 1.99985 to 1.99821, saving model to model_30[]\n",
            "INFO:tensorflow:Assets written to: model_30[]/assets\n",
            "24676/24676 [==============================] - 90s 4ms/step - loss: 1.9514 - NN_RMSLE: 1.3908 - val_loss: 1.9982 - val_NN_RMSLE: 1.4047\n",
            "Epoch 3/100\n",
            "24668/24676 [============================>.] - ETA: 0s - loss: 1.9509 - NN_RMSLE: 1.3907\n",
            "Epoch 3: val_loss did not improve from 1.99821\n",
            "24676/24676 [==============================] - 102s 4ms/step - loss: 1.9510 - NN_RMSLE: 1.3907 - val_loss: 2.0038 - val_NN_RMSLE: 1.4067\n",
            "Epoch 4/100\n",
            "24674/24676 [============================>.] - ETA: 0s - loss: 1.9509 - NN_RMSLE: 1.3907\n",
            "Epoch 4: val_loss did not improve from 1.99821\n",
            "24676/24676 [==============================] - 94s 4ms/step - loss: 1.9509 - NN_RMSLE: 1.3907 - val_loss: 2.0010 - val_NN_RMSLE: 1.4057\n",
            "Epoch 5/100\n",
            "24665/24676 [============================>.] - ETA: 0s - loss: 1.9509 - NN_RMSLE: 1.3907\n",
            "Epoch 5: val_loss did not improve from 1.99821\n",
            "24676/24676 [==============================] - 103s 4ms/step - loss: 1.9509 - NN_RMSLE: 1.3907 - val_loss: 2.0016 - val_NN_RMSLE: 1.4059\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_92 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_69 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_93 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_70 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_94 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_71 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_95 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  2.0015588\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD4CAYAAAAD6PrjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAATv0lEQVR4nO3df5BlZX3n8fdnZtCIxqDSEjKDzpQhWMSsC9VL2LCVSokxGF2wKq6FG5EQ3NkfxBiw1iC7pW7VVq27sTSkasNmAsZxQ4EEibDGGBFN3GQDSfNDRZB1ChUGwWliBJckwsx89497+tD0dE/37e57z+0z71dV1z3nOefe851bc/vTz/Occ26qCkmSADZ1XYAkaXIYCpKklqEgSWoZCpKklqEgSWpt6bqAtTj22GNr+/btXZchSRvK7bff/mhVTS22bUOHwvbt25mZmem6DEnaUJJ8c6ltDh9JklqGgiSpZShIklqGgiSpZShIklqGgiSpZShIklqGgiSpZShIklqGgiSpZShIklqGgiSpNbJQSPLhJPuS3L3ItncmqSTHNutJ8ltJ9iT5UpJTR1WXJGlpo+wpfAQ4a2FjkhOA1wAPzGt+LXBi87MTuGKEdUmSljCyUKiqLwDfWWTTh4B3ATWv7RzgozVwK3BMkuNHVZskaXFjnVNIcg7wUFV9ccGmrcCD89b3Nm2LvcbOJDNJZmZnZ0dUqSQdmcYWCkmOBi4D3rOW16mqXVU1XVXTU1OLfnGQJGmVxvnNay8DdgBfTAKwDbgjyWnAQ8AJ8/bd1rRJksZobD2FqvpyVb24qrZX1XYGQ0SnVtUjwE3AW5uzkE4HHquqh8dVmyRpYJSnpF4D/CVwUpK9SS48zO6fAu4H9gC/C/y7UdUlSVrayIaPqurNy2zfPm+5gItGVYskaWW8olmS1DIUJEktQ0GS1DIUJEktQ0GS1DIUJEktQ0GS1DIUJEktQ0GS1DIUJEktQ0GS1DIUJEktQ0GS1DIUJEktQ0GS1DIUJEktQ0GS1DIUJEktQ0GS1DIUJEmtkYVCkg8n2Zfk7nltv5Hkq0m+lOQPkxwzb9u7k+xJcl+SnxtVXZKkpY2yp/AR4KwFbTcDr6iqfwT8X+DdAElOBs4Ffrx5zm8n2TzC2iRJixhZKFTVF4DvLGj7TFXtb1ZvBbY1y+cA11bV96vq68Ae4LRR1SZJWlyXcwq/DPxxs7wVeHDetr1N2yGS7Ewyk2RmdnZ2xCVK0pGlk1BI8h+A/cDVwz63qnZV1XRVTU9NTa1/cZJ0BNsy7gMm+SXg9cCZVVVN80PACfN229a0SZLGaKw9hSRnAe8Czq6qv5u36Sbg3CTPTrIDOBH4q3HWJkkaYU8hyTXAzwDHJtkLvJfB2UbPBm5OAnBrVf2bqvpKkuuAexgMK11UVQdGVZskaXF5egRn45menq6ZmZmuy5CkDSXJ7VU1vdg2r2iWJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSa2ShkOTDSfYluXte2wuT3Jzka83jC5r2JPmtJHuSfCnJqaOqS5K0tFH2FD4CnLWg7VLglqo6EbilWQd4LXBi87MTuGKEdUmSljCyUKiqLwDfWdB8DrC7Wd4NvGFe+0dr4FbgmCTHj6o2SdLixj2ncFxVPdwsPwIc1yxvBR6ct9/epu0QSXYmmUkyMzs7O7pKJekI1NlEc1UVUKt43q6qmq6q6ampqRFUJklHrnGHwrfnhoWax31N+0PACfP229a0SZLGaNyhcBNwfrN8PnDjvPa3NmchnQ48Nm+YSZI0JltG9cJJrgF+Bjg2yV7gvcD7geuSXAh8E3hTs/ungJ8H9gB/B1wwqrokSUsbWShU1ZuX2HTmIvsWcNGoapEkrYxXNEuSWoaCJKllKEiSWoaCJKllKEiSWoaCJKllKEiSWoaCJKllKEiSWoaCJKllKEiSWoaCJKm1olBIckOS1yUxRCSpx1b6S/63gX8JfC3J+5OcNMKaJEkdWVEoVNVnq+oXgVOBbwCfTfJ/klyQ5KhRFihJGp8VDwcleRHwS8DbgDuByxmExM0jqUySNHYrnVP4Q+B/A0cD/7yqzq6qj1XV24HnjbJAaaI99Q/wgR+D+z7ddSXSulhpT+F3q+rkqvovc9+dnOTZAFU1PbLqpEn32IPw/74Nf3JZ15VI62KlofCfF2n7y/UsRNqY0jxWp1VI6+Ww39Gc5IeBrcBzkpzC05+A5zMYSlqVJBczmJso4MvABcDxwLXAi4DbgfOq6snVHkMaizQfiTIU1A+HDQXg5xhMLm8DPjiv/XvAqvrLSbYCvwqcXFV/n+Q64Fzg54EPVdW1Sf4HcCFwxWqOIUlancOGQlXtBnYn+YWq+vg6H/c5SZ5i0ON4GHgVg2shAHYD78NQ0KSLw0fql+WGj95SVb8PbE9yycLtVfXBRZ52WFX1UJIPAA8Afw98hsFw0Xeran+z214Gw1aL1bQT2Anwkpe8ZNjDS+vM4SP1y3ITzc9tHp8H/OAiP0NL8gLgHGAH8CPNMc5a6fOraldVTVfV9NTU1GpKkNaPPQX1zHLDR7/TPP6ndTzmq4GvV9UsDO6rBJwBHJNkS9Nb2AY8tI7HlEZkrqfQbRXSelnpxWv/LcnzkxyV5JYks0nesspjPgCcnuToJAHOBO4BPg+8sdnnfODGVb6+1AFTQf2w0usUXlNVjwOvZ3Dvox8F/v1qDlhVtwHXA3cwOB11E7AL+HXgkiR7GJyWetVqXl+StHrLnZK6cL/XAX9QVY+lHUsdXlW9F3jvgub7gdNW/aKSpDVbaSh8MslXGZwt9G+TTAH/MLqyJEldWOmtsy8FfgqYrqqngCcYnEEkHdnW0GOWJtFKewoAL2dwvcL853x0neuRNiavU1BPrCgUkvxP4GXAXcCBprkwFCSpV1baU5hmcK8i/xySpB5b6SmpdwM/PMpCpI3JOQX1y0p7CscC9yT5K+D7c41VdfZIqpI2HDvR6oeVhsL7RlmEJGkyrCgUqurPkrwUOLGqPpvkaGDzaEuTNoK5HoLDSOqHld776F8xuDXF7zRNW4FPjKgmaQNy+Ej9sNKJ5osY3Mn0cYCq+hrw4lEVJW0YnpCnnllpKHx//vclNxew+WmQpJ5ZaSj8WZLLGHyF5s8CfwD8r9GVJW0U/m2kfllpKFwKzDK41fW/Bj4F/MdRFSVtOA4jqSdWevbRwSSfAD4x941pkjAM1DuH7Slk4H1JHgXuA+5rvnXtPeMpT5I0TssNH13M4Kyjf1JVL6yqFwI/CZyR5OKRVydNPHsK6pflQuE84M1V9fW5hqq6H3gL8NZRFiZtCA4fqWeWC4WjqurRhY3NvMJRoylJktSV5ULhyVVukyRtQMudffTKJI8v0h7gB1Z70CTHAFcCr2AwKPvLDCayPwZsB74BvKmq/na1x5DGy2Ek9cNhewpVtbmqnr/Izw9W1VqGjy4HPl1VLwdeCdzL4FqIW6rqROCWZl2abM4pqGdWevHauknyQ8BPA1cBVNWTVfVd4Bxgd7PbbuAN465Nko50Yw8FYAeDq6N/L8mdSa5M8lzguKp6uNnnEeC4xZ6cZGeSmSQzs7NeR6eu2VNQv3QRCluAU4ErquoU4AkWDBU13wW96KetqnZV1XRVTU9NTY28WEk6knQRCnuBvVV1W7N+PYOQ+HaS4wGax30d1CYNxzkF9czYQ6GqHgEeTHJS03QmcA9wE3B+03Y+cOO4a5NWzXBQT6z0O5rX29uBq5M8C7gfuIBBQF2X5ELgm8CbOqpNGoJhoH7pJBSq6i5gepFNZ465FGlt7CGoZ7qYU5AkTShDQVoTewrqF0NBktQyFKS1cE5BPWMoSOvCcFA/GArSmhgG6hdDQZLUMhSktXBOQT1jKEhrYiioXwwFSVLLUJDWwuEj9YyhIK0Hw0E9YShIwzh4AG5+DzzxaNNgGKhfDAVpGHs+C39xOfzRJV1XIo2EoSAN4+CBweP+JwePDhupZwwFaVUWhoHhoH4wFKRhJIPHtodgGKhfDAVpKOm6AGmkDAVpVZoegnMK6pnOQiHJ5iR3Jvlks74jyW1J9iT5WJJndVWbtKQs7CkYCuqXLnsK7wDunbf+X4EPVdWPAn8LXNhJVdJK2ENQT3USCkm2Aa8DrmzWA7wKuL7ZZTfwhi5qkw5vQU/BbFDPdNVT+E3gXcDBZv1FwHeran+zvhfY2kFd0urYc1BPjD0Ukrwe2FdVt6/y+TuTzCSZmZ2dXefqpGEZBuqXLnoKZwBnJ/kGcC2DYaPLgWOSbGn22QY8tNiTq2pXVU1X1fTU1NQ46pUWYRion8YeClX17qraVlXbgXOBz1XVLwKfB97Y7HY+cOO4a5OWtfDsI4eN1DOTdJ3CrwOXJNnDYI7hqo7rkYZgOKgftiy/y+hU1Z8Cf9os3w+c1mU90vAMA/XLJPUUpI2jFl7R7O0v1A+GgjSUpX7522NQPxgK0poYBuoXQ0FaC88+Us8YCtKqGAbqJ0NBGsYhUwqGg/rFUJDWwuEj9YyhIK2Jp6SqXwwFaTUO6SHYY1A/GArSULz3kfrNUJDWxFBQvxgKkqSWoSCtysJ7H0n9YChIw1j4fQoOH6lnDAVJUstQkIaxcLjI4SP1jKEgDWXhXIKhoH4xFKRhmAHqOUNBGorDR+o3Q0Eahre3UM+NPRSSnJDk80nuSfKVJO9o2l+Y5OYkX2seXzDu2qTlOZegfuuip7AfeGdVnQycDlyU5GTgUuCWqjoRuKVZlybLIWcfdVOGNCpjD4Wqeriq7miWvwfcC2wFzgF2N7vtBt4w7tqk5Tl8pH7rdE4hyXbgFOA24LiqerjZ9Ahw3BLP2ZlkJsnM7OzseAqV5ix1nYITzuqJzkIhyfOAjwO/VlWPz99WVcUSf4JV1a6qmq6q6ampqTFUKs1nCKjfOgmFJEcxCISrq+qGpvnbSY5vth8P7OuiNumwljr76JB7IkkbUxdnHwW4Cri3qj44b9NNwPnN8vnAjeOuTVqe1ymo37Z0cMwzgPOALye5q2m7DHg/cF2SC4FvAm/qoDbp8AwB9dzYQ6Gq/pylv+X8zHHWIg3Ps4/Ub17RLA3Du6Sq5wwFaShLhIDhoJ4wFKRheO8j9ZyhIA1lieEjT0lVTxgK0jCWuoLZ4SP1hKEgrYlhoH4xFKRhLNVDcPhIPWEoSEPx7CP1m6EgDaP95e+X7aifDAVpKE4wq98MBWkYhoB6zlCQhrLwlFRDQv1iKEjDWBgG9hzUM4aCtCaekqp+MRSkoXhKqvrNUJCG4e0t1HOGgjSUBXMJdXDwGD9K6gf/J0vDWNgzOHhg8Lhp8/hrkUbAUJCGUU0IzE0st+t+lNQP/k+WhnFg/+BxU/P15gcNBfXLxP1PTnJWkvuS7Elyadf1SM9wsAmFuRCwp6Ce2dJ1AfMl2Qz8d+Bngb3AXye5qaru6bay9VXNuHQ7V7nYtme0ze1Xh7Qttj633zPbln991uE1FtZ44GBx4GANlmuwfHDe48GDS7cXg+cVcLBZaNua9qpqHhcsz3vuwvd7oZVeYpCEl+39G34c2PfEAW794rfY8eDf8BPAE08Vn/vit5Z8vXBo4+L7rbS+Qxs3BTYlbNo0qHVzMlhPs77p0OVN8148GdQ51zS3/vTy/Hrm7de8N08vP/1vnl97svx+zUsvcdw8o4bw9Mbl9ltYx2LHnf+8+fvNveaRYqJCATgN2FNV9wMkuRY4B1jXUPj03Y9wyXV3AYf+Mlvsl+B6/LJUP/yLzY/zG0fBi/f9Oa++4R9zdL4PwGe+91IuvubOjqvTuD0jOJ7RniXa5+9/6JNXsu9c+9v+2Q4uec1JQ9e8nNQE/dZK8kbgrKp6W7N+HvCTVfUr8/bZCexsVk8C7htROccCj47otfvA9+fwfH8Oz/dnaeN4b15aVVOLbZi0nsKyqmoXsGvUx0kyU1XToz7ORuX7c3i+P4fn+7O0rt+bSZsdewg4Yd76tqZNkjQGkxYKfw2cmGRHkmcB5wI3dVyTJB0xJmr4qKr2J/kV4E+AzcCHq+orHZUz8iGqDc735/B8fw7P92dpnb43EzXRLEnq1qQNH0mSOmQoSJJahsIivNXG0pKckOTzSe5J8pUk7+i6pkmTZHOSO5N8sutaJk2SY5Jcn+SrSe5N8k+7rmmSJLm4+VzdneSaJD8w7hoMhQXm3WrjtcDJwJuTnNxtVRNlP/DOqjoZOB24yPfnEO8A7u26iAl1OfDpqno58Ep8n1pJtgK/CkxX1SsYnGxz7rjrMBQO1d5qo6qeBOZutSGgqh6uqjua5e8x+FBv7baqyZFkG/A64Mqua5k0SX4I+GngKoCqerKqvttpUZNnC/CcJFuAo4FvjbsAQ+FQW4EH563vxV96i0qyHTgFuK3jUibJbwLvAg52XMck2gHMAr/XDK9dmeS5XRc1KarqIeADwAPAw8BjVfWZcddhKGhVkjwP+Djwa1X1eNf1TIIkrwf2VdXtXdcyobYApwJXVNUpwBOAc3aNJC9gMCqxA/gR4LlJ3jLuOgyFQ3mrjWUkOYpBIFxdVTd0Xc8EOQM4O8k3GAw7virJ73db0kTZC+ytqrme5fUMQkIDrwa+XlWzVfUUcAPwU+MuwlA4lLfaOIwM7gl8FXBvVX2w63omSVW9u6q2VdV2Bv9vPldVY/9Lb1JV1SPAg0nm7vd8Jut8W/wN7gHg9CRHN5+zM+lgIn6ibnMxCSbsVhuT6AzgPODLSe5q2i6rqk91V5I2kLcDVzd/cN0PXNBxPROjqm5Lcj1wB4Oz/O6kg1teeJsLSVLL4SNJUstQkCS1DAVJUstQkCS1DAVJUstQkCS1DAVJUuv/A5NH5gMRii2eAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 40 (746461, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
            "train 497640 valid 248821\n",
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_96 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_72 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_97 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_73 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_98 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_74 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_99 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "7773/7776 [============================>.] - ETA: 0s - loss: 88.3826 - NN_RMSLE: 2.0973\n",
            "Epoch 1: val_loss improved from inf to 2.96378, saving model to model_40[]\n",
            "INFO:tensorflow:Assets written to: model_40[]/assets\n",
            "7776/7776 [==============================] - 32s 4ms/step - loss: 88.3537 - NN_RMSLE: 2.0972 - val_loss: 2.9638 - val_NN_RMSLE: 1.7156\n",
            "Epoch 2/100\n",
            "7768/7776 [============================>.] - ETA: 0s - loss: 3.1449 - NN_RMSLE: 1.7675\n",
            "Epoch 2: val_loss did not improve from 2.96378\n",
            "7776/7776 [==============================] - 33s 4ms/step - loss: 3.1447 - NN_RMSLE: 1.7674 - val_loss: 2.9659 - val_NN_RMSLE: 1.7163\n",
            "Epoch 3/100\n",
            "7765/7776 [============================>.] - ETA: 0s - loss: 3.0921 - NN_RMSLE: 1.7527\n",
            "Epoch 3: val_loss improved from 2.96378 to 2.96319, saving model to model_40[]\n",
            "INFO:tensorflow:Assets written to: model_40[]/assets\n",
            "7776/7776 [==============================] - 33s 4ms/step - loss: 3.0921 - NN_RMSLE: 1.7527 - val_loss: 2.9632 - val_NN_RMSLE: 1.7150\n",
            "Epoch 4/100\n",
            "7776/7776 [==============================] - ETA: 0s - loss: 3.0820 - NN_RMSLE: 1.7497\n",
            "Epoch 4: val_loss improved from 2.96319 to 2.96068, saving model to model_40[]\n",
            "INFO:tensorflow:Assets written to: model_40[]/assets\n",
            "7776/7776 [==============================] - 30s 4ms/step - loss: 3.0820 - NN_RMSLE: 1.7497 - val_loss: 2.9607 - val_NN_RMSLE: 1.7146\n",
            "Epoch 5/100\n",
            "7765/7776 [============================>.] - ETA: 0s - loss: 3.0805 - NN_RMSLE: 1.7494\n",
            "Epoch 5: val_loss did not improve from 2.96068\n",
            "7776/7776 [==============================] - 31s 4ms/step - loss: 3.0802 - NN_RMSLE: 1.7493 - val_loss: 2.9614 - val_NN_RMSLE: 1.7148\n",
            "Epoch 6/100\n",
            "7766/7776 [============================>.] - ETA: 0s - loss: 3.0798 - NN_RMSLE: 1.7492\n",
            "Epoch 6: val_loss did not improve from 2.96068\n",
            "7776/7776 [==============================] - 30s 4ms/step - loss: 3.0799 - NN_RMSLE: 1.7492 - val_loss: 2.9629 - val_NN_RMSLE: 1.7154\n",
            "Epoch 7/100\n",
            "7768/7776 [============================>.] - ETA: 0s - loss: 3.0794 - NN_RMSLE: 1.7492\n",
            "Epoch 7: val_loss did not improve from 2.96068\n",
            "7776/7776 [==============================] - 31s 4ms/step - loss: 3.0796 - NN_RMSLE: 1.7492 - val_loss: 2.9608 - val_NN_RMSLE: 1.7146\n",
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_96 (Dense)            (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_72 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_97 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_73 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_98 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_74 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_99 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  2.9607575\n",
            "\n",
            "[ 3  4  5  6  7  8  9 10 11 12]\n",
            "train 497641 valid 248820\n",
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_100 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_75 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_101 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_76 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_102 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_77 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_103 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "7776/7776 [==============================] - ETA: 0s - loss: 62.5186 - NN_RMSLE: 2.1298\n",
            "Epoch 1: val_loss improved from inf to 3.08750, saving model to model_40[]\n",
            "INFO:tensorflow:Assets written to: model_40[]/assets\n",
            "7776/7776 [==============================] - 34s 4ms/step - loss: 62.5186 - NN_RMSLE: 2.1298 - val_loss: 3.0875 - val_NN_RMSLE: 1.7530\n",
            "Epoch 2/100\n",
            "7770/7776 [============================>.] - ETA: 0s - loss: 3.0835 - NN_RMSLE: 1.7501\n",
            "Epoch 2: val_loss improved from 3.08750 to 3.08638, saving model to model_40[]\n",
            "INFO:tensorflow:Assets written to: model_40[]/assets\n",
            "7776/7776 [==============================] - 37s 5ms/step - loss: 3.0835 - NN_RMSLE: 1.7501 - val_loss: 3.0864 - val_NN_RMSLE: 1.7527\n",
            "Epoch 3/100\n",
            "7776/7776 [==============================] - ETA: 0s - loss: 3.0289 - NN_RMSLE: 1.7347\n",
            "Epoch 3: val_loss did not improve from 3.08638\n",
            "7776/7776 [==============================] - 34s 4ms/step - loss: 3.0289 - NN_RMSLE: 1.7347 - val_loss: 3.0867 - val_NN_RMSLE: 1.7528\n",
            "Epoch 4/100\n",
            "7774/7776 [============================>.] - ETA: 0s - loss: 3.0193 - NN_RMSLE: 1.7319\n",
            "Epoch 4: val_loss did not improve from 3.08638\n",
            "7776/7776 [==============================] - 34s 4ms/step - loss: 3.0193 - NN_RMSLE: 1.7319 - val_loss: 3.0868 - val_NN_RMSLE: 1.7528\n",
            "Epoch 5/100\n",
            "7764/7776 [============================>.] - ETA: 0s - loss: 3.0175 - NN_RMSLE: 1.7314\n",
            "Epoch 5: val_loss did not improve from 3.08638\n",
            "7776/7776 [==============================] - 32s 4ms/step - loss: 3.0173 - NN_RMSLE: 1.7314 - val_loss: 3.0869 - val_NN_RMSLE: 1.7528\n",
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_100 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_75 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_101 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_76 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_102 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_77 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_103 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  3.08692\n",
            "\n",
            "[ 8  9 10 11 12]\n",
            "train 497641 valid 248820\n",
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_104 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_78 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_105 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_79 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_106 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_80 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_107 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "7770/7776 [============================>.] - ETA: 0s - loss: 37.1198 - NN_RMSLE: 2.0616\n",
            "Epoch 1: val_loss improved from inf to 3.07761, saving model to model_40[]\n",
            "INFO:tensorflow:Assets written to: model_40[]/assets\n",
            "7776/7776 [==============================] - 36s 5ms/step - loss: 37.0950 - NN_RMSLE: 2.0614 - val_loss: 3.0776 - val_NN_RMSLE: 1.7518\n",
            "Epoch 2/100\n",
            "7771/7776 [============================>.] - ETA: 0s - loss: 3.0894 - NN_RMSLE: 1.7521\n",
            "Epoch 2: val_loss improved from 3.07761 to 3.07666, saving model to model_40[]\n",
            "INFO:tensorflow:Assets written to: model_40[]/assets\n",
            "7776/7776 [==============================] - 34s 4ms/step - loss: 3.0895 - NN_RMSLE: 1.7521 - val_loss: 3.0767 - val_NN_RMSLE: 1.7515\n",
            "Epoch 3/100\n",
            "7763/7776 [============================>.] - ETA: 0s - loss: 3.0321 - NN_RMSLE: 1.7355\n",
            "Epoch 3: val_loss improved from 3.07666 to 3.07208, saving model to model_40[]\n",
            "INFO:tensorflow:Assets written to: model_40[]/assets\n",
            "7776/7776 [==============================] - 32s 4ms/step - loss: 3.0319 - NN_RMSLE: 1.7355 - val_loss: 3.0721 - val_NN_RMSLE: 1.7500\n",
            "Epoch 4/100\n",
            "7757/7776 [============================>.] - ETA: 0s - loss: 3.0247 - NN_RMSLE: 1.7334\n",
            "Epoch 4: val_loss did not improve from 3.07208\n",
            "7776/7776 [==============================] - 33s 4ms/step - loss: 3.0248 - NN_RMSLE: 1.7334 - val_loss: 3.0721 - val_NN_RMSLE: 1.7501\n",
            "Epoch 5/100\n",
            "7774/7776 [============================>.] - ETA: 0s - loss: 3.0241 - NN_RMSLE: 1.7333\n",
            "Epoch 5: val_loss did not improve from 3.07208\n",
            "7776/7776 [==============================] - 34s 4ms/step - loss: 3.0241 - NN_RMSLE: 1.7333 - val_loss: 3.0721 - val_NN_RMSLE: 1.7501\n",
            "Epoch 6/100\n",
            "7772/7776 [============================>.] - ETA: 0s - loss: 3.0238 - NN_RMSLE: 1.7332\n",
            "Epoch 6: val_loss improved from 3.07208 to 3.07207, saving model to model_40[]\n",
            "INFO:tensorflow:Assets written to: model_40[]/assets\n",
            "7776/7776 [==============================] - 33s 4ms/step - loss: 3.0238 - NN_RMSLE: 1.7332 - val_loss: 3.0721 - val_NN_RMSLE: 1.7501\n",
            "Epoch 7/100\n",
            "7760/7776 [============================>.] - ETA: 0s - loss: 3.0238 - NN_RMSLE: 1.7331\n",
            "Epoch 7: val_loss did not improve from 3.07207\n",
            "7776/7776 [==============================] - 34s 4ms/step - loss: 3.0237 - NN_RMSLE: 1.7331 - val_loss: 3.0726 - val_NN_RMSLE: 1.7503\n",
            "Epoch 8/100\n",
            "7773/7776 [============================>.] - ETA: 0s - loss: 3.0237 - NN_RMSLE: 1.7329\n",
            "Epoch 8: val_loss improved from 3.07207 to 3.07205, saving model to model_40[]\n",
            "INFO:tensorflow:Assets written to: model_40[]/assets\n",
            "7776/7776 [==============================] - 32s 4ms/step - loss: 3.0238 - NN_RMSLE: 1.7330 - val_loss: 3.0720 - val_NN_RMSLE: 1.7500\n",
            "Epoch 9/100\n",
            "7774/7776 [============================>.] - ETA: 0s - loss: 3.0237 - NN_RMSLE: 1.7332\n",
            "Epoch 9: val_loss did not improve from 3.07205\n",
            "7776/7776 [==============================] - 28s 4ms/step - loss: 3.0237 - NN_RMSLE: 1.7333 - val_loss: 3.0721 - val_NN_RMSLE: 1.7501\n",
            "Epoch 10/100\n",
            "7769/7776 [============================>.] - ETA: 0s - loss: 3.0237 - NN_RMSLE: 1.7331\n",
            "Epoch 10: val_loss did not improve from 3.07205\n",
            "7776/7776 [==============================] - 30s 4ms/step - loss: 3.0237 - NN_RMSLE: 1.7331 - val_loss: 3.0722 - val_NN_RMSLE: 1.7501\n",
            "Epoch 11/100\n",
            "7766/7776 [============================>.] - ETA: 0s - loss: 3.0240 - NN_RMSLE: 1.7333\n",
            "Epoch 11: val_loss did not improve from 3.07205\n",
            "7776/7776 [==============================] - 34s 4ms/step - loss: 3.0238 - NN_RMSLE: 1.7333 - val_loss: 3.0721 - val_NN_RMSLE: 1.7500\n",
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_104 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_78 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_105 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_79 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_106 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_80 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_107 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  3.0720804\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 50 (775395, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[1 2 3 4 5 6 7]\n",
            "train 516930 valid 258465\n",
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_108 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_81 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_109 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_82 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_110 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_83 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_111 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "8067/8078 [============================>.] - ETA: 0s - loss: 2.4574 - NN_RMSLE: 1.5106\n",
            "Epoch 1: val_loss improved from inf to 1.67188, saving model to model_50[]\n",
            "INFO:tensorflow:Assets written to: model_50[]/assets\n",
            "8078/8078 [==============================] - 37s 5ms/step - loss: 2.4565 - NN_RMSLE: 1.5103 - val_loss: 1.6719 - val_NN_RMSLE: 1.2814\n",
            "Epoch 2/100\n",
            "8070/8078 [============================>.] - ETA: 0s - loss: 1.6439 - NN_RMSLE: 1.2780\n",
            "Epoch 2: val_loss improved from 1.67188 to 1.67096, saving model to model_50[]\n",
            "INFO:tensorflow:Assets written to: model_50[]/assets\n",
            "8078/8078 [==============================] - 42s 5ms/step - loss: 1.6439 - NN_RMSLE: 1.2779 - val_loss: 1.6710 - val_NN_RMSLE: 1.2812\n",
            "Epoch 3/100\n",
            "8069/8078 [============================>.] - ETA: 0s - loss: 1.6438 - NN_RMSLE: 1.2779\n",
            "Epoch 3: val_loss improved from 1.67096 to 1.67077, saving model to model_50[]\n",
            "INFO:tensorflow:Assets written to: model_50[]/assets\n",
            "8078/8078 [==============================] - 33s 4ms/step - loss: 1.6439 - NN_RMSLE: 1.2780 - val_loss: 1.6708 - val_NN_RMSLE: 1.2812\n",
            "Epoch 4/100\n",
            "8073/8078 [============================>.] - ETA: 0s - loss: 1.6438 - NN_RMSLE: 1.2780\n",
            "Epoch 4: val_loss did not improve from 1.67077\n",
            "8078/8078 [==============================] - 34s 4ms/step - loss: 1.6438 - NN_RMSLE: 1.2779 - val_loss: 1.6752 - val_NN_RMSLE: 1.2823\n",
            "Epoch 5/100\n",
            "8072/8078 [============================>.] - ETA: 0s - loss: 1.6439 - NN_RMSLE: 1.2779\n",
            "Epoch 5: val_loss did not improve from 1.67077\n",
            "8078/8078 [==============================] - 37s 5ms/step - loss: 1.6439 - NN_RMSLE: 1.2779 - val_loss: 1.6742 - val_NN_RMSLE: 1.2820\n",
            "Epoch 6/100\n",
            "8054/8078 [============================>.] - ETA: 0s - loss: 1.6438 - NN_RMSLE: 1.2781\n",
            "Epoch 6: val_loss did not improve from 1.67077\n",
            "8078/8078 [==============================] - 35s 4ms/step - loss: 1.6438 - NN_RMSLE: 1.2780 - val_loss: 1.6754 - val_NN_RMSLE: 1.2824\n",
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_108 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_81 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_109 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_82 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_110 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_83 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_111 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.6754336\n",
            "\n",
            "[ 4  5  6  7  8  9 10]\n",
            "train 516930 valid 258465\n",
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_112 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_84 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_113 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_85 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_114 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_86 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_115 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "8067/8078 [============================>.] - ETA: 0s - loss: 2.5888 - NN_RMSLE: 1.5447\n",
            "Epoch 1: val_loss improved from inf to 1.63888, saving model to model_50[]\n",
            "INFO:tensorflow:Assets written to: model_50[]/assets\n",
            "8078/8078 [==============================] - 36s 4ms/step - loss: 2.5876 - NN_RMSLE: 1.5443 - val_loss: 1.6389 - val_NN_RMSLE: 1.2737\n",
            "Epoch 2/100\n",
            "8073/8078 [============================>.] - ETA: 0s - loss: 1.6658 - NN_RMSLE: 1.2867\n",
            "Epoch 2: val_loss improved from 1.63888 to 1.63701, saving model to model_50[]\n",
            "INFO:tensorflow:Assets written to: model_50[]/assets\n",
            "8078/8078 [==============================] - 37s 5ms/step - loss: 1.6657 - NN_RMSLE: 1.2866 - val_loss: 1.6370 - val_NN_RMSLE: 1.2730\n",
            "Epoch 3/100\n",
            "8068/8078 [============================>.] - ETA: 0s - loss: 1.6657 - NN_RMSLE: 1.2866\n",
            "Epoch 3: val_loss improved from 1.63701 to 1.63425, saving model to model_50[]\n",
            "INFO:tensorflow:Assets written to: model_50[]/assets\n",
            "8078/8078 [==============================] - 37s 5ms/step - loss: 1.6658 - NN_RMSLE: 1.2866 - val_loss: 1.6342 - val_NN_RMSLE: 1.2718\n",
            "Epoch 4/100\n",
            "8076/8078 [============================>.] - ETA: 0s - loss: 1.6658 - NN_RMSLE: 1.2867\n",
            "Epoch 4: val_loss did not improve from 1.63425\n",
            "8078/8078 [==============================] - 32s 4ms/step - loss: 1.6658 - NN_RMSLE: 1.2866 - val_loss: 1.6423 - val_NN_RMSLE: 1.2751\n",
            "Epoch 5/100\n",
            "8060/8078 [============================>.] - ETA: 0s - loss: 1.6659 - NN_RMSLE: 1.2868\n",
            "Epoch 5: val_loss did not improve from 1.63425\n",
            "8078/8078 [==============================] - 31s 4ms/step - loss: 1.6658 - NN_RMSLE: 1.2868 - val_loss: 1.6356 - val_NN_RMSLE: 1.2724\n",
            "Epoch 6/100\n",
            "8067/8078 [============================>.] - ETA: 0s - loss: 1.6659 - NN_RMSLE: 1.2867\n",
            "Epoch 6: val_loss improved from 1.63425 to 1.63379, saving model to model_50[]\n",
            "INFO:tensorflow:Assets written to: model_50[]/assets\n",
            "8078/8078 [==============================] - 32s 4ms/step - loss: 1.6658 - NN_RMSLE: 1.2866 - val_loss: 1.6338 - val_NN_RMSLE: 1.2716\n",
            "Epoch 7/100\n",
            "8060/8078 [============================>.] - ETA: 0s - loss: 1.6659 - NN_RMSLE: 1.2868\n",
            "Epoch 7: val_loss did not improve from 1.63379\n",
            "8078/8078 [==============================] - 37s 5ms/step - loss: 1.6658 - NN_RMSLE: 1.2867 - val_loss: 1.6377 - val_NN_RMSLE: 1.2733\n",
            "Epoch 8/100\n",
            "8067/8078 [============================>.] - ETA: 0s - loss: 1.6658 - NN_RMSLE: 1.2866\n",
            "Epoch 8: val_loss did not improve from 1.63379\n",
            "8078/8078 [==============================] - 43s 5ms/step - loss: 1.6658 - NN_RMSLE: 1.2867 - val_loss: 1.6416 - val_NN_RMSLE: 1.2749\n",
            "Epoch 9/100\n",
            "8073/8078 [============================>.] - ETA: 0s - loss: 1.6658 - NN_RMSLE: 1.2867\n",
            "Epoch 9: val_loss improved from 1.63379 to 1.63030, saving model to model_50[]\n",
            "INFO:tensorflow:Assets written to: model_50[]/assets\n",
            "8078/8078 [==============================] - 34s 4ms/step - loss: 1.6657 - NN_RMSLE: 1.2866 - val_loss: 1.6303 - val_NN_RMSLE: 1.2701\n",
            "Epoch 10/100\n",
            "8078/8078 [==============================] - ETA: 0s - loss: 1.6658 - NN_RMSLE: 1.2866\n",
            "Epoch 10: val_loss did not improve from 1.63030\n",
            "8078/8078 [==============================] - 30s 4ms/step - loss: 1.6658 - NN_RMSLE: 1.2866 - val_loss: 1.6364 - val_NN_RMSLE: 1.2727\n",
            "Epoch 11/100\n",
            "8065/8078 [============================>.] - ETA: 0s - loss: 1.6658 - NN_RMSLE: 1.2868\n",
            "Epoch 11: val_loss did not improve from 1.63030\n",
            "8078/8078 [==============================] - 30s 4ms/step - loss: 1.6658 - NN_RMSLE: 1.2867 - val_loss: 1.6345 - val_NN_RMSLE: 1.2719\n",
            "Epoch 12/100\n",
            "8071/8078 [============================>.] - ETA: 0s - loss: 1.6657 - NN_RMSLE: 1.2868\n",
            "Epoch 12: val_loss did not improve from 1.63030\n",
            "8078/8078 [==============================] - 32s 4ms/step - loss: 1.6657 - NN_RMSLE: 1.2867 - val_loss: 1.6445 - val_NN_RMSLE: 1.2761\n",
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_112 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_84 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_113 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_85 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_114 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_86 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_115 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.6445464\n",
            "\n",
            "[ 7  8  9 10 11 12]\n",
            "train 516930 valid 258465\n",
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_116 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_87 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_117 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_88 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_118 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_89 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_119 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "8072/8078 [============================>.] - ETA: 0s - loss: 2.4777 - NN_RMSLE: 1.5147\n",
            "Epoch 1: val_loss improved from inf to 1.68022, saving model to model_50[]\n",
            "INFO:tensorflow:Assets written to: model_50[]/assets\n",
            "8078/8078 [==============================] - 33s 4ms/step - loss: 2.4772 - NN_RMSLE: 1.5144 - val_loss: 1.6802 - val_NN_RMSLE: 1.2858\n",
            "Epoch 2/100\n",
            "8075/8078 [============================>.] - ETA: 0s - loss: 1.6402 - NN_RMSLE: 1.2765\n",
            "Epoch 2: val_loss improved from 1.68022 to 1.67711, saving model to model_50[]\n",
            "INFO:tensorflow:Assets written to: model_50[]/assets\n",
            "8078/8078 [==============================] - 30s 4ms/step - loss: 1.6403 - NN_RMSLE: 1.2766 - val_loss: 1.6771 - val_NN_RMSLE: 1.2851\n",
            "Epoch 3/100\n",
            "8068/8078 [============================>.] - ETA: 0s - loss: 1.6402 - NN_RMSLE: 1.2766\n",
            "Epoch 3: val_loss improved from 1.67711 to 1.67609, saving model to model_50[]\n",
            "INFO:tensorflow:Assets written to: model_50[]/assets\n",
            "8078/8078 [==============================] - 33s 4ms/step - loss: 1.6402 - NN_RMSLE: 1.2766 - val_loss: 1.6761 - val_NN_RMSLE: 1.2849\n",
            "Epoch 4/100\n",
            "8062/8078 [============================>.] - ETA: 0s - loss: 1.6401 - NN_RMSLE: 1.2765\n",
            "Epoch 4: val_loss did not improve from 1.67609\n",
            "8078/8078 [==============================] - 34s 4ms/step - loss: 1.6402 - NN_RMSLE: 1.2765 - val_loss: 1.6761 - val_NN_RMSLE: 1.2849\n",
            "Epoch 5/100\n",
            "8066/8078 [============================>.] - ETA: 0s - loss: 1.6403 - NN_RMSLE: 1.2767\n",
            "Epoch 5: val_loss did not improve from 1.67609\n",
            "8078/8078 [==============================] - 33s 4ms/step - loss: 1.6403 - NN_RMSLE: 1.2767 - val_loss: 1.6779 - val_NN_RMSLE: 1.2853\n",
            "Epoch 6/100\n",
            "8067/8078 [============================>.] - ETA: 0s - loss: 1.6402 - NN_RMSLE: 1.2765\n",
            "Epoch 6: val_loss did not improve from 1.67609\n",
            "8078/8078 [==============================] - 34s 4ms/step - loss: 1.6402 - NN_RMSLE: 1.2765 - val_loss: 1.6764 - val_NN_RMSLE: 1.2850\n",
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_116 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_87 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_117 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_88 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_118 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_89 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_119 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.676433\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD4CAYAAAAD6PrjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAATn0lEQVR4nO3dfYxld33f8fdnd22wTYkxnjrbXcNawiKiqMR0YkiMEMWFmuDYlhohUyCO63RTyU0MjkqMW9WJVFXQRiRUSlC2mGRJXIMxD3YpJTGOE5q0GHYN1E8QbwzGu1mz44IxhrJmZr794545vjsPu/N075l75/2SRuee33n6zt3R/ezvdx5uqgpJkgC2dF2AJGnjMBQkSS1DQZLUMhQkSS1DQZLU2tZ1AWtx5pln1q5du7ouQ5JGyv79+x+vqonFlg0sFJJ8ELgYOFJVL23a/hPwc8DTwN8AV1bVE82ydwFXATPAr1bVn5zoGLt27WLfvn2D+QUkaUwleWSpZYMcPvpD4KJ5bXcAL62qfwD8NfAugCQvAS4H/n6zze8l2TrA2iRJixhYKFTV54Bvz2v706qabmY/D+xsXl8KfLiqjlbV14EDwPmDqk2StLguTzT/c+B/NK93AI/2LTvYtEmShqiTUEjyb4Bp4KZVbLs7yb4k+6ampta/OEnaxIYeCkl+kd4J6LfUMw9eOgSc3bfazqZtgaraU1WTVTU5MbHoyXNJ0ioNNRSSXAS8E7ikqn7Qt+h24PIkz0pyDnAu8IVh1iZJGuwlqTcDrwHOTHIQuIHe1UbPAu5IAvD5qvqXVXV/kluAB+gNK11dVTODqk2StLiM8qOzJycny/sUJGllkuyvqsnFlvmYC0lSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSa2ChkOSDSY4kua+v7YwkdyR5qJk+r2lPkv+c5ECS/5Pk5YOqS5K0tEH2FP4QuGhe23XAnVV1LnBnMw/wBuDc5mc38P4B1iVJWsLAQqGqPgd8e17zpcDe5vVe4LK+9g9Vz+eB05NsH1RtkqTFDfucwllVdbh5/RhwVvN6B/Bo33oHm7YFkuxOsi/JvqmpqcFVKkmbUGcnmquqgFrFdnuqarKqJicmJgZQmSRtXsMOhW/NDQs10yNN+yHg7L71djZtkqQhGnYo3A5c0by+Aritr/0XmquQXgl8t2+YSZI0JNsGteMkNwOvAc5MchC4AXg3cEuSq4BHgDc1q38a+FngAPAD4MpB1SVJWtrAQqGq3rzEogsXWbeAqwdViyRpebyjWZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLU6iQUkrwjyf1J7ktyc5JnJzknyd1JDiT5SJKTu6hNkjazoYdCkh3ArwKTVfVSYCtwOfAe4Ler6kXAd4Crhl2bJG12XQ0fbQNOSbINOBU4DLwWuLVZvhe4rJvSJGnzGnooVNUh4LeAb9ILg+8C+4Enqmq6We0gsGOx7ZPsTrIvyb6pqalhlCxJm0YXw0fPAy4FzgH+HnAacNFyt6+qPVU1WVWTExMTA6pSkjanLoaP/jHw9aqaqqofAR8HLgBOb4aTAHYChzqoTZI2tS5C4ZvAK5OcmiTAhcADwF3AzzfrXAHc1kFtkrSpdXFO4W56J5TvAe5tatgD/DpwbZIDwPOBG4ddmyRtdttOvMr6q6obgBvmNT8MnN9BOZKkhnc0S5JahoIkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJaywqFJB9P8sYkhogkjbHlfsj/HvDPgIeSvDvJiwdYkySpI8sKhar6bFW9BXg58A3gs0n+V5Irk5w0yAIlScOz7OGgJM8HfhH4JeBLwPvohcQdA6lMkjR0y/o+hSSfAF4M/BHwc1V1uFn0kST7BlWcJGm4lvslO/+lqj7d35DkWVV1tKomB1CXJKkDyx0++veLtP3v9SxEktS94/YUkvw4sAM4Jcl5QJpFzwVOHXBtkqQhO9Hw0T+hd3J5J/DevvbvAdcPqCZJUkeOGwpVtRfYm+SfVtXHhlSTJKkjJxo+emtV/TGwK8m185dX1XsX2UySNKJONHx0WjN9zqALkSR170TDR7/fTH9zOOVIkrq03Afi/cckz01yUpI7k0wleeugi5MkDddy71N4fVU9CVxM79lHLwL+9aCKkiR1Y7mhMDfM9Ebgo1X13bUcNMnpSW5N8tUkDyb56SRnJLkjyUPN9HlrOYYkaeWWGwqfSvJV4B8CdyaZAH64huO+D/hMVf0E8DLgQeA64M6qOhe4s5mXJA3Rch+dfR3wM8BkVf0I+D5w6WoOmOTHgFcDNzb7frqqnmj2t7dZbS9w2Wr2L0laveU+EA/gJ+jdr9C/zYdWccxzgCngD5K8DNgPXAOc1ff01ceAsxbbOMluYDfAC17wglUcXpK0lOVeffRHwG8BrwJ+qvlZ7dNRt9H7Hob3V9V59HodxwwVVVUBtdjGVbWnqiaranJiYmKVJUiSFrPcnsIk8JLmw3qtDgIHq+ruZv5WeqHwrSTbq+pwku3AkXU4liRpBZZ7ovk+4MfX44BV9RjwaN/3PF8IPADcDlzRtF0B3LYex5MkLd9yewpnAg8k+QJwdK6xqi5Z5XF/BbgpycnAw8CV9ALqliRXAY8Ab1rlviVJq7TcUPiN9TxoVX2Zxc9JXLiex5EkrcyyQqGq/iLJC4Fzq+qzSU4Ftg62NEnSsC336qN/Qe+E8O83TTuATw6oJklSR5Z7ovlq4ALgSYCqegj4u4MqSpLUjeWGwtGqenpuprmBbT0uT5UkbSDLDYW/SHI9cEqS1wEfBf7b4MqSJHVhuaFwHb1HU9wL/DLwaeDfDqooSVI3lnv10WySTwKfrKqpwZYkSerKcXsK6fmNJI8DXwO+1nzr2r8bTnmSpGE60fDRO+hddfRTVXVGVZ0BvAK4IMk7Bl6dJGmoThQKbwPeXFVfn2uoqoeBtwK/MMjCJEnDd6JQOKmqHp/f2JxXOGkwJUmSunKiUHh6lcskSSPoRFcfvSzJk4u0B3j2AOqRJHXouKFQVT70TpI2keXevCZJ2gQMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLU6C4UkW5N8Kcmnmvlzktyd5ECSjyQ5uavaJGmz6rKncA3wYN/8e4DfrqoXAd8BruqkKknaxDoJhSQ7gTcCH2jmA7wWuLVZZS9wWRe1SdJm1lVP4XeAdwKzzfzzgSeqarqZPwjsWGzDJLuT7Euyb2pqauCFStJmMvRQSHIxcKSq9q9m+6raU1WTVTU5MTGxztVJ0uZ2ou9oHoQLgEuS/Cy973l+LvA+4PQk25rewk7gUAe1SdKmNvSeQlW9q6p2VtUu4HLgz6rqLcBdwM83q10B3Dbs2iRps9tI9yn8OnBtkgP0zjHc2HE9krTpdDF81KqqPwf+vHn9MHB+l/VI0ma3kXoK0upMH4WnfwA/fPLY9v/3RCflSKPMUNDoe99Pwn/YDu8+G77bXJ/w9c/Be14ID93RaWnSqDEUNPq+97fPvH7ikd700S/0po/81fDrkUaYoaDxMtvc/5jmT7uqu1qkEWQoaLy0oZDetGaXXlfSAoaCxkvbM0inZUijylDQmJk/XOTwkbQShoLGixkgrYmhoDFjKkhrYShoPMVzCtJqGAoaL/MvQfWSVGlFDAWNGa8+ktbCUNB4sWcgrYmhIElqGQoaM/YUpLUwFDRe5oaPvPpIWhVDQZLUMhQ0Zhw+ktbCUNB4mf9APK9GklbEUJAktQwFjZn5J5rtKUgrYShovDhcJK2JoSBJahkKGjP2FKS1MBQ0XtrvZPbqI2k1DAWNlzYUJK3G0EMhydlJ7kryQJL7k1zTtJ+R5I4kDzXT5w27No0BewbSmnTRU5gGfq2qXgK8Erg6yUuA64A7q+pc4M5mXlqZ2Zne1EtSpVUZeihU1eGquqd5/T3gQWAHcCmwt1ltL3DZsGvTGHD4SFqTTs8pJNkFnAfcDZxVVYebRY8BZy2xze4k+5Lsm5qaGk6hGh2eaJbWpLNQSPIc4GPA26vqyf5lVVUs0e+vqj1VNVlVkxMTE0OoVCPFnoK0Jp2EQpKT6AXCTVX18ab5W0m2N8u3A0e6qE0jzlCQ1qSLq48C3Ag8WFXv7Vt0O3BF8/oK4LZh16YxYChIa7Ktg2NeALwNuDfJl5u264F3A7ckuQp4BHhTB7Vp1M2FglcfSasy9FCoqr+kPQu4wIXDrEVjaC4UPMEsrYp3NGu8tGFgKEirYShovLQ9Bc8tSKthKGi8zB8+chhJWhFDQeOl7SEYBtJqGAoaLw4fSWtiKGi8ePWRtCaGgsbLgp6C4SCthKGg8WIYSGtiKGi8tFcdeU5BWg1DQeOlHT7qtgxpVBkKGi/zzyl4wllaEUNB42XBOQVDQVoJQ0HjxZ6CtCaGgsZLzTRTb2KTVsNQ0HiZC4HZmbmGzkqRRpGhoPGyYPjInoK0EoaCxsv8+xQ8pyCtiKGg8WJPQVoTQ0Hjxe9TkNbEUNB4aUNh3lVIkpbFUNBom98TcPhIWhNDQaNt/oe+oSCtiaGg0WYoSOvKUNBoWyoUvHlNWhVDQaPNnoK0rgwFjbYFoVCLTyUti6Gg0Tbzo2Pn2+Gj6WPnJS3LhguFJBcl+VqSA0mu67oebXDTR4+dnwuB6R828/YUpJXY1nUB/ZJsBX4XeB1wEPhiktur6oFBHreqmJktpmd705kqZmZ609m5+dliS8LWLWFLwrYtYcuW3vy2pq23DJK0+62C2SqKZlrHTmcLaF/35otj15uZLY5Oz3J0eoanp2c5Oj07bzrDj2ZmmZmd26a3n3Z/fftujz3bP997PVPF9Mws07PF9Ew101lmqvnd0/udt4T2fej93jTt89ZpXzfr5Nj3qX+b9O2zefua93Dev9W8E8enfP8QF/XNf/P/PsUX9x/kZx7/DtuBw0/8gL/af7D99zh2X/P/EI5/rKreKtX3b9Ru1vwbV/N+17xtgGPet61bnnmvFr43zfKmvX/d/vfy2HV77+kzejNz72X/orm/z7Tz/VtlQduCdVaw/SIlLXqMZ/Z14n23k2Vsf2wti/9uJ1pnWftebKcjakOFAnA+cKCqHgZI8mHgUmBdQ+Ez9x3mHR/5yjMBMLu+/5vcEljnXQ5U6P1xh7BlS98HV/NBlPR92PWHzbzw6g/AYdmZI/yjk0/iWekNI73g0H/n+Qc/y2np9SDu+tstXP/RrwyxIqlnfjD2B8f80JsfeMddp2n7pVedw7Wvf/G61gwbLxR2AI/2zR8EXtG/QpLdwO5m9qkkXxtCXWcCjw/hOGsxCjXCOtf5CPDs465xW/OzIqPwXlrj+hmFOhfU+GvNzyq9cKkFGy0UTqiq9gB7hnnMJPuqanKYx1ypUagRRqNOa1wfo1AjjEadw6xxo51oPgSc3Te/s2mTJA3BRguFLwLnJjknycnA5cDtHdckSZvGhho+qqrpJP8K+BNgK/DBqrq/47JgyMNVqzQKNcJo1GmN62MUaoTRqHNoNWb+ZXqSpM1row0fSZI6ZChIklqGwnGMwiM3knwwyZEk93Vdy1KSnJ3kriQPJLk/yTVd1zRfkmcn+UKSrzQ1/mbXNS0lydYkX0ryqa5rWUqSbyS5N8mXk+zrup7FJDk9ya1JvprkwSQ/3XVN/ZK8uHn/5n6eTPL2gR/XcwqLax658df0PXIDePOgH7mxUkleDTwFfKiqXtp1PYtJsh3YXlX3JPk7wH7gso30XqZ3u+lpVfVUkpOAvwSuqarPd1zaAkmuBSaB51bVxV3Xs5gk3wAmq2rD3hSWZC/wP6vqA83VjqdW1RMdl7Wo5vPoEPCKqnpkkMeyp7C09pEbVfU0MPfIjQ2lqj4HfLvrOo6nqg5X1T3N6+8BD9K7e33DqJ6nmtmTmp8N9z+mJDuBNwIf6LqWUZbkx4BXAzcCVNXTGzUQGhcCfzPoQABD4XgWe+TGhvogG0VJdgHnAXd3XMoCzbDMl4EjwB1VteFqBH4HeCew0Z8JXsCfJtnfPJpmozkHmAL+oBmK+0CS07ou6jguB24exoEMBQ1NkucAHwPeXlVPdl3PfFU1U1U/Se9O+vOTbKjhuCQXA0eqan/XtSzDq6rq5cAbgKubYc6NZBvwcuD9VXUe8H1go543PBm4BPjoMI5nKCzNR26so2ac/mPATVX18a7rOZ5mGOEuOOap3BvBBcAlzXj9h4HXJvnjbktaXFUdaqZHgE/QG47dSA4CB/t6g7fSC4mN6A3APVX1rWEczFBYmo/cWCfNSdwbgQer6r1d17OYJBNJTm9en0LvAoOvdlrUPFX1rqraWVW76P09/llVvbXjshZIclpzQQHNkMzrgQ11dVxVPQY8mmTu2dMXss6P6F9Hb2ZIQ0ewwR5zsZFs4EduHCPJzcBrgDOTHARuqKobu61qgQuAtwH3NmP2ANdX1ae7K2mB7cDe5iqPLcAtVbVhL/nc4M4CPtF8f8A24L9W1We6LWlRvwLc1Pyn72Hgyo7rWaAJ1dcBvzy0Y3pJqiRpjsNHkqSWoSBJahkKkqSWoSBJahkKkqSWoSBJahkKkqTW/wetCkFL0/20BQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 60 (309558, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[ 1  2  3  4  5  9 10]\n",
            "train 206372 valid 103186\n",
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_120 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_90 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_121 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_91 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_122 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_92 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_123 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "3216/3225 [============================>.] - ETA: 0s - loss: 11.5527 - NN_RMSLE: 3.3142\n",
            "Epoch 1: val_loss improved from inf to 4.81465, saving model to model_60[]\n",
            "INFO:tensorflow:Assets written to: model_60[]/assets\n",
            "3225/3225 [==============================] - 15s 5ms/step - loss: 11.5340 - NN_RMSLE: 3.3109 - val_loss: 4.8146 - val_NN_RMSLE: 2.1834\n",
            "Epoch 2/100\n",
            "3218/3225 [============================>.] - ETA: 0s - loss: 2.2047 - NN_RMSLE: 1.4493\n",
            "Epoch 2: val_loss improved from 4.81465 to 1.22870, saving model to model_60[]\n",
            "INFO:tensorflow:Assets written to: model_60[]/assets\n",
            "3225/3225 [==============================] - 20s 6ms/step - loss: 2.2026 - NN_RMSLE: 1.4485 - val_loss: 1.2287 - val_NN_RMSLE: 1.1071\n",
            "Epoch 3/100\n",
            "3224/3225 [============================>.] - ETA: 0s - loss: 1.2082 - NN_RMSLE: 1.0957\n",
            "Epoch 3: val_loss improved from 1.22870 to 1.15735, saving model to model_60[]\n",
            "INFO:tensorflow:Assets written to: model_60[]/assets\n",
            "3225/3225 [==============================] - 17s 5ms/step - loss: 1.2082 - NN_RMSLE: 1.0957 - val_loss: 1.1574 - val_NN_RMSLE: 1.0738\n",
            "Epoch 4/100\n",
            "3213/3225 [============================>.] - ETA: 0s - loss: 1.2049 - NN_RMSLE: 1.0944\n",
            "Epoch 4: val_loss improved from 1.15735 to 1.15690, saving model to model_60[]\n",
            "INFO:tensorflow:Assets written to: model_60[]/assets\n",
            "3225/3225 [==============================] - 14s 4ms/step - loss: 1.2045 - NN_RMSLE: 1.0942 - val_loss: 1.1569 - val_NN_RMSLE: 1.0736\n",
            "Epoch 5/100\n",
            "3209/3225 [============================>.] - ETA: 0s - loss: 1.2040 - NN_RMSLE: 1.0939\n",
            "Epoch 5: val_loss did not improve from 1.15690\n",
            "3225/3225 [==============================] - 13s 4ms/step - loss: 1.2045 - NN_RMSLE: 1.0941 - val_loss: 1.1596 - val_NN_RMSLE: 1.0749\n",
            "Epoch 6/100\n",
            "3216/3225 [============================>.] - ETA: 0s - loss: 1.2043 - NN_RMSLE: 1.0941\n",
            "Epoch 6: val_loss did not improve from 1.15690\n",
            "3225/3225 [==============================] - 13s 4ms/step - loss: 1.2045 - NN_RMSLE: 1.0942 - val_loss: 1.1570 - val_NN_RMSLE: 1.0737\n",
            "Epoch 7/100\n",
            "3224/3225 [============================>.] - ETA: 0s - loss: 1.2045 - NN_RMSLE: 1.0941\n",
            "Epoch 7: val_loss did not improve from 1.15690\n",
            "3225/3225 [==============================] - 12s 4ms/step - loss: 1.2046 - NN_RMSLE: 1.0942 - val_loss: 1.1594 - val_NN_RMSLE: 1.0748\n",
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_120 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_90 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_121 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_91 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_122 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_92 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_123 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.159442\n",
            "\n",
            "[ 5  6  7  8  9 10 11]\n",
            "train 206372 valid 103186\n",
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_124 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_93 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_125 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_94 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_126 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_95 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_127 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "3216/3225 [============================>.] - ETA: 0s - loss: 11.8641 - NN_RMSLE: 3.3601\n",
            "Epoch 1: val_loss improved from inf to 4.42470, saving model to model_60[]\n",
            "INFO:tensorflow:Assets written to: model_60[]/assets\n",
            "3225/3225 [==============================] - 12s 4ms/step - loss: 11.8450 - NN_RMSLE: 3.3568 - val_loss: 4.4247 - val_NN_RMSLE: 2.0923\n",
            "Epoch 2/100\n",
            "3212/3225 [============================>.] - ETA: 0s - loss: 2.2417 - NN_RMSLE: 1.4602\n",
            "Epoch 2: val_loss improved from 4.42470 to 1.23447, saving model to model_60[]\n",
            "INFO:tensorflow:Assets written to: model_60[]/assets\n",
            "3225/3225 [==============================] - 13s 4ms/step - loss: 2.2377 - NN_RMSLE: 1.4587 - val_loss: 1.2345 - val_NN_RMSLE: 1.1090\n",
            "Epoch 3/100\n",
            "3214/3225 [============================>.] - ETA: 0s - loss: 1.1756 - NN_RMSLE: 1.0811\n",
            "Epoch 3: val_loss improved from 1.23447 to 1.22289, saving model to model_60[]\n",
            "INFO:tensorflow:Assets written to: model_60[]/assets\n",
            "3225/3225 [==============================] - 13s 4ms/step - loss: 1.1752 - NN_RMSLE: 1.0809 - val_loss: 1.2229 - val_NN_RMSLE: 1.1027\n",
            "Epoch 4/100\n",
            "3217/3225 [============================>.] - ETA: 0s - loss: 1.1707 - NN_RMSLE: 1.0789\n",
            "Epoch 4: val_loss improved from 1.22289 to 1.22249, saving model to model_60[]\n",
            "INFO:tensorflow:Assets written to: model_60[]/assets\n",
            "3225/3225 [==============================] - 15s 5ms/step - loss: 1.1708 - NN_RMSLE: 1.0790 - val_loss: 1.2225 - val_NN_RMSLE: 1.1025\n",
            "Epoch 5/100\n",
            "3215/3225 [============================>.] - ETA: 0s - loss: 1.1710 - NN_RMSLE: 1.0790\n",
            "Epoch 5: val_loss did not improve from 1.22249\n",
            "3225/3225 [==============================] - 14s 4ms/step - loss: 1.1709 - NN_RMSLE: 1.0789 - val_loss: 1.2241 - val_NN_RMSLE: 1.1032\n",
            "Epoch 6/100\n",
            "3225/3225 [==============================] - ETA: 0s - loss: 1.1709 - NN_RMSLE: 1.0789\n",
            "Epoch 6: val_loss improved from 1.22249 to 1.22204, saving model to model_60[]\n",
            "INFO:tensorflow:Assets written to: model_60[]/assets\n",
            "3225/3225 [==============================] - 16s 5ms/step - loss: 1.1709 - NN_RMSLE: 1.0789 - val_loss: 1.2220 - val_NN_RMSLE: 1.1023\n",
            "Epoch 7/100\n",
            "3217/3225 [============================>.] - ETA: 0s - loss: 1.1705 - NN_RMSLE: 1.0788\n",
            "Epoch 7: val_loss did not improve from 1.22204\n",
            "3225/3225 [==============================] - 16s 5ms/step - loss: 1.1708 - NN_RMSLE: 1.0789 - val_loss: 1.2259 - val_NN_RMSLE: 1.1039\n",
            "Epoch 8/100\n",
            "3221/3225 [============================>.] - ETA: 0s - loss: 1.1710 - NN_RMSLE: 1.0789\n",
            "Epoch 8: val_loss did not improve from 1.22204\n",
            "3225/3225 [==============================] - 16s 5ms/step - loss: 1.1709 - NN_RMSLE: 1.0788 - val_loss: 1.2236 - val_NN_RMSLE: 1.1030\n",
            "Epoch 9/100\n",
            "3214/3225 [============================>.] - ETA: 0s - loss: 1.1710 - NN_RMSLE: 1.0789\n",
            "Epoch 9: val_loss did not improve from 1.22204\n",
            "3225/3225 [==============================] - 13s 4ms/step - loss: 1.1709 - NN_RMSLE: 1.0788 - val_loss: 1.2258 - val_NN_RMSLE: 1.1039\n",
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_124 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_93 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_125 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_94 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_126 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_95 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_127 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.225828\n",
            "\n",
            "[ 8  9 10 11 12]\n",
            "train 206372 valid 103186\n",
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_128 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_96 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_129 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_97 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_130 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_98 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_131 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "3224/3225 [============================>.] - ETA: 0s - loss: 11.7657 - NN_RMSLE: 3.3447\n",
            "Epoch 1: val_loss improved from inf to 4.54201, saving model to model_60[]\n",
            "INFO:tensorflow:Assets written to: model_60[]/assets\n",
            "3225/3225 [==============================] - 15s 5ms/step - loss: 11.7646 - NN_RMSLE: 3.3444 - val_loss: 4.5420 - val_NN_RMSLE: 2.1270\n",
            "Epoch 2/100\n",
            "3207/3225 [============================>.] - ETA: 0s - loss: 2.2407 - NN_RMSLE: 1.4605\n",
            "Epoch 2: val_loss improved from 4.54201 to 1.22202, saving model to model_60[]\n",
            "INFO:tensorflow:Assets written to: model_60[]/assets\n",
            "3225/3225 [==============================] - 15s 5ms/step - loss: 2.2353 - NN_RMSLE: 1.4585 - val_loss: 1.2220 - val_NN_RMSLE: 1.1043\n",
            "Epoch 3/100\n",
            "3220/3225 [============================>.] - ETA: 0s - loss: 1.1907 - NN_RMSLE: 1.0879\n",
            "Epoch 3: val_loss improved from 1.22202 to 1.19089, saving model to model_60[]\n",
            "INFO:tensorflow:Assets written to: model_60[]/assets\n",
            "3225/3225 [==============================] - 14s 4ms/step - loss: 1.1906 - NN_RMSLE: 1.0879 - val_loss: 1.1909 - val_NN_RMSLE: 1.0897\n",
            "Epoch 4/100\n",
            "3222/3225 [============================>.] - ETA: 0s - loss: 1.1862 - NN_RMSLE: 1.0859\n",
            "Epoch 4: val_loss did not improve from 1.19089\n",
            "3225/3225 [==============================] - 13s 4ms/step - loss: 1.1863 - NN_RMSLE: 1.0859 - val_loss: 1.1910 - val_NN_RMSLE: 1.0898\n",
            "Epoch 5/100\n",
            "3210/3225 [============================>.] - ETA: 0s - loss: 1.1863 - NN_RMSLE: 1.0859\n",
            "Epoch 5: val_loss improved from 1.19089 to 1.19076, saving model to model_60[]\n",
            "INFO:tensorflow:Assets written to: model_60[]/assets\n",
            "3225/3225 [==============================] - 15s 5ms/step - loss: 1.1863 - NN_RMSLE: 1.0859 - val_loss: 1.1908 - val_NN_RMSLE: 1.0897\n",
            "Epoch 6/100\n",
            "3214/3225 [============================>.] - ETA: 0s - loss: 1.1867 - NN_RMSLE: 1.0860\n",
            "Epoch 6: val_loss did not improve from 1.19076\n",
            "3225/3225 [==============================] - 15s 5ms/step - loss: 1.1863 - NN_RMSLE: 1.0858 - val_loss: 1.1909 - val_NN_RMSLE: 1.0897\n",
            "Epoch 7/100\n",
            "3218/3225 [============================>.] - ETA: 0s - loss: 1.1862 - NN_RMSLE: 1.0860\n",
            "Epoch 7: val_loss did not improve from 1.19076\n",
            "3225/3225 [==============================] - 13s 4ms/step - loss: 1.1863 - NN_RMSLE: 1.0860 - val_loss: 1.1910 - val_NN_RMSLE: 1.0898\n",
            "Epoch 8/100\n",
            "3214/3225 [============================>.] - ETA: 0s - loss: 1.1863 - NN_RMSLE: 1.0859\n",
            "Epoch 8: val_loss did not improve from 1.19076\n",
            "3225/3225 [==============================] - 11s 3ms/step - loss: 1.1863 - NN_RMSLE: 1.0859 - val_loss: 1.1909 - val_NN_RMSLE: 1.0897\n",
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_128 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_96 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_129 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_97 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_130 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_98 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_131 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.1909226\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 62 (188590, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[ 1  2  3  4  5  9 10]\n",
            "train 125726 valid 62864\n",
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_132 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_99 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_133 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_100 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_134 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_101 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_135 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1959/1965 [============================>.] - ETA: 0s - loss: 17.7780 - NN_RMSLE: 4.1952\n",
            "Epoch 1: val_loss improved from inf to 18.14193, saving model to model_62[]\n",
            "INFO:tensorflow:Assets written to: model_62[]/assets\n",
            "1965/1965 [==============================] - 10s 5ms/step - loss: 17.7676 - NN_RMSLE: 4.1939 - val_loss: 18.1419 - val_NN_RMSLE: 4.2252\n",
            "Epoch 2/100\n",
            "1958/1965 [============================>.] - ETA: 0s - loss: 11.6751 - NN_RMSLE: 3.4091\n",
            "Epoch 2: val_loss improved from 18.14193 to 11.82500, saving model to model_62[]\n",
            "INFO:tensorflow:Assets written to: model_62[]/assets\n",
            "1965/1965 [==============================] - 11s 6ms/step - loss: 11.6696 - NN_RMSLE: 3.4081 - val_loss: 11.8250 - val_NN_RMSLE: 3.4302\n",
            "Epoch 3/100\n",
            "1958/1965 [============================>.] - ETA: 0s - loss: 10.0478 - NN_RMSLE: 3.1673\n",
            "Epoch 3: val_loss improved from 11.82500 to 9.83969, saving model to model_62[]\n",
            "INFO:tensorflow:Assets written to: model_62[]/assets\n",
            "1965/1965 [==============================] - 9s 5ms/step - loss: 10.0489 - NN_RMSLE: 3.1675 - val_loss: 9.8397 - val_NN_RMSLE: 3.1315\n",
            "Epoch 4/100\n",
            "1954/1965 [============================>.] - ETA: 0s - loss: 9.9048 - NN_RMSLE: 3.1448\n",
            "Epoch 4: val_loss improved from 9.83969 to 9.58359, saving model to model_62[]\n",
            "INFO:tensorflow:Assets written to: model_62[]/assets\n",
            "1965/1965 [==============================] - 9s 5ms/step - loss: 9.9051 - NN_RMSLE: 3.1449 - val_loss: 9.5836 - val_NN_RMSLE: 3.0899\n",
            "Epoch 5/100\n",
            "1954/1965 [============================>.] - ETA: 0s - loss: 9.9042 - NN_RMSLE: 3.1448\n",
            "Epoch 5: val_loss did not improve from 9.58359\n",
            "1965/1965 [==============================] - 9s 4ms/step - loss: 9.9044 - NN_RMSLE: 3.1448 - val_loss: 9.5955 - val_NN_RMSLE: 3.0919\n",
            "Epoch 6/100\n",
            "1957/1965 [============================>.] - ETA: 0s - loss: 9.9049 - NN_RMSLE: 3.1448\n",
            "Epoch 6: val_loss did not improve from 9.58359\n",
            "1965/1965 [==============================] - 9s 4ms/step - loss: 9.9042 - NN_RMSLE: 3.1446 - val_loss: 9.6134 - val_NN_RMSLE: 3.0948\n",
            "Epoch 7/100\n",
            "1965/1965 [==============================] - ETA: 0s - loss: 9.9042 - NN_RMSLE: 3.1445\n",
            "Epoch 7: val_loss did not improve from 9.58359\n",
            "1965/1965 [==============================] - 7s 4ms/step - loss: 9.9042 - NN_RMSLE: 3.1445 - val_loss: 9.6626 - val_NN_RMSLE: 3.1028\n",
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_132 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_99 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_133 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_100 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_134 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_101 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_135 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  9.662564\n",
            "\n",
            "[ 2  3  4  5  6  7  8  9 10 11]\n",
            "train 125727 valid 62863\n",
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_136 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_102 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_137 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_103 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_138 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_104 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_139 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1954/1965 [============================>.] - ETA: 0s - loss: 22.1926 - NN_RMSLE: 4.6890\n",
            "Epoch 1: val_loss improved from inf to 11.81186, saving model to model_62[]\n",
            "INFO:tensorflow:Assets written to: model_62[]/assets\n",
            "1965/1965 [==============================] - 10s 5ms/step - loss: 22.1619 - NN_RMSLE: 4.6854 - val_loss: 11.8119 - val_NN_RMSLE: 3.4134\n",
            "Epoch 2/100\n",
            "1960/1965 [============================>.] - ETA: 0s - loss: 13.1005 - NN_RMSLE: 3.6082\n",
            "Epoch 2: val_loss improved from 11.81186 to 9.89398, saving model to model_62[]\n",
            "INFO:tensorflow:Assets written to: model_62[]/assets\n",
            "1965/1965 [==============================] - 9s 5ms/step - loss: 13.0944 - NN_RMSLE: 3.6072 - val_loss: 9.8940 - val_NN_RMSLE: 3.1402\n",
            "Epoch 3/100\n",
            "1954/1965 [============================>.] - ETA: 0s - loss: 9.5919 - NN_RMSLE: 3.0934\n",
            "Epoch 3: val_loss did not improve from 9.89398\n",
            "1965/1965 [==============================] - 7s 4ms/step - loss: 9.5871 - NN_RMSLE: 3.0925 - val_loss: 10.9299 - val_NN_RMSLE: 3.2898\n",
            "Epoch 4/100\n",
            "1961/1965 [============================>.] - ETA: 0s - loss: 8.9141 - NN_RMSLE: 2.9814\n",
            "Epoch 4: val_loss did not improve from 9.89398\n",
            "1965/1965 [==============================] - 7s 4ms/step - loss: 8.9145 - NN_RMSLE: 2.9814 - val_loss: 11.7122 - val_NN_RMSLE: 3.3997\n",
            "Epoch 5/100\n",
            "1964/1965 [============================>.] - ETA: 0s - loss: 8.8872 - NN_RMSLE: 2.9765\n",
            "Epoch 5: val_loss did not improve from 9.89398\n",
            "1965/1965 [==============================] - 8s 4ms/step - loss: 8.8874 - NN_RMSLE: 2.9766 - val_loss: 11.7735 - val_NN_RMSLE: 3.4082\n",
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_136 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_102 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_137 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_103 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_138 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_104 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_139 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  11.77353\n",
            "\n",
            "[ 8  9 10 11 12]\n",
            "train 125727 valid 62863\n",
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_140 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_105 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_141 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_106 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_142 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_107 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_143 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1953/1965 [============================>.] - ETA: 0s - loss: 19.7451 - NN_RMSLE: 4.4224\n",
            "Epoch 1: val_loss improved from inf to 15.24281, saving model to model_62[]\n",
            "INFO:tensorflow:Assets written to: model_62[]/assets\n",
            "1965/1965 [==============================] - 9s 4ms/step - loss: 19.7131 - NN_RMSLE: 4.4182 - val_loss: 15.2428 - val_NN_RMSLE: 3.8693\n",
            "Epoch 2/100\n",
            "1962/1965 [============================>.] - ETA: 0s - loss: 12.3864 - NN_RMSLE: 3.5107\n",
            "Epoch 2: val_loss improved from 15.24281 to 10.59246, saving model to model_62[]\n",
            "INFO:tensorflow:Assets written to: model_62[]/assets\n",
            "1965/1965 [==============================] - 8s 4ms/step - loss: 12.3843 - NN_RMSLE: 3.5103 - val_loss: 10.5925 - val_NN_RMSLE: 3.2482\n",
            "Epoch 3/100\n",
            "1936/1965 [============================>.] - ETA: 0s - loss: 10.0609 - NN_RMSLE: 3.1691\n",
            "Epoch 3: val_loss improved from 10.59246 to 9.51577, saving model to model_62[]\n",
            "INFO:tensorflow:Assets written to: model_62[]/assets\n",
            "1965/1965 [==============================] - 9s 4ms/step - loss: 10.0535 - NN_RMSLE: 3.1679 - val_loss: 9.5158 - val_NN_RMSLE: 3.0791\n",
            "Epoch 4/100\n",
            "1956/1965 [============================>.] - ETA: 0s - loss: 9.7480 - NN_RMSLE: 3.1196\n",
            "Epoch 4: val_loss improved from 9.51577 to 9.43959, saving model to model_62[]\n",
            "INFO:tensorflow:Assets written to: model_62[]/assets\n",
            "1965/1965 [==============================] - 8s 4ms/step - loss: 9.7470 - NN_RMSLE: 3.1195 - val_loss: 9.4396 - val_NN_RMSLE: 3.0641\n",
            "Epoch 5/100\n",
            "1949/1965 [============================>.] - ETA: 0s - loss: 9.7403 - NN_RMSLE: 3.1181\n",
            "Epoch 5: val_loss improved from 9.43959 to 9.43078, saving model to model_62[]\n",
            "INFO:tensorflow:Assets written to: model_62[]/assets\n",
            "1965/1965 [==============================] - 7s 3ms/step - loss: 9.7405 - NN_RMSLE: 3.1181 - val_loss: 9.4308 - val_NN_RMSLE: 3.0620\n",
            "Epoch 6/100\n",
            "1949/1965 [============================>.] - ETA: 0s - loss: 9.7385 - NN_RMSLE: 3.1177\n",
            "Epoch 6: val_loss did not improve from 9.43078\n",
            "1965/1965 [==============================] - 9s 5ms/step - loss: 9.7406 - NN_RMSLE: 3.1182 - val_loss: 9.4367 - val_NN_RMSLE: 3.0634\n",
            "Epoch 7/100\n",
            "1962/1965 [============================>.] - ETA: 0s - loss: 9.7416 - NN_RMSLE: 3.1183\n",
            "Epoch 7: val_loss did not improve from 9.43078\n",
            "1965/1965 [==============================] - 8s 4ms/step - loss: 9.7407 - NN_RMSLE: 3.1182 - val_loss: 9.4361 - val_NN_RMSLE: 3.0633\n",
            "Epoch 8/100\n",
            "1955/1965 [============================>.] - ETA: 0s - loss: 9.7422 - NN_RMSLE: 3.1182\n",
            "Epoch 8: val_loss did not improve from 9.43078\n",
            "1965/1965 [==============================] - 7s 4ms/step - loss: 9.7407 - NN_RMSLE: 3.1179 - val_loss: 9.4330 - val_NN_RMSLE: 3.0625\n",
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_140 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_105 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_141 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_106 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_142 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_107 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_143 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  9.432969\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 61 (161567, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[1 2 3 4 5 6]\n",
            "train 107711 valid 53856\n",
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_144 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_108 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_145 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_109 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_146 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_110 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_147 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1677/1683 [============================>.] - ETA: 0s - loss: 14.4666 - NN_RMSLE: 3.7798\n",
            "Epoch 1: val_loss improved from inf to 6.30089, saving model to model_61[]\n",
            "INFO:tensorflow:Assets written to: model_61[]/assets\n",
            "1683/1683 [==============================] - 8s 5ms/step - loss: 14.4550 - NN_RMSLE: 3.7782 - val_loss: 6.3009 - val_NN_RMSLE: 2.4187\n",
            "Epoch 2/100\n",
            "1682/1683 [============================>.] - ETA: 0s - loss: 9.2973 - NN_RMSLE: 3.0338\n",
            "Epoch 2: val_loss did not improve from 6.30089\n",
            "1683/1683 [==============================] - 12s 7ms/step - loss: 9.2961 - NN_RMSLE: 3.0336 - val_loss: 6.5259 - val_NN_RMSLE: 2.5470\n",
            "Epoch 3/100\n",
            "1676/1683 [============================>.] - ETA: 0s - loss: 7.6947 - NN_RMSLE: 2.7653\n",
            "Epoch 3: val_loss did not improve from 6.30089\n",
            "1683/1683 [==============================] - 7s 4ms/step - loss: 7.6955 - NN_RMSLE: 2.7654 - val_loss: 7.7317 - val_NN_RMSLE: 2.7647\n",
            "Epoch 4/100\n",
            "1679/1683 [============================>.] - ETA: 0s - loss: 7.4780 - NN_RMSLE: 2.7264\n",
            "Epoch 4: val_loss did not improve from 6.30089\n",
            "1683/1683 [==============================] - 8s 4ms/step - loss: 7.4786 - NN_RMSLE: 2.7265 - val_loss: 8.1552 - val_NN_RMSLE: 2.8339\n",
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_144 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_108 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_145 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_109 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_146 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_110 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_147 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  8.15523\n",
            "\n",
            "[4 5 6 7 8 9]\n",
            "train 107711 valid 53856\n",
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_148 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_111 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_149 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_112 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_150 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_113 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_151 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1680/1683 [============================>.] - ETA: 0s - loss: 9.5176 - NN_RMSLE: 3.0593\n",
            "Epoch 1: val_loss improved from inf to 13.76201, saving model to model_61[]\n",
            "INFO:tensorflow:Assets written to: model_61[]/assets\n",
            "1683/1683 [==============================] - 7s 4ms/step - loss: 9.5125 - NN_RMSLE: 3.0585 - val_loss: 13.7620 - val_NN_RMSLE: 3.6561\n",
            "Epoch 2/100\n",
            "1681/1683 [============================>.] - ETA: 0s - loss: 7.3122 - NN_RMSLE: 2.6871\n",
            "Epoch 2: val_loss improved from 13.76201 to 10.23380, saving model to model_61[]\n",
            "INFO:tensorflow:Assets written to: model_61[]/assets\n",
            "1683/1683 [==============================] - 7s 4ms/step - loss: 7.3105 - NN_RMSLE: 2.6868 - val_loss: 10.2338 - val_NN_RMSLE: 3.1640\n",
            "Epoch 3/100\n",
            "1677/1683 [============================>.] - ETA: 0s - loss: 7.0525 - NN_RMSLE: 2.6427\n",
            "Epoch 3: val_loss improved from 10.23380 to 9.59822, saving model to model_61[]\n",
            "INFO:tensorflow:Assets written to: model_61[]/assets\n",
            "1683/1683 [==============================] - 8s 5ms/step - loss: 7.0528 - NN_RMSLE: 2.6427 - val_loss: 9.5982 - val_NN_RMSLE: 3.0679\n",
            "Epoch 4/100\n",
            "1673/1683 [============================>.] - ETA: 0s - loss: 7.0471 - NN_RMSLE: 2.6417\n",
            "Epoch 4: val_loss improved from 9.59822 to 9.54487, saving model to model_61[]\n",
            "INFO:tensorflow:Assets written to: model_61[]/assets\n",
            "1683/1683 [==============================] - 8s 5ms/step - loss: 7.0477 - NN_RMSLE: 2.6418 - val_loss: 9.5449 - val_NN_RMSLE: 3.0597\n",
            "Epoch 5/100\n",
            "1676/1683 [============================>.] - ETA: 0s - loss: 7.0422 - NN_RMSLE: 2.6410\n",
            "Epoch 5: val_loss did not improve from 9.54487\n",
            "1683/1683 [==============================] - 7s 4ms/step - loss: 7.0478 - NN_RMSLE: 2.6420 - val_loss: 9.5561 - val_NN_RMSLE: 3.0614\n",
            "Epoch 6/100\n",
            "1680/1683 [============================>.] - ETA: 0s - loss: 7.0475 - NN_RMSLE: 2.6423\n",
            "Epoch 6: val_loss did not improve from 9.54487\n",
            "1683/1683 [==============================] - 7s 4ms/step - loss: 7.0478 - NN_RMSLE: 2.6423 - val_loss: 9.5630 - val_NN_RMSLE: 3.0625\n",
            "Epoch 7/100\n",
            "1677/1683 [============================>.] - ETA: 0s - loss: 7.0489 - NN_RMSLE: 2.6425\n",
            "Epoch 7: val_loss improved from 9.54487 to 9.51175, saving model to model_61[]\n",
            "INFO:tensorflow:Assets written to: model_61[]/assets\n",
            "1683/1683 [==============================] - 8s 5ms/step - loss: 7.0477 - NN_RMSLE: 2.6423 - val_loss: 9.5118 - val_NN_RMSLE: 3.0546\n",
            "Epoch 8/100\n",
            "1676/1683 [============================>.] - ETA: 0s - loss: 7.0477 - NN_RMSLE: 2.6420\n",
            "Epoch 8: val_loss did not improve from 9.51175\n",
            "1683/1683 [==============================] - 6s 3ms/step - loss: 7.0477 - NN_RMSLE: 2.6420 - val_loss: 9.5721 - val_NN_RMSLE: 3.0639\n",
            "Epoch 9/100\n",
            "1665/1683 [============================>.] - ETA: 0s - loss: 7.0469 - NN_RMSLE: 2.6414\n",
            "Epoch 9: val_loss did not improve from 9.51175\n",
            "1683/1683 [==============================] - 5s 3ms/step - loss: 7.0478 - NN_RMSLE: 2.6416 - val_loss: 9.5713 - val_NN_RMSLE: 3.0637\n",
            "Epoch 10/100\n",
            "1661/1683 [============================>.] - ETA: 0s - loss: 7.0470 - NN_RMSLE: 2.6416\n",
            "Epoch 10: val_loss did not improve from 9.51175\n",
            "1683/1683 [==============================] - 5s 3ms/step - loss: 7.0478 - NN_RMSLE: 2.6417 - val_loss: 9.5936 - val_NN_RMSLE: 3.0672\n",
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_148 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_111 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_149 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_112 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_150 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_113 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_151 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  9.593567\n",
            "\n",
            "[ 7  8  9 10 11 12]\n",
            "train 107712 valid 53855\n",
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_152 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_114 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_153 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_115 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_154 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_116 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_155 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1673/1683 [============================>.] - ETA: 0s - loss: 12.6887 - NN_RMSLE: 3.5429\n",
            "Epoch 1: val_loss improved from inf to 9.03671, saving model to model_61[]\n",
            "INFO:tensorflow:Assets written to: model_61[]/assets\n",
            "1683/1683 [==============================] - 5s 3ms/step - loss: 12.6720 - NN_RMSLE: 3.5405 - val_loss: 9.0367 - val_NN_RMSLE: 2.8489\n",
            "Epoch 2/100\n",
            "1661/1683 [============================>.] - ETA: 0s - loss: 8.4421 - NN_RMSLE: 2.8983\n",
            "Epoch 2: val_loss improved from 9.03671 to 7.79739, saving model to model_61[]\n",
            "INFO:tensorflow:Assets written to: model_61[]/assets\n",
            "1683/1683 [==============================] - 5s 3ms/step - loss: 8.4326 - NN_RMSLE: 2.8967 - val_loss: 7.7974 - val_NN_RMSLE: 2.7211\n",
            "Epoch 3/100\n",
            "1666/1683 [============================>.] - ETA: 0s - loss: 7.3497 - NN_RMSLE: 2.7079\n",
            "Epoch 3: val_loss did not improve from 7.79739\n",
            "1683/1683 [==============================] - 5s 3ms/step - loss: 7.3505 - NN_RMSLE: 2.7080 - val_loss: 7.9403 - val_NN_RMSLE: 2.7783\n",
            "Epoch 4/100\n",
            "1672/1683 [============================>.] - ETA: 0s - loss: 7.2515 - NN_RMSLE: 2.6902\n",
            "Epoch 4: val_loss did not improve from 7.79739\n",
            "1683/1683 [==============================] - 6s 3ms/step - loss: 7.2507 - NN_RMSLE: 2.6900 - val_loss: 8.0102 - val_NN_RMSLE: 2.7945\n",
            "Epoch 5/100\n",
            "1672/1683 [============================>.] - ETA: 0s - loss: 7.2483 - NN_RMSLE: 2.6896\n",
            "Epoch 5: val_loss did not improve from 7.79739\n",
            "1683/1683 [==============================] - 5s 3ms/step - loss: 7.2498 - NN_RMSLE: 2.6899 - val_loss: 8.0115 - val_NN_RMSLE: 2.7948\n",
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_152 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_114 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_153 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_115 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_154 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_116 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_155 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  8.01146\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 71 (130956, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[1 2 3 4 5]\n",
            "train 87304 valid 43652\n",
            "Model: \"sequential_39\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_156 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_117 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_157 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_118 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_158 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_119 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_159 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1360/1365 [============================>.] - ETA: 0s - loss: 27.7936 - NN_RMSLE: 5.2574\n",
            "Epoch 1: val_loss improved from inf to 9.64143, saving model to model_71[]\n",
            "INFO:tensorflow:Assets written to: model_71[]/assets\n",
            "1365/1365 [==============================] - 5s 4ms/step - loss: 27.7776 - NN_RMSLE: 5.2558 - val_loss: 9.6414 - val_NN_RMSLE: 3.0887\n",
            "Epoch 2/100\n",
            "1356/1365 [============================>.] - ETA: 0s - loss: 18.6426 - NN_RMSLE: 4.3066\n",
            "Epoch 2: val_loss improved from 9.64143 to 7.76531, saving model to model_71[]\n",
            "INFO:tensorflow:Assets written to: model_71[]/assets\n",
            "1365/1365 [==============================] - 8s 6ms/step - loss: 18.6245 - NN_RMSLE: 4.3038 - val_loss: 7.7653 - val_NN_RMSLE: 2.7786\n",
            "Epoch 3/100\n",
            "1351/1365 [============================>.] - ETA: 0s - loss: 12.9637 - NN_RMSLE: 3.5934\n",
            "Epoch 3: val_loss did not improve from 7.76531\n",
            "1365/1365 [==============================] - 6s 4ms/step - loss: 12.9463 - NN_RMSLE: 3.5907 - val_loss: 8.2400 - val_NN_RMSLE: 2.8664\n",
            "Epoch 4/100\n",
            "1354/1365 [============================>.] - ETA: 0s - loss: 9.8941 - NN_RMSLE: 3.1415\n",
            "Epoch 4: val_loss did not improve from 7.76531\n",
            "1365/1365 [==============================] - 4s 3ms/step - loss: 9.8862 - NN_RMSLE: 3.1402 - val_loss: 10.1067 - val_NN_RMSLE: 3.1716\n",
            "Epoch 5/100\n",
            "1346/1365 [============================>.] - ETA: 0s - loss: 8.6643 - NN_RMSLE: 2.9390\n",
            "Epoch 5: val_loss did not improve from 7.76531\n",
            "1365/1365 [==============================] - 4s 3ms/step - loss: 8.6670 - NN_RMSLE: 2.9399 - val_loss: 12.1127 - val_NN_RMSLE: 3.4680\n",
            "Model: \"sequential_39\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_156 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_117 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_157 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_118 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_158 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_119 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_159 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  12.11271\n",
            "\n",
            "[5 6 7 8 9]\n",
            "train 87304 valid 43652\n",
            "Model: \"sequential_40\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_160 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_120 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_161 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_121 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_162 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_122 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_163 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1350/1365 [============================>.] - ETA: 0s - loss: 16.1005 - NN_RMSLE: 3.9964\n",
            "Epoch 1: val_loss improved from inf to 29.42303, saving model to model_71[]\n",
            "INFO:tensorflow:Assets written to: model_71[]/assets\n",
            "1365/1365 [==============================] - 5s 3ms/step - loss: 16.0677 - NN_RMSLE: 3.9922 - val_loss: 29.4230 - val_NN_RMSLE: 5.3369\n",
            "Epoch 2/100\n",
            "1345/1365 [============================>.] - ETA: 0s - loss: 11.3837 - NN_RMSLE: 3.3660\n",
            "Epoch 2: val_loss improved from 29.42303 to 20.71972, saving model to model_71[]\n",
            "INFO:tensorflow:Assets written to: model_71[]/assets\n",
            "1365/1365 [==============================] - 5s 4ms/step - loss: 11.3653 - NN_RMSLE: 3.3628 - val_loss: 20.7197 - val_NN_RMSLE: 4.4813\n",
            "Epoch 3/100\n",
            "1363/1365 [============================>.] - ETA: 0s - loss: 9.4221 - NN_RMSLE: 3.0660\n",
            "Epoch 3: val_loss improved from 20.71972 to 15.81521, saving model to model_71[]\n",
            "INFO:tensorflow:Assets written to: model_71[]/assets\n",
            "1365/1365 [==============================] - 5s 4ms/step - loss: 9.4220 - NN_RMSLE: 3.0663 - val_loss: 15.8152 - val_NN_RMSLE: 3.9220\n",
            "Epoch 4/100\n",
            "1361/1365 [============================>.] - ETA: 0s - loss: 8.9068 - NN_RMSLE: 2.9823\n",
            "Epoch 4: val_loss improved from 15.81521 to 13.65731, saving model to model_71[]\n",
            "INFO:tensorflow:Assets written to: model_71[]/assets\n",
            "1365/1365 [==============================] - 4s 3ms/step - loss: 8.9058 - NN_RMSLE: 2.9820 - val_loss: 13.6573 - val_NN_RMSLE: 3.6488\n",
            "Epoch 5/100\n",
            "1364/1365 [============================>.] - ETA: 0s - loss: 8.8509 - NN_RMSLE: 2.9731\n",
            "Epoch 5: val_loss improved from 13.65731 to 13.23494, saving model to model_71[]\n",
            "INFO:tensorflow:Assets written to: model_71[]/assets\n",
            "1365/1365 [==============================] - 5s 4ms/step - loss: 8.8511 - NN_RMSLE: 2.9733 - val_loss: 13.2349 - val_NN_RMSLE: 3.5928\n",
            "Epoch 6/100\n",
            "1363/1365 [============================>.] - ETA: 0s - loss: 8.8504 - NN_RMSLE: 2.9730\n",
            "Epoch 6: val_loss improved from 13.23494 to 13.21740, saving model to model_71[]\n",
            "INFO:tensorflow:Assets written to: model_71[]/assets\n",
            "1365/1365 [==============================] - 5s 4ms/step - loss: 8.8501 - NN_RMSLE: 2.9728 - val_loss: 13.2174 - val_NN_RMSLE: 3.5905\n",
            "Epoch 7/100\n",
            "1357/1365 [============================>.] - ETA: 0s - loss: 8.8503 - NN_RMSLE: 2.9730\n",
            "Epoch 7: val_loss improved from 13.21740 to 13.16378, saving model to model_71[]\n",
            "INFO:tensorflow:Assets written to: model_71[]/assets\n",
            "1365/1365 [==============================] - 6s 4ms/step - loss: 8.8501 - NN_RMSLE: 2.9725 - val_loss: 13.1638 - val_NN_RMSLE: 3.5833\n",
            "Epoch 8/100\n",
            "1351/1365 [============================>.] - ETA: 0s - loss: 8.8527 - NN_RMSLE: 2.9735\n",
            "Epoch 8: val_loss did not improve from 13.16378\n",
            "1365/1365 [==============================] - 4s 3ms/step - loss: 8.8501 - NN_RMSLE: 2.9727 - val_loss: 13.3334 - val_NN_RMSLE: 3.6060\n",
            "Epoch 9/100\n",
            "1348/1365 [============================>.] - ETA: 0s - loss: 8.8457 - NN_RMSLE: 2.9723\n",
            "Epoch 9: val_loss did not improve from 13.16378\n",
            "1365/1365 [==============================] - 5s 3ms/step - loss: 8.8503 - NN_RMSLE: 2.9730 - val_loss: 13.2522 - val_NN_RMSLE: 3.5951\n",
            "Epoch 10/100\n",
            "1360/1365 [============================>.] - ETA: 0s - loss: 8.8491 - NN_RMSLE: 2.9727\n",
            "Epoch 10: val_loss did not improve from 13.16378\n",
            "1365/1365 [==============================] - 4s 3ms/step - loss: 8.8502 - NN_RMSLE: 2.9729 - val_loss: 13.2402 - val_NN_RMSLE: 3.5935\n",
            "Model: \"sequential_40\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_160 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_120 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_161 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_121 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_162 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_122 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_163 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  13.240231\n",
            "\n",
            "[ 9 10 11 12]\n",
            "train 87304 valid 43652\n",
            "Model: \"sequential_41\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_164 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_123 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_165 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_124 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_166 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_125 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_167 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1359/1365 [============================>.] - ETA: 0s - loss: 23.7810 - NN_RMSLE: 4.8613\n",
            "Epoch 1: val_loss improved from inf to 16.25625, saving model to model_71[]\n",
            "INFO:tensorflow:Assets written to: model_71[]/assets\n",
            "1365/1365 [==============================] - 4s 3ms/step - loss: 23.7628 - NN_RMSLE: 4.8593 - val_loss: 16.2563 - val_NN_RMSLE: 3.9294\n",
            "Epoch 2/100\n",
            "1357/1365 [============================>.] - ETA: 0s - loss: 16.2358 - NN_RMSLE: 4.0192\n",
            "Epoch 2: val_loss improved from 16.25625 to 11.65269, saving model to model_71[]\n",
            "INFO:tensorflow:Assets written to: model_71[]/assets\n",
            "1365/1365 [==============================] - 5s 3ms/step - loss: 16.2240 - NN_RMSLE: 4.0184 - val_loss: 11.6527 - val_NN_RMSLE: 3.3519\n",
            "Epoch 3/100\n",
            "1348/1365 [============================>.] - ETA: 0s - loss: 11.9922 - NN_RMSLE: 3.4572\n",
            "Epoch 3: val_loss improved from 11.65269 to 9.63922, saving model to model_71[]\n",
            "INFO:tensorflow:Assets written to: model_71[]/assets\n",
            "1365/1365 [==============================] - 5s 3ms/step - loss: 11.9807 - NN_RMSLE: 3.4556 - val_loss: 9.6392 - val_NN_RMSLE: 3.0816\n",
            "Epoch 4/100\n",
            "1356/1365 [============================>.] - ETA: 0s - loss: 10.0456 - NN_RMSLE: 3.1665\n",
            "Epoch 4: val_loss improved from 9.63922 to 9.23062, saving model to model_71[]\n",
            "INFO:tensorflow:Assets written to: model_71[]/assets\n",
            "1365/1365 [==============================] - 4s 3ms/step - loss: 10.0438 - NN_RMSLE: 3.1659 - val_loss: 9.2306 - val_NN_RMSLE: 3.0239\n",
            "Epoch 5/100\n",
            "1363/1365 [============================>.] - ETA: 0s - loss: 9.4740 - NN_RMSLE: 3.0744\n",
            "Epoch 5: val_loss did not improve from 9.23062\n",
            "1365/1365 [==============================] - 4s 3ms/step - loss: 9.4734 - NN_RMSLE: 3.0745 - val_loss: 9.3855 - val_NN_RMSLE: 3.0416\n",
            "Epoch 6/100\n",
            "1350/1365 [============================>.] - ETA: 0s - loss: 9.3934 - NN_RMSLE: 3.0606\n",
            "Epoch 6: val_loss did not improve from 9.23062\n",
            "1365/1365 [==============================] - 4s 3ms/step - loss: 9.3983 - NN_RMSLE: 3.0616 - val_loss: 9.4787 - val_NN_RMSLE: 3.0527\n",
            "Epoch 7/100\n",
            "1354/1365 [============================>.] - ETA: 0s - loss: 9.3953 - NN_RMSLE: 3.0611\n",
            "Epoch 7: val_loss did not improve from 9.23062\n",
            "1365/1365 [==============================] - 4s 3ms/step - loss: 9.3959 - NN_RMSLE: 3.0614 - val_loss: 9.4923 - val_NN_RMSLE: 3.0543\n",
            "Model: \"sequential_41\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_164 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_123 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_165 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_124 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_166 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_125 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_167 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  9.492269\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 72 (104597, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[1 2 3 4 5]\n",
            "train 69731 valid 34866\n",
            "Model: \"sequential_42\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_168 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_126 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_169 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_127 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_170 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_128 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_171 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1074/1090 [============================>.] - ETA: 0s - loss: 18.5238 - NN_RMSLE: 4.2899\n",
            "Epoch 1: val_loss improved from inf to 36.78062, saving model to model_72[]\n",
            "INFO:tensorflow:Assets written to: model_72[]/assets\n",
            "1090/1090 [==============================] - 4s 4ms/step - loss: 18.4913 - NN_RMSLE: 4.2859 - val_loss: 36.7806 - val_NN_RMSLE: 6.0226\n",
            "Epoch 2/100\n",
            "1087/1090 [============================>.] - ETA: 0s - loss: 14.1681 - NN_RMSLE: 3.7541\n",
            "Epoch 2: val_loss improved from 36.78062 to 27.79991, saving model to model_72[]\n",
            "INFO:tensorflow:Assets written to: model_72[]/assets\n",
            "1090/1090 [==============================] - 6s 5ms/step - loss: 14.1671 - NN_RMSLE: 3.7539 - val_loss: 27.7999 - val_NN_RMSLE: 5.2330\n",
            "Epoch 3/100\n",
            "1085/1090 [============================>.] - ETA: 0s - loss: 11.8717 - NN_RMSLE: 3.4404\n",
            "Epoch 3: val_loss improved from 27.79991 to 21.62057, saving model to model_72[]\n",
            "INFO:tensorflow:Assets written to: model_72[]/assets\n",
            "1090/1090 [==============================] - 6s 5ms/step - loss: 11.8712 - NN_RMSLE: 3.4404 - val_loss: 21.6206 - val_NN_RMSLE: 4.6146\n",
            "Epoch 4/100\n",
            "1079/1090 [============================>.] - ETA: 0s - loss: 10.8922 - NN_RMSLE: 3.2977\n",
            "Epoch 4: val_loss improved from 21.62057 to 17.81955, saving model to model_72[]\n",
            "INFO:tensorflow:Assets written to: model_72[]/assets\n",
            "1090/1090 [==============================] - 4s 3ms/step - loss: 10.8908 - NN_RMSLE: 3.2975 - val_loss: 17.8195 - val_NN_RMSLE: 4.1909\n",
            "Epoch 5/100\n",
            "1078/1090 [============================>.] - ETA: 0s - loss: 10.6127 - NN_RMSLE: 3.2561\n",
            "Epoch 5: val_loss improved from 17.81955 to 16.03079, saving model to model_72[]\n",
            "INFO:tensorflow:Assets written to: model_72[]/assets\n",
            "1090/1090 [==============================] - 6s 5ms/step - loss: 10.6145 - NN_RMSLE: 3.2564 - val_loss: 16.0308 - val_NN_RMSLE: 3.9764\n",
            "Epoch 6/100\n",
            "1089/1090 [============================>.] - ETA: 0s - loss: 10.5756 - NN_RMSLE: 3.2507\n",
            "Epoch 6: val_loss improved from 16.03079 to 15.54871, saving model to model_72[]\n",
            "INFO:tensorflow:Assets written to: model_72[]/assets\n",
            "1090/1090 [==============================] - 4s 4ms/step - loss: 10.5756 - NN_RMSLE: 3.2507 - val_loss: 15.5487 - val_NN_RMSLE: 3.9166\n",
            "Epoch 7/100\n",
            "1079/1090 [============================>.] - ETA: 0s - loss: 10.5751 - NN_RMSLE: 3.2506\n",
            "Epoch 7: val_loss improved from 15.54871 to 15.49145, saving model to model_72[]\n",
            "INFO:tensorflow:Assets written to: model_72[]/assets\n",
            "1090/1090 [==============================] - 4s 4ms/step - loss: 10.5734 - NN_RMSLE: 3.2502 - val_loss: 15.4914 - val_NN_RMSLE: 3.9094\n",
            "Epoch 8/100\n",
            "1073/1090 [============================>.] - ETA: 0s - loss: 10.5713 - NN_RMSLE: 3.2500\n",
            "Epoch 8: val_loss improved from 15.49145 to 15.41345, saving model to model_72[]\n",
            "INFO:tensorflow:Assets written to: model_72[]/assets\n",
            "1090/1090 [==============================] - 4s 3ms/step - loss: 10.5734 - NN_RMSLE: 3.2503 - val_loss: 15.4134 - val_NN_RMSLE: 3.8997\n",
            "Epoch 9/100\n",
            "1074/1090 [============================>.] - ETA: 0s - loss: 10.5763 - NN_RMSLE: 3.2507\n",
            "Epoch 9: val_loss improved from 15.41345 to 15.41180, saving model to model_72[]\n",
            "INFO:tensorflow:Assets written to: model_72[]/assets\n",
            "1090/1090 [==============================] - 4s 4ms/step - loss: 10.5734 - NN_RMSLE: 3.2503 - val_loss: 15.4118 - val_NN_RMSLE: 3.8995\n",
            "Epoch 10/100\n",
            "1082/1090 [============================>.] - ETA: 0s - loss: 10.5722 - NN_RMSLE: 3.2501\n",
            "Epoch 10: val_loss improved from 15.41180 to 15.40290, saving model to model_72[]\n",
            "INFO:tensorflow:Assets written to: model_72[]/assets\n",
            "1090/1090 [==============================] - 4s 4ms/step - loss: 10.5734 - NN_RMSLE: 3.2503 - val_loss: 15.4029 - val_NN_RMSLE: 3.8983\n",
            "Epoch 11/100\n",
            "1090/1090 [==============================] - ETA: 0s - loss: 10.5733 - NN_RMSLE: 3.2502\n",
            "Epoch 11: val_loss did not improve from 15.40290\n",
            "1090/1090 [==============================] - 3s 3ms/step - loss: 10.5733 - NN_RMSLE: 3.2502 - val_loss: 15.4504 - val_NN_RMSLE: 3.9043\n",
            "Epoch 12/100\n",
            "1084/1090 [============================>.] - ETA: 0s - loss: 10.5727 - NN_RMSLE: 3.2503\n",
            "Epoch 12: val_loss did not improve from 15.40290\n",
            "1090/1090 [==============================] - 3s 3ms/step - loss: 10.5734 - NN_RMSLE: 3.2503 - val_loss: 15.4368 - val_NN_RMSLE: 3.9026\n",
            "Epoch 13/100\n",
            "1074/1090 [============================>.] - ETA: 0s - loss: 10.5722 - NN_RMSLE: 3.2501\n",
            "Epoch 13: val_loss did not improve from 15.40290\n",
            "1090/1090 [==============================] - 4s 3ms/step - loss: 10.5733 - NN_RMSLE: 3.2503 - val_loss: 15.5313 - val_NN_RMSLE: 3.9144\n",
            "Model: \"sequential_42\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_168 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_126 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_169 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_127 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_170 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_128 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_171 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  15.531286\n",
            "\n",
            "[5 6 7 8 9]\n",
            "train 69731 valid 34866\n",
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_172 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_129 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_173 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_130 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_174 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_131 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_175 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1090/1090 [==============================] - ETA: 0s - loss: 34.6936 - NN_RMSLE: 5.8807\n",
            "Epoch 1: val_loss improved from inf to 8.64843, saving model to model_72[]\n",
            "INFO:tensorflow:Assets written to: model_72[]/assets\n",
            "1090/1090 [==============================] - 5s 4ms/step - loss: 34.6936 - NN_RMSLE: 5.8807 - val_loss: 8.6484 - val_NN_RMSLE: 2.8904\n",
            "Epoch 2/100\n",
            "1073/1090 [============================>.] - ETA: 0s - loss: 25.4536 - NN_RMSLE: 5.0367\n",
            "Epoch 2: val_loss improved from 8.64843 to 7.61830, saving model to model_72[]\n",
            "INFO:tensorflow:Assets written to: model_72[]/assets\n",
            "1090/1090 [==============================] - 3s 3ms/step - loss: 25.3972 - NN_RMSLE: 5.0309 - val_loss: 7.6183 - val_NN_RMSLE: 2.7398\n",
            "Epoch 3/100\n",
            "1080/1090 [============================>.] - ETA: 0s - loss: 18.6204 - NN_RMSLE: 4.3085\n",
            "Epoch 3: val_loss did not improve from 7.61830\n",
            "1090/1090 [==============================] - 3s 3ms/step - loss: 18.5954 - NN_RMSLE: 4.3054 - val_loss: 8.2971 - val_NN_RMSLE: 2.8776\n",
            "Epoch 4/100\n",
            "1070/1090 [============================>.] - ETA: 0s - loss: 13.8581 - NN_RMSLE: 3.7179\n",
            "Epoch 4: val_loss did not improve from 7.61830\n",
            "1090/1090 [==============================] - 3s 3ms/step - loss: 13.8290 - NN_RMSLE: 3.7138 - val_loss: 10.2952 - val_NN_RMSLE: 3.2048\n",
            "Epoch 5/100\n",
            "1075/1090 [============================>.] - ETA: 0s - loss: 10.7756 - NN_RMSLE: 3.2795\n",
            "Epoch 5: val_loss did not improve from 7.61830\n",
            "1090/1090 [==============================] - 3s 3ms/step - loss: 10.7591 - NN_RMSLE: 3.2768 - val_loss: 13.1635 - val_NN_RMSLE: 3.6154\n",
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_172 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_129 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_173 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_130 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_174 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_131 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_175 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  13.163491\n",
            "\n",
            "[ 9 10 11 12]\n",
            "train 69732 valid 34865\n",
            "Model: \"sequential_44\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_176 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_132 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_177 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_133 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_178 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_134 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_179 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1082/1090 [============================>.] - ETA: 0s - loss: 26.3995 - NN_RMSLE: 5.1263\n",
            "Epoch 1: val_loss improved from inf to 22.95707, saving model to model_72[]\n",
            "INFO:tensorflow:Assets written to: model_72[]/assets\n",
            "1090/1090 [==============================] - 4s 3ms/step - loss: 26.3690 - NN_RMSLE: 5.1233 - val_loss: 22.9571 - val_NN_RMSLE: 4.5435\n",
            "Epoch 2/100\n",
            "1078/1090 [============================>.] - ETA: 0s - loss: 19.7633 - NN_RMSLE: 4.4372\n",
            "Epoch 2: val_loss improved from 22.95707 to 17.31141, saving model to model_72[]\n",
            "INFO:tensorflow:Assets written to: model_72[]/assets\n",
            "1090/1090 [==============================] - 4s 3ms/step - loss: 19.7427 - NN_RMSLE: 4.4348 - val_loss: 17.3114 - val_NN_RMSLE: 3.9905\n",
            "Epoch 3/100\n",
            "1085/1090 [============================>.] - ETA: 0s - loss: 15.4347 - NN_RMSLE: 3.9230\n",
            "Epoch 3: val_loss improved from 17.31141 to 13.71785, saving model to model_72[]\n",
            "INFO:tensorflow:Assets written to: model_72[]/assets\n",
            "1090/1090 [==============================] - 4s 3ms/step - loss: 15.4269 - NN_RMSLE: 3.9220 - val_loss: 13.7178 - val_NN_RMSLE: 3.6214\n",
            "Epoch 4/100\n",
            "1071/1090 [============================>.] - ETA: 0s - loss: 12.8983 - NN_RMSLE: 3.5886\n",
            "Epoch 4: val_loss improved from 13.71785 to 11.68964, saving model to model_72[]\n",
            "INFO:tensorflow:Assets written to: model_72[]/assets\n",
            "1090/1090 [==============================] - 4s 4ms/step - loss: 12.8811 - NN_RMSLE: 3.5862 - val_loss: 11.6896 - val_NN_RMSLE: 3.3951\n",
            "Epoch 5/100\n",
            "1083/1090 [============================>.] - ETA: 0s - loss: 11.6266 - NN_RMSLE: 3.4082\n",
            "Epoch 5: val_loss improved from 11.68964 to 10.76967, saving model to model_72[]\n",
            "INFO:tensorflow:Assets written to: model_72[]/assets\n",
            "1090/1090 [==============================] - 4s 4ms/step - loss: 11.6271 - NN_RMSLE: 3.4083 - val_loss: 10.7697 - val_NN_RMSLE: 3.2732\n",
            "Epoch 6/100\n",
            "1076/1090 [============================>.] - ETA: 0s - loss: 11.1812 - NN_RMSLE: 3.3419\n",
            "Epoch 6: val_loss improved from 10.76967 to 10.47256, saving model to model_72[]\n",
            "INFO:tensorflow:Assets written to: model_72[]/assets\n",
            "1090/1090 [==============================] - 4s 4ms/step - loss: 11.1842 - NN_RMSLE: 3.3425 - val_loss: 10.4726 - val_NN_RMSLE: 3.2194\n",
            "Epoch 7/100\n",
            "1084/1090 [============================>.] - ETA: 0s - loss: 11.0975 - NN_RMSLE: 3.3289\n",
            "Epoch 7: val_loss improved from 10.47256 to 10.41500, saving model to model_72[]\n",
            "INFO:tensorflow:Assets written to: model_72[]/assets\n",
            "1090/1090 [==============================] - 4s 3ms/step - loss: 11.0974 - NN_RMSLE: 3.3288 - val_loss: 10.4150 - val_NN_RMSLE: 3.2038\n",
            "Epoch 8/100\n",
            "1082/1090 [============================>.] - ETA: 0s - loss: 11.0853 - NN_RMSLE: 3.3269\n",
            "Epoch 8: val_loss improved from 10.41500 to 10.41069, saving model to model_72[]\n",
            "INFO:tensorflow:Assets written to: model_72[]/assets\n",
            "1090/1090 [==============================] - 3s 3ms/step - loss: 11.0900 - NN_RMSLE: 3.3276 - val_loss: 10.4107 - val_NN_RMSLE: 3.2023\n",
            "Epoch 9/100\n",
            "1074/1090 [============================>.] - ETA: 0s - loss: 11.0940 - NN_RMSLE: 3.3281\n",
            "Epoch 9: val_loss improved from 10.41069 to 10.40506, saving model to model_72[]\n",
            "INFO:tensorflow:Assets written to: model_72[]/assets\n",
            "1090/1090 [==============================] - 4s 3ms/step - loss: 11.0898 - NN_RMSLE: 3.3275 - val_loss: 10.4051 - val_NN_RMSLE: 3.2002\n",
            "Epoch 10/100\n",
            "1082/1090 [============================>.] - ETA: 0s - loss: 11.0917 - NN_RMSLE: 3.3278\n",
            "Epoch 10: val_loss improved from 10.40506 to 10.40491, saving model to model_72[]\n",
            "INFO:tensorflow:Assets written to: model_72[]/assets\n",
            "1090/1090 [==============================] - 4s 3ms/step - loss: 11.0896 - NN_RMSLE: 3.3275 - val_loss: 10.4049 - val_NN_RMSLE: 3.2002\n",
            "Epoch 11/100\n",
            "1078/1090 [============================>.] - ETA: 0s - loss: 11.0956 - NN_RMSLE: 3.3285\n",
            "Epoch 11: val_loss improved from 10.40491 to 10.40478, saving model to model_72[]\n",
            "INFO:tensorflow:Assets written to: model_72[]/assets\n",
            "1090/1090 [==============================] - 4s 4ms/step - loss: 11.0898 - NN_RMSLE: 3.3275 - val_loss: 10.4048 - val_NN_RMSLE: 3.2001\n",
            "Epoch 12/100\n",
            "1074/1090 [============================>.] - ETA: 0s - loss: 11.0856 - NN_RMSLE: 3.3269\n",
            "Epoch 12: val_loss improved from 10.40478 to 10.40432, saving model to model_72[]\n",
            "INFO:tensorflow:Assets written to: model_72[]/assets\n",
            "1090/1090 [==============================] - 4s 4ms/step - loss: 11.0898 - NN_RMSLE: 3.3276 - val_loss: 10.4043 - val_NN_RMSLE: 3.1999\n",
            "Epoch 13/100\n",
            "1075/1090 [============================>.] - ETA: 0s - loss: 11.0894 - NN_RMSLE: 3.3274\n",
            "Epoch 13: val_loss improved from 10.40432 to 10.40136, saving model to model_72[]\n",
            "INFO:tensorflow:Assets written to: model_72[]/assets\n",
            "1090/1090 [==============================] - 4s 3ms/step - loss: 11.0897 - NN_RMSLE: 3.3275 - val_loss: 10.4014 - val_NN_RMSLE: 3.1988\n",
            "Epoch 14/100\n",
            "1070/1090 [============================>.] - ETA: 0s - loss: 11.0881 - NN_RMSLE: 3.3271\n",
            "Epoch 14: val_loss did not improve from 10.40136\n",
            "1090/1090 [==============================] - 3s 3ms/step - loss: 11.0897 - NN_RMSLE: 3.3273 - val_loss: 10.4071 - val_NN_RMSLE: 3.2010\n",
            "Epoch 15/100\n",
            "1089/1090 [============================>.] - ETA: 0s - loss: 11.0902 - NN_RMSLE: 3.3276\n",
            "Epoch 15: val_loss did not improve from 10.40136\n",
            "1090/1090 [==============================] - 3s 3ms/step - loss: 11.0898 - NN_RMSLE: 3.3275 - val_loss: 10.4028 - val_NN_RMSLE: 3.1994\n",
            "Epoch 16/100\n",
            "1076/1090 [============================>.] - ETA: 0s - loss: 11.0951 - NN_RMSLE: 3.3285\n",
            "Epoch 16: val_loss did not improve from 10.40136\n",
            "1090/1090 [==============================] - 3s 3ms/step - loss: 11.0898 - NN_RMSLE: 3.3277 - val_loss: 10.4044 - val_NN_RMSLE: 3.2000\n",
            "Model: \"sequential_44\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_176 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_132 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_177 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_133 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_178 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_134 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_179 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  10.404417\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 70 (90893, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[ 1  2  3  4  5  8  9 10]\n",
            "train 60595 valid 30298\n",
            "Model: \"sequential_45\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_180 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_135 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_181 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_136 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_182 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_137 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_183 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "932/947 [============================>.] - ETA: 0s - loss: 47.8365 - NN_RMSLE: 6.9105\n",
            "Epoch 1: val_loss improved from inf to 42.10310, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 4s 4ms/step - loss: 47.7438 - NN_RMSLE: 6.9036 - val_loss: 42.1031 - val_NN_RMSLE: 6.4857\n",
            "Epoch 2/100\n",
            "945/947 [============================>.] - ETA: 0s - loss: 36.3630 - NN_RMSLE: 6.0234\n",
            "Epoch 2: val_loss improved from 42.10310 to 31.71195, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 5s 6ms/step - loss: 36.3580 - NN_RMSLE: 6.0229 - val_loss: 31.7120 - val_NN_RMSLE: 5.6277\n",
            "Epoch 3/100\n",
            "944/947 [============================>.] - ETA: 0s - loss: 27.0286 - NN_RMSLE: 5.1922\n",
            "Epoch 3: val_loss improved from 31.71195 to 23.20303, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 5s 5ms/step - loss: 27.0133 - NN_RMSLE: 5.1905 - val_loss: 23.2030 - val_NN_RMSLE: 4.8126\n",
            "Epoch 4/100\n",
            "930/947 [============================>.] - ETA: 0s - loss: 19.4812 - NN_RMSLE: 4.4062\n",
            "Epoch 4: val_loss improved from 23.20303 to 16.35109, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 4s 4ms/step - loss: 19.4284 - NN_RMSLE: 4.4000 - val_loss: 16.3511 - val_NN_RMSLE: 4.0383\n",
            "Epoch 5/100\n",
            "935/947 [============================>.] - ETA: 0s - loss: 13.4404 - NN_RMSLE: 3.6582\n",
            "Epoch 5: val_loss improved from 16.35109 to 10.98887, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 3s 4ms/step - loss: 13.4088 - NN_RMSLE: 3.6537 - val_loss: 10.9889 - val_NN_RMSLE: 3.3084\n",
            "Epoch 6/100\n",
            "931/947 [============================>.] - ETA: 0s - loss: 8.8376 - NN_RMSLE: 2.9642\n",
            "Epoch 6: val_loss improved from 10.98887 to 6.98461, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 3s 4ms/step - loss: 8.8088 - NN_RMSLE: 2.9592 - val_loss: 6.9846 - val_NN_RMSLE: 2.6347\n",
            "Epoch 7/100\n",
            "939/947 [============================>.] - ETA: 0s - loss: 5.5030 - NN_RMSLE: 2.3374\n",
            "Epoch 7: val_loss improved from 6.98461 to 4.19751, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 4s 4ms/step - loss: 5.4925 - NN_RMSLE: 2.3350 - val_loss: 4.1975 - val_NN_RMSLE: 2.0388\n",
            "Epoch 8/100\n",
            "935/947 [============================>.] - ETA: 0s - loss: 3.3167 - NN_RMSLE: 1.8137\n",
            "Epoch 8: val_loss improved from 4.19751 to 2.46355, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 4s 4ms/step - loss: 3.3091 - NN_RMSLE: 1.8115 - val_loss: 2.4636 - val_NN_RMSLE: 1.5582\n",
            "Epoch 9/100\n",
            "936/947 [============================>.] - ETA: 0s - loss: 2.0737 - NN_RMSLE: 1.4339\n",
            "Epoch 9: val_loss improved from 2.46355 to 1.56488, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 4s 4ms/step - loss: 2.0676 - NN_RMSLE: 1.4317 - val_loss: 1.5649 - val_NN_RMSLE: 1.2395\n",
            "Epoch 10/100\n",
            "942/947 [============================>.] - ETA: 0s - loss: 1.5138 - NN_RMSLE: 1.2258\n",
            "Epoch 10: val_loss improved from 1.56488 to 1.22112, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 4s 4ms/step - loss: 1.5134 - NN_RMSLE: 1.2257 - val_loss: 1.2211 - val_NN_RMSLE: 1.0955\n",
            "Epoch 11/100\n",
            "938/947 [============================>.] - ETA: 0s - loss: 1.3502 - NN_RMSLE: 1.1565\n",
            "Epoch 11: val_loss improved from 1.22112 to 1.14066, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 4s 4ms/step - loss: 1.3499 - NN_RMSLE: 1.1564 - val_loss: 1.1407 - val_NN_RMSLE: 1.0598\n",
            "Epoch 12/100\n",
            "938/947 [============================>.] - ETA: 0s - loss: 1.3257 - NN_RMSLE: 1.1451\n",
            "Epoch 12: val_loss improved from 1.14066 to 1.12886, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 4s 4ms/step - loss: 1.3248 - NN_RMSLE: 1.1446 - val_loss: 1.1289 - val_NN_RMSLE: 1.0546\n",
            "Epoch 13/100\n",
            "935/947 [============================>.] - ETA: 0s - loss: 1.3241 - NN_RMSLE: 1.1447\n",
            "Epoch 13: val_loss improved from 1.12886 to 1.12807, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 4s 4ms/step - loss: 1.3234 - NN_RMSLE: 1.1444 - val_loss: 1.1281 - val_NN_RMSLE: 1.0543\n",
            "Epoch 14/100\n",
            "934/947 [============================>.] - ETA: 0s - loss: 1.3226 - NN_RMSLE: 1.1433\n",
            "Epoch 14: val_loss did not improve from 1.12807\n",
            "947/947 [==============================] - 3s 4ms/step - loss: 1.3234 - NN_RMSLE: 1.1436 - val_loss: 1.1291 - val_NN_RMSLE: 1.0547\n",
            "Epoch 15/100\n",
            "945/947 [============================>.] - ETA: 0s - loss: 1.3234 - NN_RMSLE: 1.1441\n",
            "Epoch 15: val_loss improved from 1.12807 to 1.12755, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 4s 4ms/step - loss: 1.3235 - NN_RMSLE: 1.1442 - val_loss: 1.1275 - val_NN_RMSLE: 1.0540\n",
            "Epoch 16/100\n",
            "938/947 [============================>.] - ETA: 0s - loss: 1.3234 - NN_RMSLE: 1.1439\n",
            "Epoch 16: val_loss did not improve from 1.12755\n",
            "947/947 [==============================] - 3s 3ms/step - loss: 1.3235 - NN_RMSLE: 1.1439 - val_loss: 1.1285 - val_NN_RMSLE: 1.0544\n",
            "Epoch 17/100\n",
            "927/947 [============================>.] - ETA: 0s - loss: 1.3219 - NN_RMSLE: 1.1435\n",
            "Epoch 17: val_loss did not improve from 1.12755\n",
            "947/947 [==============================] - 3s 3ms/step - loss: 1.3235 - NN_RMSLE: 1.1441 - val_loss: 1.1280 - val_NN_RMSLE: 1.0542\n",
            "Epoch 18/100\n",
            "935/947 [============================>.] - ETA: 0s - loss: 1.3232 - NN_RMSLE: 1.1438\n",
            "Epoch 18: val_loss improved from 1.12755 to 1.12715, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 4s 4ms/step - loss: 1.3235 - NN_RMSLE: 1.1439 - val_loss: 1.1271 - val_NN_RMSLE: 1.0539\n",
            "Epoch 19/100\n",
            "934/947 [============================>.] - ETA: 0s - loss: 1.3239 - NN_RMSLE: 1.1442\n",
            "Epoch 19: val_loss did not improve from 1.12715\n",
            "947/947 [==============================] - 3s 3ms/step - loss: 1.3235 - NN_RMSLE: 1.1440 - val_loss: 1.1298 - val_NN_RMSLE: 1.0550\n",
            "Epoch 20/100\n",
            "935/947 [============================>.] - ETA: 0s - loss: 1.3240 - NN_RMSLE: 1.1441\n",
            "Epoch 20: val_loss did not improve from 1.12715\n",
            "947/947 [==============================] - 3s 3ms/step - loss: 1.3235 - NN_RMSLE: 1.1439 - val_loss: 1.1280 - val_NN_RMSLE: 1.0543\n",
            "Epoch 21/100\n",
            "941/947 [============================>.] - ETA: 0s - loss: 1.3236 - NN_RMSLE: 1.1440\n",
            "Epoch 21: val_loss did not improve from 1.12715\n",
            "947/947 [==============================] - 3s 3ms/step - loss: 1.3235 - NN_RMSLE: 1.1439 - val_loss: 1.1279 - val_NN_RMSLE: 1.0542\n",
            "Model: \"sequential_45\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_180 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_135 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_181 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_136 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_182 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_137 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_183 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.1279122\n",
            "\n",
            "[ 3  4  5  6  7  8  9 10 11]\n",
            "train 60595 valid 30298\n",
            "Model: \"sequential_46\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_184 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_138 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_185 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_139 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_186 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_140 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_187 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "939/947 [============================>.] - ETA: 0s - loss: 48.2842 - NN_RMSLE: 6.9427\n",
            "Epoch 1: val_loss improved from inf to 41.19230, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 4s 4ms/step - loss: 48.2371 - NN_RMSLE: 6.9392 - val_loss: 41.1923 - val_NN_RMSLE: 6.4106\n",
            "Epoch 2/100\n",
            "946/947 [============================>.] - ETA: 0s - loss: 36.7648 - NN_RMSLE: 6.0573\n",
            "Epoch 2: val_loss improved from 41.19230 to 30.95334, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 4s 4ms/step - loss: 36.7617 - NN_RMSLE: 6.0570 - val_loss: 30.9533 - val_NN_RMSLE: 5.5549\n",
            "Epoch 3/100\n",
            "933/947 [============================>.] - ETA: 0s - loss: 27.3932 - NN_RMSLE: 5.2267\n",
            "Epoch 3: val_loss improved from 30.95334 to 22.59939, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 4s 4ms/step - loss: 27.3344 - NN_RMSLE: 5.2209 - val_loss: 22.5994 - val_NN_RMSLE: 4.7438\n",
            "Epoch 4/100\n",
            "933/947 [============================>.] - ETA: 0s - loss: 19.7144 - NN_RMSLE: 4.4327\n",
            "Epoch 4: val_loss improved from 22.59939 to 15.88788, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 3s 3ms/step - loss: 19.6679 - NN_RMSLE: 4.4273 - val_loss: 15.8879 - val_NN_RMSLE: 3.9742\n",
            "Epoch 5/100\n",
            "940/947 [============================>.] - ETA: 0s - loss: 13.5834 - NN_RMSLE: 3.6778\n",
            "Epoch 5: val_loss improved from 15.88788 to 10.66034, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 3s 3ms/step - loss: 13.5675 - NN_RMSLE: 3.6755 - val_loss: 10.6603 - val_NN_RMSLE: 3.2512\n",
            "Epoch 6/100\n",
            "946/947 [============================>.] - ETA: 0s - loss: 8.8943 - NN_RMSLE: 2.9740\n",
            "Epoch 6: val_loss improved from 10.66034 to 6.78452, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 3s 4ms/step - loss: 8.8917 - NN_RMSLE: 2.9734 - val_loss: 6.7845 - val_NN_RMSLE: 2.5883\n",
            "Epoch 7/100\n",
            "931/947 [============================>.] - ETA: 0s - loss: 5.5307 - NN_RMSLE: 2.3437\n",
            "Epoch 7: val_loss improved from 6.78452 to 4.11984, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 4s 4ms/step - loss: 5.5067 - NN_RMSLE: 2.3383 - val_loss: 4.1198 - val_NN_RMSLE: 2.0103\n",
            "Epoch 8/100\n",
            "933/947 [============================>.] - ETA: 0s - loss: 3.2772 - NN_RMSLE: 1.8025\n",
            "Epoch 8: val_loss improved from 4.11984 to 2.50125, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 3s 3ms/step - loss: 3.2654 - NN_RMSLE: 1.7991 - val_loss: 2.5012 - val_NN_RMSLE: 1.5592\n",
            "Epoch 9/100\n",
            "930/947 [============================>.] - ETA: 0s - loss: 1.9823 - NN_RMSLE: 1.4030\n",
            "Epoch 9: val_loss improved from 2.50125 to 1.70066, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 4s 4ms/step - loss: 1.9758 - NN_RMSLE: 1.4006 - val_loss: 1.7007 - val_NN_RMSLE: 1.2813\n",
            "Epoch 10/100\n",
            "940/947 [============================>.] - ETA: 0s - loss: 1.3906 - NN_RMSLE: 1.1761\n",
            "Epoch 10: val_loss improved from 1.70066 to 1.43552, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 4s 4ms/step - loss: 1.3895 - NN_RMSLE: 1.1756 - val_loss: 1.4355 - val_NN_RMSLE: 1.1761\n",
            "Epoch 11/100\n",
            "936/947 [============================>.] - ETA: 0s - loss: 1.2116 - NN_RMSLE: 1.0974\n",
            "Epoch 11: val_loss improved from 1.43552 to 1.40231, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 4s 4ms/step - loss: 1.2127 - NN_RMSLE: 1.0979 - val_loss: 1.4023 - val_NN_RMSLE: 1.1621\n",
            "Epoch 12/100\n",
            "944/947 [============================>.] - ETA: 0s - loss: 1.1855 - NN_RMSLE: 1.0852\n",
            "Epoch 12: val_loss did not improve from 1.40231\n",
            "947/947 [==============================] - 3s 3ms/step - loss: 1.1849 - NN_RMSLE: 1.0848 - val_loss: 1.4088 - val_NN_RMSLE: 1.1645\n",
            "Epoch 13/100\n",
            "944/947 [============================>.] - ETA: 0s - loss: 1.1834 - NN_RMSLE: 1.0840\n",
            "Epoch 13: val_loss did not improve from 1.40231\n",
            "947/947 [==============================] - 3s 3ms/step - loss: 1.1834 - NN_RMSLE: 1.0840 - val_loss: 1.4102 - val_NN_RMSLE: 1.1651\n",
            "Epoch 14/100\n",
            "929/947 [============================>.] - ETA: 0s - loss: 1.1826 - NN_RMSLE: 1.0831\n",
            "Epoch 14: val_loss did not improve from 1.40231\n",
            "947/947 [==============================] - 3s 3ms/step - loss: 1.1834 - NN_RMSLE: 1.0835 - val_loss: 1.4112 - val_NN_RMSLE: 1.1654\n",
            "Model: \"sequential_46\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_184 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_138 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_185 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_139 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_186 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_140 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_187 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.4111525\n",
            "\n",
            "[ 6  7  8  9 10 11 12]\n",
            "train 60596 valid 30297\n",
            "Model: \"sequential_47\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_188 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_141 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_189 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_142 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_190 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_143 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_191 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "938/947 [============================>.] - ETA: 0s - loss: 47.7763 - NN_RMSLE: 6.9061\n",
            "Epoch 1: val_loss improved from inf to 42.14902, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 4s 4ms/step - loss: 47.7218 - NN_RMSLE: 6.9019 - val_loss: 42.1490 - val_NN_RMSLE: 6.4830\n",
            "Epoch 2/100\n",
            "945/947 [============================>.] - ETA: 0s - loss: 36.3422 - NN_RMSLE: 6.0220\n",
            "Epoch 2: val_loss improved from 42.14902 to 31.76568, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 3s 4ms/step - loss: 36.3306 - NN_RMSLE: 6.0209 - val_loss: 31.7657 - val_NN_RMSLE: 5.6257\n",
            "Epoch 3/100\n",
            "945/947 [============================>.] - ETA: 0s - loss: 26.9895 - NN_RMSLE: 5.1881\n",
            "Epoch 3: val_loss improved from 31.76568 to 23.26872, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 4s 4ms/step - loss: 26.9820 - NN_RMSLE: 5.1874 - val_loss: 23.2687 - val_NN_RMSLE: 4.8119\n",
            "Epoch 4/100\n",
            "937/947 [============================>.] - ETA: 0s - loss: 19.4270 - NN_RMSLE: 4.4009\n",
            "Epoch 4: val_loss improved from 23.26872 to 16.41985, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 4s 4ms/step - loss: 19.3907 - NN_RMSLE: 4.3965 - val_loss: 16.4198 - val_NN_RMSLE: 4.0385\n",
            "Epoch 5/100\n",
            "937/947 [============================>.] - ETA: 0s - loss: 13.3931 - NN_RMSLE: 3.6519\n",
            "Epoch 5: val_loss improved from 16.41985 to 11.06631, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 4s 4ms/step - loss: 13.3657 - NN_RMSLE: 3.6480 - val_loss: 11.0663 - val_NN_RMSLE: 3.3108\n",
            "Epoch 6/100\n",
            "938/947 [============================>.] - ETA: 0s - loss: 8.7795 - NN_RMSLE: 2.9547\n",
            "Epoch 6: val_loss improved from 11.06631 to 7.06997, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 3s 3ms/step - loss: 8.7620 - NN_RMSLE: 2.9515 - val_loss: 7.0700 - val_NN_RMSLE: 2.6406\n",
            "Epoch 7/100\n",
            "930/947 [============================>.] - ETA: 0s - loss: 5.4672 - NN_RMSLE: 2.3303\n",
            "Epoch 7: val_loss improved from 7.06997 to 4.28921, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 4s 4ms/step - loss: 5.4420 - NN_RMSLE: 2.3245 - val_loss: 4.2892 - val_NN_RMSLE: 2.0504\n",
            "Epoch 8/100\n",
            "941/947 [============================>.] - ETA: 0s - loss: 3.2626 - NN_RMSLE: 1.7982\n",
            "Epoch 8: val_loss improved from 4.28921 to 2.56490, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 4s 4ms/step - loss: 3.2575 - NN_RMSLE: 1.7967 - val_loss: 2.5649 - val_NN_RMSLE: 1.5812\n",
            "Epoch 9/100\n",
            "947/947 [==============================] - ETA: 0s - loss: 2.0130 - NN_RMSLE: 1.4129\n",
            "Epoch 9: val_loss improved from 2.56490 to 1.67142, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 3s 4ms/step - loss: 2.0130 - NN_RMSLE: 1.4129 - val_loss: 1.6714 - val_NN_RMSLE: 1.2780\n",
            "Epoch 10/100\n",
            "947/947 [==============================] - ETA: 0s - loss: 1.4570 - NN_RMSLE: 1.2022\n",
            "Epoch 10: val_loss improved from 1.67142 to 1.33202, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 4s 4ms/step - loss: 1.4570 - NN_RMSLE: 1.2022 - val_loss: 1.3320 - val_NN_RMSLE: 1.1470\n",
            "Epoch 11/100\n",
            "939/947 [============================>.] - ETA: 0s - loss: 1.2930 - NN_RMSLE: 1.1313\n",
            "Epoch 11: val_loss improved from 1.33202 to 1.25299, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 3s 3ms/step - loss: 1.2923 - NN_RMSLE: 1.1310 - val_loss: 1.2530 - val_NN_RMSLE: 1.1160\n",
            "Epoch 12/100\n",
            "936/947 [============================>.] - ETA: 0s - loss: 1.2653 - NN_RMSLE: 1.1189\n",
            "Epoch 12: val_loss improved from 1.25299 to 1.24295, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 3s 4ms/step - loss: 1.2673 - NN_RMSLE: 1.1198 - val_loss: 1.2429 - val_NN_RMSLE: 1.1124\n",
            "Epoch 13/100\n",
            "937/947 [============================>.] - ETA: 0s - loss: 1.2637 - NN_RMSLE: 1.1177\n",
            "Epoch 13: val_loss improved from 1.24295 to 1.24266, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 3s 4ms/step - loss: 1.2662 - NN_RMSLE: 1.1187 - val_loss: 1.2427 - val_NN_RMSLE: 1.1123\n",
            "Epoch 14/100\n",
            "938/947 [============================>.] - ETA: 0s - loss: 1.2675 - NN_RMSLE: 1.1195\n",
            "Epoch 14: val_loss improved from 1.24266 to 1.24203, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 3s 3ms/step - loss: 1.2662 - NN_RMSLE: 1.1189 - val_loss: 1.2420 - val_NN_RMSLE: 1.1121\n",
            "Epoch 15/100\n",
            "922/947 [============================>.] - ETA: 0s - loss: 1.2674 - NN_RMSLE: 1.1191\n",
            "Epoch 15: val_loss improved from 1.24203 to 1.24201, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 3s 4ms/step - loss: 1.2662 - NN_RMSLE: 1.1187 - val_loss: 1.2420 - val_NN_RMSLE: 1.1121\n",
            "Epoch 16/100\n",
            "932/947 [============================>.] - ETA: 0s - loss: 1.2677 - NN_RMSLE: 1.1198\n",
            "Epoch 16: val_loss improved from 1.24201 to 1.24200, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 4s 4ms/step - loss: 1.2662 - NN_RMSLE: 1.1191 - val_loss: 1.2420 - val_NN_RMSLE: 1.1121\n",
            "Epoch 17/100\n",
            "942/947 [============================>.] - ETA: 0s - loss: 1.2669 - NN_RMSLE: 1.1187\n",
            "Epoch 17: val_loss did not improve from 1.24200\n",
            "947/947 [==============================] - 3s 3ms/step - loss: 1.2663 - NN_RMSLE: 1.1184 - val_loss: 1.2429 - val_NN_RMSLE: 1.1123\n",
            "Epoch 18/100\n",
            "933/947 [============================>.] - ETA: 0s - loss: 1.2669 - NN_RMSLE: 1.1189\n",
            "Epoch 18: val_loss improved from 1.24200 to 1.24191, saving model to model_70[]\n",
            "INFO:tensorflow:Assets written to: model_70[]/assets\n",
            "947/947 [==============================] - 3s 4ms/step - loss: 1.2662 - NN_RMSLE: 1.1186 - val_loss: 1.2419 - val_NN_RMSLE: 1.1120\n",
            "Epoch 19/100\n",
            "932/947 [============================>.] - ETA: 0s - loss: 1.2639 - NN_RMSLE: 1.1184\n",
            "Epoch 19: val_loss did not improve from 1.24191\n",
            "947/947 [==============================] - 3s 3ms/step - loss: 1.2663 - NN_RMSLE: 1.1193 - val_loss: 1.2431 - val_NN_RMSLE: 1.1124\n",
            "Epoch 20/100\n",
            "932/947 [============================>.] - ETA: 0s - loss: 1.2639 - NN_RMSLE: 1.1180\n",
            "Epoch 20: val_loss did not improve from 1.24191\n",
            "947/947 [==============================] - 3s 3ms/step - loss: 1.2662 - NN_RMSLE: 1.1191 - val_loss: 1.2427 - val_NN_RMSLE: 1.1123\n",
            "Epoch 21/100\n",
            "935/947 [============================>.] - ETA: 0s - loss: 1.2656 - NN_RMSLE: 1.1189\n",
            "Epoch 21: val_loss did not improve from 1.24191\n",
            "947/947 [==============================] - 3s 3ms/step - loss: 1.2662 - NN_RMSLE: 1.1192 - val_loss: 1.2438 - val_NN_RMSLE: 1.1126\n",
            "Model: \"sequential_47\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_188 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_141 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_189 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_142 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_190 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_143 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_191 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.2437516\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 73 (26344, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[1 2 3 4 5]\n",
            "train 17562 valid 8782\n",
            "Model: \"sequential_48\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_192 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_144 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_193 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_145 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_194 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_146 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_195 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "250/275 [==========================>...] - ETA: 0s - loss: 23.0120 - NN_RMSLE: 4.7852\n",
            "Epoch 1: val_loss improved from inf to 51.11885, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 2s 5ms/step - loss: 22.9970 - NN_RMSLE: 4.7856 - val_loss: 51.1189 - val_NN_RMSLE: 7.1110\n",
            "Epoch 2/100\n",
            "274/275 [============================>.] - ETA: 0s - loss: 21.2551 - NN_RMSLE: 4.5974\n",
            "Epoch 2: val_loss improved from 51.11885 to 47.60875, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 2s 7ms/step - loss: 21.2499 - NN_RMSLE: 4.5960 - val_loss: 47.6088 - val_NN_RMSLE: 6.8617\n",
            "Epoch 3/100\n",
            "264/275 [===========================>..] - ETA: 0s - loss: 19.7751 - NN_RMSLE: 4.4356\n",
            "Epoch 3: val_loss improved from 47.60875 to 44.35638, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 2s 9ms/step - loss: 19.7069 - NN_RMSLE: 4.4259 - val_loss: 44.3564 - val_NN_RMSLE: 6.6225\n",
            "Epoch 4/100\n",
            "255/275 [==========================>...] - ETA: 0s - loss: 18.4166 - NN_RMSLE: 4.2832\n",
            "Epoch 4: val_loss improved from 44.35638 to 41.34082, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 2s 7ms/step - loss: 18.3418 - NN_RMSLE: 4.2743 - val_loss: 41.3408 - val_NN_RMSLE: 6.3929\n",
            "Epoch 5/100\n",
            "274/275 [============================>.] - ETA: 0s - loss: 17.1355 - NN_RMSLE: 4.1287\n",
            "Epoch 5: val_loss improved from 41.34082 to 38.54439, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 2s 9ms/step - loss: 17.1379 - NN_RMSLE: 4.1294 - val_loss: 38.5444 - val_NN_RMSLE: 6.1725\n",
            "Epoch 6/100\n",
            "265/275 [===========================>..] - ETA: 0s - loss: 16.0380 - NN_RMSLE: 3.9962\n",
            "Epoch 6: val_loss improved from 38.54439 to 35.96526, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 16.0847 - NN_RMSLE: 4.0017 - val_loss: 35.9653 - val_NN_RMSLE: 5.9623\n",
            "Epoch 7/100\n",
            "274/275 [============================>.] - ETA: 0s - loss: 15.1698 - NN_RMSLE: 3.8868\n",
            "Epoch 7: val_loss improved from 35.96526 to 33.57533, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 15.1708 - NN_RMSLE: 3.8872 - val_loss: 33.5753 - val_NN_RMSLE: 5.7607\n",
            "Epoch 8/100\n",
            "269/275 [============================>.] - ETA: 0s - loss: 14.3985 - NN_RMSLE: 3.7871\n",
            "Epoch 8: val_loss improved from 33.57533 to 31.37337, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 14.3825 - NN_RMSLE: 3.7851 - val_loss: 31.3734 - val_NN_RMSLE: 5.5687\n",
            "Epoch 9/100\n",
            "251/275 [==========================>...] - ETA: 0s - loss: 13.7187 - NN_RMSLE: 3.6976\n",
            "Epoch 9: val_loss improved from 31.37337 to 29.34979, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 13.7080 - NN_RMSLE: 3.6961 - val_loss: 29.3498 - val_NN_RMSLE: 5.3864\n",
            "Epoch 10/100\n",
            "273/275 [============================>.] - ETA: 0s - loss: 13.1426 - NN_RMSLE: 3.6203\n",
            "Epoch 10: val_loss improved from 29.34979 to 27.49628, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 2s 6ms/step - loss: 13.1399 - NN_RMSLE: 3.6190 - val_loss: 27.4963 - val_NN_RMSLE: 5.2140\n",
            "Epoch 11/100\n",
            "253/275 [==========================>...] - ETA: 0s - loss: 12.6729 - NN_RMSLE: 3.5541\n",
            "Epoch 11: val_loss improved from 27.49628 to 25.81182, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 12.6681 - NN_RMSLE: 3.5524 - val_loss: 25.8118 - val_NN_RMSLE: 5.0523\n",
            "Epoch 12/100\n",
            "254/275 [==========================>...] - ETA: 0s - loss: 12.2694 - NN_RMSLE: 3.4984\n",
            "Epoch 12: val_loss improved from 25.81182 to 24.27783, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 12.2812 - NN_RMSLE: 3.4989 - val_loss: 24.2778 - val_NN_RMSLE: 4.9005\n",
            "Epoch 13/100\n",
            "273/275 [============================>.] - ETA: 0s - loss: 11.9729 - NN_RMSLE: 3.4566\n",
            "Epoch 13: val_loss improved from 24.27783 to 22.89837, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 11.9712 - NN_RMSLE: 3.4573 - val_loss: 22.8984 - val_NN_RMSLE: 4.7599\n",
            "Epoch 14/100\n",
            "268/275 [============================>.] - ETA: 0s - loss: 11.7268 - NN_RMSLE: 3.4210\n",
            "Epoch 14: val_loss improved from 22.89837 to 21.66640, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 11.7281 - NN_RMSLE: 3.4209 - val_loss: 21.6664 - val_NN_RMSLE: 4.6308\n",
            "Epoch 15/100\n",
            "271/275 [============================>.] - ETA: 0s - loss: 11.5390 - NN_RMSLE: 3.3935\n",
            "Epoch 15: val_loss improved from 21.66640 to 20.59467, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 11.5448 - NN_RMSLE: 3.3937 - val_loss: 20.5947 - val_NN_RMSLE: 4.5155\n",
            "Epoch 16/100\n",
            "258/275 [===========================>..] - ETA: 0s - loss: 11.4288 - NN_RMSLE: 3.3775\n",
            "Epoch 16: val_loss improved from 20.59467 to 19.66790, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 11.4101 - NN_RMSLE: 3.3743 - val_loss: 19.6679 - val_NN_RMSLE: 4.4135\n",
            "Epoch 17/100\n",
            "263/275 [===========================>..] - ETA: 0s - loss: 11.3346 - NN_RMSLE: 3.3642\n",
            "Epoch 17: val_loss improved from 19.66790 to 18.85897, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 11.3147 - NN_RMSLE: 3.3613 - val_loss: 18.8590 - val_NN_RMSLE: 4.3224\n",
            "Epoch 18/100\n",
            "272/275 [============================>.] - ETA: 0s - loss: 11.2518 - NN_RMSLE: 3.3520\n",
            "Epoch 18: val_loss improved from 18.85897 to 18.21736, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 11.2513 - NN_RMSLE: 3.3520 - val_loss: 18.2174 - val_NN_RMSLE: 4.2488\n",
            "Epoch 19/100\n",
            "258/275 [===========================>..] - ETA: 0s - loss: 11.2249 - NN_RMSLE: 3.3483\n",
            "Epoch 19: val_loss improved from 18.21736 to 17.68152, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 11.2105 - NN_RMSLE: 3.3461 - val_loss: 17.6815 - val_NN_RMSLE: 4.1863\n",
            "Epoch 20/100\n",
            "272/275 [============================>.] - ETA: 0s - loss: 11.1848 - NN_RMSLE: 3.3423\n",
            "Epoch 20: val_loss improved from 17.68152 to 17.24912, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 2s 6ms/step - loss: 11.1856 - NN_RMSLE: 3.3423 - val_loss: 17.2491 - val_NN_RMSLE: 4.1352\n",
            "Epoch 21/100\n",
            "262/275 [===========================>..] - ETA: 0s - loss: 11.1774 - NN_RMSLE: 3.3414\n",
            "Epoch 21: val_loss improved from 17.24912 to 16.92609, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 11.1720 - NN_RMSLE: 3.3409 - val_loss: 16.9261 - val_NN_RMSLE: 4.0966\n",
            "Epoch 22/100\n",
            "251/275 [==========================>...] - ETA: 0s - loss: 11.1596 - NN_RMSLE: 3.3382\n",
            "Epoch 22: val_loss improved from 16.92609 to 16.71735, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 11.1646 - NN_RMSLE: 3.3389 - val_loss: 16.7174 - val_NN_RMSLE: 4.0714\n",
            "Epoch 23/100\n",
            "253/275 [==========================>...] - ETA: 0s - loss: 11.1688 - NN_RMSLE: 3.3403\n",
            "Epoch 23: val_loss improved from 16.71735 to 16.54036, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 11.1608 - NN_RMSLE: 3.3390 - val_loss: 16.5404 - val_NN_RMSLE: 4.0500\n",
            "Epoch 24/100\n",
            "272/275 [============================>.] - ETA: 0s - loss: 11.1633 - NN_RMSLE: 3.3391\n",
            "Epoch 24: val_loss improved from 16.54036 to 16.41809, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 11.1592 - NN_RMSLE: 3.3380 - val_loss: 16.4181 - val_NN_RMSLE: 4.0351\n",
            "Epoch 25/100\n",
            "275/275 [==============================] - ETA: 0s - loss: 11.1587 - NN_RMSLE: 3.3388\n",
            "Epoch 25: val_loss improved from 16.41809 to 16.38236, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 2s 6ms/step - loss: 11.1587 - NN_RMSLE: 3.3388 - val_loss: 16.3824 - val_NN_RMSLE: 4.0308\n",
            "Epoch 26/100\n",
            "265/275 [===========================>..] - ETA: 0s - loss: 11.1489 - NN_RMSLE: 3.3368\n",
            "Epoch 26: val_loss improved from 16.38236 to 16.29941, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 11.1584 - NN_RMSLE: 3.3384 - val_loss: 16.2994 - val_NN_RMSLE: 4.0206\n",
            "Epoch 27/100\n",
            "263/275 [===========================>..] - ETA: 0s - loss: 11.1588 - NN_RMSLE: 3.3383\n",
            "Epoch 27: val_loss improved from 16.29941 to 16.27605, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 11.1582 - NN_RMSLE: 3.3383 - val_loss: 16.2760 - val_NN_RMSLE: 4.0178\n",
            "Epoch 28/100\n",
            "264/275 [===========================>..] - ETA: 0s - loss: 11.1561 - NN_RMSLE: 3.3380\n",
            "Epoch 28: val_loss improved from 16.27605 to 16.26567, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 11.1583 - NN_RMSLE: 3.3382 - val_loss: 16.2657 - val_NN_RMSLE: 4.0165\n",
            "Epoch 29/100\n",
            "265/275 [===========================>..] - ETA: 0s - loss: 11.1578 - NN_RMSLE: 3.3383\n",
            "Epoch 29: val_loss did not improve from 16.26567\n",
            "275/275 [==============================] - 1s 3ms/step - loss: 11.1582 - NN_RMSLE: 3.3385 - val_loss: 16.2798 - val_NN_RMSLE: 4.0182\n",
            "Epoch 30/100\n",
            "273/275 [============================>.] - ETA: 0s - loss: 11.1612 - NN_RMSLE: 3.3389\n",
            "Epoch 30: val_loss improved from 16.26567 to 16.25891, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 11.1584 - NN_RMSLE: 3.3382 - val_loss: 16.2589 - val_NN_RMSLE: 4.0157\n",
            "Epoch 31/100\n",
            "254/275 [==========================>...] - ETA: 0s - loss: 11.1722 - NN_RMSLE: 3.3405\n",
            "Epoch 31: val_loss did not improve from 16.25891\n",
            "275/275 [==============================] - 1s 3ms/step - loss: 11.1582 - NN_RMSLE: 3.3377 - val_loss: 16.2630 - val_NN_RMSLE: 4.0162\n",
            "Epoch 32/100\n",
            "255/275 [==========================>...] - ETA: 0s - loss: 11.1530 - NN_RMSLE: 3.3376\n",
            "Epoch 32: val_loss improved from 16.25891 to 16.25045, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 11.1581 - NN_RMSLE: 3.3386 - val_loss: 16.2505 - val_NN_RMSLE: 4.0146\n",
            "Epoch 33/100\n",
            "259/275 [===========================>..] - ETA: 0s - loss: 11.1417 - NN_RMSLE: 3.3359\n",
            "Epoch 33: val_loss did not improve from 16.25045\n",
            "275/275 [==============================] - 1s 3ms/step - loss: 11.1584 - NN_RMSLE: 3.3373 - val_loss: 16.2654 - val_NN_RMSLE: 4.0165\n",
            "Epoch 34/100\n",
            "273/275 [============================>.] - ETA: 0s - loss: 11.1571 - NN_RMSLE: 3.3377\n",
            "Epoch 34: val_loss did not improve from 16.25045\n",
            "275/275 [==============================] - 1s 3ms/step - loss: 11.1583 - NN_RMSLE: 3.3382 - val_loss: 16.2645 - val_NN_RMSLE: 4.0164\n",
            "Epoch 35/100\n",
            "263/275 [===========================>..] - ETA: 0s - loss: 11.1547 - NN_RMSLE: 3.3380\n",
            "Epoch 35: val_loss did not improve from 16.25045\n",
            "275/275 [==============================] - 1s 3ms/step - loss: 11.1586 - NN_RMSLE: 3.3387 - val_loss: 16.2607 - val_NN_RMSLE: 4.0159\n",
            "Model: \"sequential_48\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_192 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_144 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_193 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_145 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_194 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_146 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_195 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  16.26066\n",
            "\n",
            "[5 6 7 8 9]\n",
            "train 17563 valid 8781\n",
            "Model: \"sequential_49\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_196 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_147 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_197 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_148 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_198 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_149 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_199 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "267/275 [============================>.] - ETA: 0s - loss: 44.6760 - NN_RMSLE: 6.6803\n",
            "Epoch 1: val_loss improved from inf to 9.29935, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 2s 5ms/step - loss: 44.6145 - NN_RMSLE: 6.6746 - val_loss: 9.2994 - val_NN_RMSLE: 2.8087\n",
            "Epoch 2/100\n",
            "271/275 [============================>.] - ETA: 0s - loss: 41.4106 - NN_RMSLE: 6.4315\n",
            "Epoch 2: val_loss improved from 9.29935 to 8.51280, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 41.4087 - NN_RMSLE: 6.4316 - val_loss: 8.5128 - val_NN_RMSLE: 2.6917\n",
            "Epoch 3/100\n",
            "265/275 [===========================>..] - ETA: 0s - loss: 38.4728 - NN_RMSLE: 6.1993\n",
            "Epoch 3: val_loss improved from 8.51280 to 7.87854, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 38.4039 - NN_RMSLE: 6.1935 - val_loss: 7.8785 - val_NN_RMSLE: 2.6020\n",
            "Epoch 4/100\n",
            "253/275 [==========================>...] - ETA: 0s - loss: 35.6970 - NN_RMSLE: 5.9708\n",
            "Epoch 4: val_loss improved from 7.87854 to 7.38882, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 35.5920 - NN_RMSLE: 5.9628 - val_loss: 7.3888 - val_NN_RMSLE: 2.5390\n",
            "Epoch 5/100\n",
            "265/275 [===========================>..] - ETA: 0s - loss: 33.0096 - NN_RMSLE: 5.7412\n",
            "Epoch 5: val_loss improved from 7.38882 to 7.03578, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 32.9619 - NN_RMSLE: 5.7363 - val_loss: 7.0358 - val_NN_RMSLE: 2.5015\n",
            "Epoch 6/100\n",
            "274/275 [============================>.] - ETA: 0s - loss: 30.5065 - NN_RMSLE: 5.5198\n",
            "Epoch 6: val_loss improved from 7.03578 to 6.81209, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 30.5059 - NN_RMSLE: 5.5197 - val_loss: 6.8121 - val_NN_RMSLE: 2.4877\n",
            "Epoch 7/100\n",
            "267/275 [============================>.] - ETA: 0s - loss: 28.2615 - NN_RMSLE: 5.3126\n",
            "Epoch 7: val_loss improved from 6.81209 to 6.71115, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 28.2122 - NN_RMSLE: 5.3070 - val_loss: 6.7111 - val_NN_RMSLE: 2.4954\n",
            "Epoch 8/100\n",
            "273/275 [============================>.] - ETA: 0s - loss: 26.0822 - NN_RMSLE: 5.1041\n",
            "Epoch 8: val_loss did not improve from 6.71115\n",
            "275/275 [==============================] - 1s 3ms/step - loss: 26.0761 - NN_RMSLE: 5.1030 - val_loss: 6.7268 - val_NN_RMSLE: 2.5226\n",
            "Epoch 9/100\n",
            "270/275 [============================>.] - ETA: 0s - loss: 24.1128 - NN_RMSLE: 4.9075\n",
            "Epoch 9: val_loss did not improve from 6.71115\n",
            "275/275 [==============================] - 1s 3ms/step - loss: 24.0870 - NN_RMSLE: 4.9042 - val_loss: 6.8534 - val_NN_RMSLE: 2.5670\n",
            "Epoch 10/100\n",
            "258/275 [===========================>..] - ETA: 0s - loss: 22.2796 - NN_RMSLE: 4.7169\n",
            "Epoch 10: val_loss did not improve from 6.71115\n",
            "275/275 [==============================] - 1s 3ms/step - loss: 22.2396 - NN_RMSLE: 4.7126 - val_loss: 7.0857 - val_NN_RMSLE: 2.6268\n",
            "Model: \"sequential_49\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_196 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_147 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_197 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_148 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_198 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_149 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_199 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  7.085658\n",
            "\n",
            "[ 9 10 11 12]\n",
            "train 17563 valid 8781\n",
            "Model: \"sequential_50\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_200 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_150 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_201 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_151 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_202 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_152 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_203 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "263/275 [===========================>..] - ETA: 0s - loss: 31.4443 - NN_RMSLE: 5.6003\n",
            "Epoch 1: val_loss improved from inf to 34.84433, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 2s 5ms/step - loss: 31.3808 - NN_RMSLE: 5.5951 - val_loss: 34.8443 - val_NN_RMSLE: 5.5762\n",
            "Epoch 2/100\n",
            "264/275 [===========================>..] - ETA: 0s - loss: 29.1663 - NN_RMSLE: 5.3920\n",
            "Epoch 2: val_loss improved from 34.84433 to 32.29158, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 29.1048 - NN_RMSLE: 5.3862 - val_loss: 32.2916 - val_NN_RMSLE: 5.3649\n",
            "Epoch 3/100\n",
            "262/275 [===========================>..] - ETA: 0s - loss: 27.1016 - NN_RMSLE: 5.1980\n",
            "Epoch 3: val_loss improved from 32.29158 to 29.94455, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 27.0314 - NN_RMSLE: 5.1921 - val_loss: 29.9445 - val_NN_RMSLE: 5.1667\n",
            "Epoch 4/100\n",
            "260/275 [===========================>..] - ETA: 0s - loss: 25.1500 - NN_RMSLE: 5.0073\n",
            "Epoch 4: val_loss improved from 29.94455 to 27.78981, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 25.1435 - NN_RMSLE: 5.0066 - val_loss: 27.7898 - val_NN_RMSLE: 4.9814\n",
            "Epoch 5/100\n",
            "265/275 [===========================>..] - ETA: 0s - loss: 23.4806 - NN_RMSLE: 4.8388\n",
            "Epoch 5: val_loss improved from 27.78981 to 25.80505, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 23.4289 - NN_RMSLE: 4.8344 - val_loss: 25.8051 - val_NN_RMSLE: 4.8076\n",
            "Epoch 6/100\n",
            "267/275 [============================>.] - ETA: 0s - loss: 21.9023 - NN_RMSLE: 4.6739\n",
            "Epoch 6: val_loss improved from 25.80505 to 23.99081, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 21.8765 - NN_RMSLE: 4.6715 - val_loss: 23.9908 - val_NN_RMSLE: 4.6460\n",
            "Epoch 7/100\n",
            "268/275 [============================>.] - ETA: 0s - loss: 20.4966 - NN_RMSLE: 4.5204\n",
            "Epoch 7: val_loss improved from 23.99081 to 22.33150, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 20.4752 - NN_RMSLE: 4.5193 - val_loss: 22.3315 - val_NN_RMSLE: 4.4956\n",
            "Epoch 8/100\n",
            "266/275 [============================>.] - ETA: 0s - loss: 19.1764 - NN_RMSLE: 4.3719\n",
            "Epoch 8: val_loss improved from 22.33150 to 20.81739, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 19.2139 - NN_RMSLE: 4.3763 - val_loss: 20.8174 - val_NN_RMSLE: 4.3559\n",
            "Epoch 9/100\n",
            "274/275 [============================>.] - ETA: 0s - loss: 18.0873 - NN_RMSLE: 4.2476\n",
            "Epoch 9: val_loss improved from 20.81739 to 19.43903, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 18.0860 - NN_RMSLE: 4.2472 - val_loss: 19.4390 - val_NN_RMSLE: 4.2263\n",
            "Epoch 10/100\n",
            "247/275 [=========================>....] - ETA: 0s - loss: 17.1540 - NN_RMSLE: 4.1358\n",
            "Epoch 10: val_loss improved from 19.43903 to 18.19338, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 2s 6ms/step - loss: 17.0833 - NN_RMSLE: 4.1268 - val_loss: 18.1934 - val_NN_RMSLE: 4.1067\n",
            "Epoch 11/100\n",
            "265/275 [===========================>..] - ETA: 0s - loss: 16.2329 - NN_RMSLE: 4.0247\n",
            "Epoch 11: val_loss improved from 18.19338 to 17.07246, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 16.1981 - NN_RMSLE: 4.0206 - val_loss: 17.0725 - val_NN_RMSLE: 3.9967\n",
            "Epoch 12/100\n",
            "275/275 [==============================] - ETA: 0s - loss: 15.4202 - NN_RMSLE: 3.9226\n",
            "Epoch 12: val_loss improved from 17.07246 to 16.06415, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 15.4202 - NN_RMSLE: 3.9226 - val_loss: 16.0641 - val_NN_RMSLE: 3.8952\n",
            "Epoch 13/100\n",
            "265/275 [===========================>..] - ETA: 0s - loss: 14.7678 - NN_RMSLE: 3.8391\n",
            "Epoch 13: val_loss improved from 16.06415 to 15.16619, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 14.7463 - NN_RMSLE: 3.8362 - val_loss: 15.1662 - val_NN_RMSLE: 3.8022\n",
            "Epoch 14/100\n",
            "274/275 [============================>.] - ETA: 0s - loss: 14.1703 - NN_RMSLE: 3.7610\n",
            "Epoch 14: val_loss improved from 15.16619 to 14.37469, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 14.1681 - NN_RMSLE: 3.7603 - val_loss: 14.3747 - val_NN_RMSLE: 3.7177\n",
            "Epoch 15/100\n",
            "262/275 [===========================>..] - ETA: 0s - loss: 13.6963 - NN_RMSLE: 3.6980\n",
            "Epoch 15: val_loss improved from 14.37469 to 13.67562, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 13.6779 - NN_RMSLE: 3.6951 - val_loss: 13.6756 - val_NN_RMSLE: 3.6405\n",
            "Epoch 16/100\n",
            "269/275 [============================>.] - ETA: 0s - loss: 13.2673 - NN_RMSLE: 3.6402\n",
            "Epoch 16: val_loss improved from 13.67562 to 13.07339, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 13.2688 - NN_RMSLE: 3.6407 - val_loss: 13.0734 - val_NN_RMSLE: 3.5714\n",
            "Epoch 17/100\n",
            "260/275 [===========================>..] - ETA: 0s - loss: 12.9324 - NN_RMSLE: 3.5941\n",
            "Epoch 17: val_loss improved from 13.07339 to 12.54993, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 12.9340 - NN_RMSLE: 3.5944 - val_loss: 12.5499 - val_NN_RMSLE: 3.5088\n",
            "Epoch 18/100\n",
            "261/275 [===========================>..] - ETA: 0s - loss: 12.6665 - NN_RMSLE: 3.5572\n",
            "Epoch 18: val_loss improved from 12.54993 to 12.10777, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 12.6661 - NN_RMSLE: 3.5575 - val_loss: 12.1078 - val_NN_RMSLE: 3.4536\n",
            "Epoch 19/100\n",
            "272/275 [============================>.] - ETA: 0s - loss: 12.4505 - NN_RMSLE: 3.5267\n",
            "Epoch 19: val_loss improved from 12.10777 to 11.73347, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 12.4563 - NN_RMSLE: 3.5265 - val_loss: 11.7335 - val_NN_RMSLE: 3.4044\n",
            "Epoch 20/100\n",
            "267/275 [============================>.] - ETA: 0s - loss: 12.2941 - NN_RMSLE: 3.5045\n",
            "Epoch 20: val_loss improved from 11.73347 to 11.42562, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 12.2969 - NN_RMSLE: 3.5049 - val_loss: 11.4256 - val_NN_RMSLE: 3.3619\n",
            "Epoch 21/100\n",
            "252/275 [==========================>...] - ETA: 0s - loss: 12.1792 - NN_RMSLE: 3.4878\n",
            "Epoch 21: val_loss improved from 11.42562 to 11.17387, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 2s 6ms/step - loss: 12.1805 - NN_RMSLE: 3.4884 - val_loss: 11.1739 - val_NN_RMSLE: 3.3253\n",
            "Epoch 22/100\n",
            "273/275 [============================>.] - ETA: 0s - loss: 12.0972 - NN_RMSLE: 3.4759\n",
            "Epoch 22: val_loss improved from 11.17387 to 10.97396, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 12.0987 - NN_RMSLE: 3.4760 - val_loss: 10.9740 - val_NN_RMSLE: 3.2947\n",
            "Epoch 23/100\n",
            "252/275 [==========================>...] - ETA: 0s - loss: 12.0537 - NN_RMSLE: 3.4698\n",
            "Epoch 23: val_loss improved from 10.97396 to 10.81463, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 12.0445 - NN_RMSLE: 3.4683 - val_loss: 10.8146 - val_NN_RMSLE: 3.2690\n",
            "Epoch 24/100\n",
            "269/275 [============================>.] - ETA: 0s - loss: 12.0156 - NN_RMSLE: 3.4640\n",
            "Epoch 24: val_loss improved from 10.81463 to 10.69998, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 12.0105 - NN_RMSLE: 3.4626 - val_loss: 10.7000 - val_NN_RMSLE: 3.2497\n",
            "Epoch 25/100\n",
            "256/275 [==========================>...] - ETA: 0s - loss: 11.9649 - NN_RMSLE: 3.4565\n",
            "Epoch 25: val_loss improved from 10.69998 to 10.60777, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 11.9898 - NN_RMSLE: 3.4600 - val_loss: 10.6078 - val_NN_RMSLE: 3.2334\n",
            "Epoch 26/100\n",
            "274/275 [============================>.] - ETA: 0s - loss: 11.9819 - NN_RMSLE: 3.4591\n",
            "Epoch 26: val_loss improved from 10.60777 to 10.54375, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 11.9782 - NN_RMSLE: 3.4577 - val_loss: 10.5438 - val_NN_RMSLE: 3.2218\n",
            "Epoch 27/100\n",
            "260/275 [===========================>..] - ETA: 0s - loss: 11.9732 - NN_RMSLE: 3.4579\n",
            "Epoch 27: val_loss improved from 10.54375 to 10.49766, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 11.9723 - NN_RMSLE: 3.4578 - val_loss: 10.4977 - val_NN_RMSLE: 3.2131\n",
            "Epoch 28/100\n",
            "256/275 [==========================>...] - ETA: 0s - loss: 11.9477 - NN_RMSLE: 3.4541\n",
            "Epoch 28: val_loss improved from 10.49766 to 10.46917, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 11.9696 - NN_RMSLE: 3.4574 - val_loss: 10.4692 - val_NN_RMSLE: 3.2077\n",
            "Epoch 29/100\n",
            "258/275 [===========================>..] - ETA: 0s - loss: 11.9714 - NN_RMSLE: 3.4576\n",
            "Epoch 29: val_loss improved from 10.46917 to 10.44961, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 11.9682 - NN_RMSLE: 3.4569 - val_loss: 10.4496 - val_NN_RMSLE: 3.2039\n",
            "Epoch 30/100\n",
            "275/275 [==============================] - ETA: 0s - loss: 11.9677 - NN_RMSLE: 3.4566\n",
            "Epoch 30: val_loss improved from 10.44961 to 10.43164, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 11.9677 - NN_RMSLE: 3.4566 - val_loss: 10.4316 - val_NN_RMSLE: 3.2003\n",
            "Epoch 31/100\n",
            "264/275 [===========================>..] - ETA: 0s - loss: 11.9662 - NN_RMSLE: 3.4563\n",
            "Epoch 31: val_loss improved from 10.43164 to 10.42645, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 2s 5ms/step - loss: 11.9674 - NN_RMSLE: 3.4566 - val_loss: 10.4264 - val_NN_RMSLE: 3.1993\n",
            "Epoch 32/100\n",
            "265/275 [===========================>..] - ETA: 0s - loss: 11.9821 - NN_RMSLE: 3.4588\n",
            "Epoch 32: val_loss improved from 10.42645 to 10.42184, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 11.9673 - NN_RMSLE: 3.4560 - val_loss: 10.4218 - val_NN_RMSLE: 3.1984\n",
            "Epoch 33/100\n",
            "274/275 [============================>.] - ETA: 0s - loss: 11.9656 - NN_RMSLE: 3.4568\n",
            "Epoch 33: val_loss improved from 10.42184 to 10.41422, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 11.9674 - NN_RMSLE: 3.4574 - val_loss: 10.4142 - val_NN_RMSLE: 3.1969\n",
            "Epoch 34/100\n",
            "265/275 [===========================>..] - ETA: 0s - loss: 11.9608 - NN_RMSLE: 3.4559\n",
            "Epoch 34: val_loss improved from 10.41422 to 10.41034, saving model to model_73[]\n",
            "INFO:tensorflow:Assets written to: model_73[]/assets\n",
            "275/275 [==============================] - 1s 5ms/step - loss: 11.9672 - NN_RMSLE: 3.4572 - val_loss: 10.4103 - val_NN_RMSLE: 3.1961\n",
            "Epoch 35/100\n",
            "270/275 [============================>.] - ETA: 0s - loss: 11.9815 - NN_RMSLE: 3.4587\n",
            "Epoch 35: val_loss did not improve from 10.41034\n",
            "275/275 [==============================] - 1s 3ms/step - loss: 11.9675 - NN_RMSLE: 3.4568 - val_loss: 10.4216 - val_NN_RMSLE: 3.1983\n",
            "Epoch 36/100\n",
            "273/275 [============================>.] - ETA: 0s - loss: 11.9623 - NN_RMSLE: 3.4561\n",
            "Epoch 36: val_loss did not improve from 10.41034\n",
            "275/275 [==============================] - 1s 3ms/step - loss: 11.9674 - NN_RMSLE: 3.4567 - val_loss: 10.4142 - val_NN_RMSLE: 3.1969\n",
            "Epoch 37/100\n",
            "255/275 [==========================>...] - ETA: 0s - loss: 11.9748 - NN_RMSLE: 3.4572\n",
            "Epoch 37: val_loss did not improve from 10.41034\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 11.9675 - NN_RMSLE: 3.4562 - val_loss: 10.4129 - val_NN_RMSLE: 3.1966\n",
            "Model: \"sequential_50\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_200 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_150 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_201 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_151 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_202 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_152 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_203 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  10.412942\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 80 (556575, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[1 2 3 4 5 6]\n",
            "train 371050 valid 185525\n",
            "Model: \"sequential_51\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_204 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_153 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_205 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_154 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_206 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_155 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_207 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "5771/5798 [============================>.] - ETA: 0s - loss: 4.0044 - NN_RMSLE: 1.9465\n",
            "Epoch 1: val_loss improved from inf to 2.62361, saving model to model_80[]\n",
            "INFO:tensorflow:Assets written to: model_80[]/assets\n",
            "5798/5798 [==============================] - 17s 3ms/step - loss: 3.9980 - NN_RMSLE: 1.9450 - val_loss: 2.6236 - val_NN_RMSLE: 1.6182\n",
            "Epoch 2/100\n",
            "5780/5798 [============================>.] - ETA: 0s - loss: 2.6239 - NN_RMSLE: 1.6137\n",
            "Epoch 2: val_loss improved from 2.62361 to 2.62295, saving model to model_80[]\n",
            "INFO:tensorflow:Assets written to: model_80[]/assets\n",
            "5798/5798 [==============================] - 21s 4ms/step - loss: 2.6242 - NN_RMSLE: 1.6138 - val_loss: 2.6230 - val_NN_RMSLE: 1.6180\n",
            "Epoch 3/100\n",
            "5795/5798 [============================>.] - ETA: 0s - loss: 2.6243 - NN_RMSLE: 1.6138\n",
            "Epoch 3: val_loss did not improve from 2.62295\n",
            "5798/5798 [==============================] - 22s 4ms/step - loss: 2.6242 - NN_RMSLE: 1.6138 - val_loss: 2.6261 - val_NN_RMSLE: 1.6190\n",
            "Epoch 4/100\n",
            "5795/5798 [============================>.] - ETA: 0s - loss: 2.6243 - NN_RMSLE: 1.6140\n",
            "Epoch 4: val_loss improved from 2.62295 to 2.62002, saving model to model_80[]\n",
            "INFO:tensorflow:Assets written to: model_80[]/assets\n",
            "5798/5798 [==============================] - 22s 4ms/step - loss: 2.6241 - NN_RMSLE: 1.6139 - val_loss: 2.6200 - val_NN_RMSLE: 1.6171\n",
            "Epoch 5/100\n",
            "5793/5798 [============================>.] - ETA: 0s - loss: 2.6243 - NN_RMSLE: 1.6140\n",
            "Epoch 5: val_loss did not improve from 2.62002\n",
            "5798/5798 [==============================] - 20s 3ms/step - loss: 2.6242 - NN_RMSLE: 1.6139 - val_loss: 2.6276 - val_NN_RMSLE: 1.6194\n",
            "Epoch 6/100\n",
            "5787/5798 [============================>.] - ETA: 0s - loss: 2.6245 - NN_RMSLE: 1.6139\n",
            "Epoch 6: val_loss did not improve from 2.62002\n",
            "5798/5798 [==============================] - 19s 3ms/step - loss: 2.6242 - NN_RMSLE: 1.6138 - val_loss: 2.6319 - val_NN_RMSLE: 1.6208\n",
            "Epoch 7/100\n",
            "5784/5798 [============================>.] - ETA: 0s - loss: 2.6243 - NN_RMSLE: 1.6137\n",
            "Epoch 7: val_loss did not improve from 2.62002\n",
            "5798/5798 [==============================] - 19s 3ms/step - loss: 2.6242 - NN_RMSLE: 1.6137 - val_loss: 2.6248 - val_NN_RMSLE: 1.6186\n",
            "Model: \"sequential_51\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_204 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_153 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_205 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_154 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_206 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_155 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_207 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  2.62482\n",
            "\n",
            "[2 3 4 5 6 7 8 9]\n",
            "train 371050 valid 185525\n",
            "Model: \"sequential_52\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_208 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_156 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_209 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_157 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_210 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_158 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_211 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "5794/5798 [============================>.] - ETA: 0s - loss: 3.8887 - NN_RMSLE: 1.9187\n",
            "Epoch 1: val_loss improved from inf to 2.68062, saving model to model_80[]\n",
            "INFO:tensorflow:Assets written to: model_80[]/assets\n",
            "5798/5798 [==============================] - 18s 3ms/step - loss: 3.8877 - NN_RMSLE: 1.9184 - val_loss: 2.6806 - val_NN_RMSLE: 1.6340\n",
            "Epoch 2/100\n",
            "5782/5798 [============================>.] - ETA: 0s - loss: 2.5942 - NN_RMSLE: 1.6042\n",
            "Epoch 2: val_loss did not improve from 2.68062\n",
            "5798/5798 [==============================] - 16s 3ms/step - loss: 2.5944 - NN_RMSLE: 1.6043 - val_loss: 2.6816 - val_NN_RMSLE: 1.6344\n",
            "Epoch 3/100\n",
            "5798/5798 [==============================] - ETA: 0s - loss: 2.5943 - NN_RMSLE: 1.6042\n",
            "Epoch 3: val_loss did not improve from 2.68062\n",
            "5798/5798 [==============================] - 17s 3ms/step - loss: 2.5943 - NN_RMSLE: 1.6042 - val_loss: 2.6845 - val_NN_RMSLE: 1.6353\n",
            "Epoch 4/100\n",
            "5789/5798 [============================>.] - ETA: 0s - loss: 2.5943 - NN_RMSLE: 1.6043\n",
            "Epoch 4: val_loss improved from 2.68062 to 2.67989, saving model to model_80[]\n",
            "INFO:tensorflow:Assets written to: model_80[]/assets\n",
            "5798/5798 [==============================] - 21s 4ms/step - loss: 2.5944 - NN_RMSLE: 1.6043 - val_loss: 2.6799 - val_NN_RMSLE: 1.6338\n",
            "Epoch 5/100\n",
            "5791/5798 [============================>.] - ETA: 0s - loss: 2.5944 - NN_RMSLE: 1.6043\n",
            "Epoch 5: val_loss did not improve from 2.67989\n",
            "5798/5798 [==============================] - 18s 3ms/step - loss: 2.5944 - NN_RMSLE: 1.6043 - val_loss: 2.6802 - val_NN_RMSLE: 1.6339\n",
            "Epoch 6/100\n",
            "5793/5798 [============================>.] - ETA: 0s - loss: 2.5942 - NN_RMSLE: 1.6041\n",
            "Epoch 6: val_loss did not improve from 2.67989\n",
            "5798/5798 [==============================] - 19s 3ms/step - loss: 2.5944 - NN_RMSLE: 1.6042 - val_loss: 2.6814 - val_NN_RMSLE: 1.6343\n",
            "Epoch 7/100\n",
            "5774/5798 [============================>.] - ETA: 0s - loss: 2.5941 - NN_RMSLE: 1.6042\n",
            "Epoch 7: val_loss did not improve from 2.67989\n",
            "5798/5798 [==============================] - 18s 3ms/step - loss: 2.5944 - NN_RMSLE: 1.6043 - val_loss: 2.6812 - val_NN_RMSLE: 1.6342\n",
            "Model: \"sequential_52\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_208 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_156 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_209 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_157 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_210 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_158 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_211 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  2.6812449\n",
            "\n",
            "[ 3  4  5  8  9 10 11 12]\n",
            "train 371050 valid 185525\n",
            "Model: \"sequential_53\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_212 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_159 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_213 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_160 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_214 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_161 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_215 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "5792/5798 [============================>.] - ETA: 0s - loss: 3.9487 - NN_RMSLE: 1.9345\n",
            "Epoch 1: val_loss improved from inf to 2.57492, saving model to model_80[]\n",
            "INFO:tensorflow:Assets written to: model_80[]/assets\n",
            "5798/5798 [==============================] - 21s 4ms/step - loss: 3.9473 - NN_RMSLE: 1.9342 - val_loss: 2.5749 - val_NN_RMSLE: 1.6024\n",
            "Epoch 2/100\n",
            "5797/5798 [============================>.] - ETA: 0s - loss: 2.6480 - NN_RMSLE: 1.6209\n",
            "Epoch 2: val_loss did not improve from 2.57492\n",
            "5798/5798 [==============================] - 18s 3ms/step - loss: 2.6480 - NN_RMSLE: 1.6209 - val_loss: 2.5761 - val_NN_RMSLE: 1.6028\n",
            "Epoch 3/100\n",
            "5792/5798 [============================>.] - ETA: 0s - loss: 2.6484 - NN_RMSLE: 1.6211\n",
            "Epoch 3: val_loss improved from 2.57492 to 2.57318, saving model to model_80[]\n",
            "INFO:tensorflow:Assets written to: model_80[]/assets\n",
            "5798/5798 [==============================] - 19s 3ms/step - loss: 2.6480 - NN_RMSLE: 1.6210 - val_loss: 2.5732 - val_NN_RMSLE: 1.6019\n",
            "Epoch 4/100\n",
            "5786/5798 [============================>.] - ETA: 0s - loss: 2.6482 - NN_RMSLE: 1.6209\n",
            "Epoch 4: val_loss did not improve from 2.57318\n",
            "5798/5798 [==============================] - 18s 3ms/step - loss: 2.6480 - NN_RMSLE: 1.6208 - val_loss: 2.5737 - val_NN_RMSLE: 1.6020\n",
            "Epoch 5/100\n",
            "5782/5798 [============================>.] - ETA: 0s - loss: 2.6483 - NN_RMSLE: 1.6210\n",
            "Epoch 5: val_loss did not improve from 2.57318\n",
            "5798/5798 [==============================] - 20s 3ms/step - loss: 2.6480 - NN_RMSLE: 1.6209 - val_loss: 2.5735 - val_NN_RMSLE: 1.6020\n",
            "Epoch 6/100\n",
            "5797/5798 [============================>.] - ETA: 0s - loss: 2.6479 - NN_RMSLE: 1.6213\n",
            "Epoch 6: val_loss did not improve from 2.57318\n",
            "5798/5798 [==============================] - 18s 3ms/step - loss: 2.6480 - NN_RMSLE: 1.6213 - val_loss: 2.5739 - val_NN_RMSLE: 1.6021\n",
            "Model: \"sequential_53\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_212 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_159 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_213 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_160 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_214 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_161 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_215 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  2.5739083\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 90 (1012123, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[1 2 3 4 5 6 7 8 9]\n",
            "train 674748 valid 337375\n",
            "Model: \"sequential_54\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_216 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_162 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_217 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_163 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_218 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_164 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_219 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "10526/10543 [============================>.] - ETA: 0s - loss: 5.0452 - NN_RMSLE: 2.0183\n",
            "Epoch 1: val_loss improved from inf to 2.00676, saving model to model_90[]\n",
            "INFO:tensorflow:Assets written to: model_90[]/assets\n",
            "10543/10543 [==============================] - 34s 3ms/step - loss: 5.0397 - NN_RMSLE: 2.0171 - val_loss: 2.0068 - val_NN_RMSLE: 1.3758\n",
            "Epoch 2/100\n",
            "10527/10543 [============================>.] - ETA: 0s - loss: 1.7294 - NN_RMSLE: 1.3093\n",
            "Epoch 2: val_loss did not improve from 2.00676\n",
            "10543/10543 [==============================] - 37s 4ms/step - loss: 1.7292 - NN_RMSLE: 1.3092 - val_loss: 2.0069 - val_NN_RMSLE: 1.3758\n",
            "Epoch 3/100\n",
            "10538/10543 [============================>.] - ETA: 0s - loss: 1.7292 - NN_RMSLE: 1.3091\n",
            "Epoch 3: val_loss improved from 2.00676 to 2.00626, saving model to model_90[]\n",
            "INFO:tensorflow:Assets written to: model_90[]/assets\n",
            "10543/10543 [==============================] - 39s 4ms/step - loss: 1.7293 - NN_RMSLE: 1.3091 - val_loss: 2.0063 - val_NN_RMSLE: 1.3759\n",
            "Epoch 4/100\n",
            "10532/10543 [============================>.] - ETA: 0s - loss: 1.7291 - NN_RMSLE: 1.3092\n",
            "Epoch 4: val_loss did not improve from 2.00626\n",
            "10543/10543 [==============================] - 31s 3ms/step - loss: 1.7293 - NN_RMSLE: 1.3093 - val_loss: 2.0076 - val_NN_RMSLE: 1.3758\n",
            "Epoch 5/100\n",
            "10543/10543 [==============================] - ETA: 0s - loss: 1.7293 - NN_RMSLE: 1.3092\n",
            "Epoch 5: val_loss improved from 2.00626 to 2.00621, saving model to model_90[]\n",
            "INFO:tensorflow:Assets written to: model_90[]/assets\n",
            "10543/10543 [==============================] - 31s 3ms/step - loss: 1.7293 - NN_RMSLE: 1.3092 - val_loss: 2.0062 - val_NN_RMSLE: 1.3759\n",
            "Epoch 6/100\n",
            "10543/10543 [==============================] - ETA: 0s - loss: 1.7293 - NN_RMSLE: 1.3091\n",
            "Epoch 6: val_loss did not improve from 2.00621\n",
            "10543/10543 [==============================] - 33s 3ms/step - loss: 1.7293 - NN_RMSLE: 1.3091 - val_loss: 2.0066 - val_NN_RMSLE: 1.3758\n",
            "Epoch 7/100\n",
            "10540/10543 [============================>.] - ETA: 0s - loss: 1.7292 - NN_RMSLE: 1.3093\n",
            "Epoch 7: val_loss did not improve from 2.00621\n",
            "10543/10543 [==============================] - 31s 3ms/step - loss: 1.7292 - NN_RMSLE: 1.3093 - val_loss: 2.0069 - val_NN_RMSLE: 1.3758\n",
            "Epoch 8/100\n",
            "10534/10543 [============================>.] - ETA: 0s - loss: 1.7294 - NN_RMSLE: 1.3093\n",
            "Epoch 8: val_loss did not improve from 2.00621\n",
            "10543/10543 [==============================] - 32s 3ms/step - loss: 1.7293 - NN_RMSLE: 1.3092 - val_loss: 2.0075 - val_NN_RMSLE: 1.3758\n",
            "Model: \"sequential_54\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_216 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_162 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_217 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_163 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_218 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_164 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_219 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  2.007484\n",
            "\n",
            "[ 5  6  7  8  9 10 11]\n",
            "train 674749 valid 337374\n",
            "Model: \"sequential_55\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_220 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_165 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_221 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_166 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_222 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_167 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_223 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "10540/10543 [============================>.] - ETA: 0s - loss: 5.1345 - NN_RMSLE: 2.0459\n",
            "Epoch 1: val_loss improved from inf to 1.78773, saving model to model_90[]\n",
            "INFO:tensorflow:Assets written to: model_90[]/assets\n",
            "10543/10543 [==============================] - 33s 3ms/step - loss: 5.1335 - NN_RMSLE: 2.0456 - val_loss: 1.7877 - val_NN_RMSLE: 1.3346\n",
            "Epoch 2/100\n",
            "10538/10543 [============================>.] - ETA: 0s - loss: 1.8386 - NN_RMSLE: 1.3495\n",
            "Epoch 2: val_loss did not improve from 1.78773\n",
            "10543/10543 [==============================] - 33s 3ms/step - loss: 1.8386 - NN_RMSLE: 1.3495 - val_loss: 1.7877 - val_NN_RMSLE: 1.3346\n",
            "Epoch 3/100\n",
            "10536/10543 [============================>.] - ETA: 0s - loss: 1.8388 - NN_RMSLE: 1.3493\n",
            "Epoch 3: val_loss did not improve from 1.78773\n",
            "10543/10543 [==============================] - 34s 3ms/step - loss: 1.8386 - NN_RMSLE: 1.3493 - val_loss: 1.7878 - val_NN_RMSLE: 1.3346\n",
            "Epoch 4/100\n",
            "10534/10543 [============================>.] - ETA: 0s - loss: 1.8387 - NN_RMSLE: 1.3494\n",
            "Epoch 4: val_loss did not improve from 1.78773\n",
            "10543/10543 [==============================] - 35s 3ms/step - loss: 1.8386 - NN_RMSLE: 1.3493 - val_loss: 1.7879 - val_NN_RMSLE: 1.3347\n",
            "Model: \"sequential_55\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_220 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_165 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_221 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_166 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_222 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_167 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_223 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.7878543\n",
            "\n",
            "[ 9 10 11 12]\n",
            "train 674749 valid 337374\n",
            "Model: \"sequential_56\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_224 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_168 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_225 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_169 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_226 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_170 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_227 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "10541/10543 [============================>.] - ETA: 0s - loss: 5.1498 - NN_RMSLE: 2.0559\n",
            "Epoch 1: val_loss improved from inf to 1.67359, saving model to model_90[]\n",
            "INFO:tensorflow:Assets written to: model_90[]/assets\n",
            "10543/10543 [==============================] - 33s 3ms/step - loss: 5.1492 - NN_RMSLE: 2.0557 - val_loss: 1.6736 - val_NN_RMSLE: 1.2867\n",
            "Epoch 2/100\n",
            "10540/10543 [============================>.] - ETA: 0s - loss: 1.8969 - NN_RMSLE: 1.3702\n",
            "Epoch 2: val_loss improved from 1.67359 to 1.67284, saving model to model_90[]\n",
            "INFO:tensorflow:Assets written to: model_90[]/assets\n",
            "10543/10543 [==============================] - 34s 3ms/step - loss: 1.8969 - NN_RMSLE: 1.3702 - val_loss: 1.6728 - val_NN_RMSLE: 1.2863\n",
            "Epoch 3/100\n",
            "10535/10543 [============================>.] - ETA: 0s - loss: 1.8966 - NN_RMSLE: 1.3701\n",
            "Epoch 3: val_loss improved from 1.67284 to 1.67222, saving model to model_90[]\n",
            "INFO:tensorflow:Assets written to: model_90[]/assets\n",
            "10543/10543 [==============================] - 36s 3ms/step - loss: 1.8968 - NN_RMSLE: 1.3701 - val_loss: 1.6722 - val_NN_RMSLE: 1.2861\n",
            "Epoch 4/100\n",
            "10532/10543 [============================>.] - ETA: 0s - loss: 1.8969 - NN_RMSLE: 1.3704\n",
            "Epoch 4: val_loss improved from 1.67222 to 1.67133, saving model to model_90[]\n",
            "INFO:tensorflow:Assets written to: model_90[]/assets\n",
            "10543/10543 [==============================] - 35s 3ms/step - loss: 1.8968 - NN_RMSLE: 1.3704 - val_loss: 1.6713 - val_NN_RMSLE: 1.2856\n",
            "Epoch 5/100\n",
            "10532/10543 [============================>.] - ETA: 0s - loss: 1.8968 - NN_RMSLE: 1.3702\n",
            "Epoch 5: val_loss improved from 1.67133 to 1.67113, saving model to model_90[]\n",
            "INFO:tensorflow:Assets written to: model_90[]/assets\n",
            "10543/10543 [==============================] - 36s 3ms/step - loss: 1.8968 - NN_RMSLE: 1.3702 - val_loss: 1.6711 - val_NN_RMSLE: 1.2855\n",
            "Epoch 6/100\n",
            "10537/10543 [============================>.] - ETA: 0s - loss: 1.8969 - NN_RMSLE: 1.3702\n",
            "Epoch 6: val_loss did not improve from 1.67113\n",
            "10543/10543 [==============================] - 34s 3ms/step - loss: 1.8968 - NN_RMSLE: 1.3702 - val_loss: 1.6722 - val_NN_RMSLE: 1.2861\n",
            "Epoch 7/100\n",
            "10539/10543 [============================>.] - ETA: 0s - loss: 1.8969 - NN_RMSLE: 1.3702\n",
            "Epoch 7: val_loss did not improve from 1.67113\n",
            "10543/10543 [==============================] - 33s 3ms/step - loss: 1.8968 - NN_RMSLE: 1.3702 - val_loss: 1.6715 - val_NN_RMSLE: 1.2857\n",
            "Epoch 8/100\n",
            "10540/10543 [============================>.] - ETA: 0s - loss: 1.8968 - NN_RMSLE: 1.3704\n",
            "Epoch 8: val_loss did not improve from 1.67113\n",
            "10543/10543 [==============================] - 30s 3ms/step - loss: 1.8969 - NN_RMSLE: 1.3704 - val_loss: 1.6713 - val_NN_RMSLE: 1.2856\n",
            "Model: \"sequential_56\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_224 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_168 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_225 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_169 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_226 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_170 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_227 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.6712787\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 91 (791828, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[1 2 3 4 5 8 9]\n",
            "train 527885 valid 263943\n",
            "Model: \"sequential_57\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_228 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_171 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_229 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_172 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_230 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_173 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_231 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "8239/8249 [============================>.] - ETA: 0s - loss: 10.2515 - NN_RMSLE: 2.8918\n",
            "Epoch 1: val_loss improved from inf to 2.89008, saving model to model_91[]\n",
            "INFO:tensorflow:Assets written to: model_91[]/assets\n",
            "8249/8249 [==============================] - 27s 3ms/step - loss: 10.2424 - NN_RMSLE: 2.8900 - val_loss: 2.8901 - val_NN_RMSLE: 1.5932\n",
            "Epoch 2/100\n",
            "8244/8249 [============================>.] - ETA: 0s - loss: 1.9171 - NN_RMSLE: 1.3716\n",
            "Epoch 2: val_loss did not improve from 2.89008\n",
            "8249/8249 [==============================] - 29s 4ms/step - loss: 1.9170 - NN_RMSLE: 1.3716 - val_loss: 3.0168 - val_NN_RMSLE: 1.6256\n",
            "Epoch 3/100\n",
            "8249/8249 [==============================] - ETA: 0s - loss: 1.9167 - NN_RMSLE: 1.3718\n",
            "Epoch 3: val_loss did not improve from 2.89008\n",
            "8249/8249 [==============================] - 27s 3ms/step - loss: 1.9167 - NN_RMSLE: 1.3718 - val_loss: 2.9984 - val_NN_RMSLE: 1.6208\n",
            "Epoch 4/100\n",
            "8239/8249 [============================>.] - ETA: 0s - loss: 1.9168 - NN_RMSLE: 1.3716\n",
            "Epoch 4: val_loss did not improve from 2.89008\n",
            "8249/8249 [==============================] - 28s 3ms/step - loss: 1.9167 - NN_RMSLE: 1.3715 - val_loss: 3.0180 - val_NN_RMSLE: 1.6259\n",
            "Model: \"sequential_57\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_228 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_171 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_229 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_172 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_230 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_173 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_231 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  3.0180218\n",
            "\n",
            "[ 5  6  7  8  9 10 11]\n",
            "train 527885 valid 263943\n",
            "Model: \"sequential_58\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_232 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_174 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_233 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_175 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_234 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_176 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_235 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "8249/8249 [==============================] - ETA: 0s - loss: 8.6481 - NN_RMSLE: 2.6945\n",
            "Epoch 1: val_loss improved from inf to 2.21605, saving model to model_91[]\n",
            "INFO:tensorflow:Assets written to: model_91[]/assets\n",
            "8249/8249 [==============================] - 26s 3ms/step - loss: 8.6481 - NN_RMSLE: 2.6945 - val_loss: 2.2161 - val_NN_RMSLE: 1.4793\n",
            "Epoch 2/100\n",
            "8231/8249 [============================>.] - ETA: 0s - loss: 2.3854 - NN_RMSLE: 1.5323\n",
            "Epoch 2: val_loss improved from 2.21605 to 2.15961, saving model to model_91[]\n",
            "INFO:tensorflow:Assets written to: model_91[]/assets\n",
            "8249/8249 [==============================] - 24s 3ms/step - loss: 2.3848 - NN_RMSLE: 1.5322 - val_loss: 2.1596 - val_NN_RMSLE: 1.4602\n",
            "Epoch 3/100\n",
            "8239/8249 [============================>.] - ETA: 0s - loss: 2.3849 - NN_RMSLE: 1.5326\n",
            "Epoch 3: val_loss did not improve from 2.15961\n",
            "8249/8249 [==============================] - 28s 3ms/step - loss: 2.3848 - NN_RMSLE: 1.5325 - val_loss: 2.1901 - val_NN_RMSLE: 1.4705\n",
            "Epoch 4/100\n",
            "8238/8249 [============================>.] - ETA: 0s - loss: 2.3853 - NN_RMSLE: 1.5326\n",
            "Epoch 4: val_loss did not improve from 2.15961\n",
            "8249/8249 [==============================] - 25s 3ms/step - loss: 2.3848 - NN_RMSLE: 1.5324 - val_loss: 2.1897 - val_NN_RMSLE: 1.4704\n",
            "Epoch 5/100\n",
            "8238/8249 [============================>.] - ETA: 0s - loss: 2.3846 - NN_RMSLE: 1.5325\n",
            "Epoch 5: val_loss did not improve from 2.15961\n",
            "8249/8249 [==============================] - 26s 3ms/step - loss: 2.3847 - NN_RMSLE: 1.5325 - val_loss: 2.1704 - val_NN_RMSLE: 1.4638\n",
            "Model: \"sequential_58\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_232 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_174 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_233 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_175 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_234 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_176 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_235 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  2.1704214\n",
            "\n",
            "[ 9 10 11 12]\n",
            "train 527886 valid 263942\n",
            "Model: \"sequential_59\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_236 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_177 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_237 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_178 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_238 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_179 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_239 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "8232/8249 [============================>.] - ETA: 0s - loss: 9.8578 - NN_RMSLE: 2.8590\n",
            "Epoch 1: val_loss improved from inf to 2.18474, saving model to model_91[]\n",
            "INFO:tensorflow:Assets written to: model_91[]/assets\n",
            "8249/8249 [==============================] - 27s 3ms/step - loss: 9.8429 - NN_RMSLE: 2.8562 - val_loss: 2.1847 - val_NN_RMSLE: 1.4350\n",
            "Epoch 2/100\n",
            "8243/8249 [============================>.] - ETA: 0s - loss: 2.2469 - NN_RMSLE: 1.4853\n",
            "Epoch 2: val_loss did not improve from 2.18474\n",
            "8249/8249 [==============================] - 26s 3ms/step - loss: 2.2469 - NN_RMSLE: 1.4853 - val_loss: 2.2054 - val_NN_RMSLE: 1.4361\n",
            "Epoch 3/100\n",
            "8238/8249 [============================>.] - ETA: 0s - loss: 2.2467 - NN_RMSLE: 1.4849\n",
            "Epoch 3: val_loss did not improve from 2.18474\n",
            "8249/8249 [==============================] - 26s 3ms/step - loss: 2.2466 - NN_RMSLE: 1.4849 - val_loss: 2.2095 - val_NN_RMSLE: 1.4366\n",
            "Epoch 4/100\n",
            "8233/8249 [============================>.] - ETA: 0s - loss: 2.2469 - NN_RMSLE: 1.4850\n",
            "Epoch 4: val_loss did not improve from 2.18474\n",
            "8249/8249 [==============================] - 25s 3ms/step - loss: 2.2467 - NN_RMSLE: 1.4849 - val_loss: 2.2043 - val_NN_RMSLE: 1.4360\n",
            "Model: \"sequential_59\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_236 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_177 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_237 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_178 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_238 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_179 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_239 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  2.204316\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAV4ElEQVR4nO3dfZBld13n8ff33u55yEwgGdLGMUGHwlQgxUKCbYxELZYYNwoSLKwto8SoyFAWrICUVkTLjVvUVlZ5kC13YQcSGDEbRQgQsyhMIiXlymbpQJ5HNhgCTpxkOpWHmWRmuvve+90/7jk9t3v64fRMn3vndr9fVV3n4f7uPd8zD+fT5/c759zITCRJ61tj0AVIkgbPMJAkGQaSJMNAkoRhIEkCRgZdQBVnnXVW7tixY9BlSNJQueuuu57IzLEqbYciDHbs2MHExMSgy5CkoRIR36na1m4iSZJhIEkyDCRJGAaSJAwDSRI1hkFEbIqI/xsR90TEAxHxh8X6F0XEnRHxrYj4y4jYUFcNkqRq6jwzmAJek5mvAC4EroiIS4D/AnwwM38QeAp4c401SJIqqC0MsuvZYnG0+EngNcCni/W7gTfUVYMkqZpaxwwiohkRdwMHgD3APwNPZ2araLIPOKfOGiRJy6s1DDKznZkXAucCFwMvqfreiNgZERMRMTE5OVlXidLKTXx80BVIq64vVxNl5tPAl4EfBc6IiPIxGOcCjy7ynl2ZOZ6Z42NjlR6tIUk6QXVeTTQWEWcU85uBy4G9dEPh54tm1wCfr6sGSVI1dT6objuwOyKadEPnU5l5W0Q8CPxFRLwX+AZwQ401SJIqqC0MMvNe4KIF1j9Md/xAknSK8A5kSZJhIEkyDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJKoMQwi4oUR8eWIeDAiHoiIdxTrr4uIRyPi7uLnZ+qqQZJUzUiNn90C3p2ZX4+I04G7ImJP8doHM/N9NW5bkrQCtYVBZu4H9hfzhyJiL3BOXduTJJ24vowZRMQO4CLgzmLV2yPi3oi4MSLOXOQ9OyNiIiImJicn+1GmJK1btYdBRGwFPgO8MzMPAh8GXgxcSPfM4f0LvS8zd2XmeGaOj42N1V2mJK1rtYZBRIzSDYKbMvMWgMx8PDPbmdkBPgpcXGcNkqTl1Xk1UQA3AHsz8wM967f3NPs54P66apAkVVPn1USXAlcD90XE3cW69wBXRcSFQAKPAG+tsQZJUgV1Xk30D0As8NIX6tqmJOnEeAeyJMkwkCQZBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEnUGAYR8cKI+HJEPBgRD0TEO4r12yJiT0Q8VEzPrKsGSVI1dZ4ZtIB3Z+YFwCXA2yLiAuBa4I7MPA+4o1iWJA1QbWGQmfsz8+vF/CFgL3AOcCWwu2i2G3hDXTVIkqrpy5hBROwALgLuBM7OzP3FS48BZy/ynp0RMRERE5OTk/0oU5LWrdrDICK2Ap8B3pmZB3tfy8wEcqH3ZeauzBzPzPGxsbG6y5Skda3WMIiIUbpBcFNm3lKsfjwithevbwcO1FmDJGl5dV5NFMANwN7M/EDPS7cC1xTz1wCfr6sGSVI1IzV+9qXA1cB9EXF3se49wPXApyLizcB3gH9fYw2SpApqC4PM/AcgFnn5srq2K0laOe9AliQZBpIkw0CShGEgScIwkCRhGEiSMAwkSVQMg4i4JSJeGxGGhyStQVUP7v8d+EXgoYi4PiLOr7EmSVKfVQqDzLw9M38JeCXwCHB7RPxjRPxq8TA6SdIQq9ztExEvAH4F+HXgG8CH6IbDnloqkyT1TaVnE0XEZ4HzgU8CP9vz5TR/GRETdRUnSeqPqg+q+2hmfqF3RURszMypzByvoS5JUh9V7SZ67wLrvrqahUiSBmfJM4OI+F66X2K/OSIu4tgjqZ8HnFZzbZKkPlmum+jf0R00Phfo/bayQ3S/qEaStAYsGQaZuRvYHRFvzMzP9KkmSVKfLddN9KbM/HNgR0T81vzX5323sSRpSC3XTbSlmG6tuxBJ0uAs1030P4rpH/anHEnSIFR9UN0fRcTzImI0Iu6IiMmIeFPdxUmS+qPqfQY/lZkHgdfRfTbRDwK/XVdRkqT+qhoGZXfSa4G/ysxnaqpHkjQAVR9HcVtE/BNwBPiNiBgDjtZXliSpn6o+wvpa4FXAeGbOAM8BV9ZZmCSpf6qeGQC8hO79Br3v+bPFGkfEjXTHGA5k5suKddcBbwEmi2bvmf8APElS/1V9hPUngRcDdwPtYnWyRBgAnwD+dIE2H8zM962oSklSraqeGYwDF2RmVv3gzPxKROw4oaokSX1V9Wqi+4HvXaVtvj0i7o2IGyPizMUaRcTOiJiIiInJycnFmkmSVkHVMDgLeDAivhgRt5Y/J7C9D9PtbroQ2A+8f7GGmbkrM8czc3xsbOwENiVJqqpqN9F1q7GxzHy8nI+IjwK3rcbnSpJOTqUwyMy/j4gfAM7LzNsj4jSgudKNRcT2nu9P/jm63U+SpAGrejXRW4CdwDa63TznAB8BLlviPTcDrwbOioh9wH8EXh0RF9K9EukR4K0nXrokabVU7SZ6G3AxcCdAZj4UEd+z1Bsy86oFVt+wsvIkSf1QdQB5KjOny4XixrPKl5lKkk5tVcPg7yPiPcDmiLgc+Cvgr+srS5LUT1XD4Fq6j5C4j24//xeA36+rKElSf1W9mqgTEZ8DPpeZ3gEmSWvMkmcG0XVdRDwBfBP4ZvEtZ3/Qn/IkSf2wXDfRu4BLgR/OzG2ZuQ34EeDSiHhX7dVJkvpiuTC4GrgqM79drsjMh4E3Ab9cZ2GSpP5ZLgxGM/OJ+SuLcYPRekqSJPXbcmEwfYKvSZKGyHJXE70iIg4usD6ATTXUI0kagCXDIDNX/DA6SdLwqXrTmSRpDTMMJEmGgSTJMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJGoMg4i4MSIORMT9Peu2RcSeiHiomJ5Z1/YlSdXVeWbwCeCKeeuuBe7IzPOAO4plSdKA1RYGmfkV4Ml5q68Edhfzu4E31LV9SVJ1/R4zODsz9xfzjwFnL9YwInZGxERETExOTvanOklapwY2gJyZCeQSr+/KzPHMHB8bG+tjZZK0/vQ7DB6PiO0AxfRAn7cvSVpAv8PgVuCaYv4a4PN93r4kaQF1Xlp6M/BV4PyI2BcRbwauBy6PiIeAnyyWpVPDkafguufD3tsWb/PsJHzp92H/vcfW7fkD+OPz6q9PqtFIXR+cmVct8tJldW1TOilPfrs7/cofwUtft3Cbf/47mH4W/vG/whs/1l33vz/Un/qkGnkHslRqbuhOW9OLt2k0u9Ps1F+P1EeGgVSKqN6m0z7+tVz04jjplGcYSLPKMFjioB5LnBksFBDSkDAMpFKVrp9oLN42DQMNL8NAKnVa3elS3T3lmMFCZwHl+6UhZBhIpdnf7Kt0Ey0UBp4ZaHgZBlKpU3T9nOhAsN1EGmKGgVSqdDBfIig6Xm6q4WUYSKXZPv+lDvhLBIZjBhpihoFUKg/0S3UTLXX2YDeRhphhIJWqDCAv9du/A8gaYoaBVJo9mC9xJ/JS4wJ2E2mIGQZSqQyDpR5LsWQ3kQPIGl6GgVTKCmMGdhNpjTIMpFKVg7lXE2mNMgykUnkwX6qbaKkDvlcTaYgZBlKpSp//Um3sJtIQMwyk0sl2E3lmoCFmGEilKgdzB5C1RhkGUmn2QH+Cl5YaBhpihoFUqtRN5ACy1ibDQCpV6iZyAFlrk2Eglao8gtoH1WmNMgyk0kruM1joElO/z0BDzDCQSpUeR1G0WWjswDMDDbGRQWw0Ih4BDgFtoJWZ44OoQ5pjJQPIC7V1zEBDbCBhUPi3mfnEALcvzVXl2UJl99BCB37PDDTE7CaSSuWBfskxg7IryTMDrS2DCoMEvhQRd0XEzoUaRMTOiJiIiInJyck+l6d1qcrXXi7VTeSZgYbYoMLgxzLzlcBPA2+LiJ+Y3yAzd2XmeGaOj42N9b9CrT+zA8hLXBWUSwwgezWRhthAwiAzHy2mB4DPAhcPog5pjtnLRit8Z8FsKPQEgGcGGmJ9D4OI2BIRp5fzwE8B9/e7Duk4nQUO8Me1mTeA3BsAjhloiA3iaqKzgc9Gd5BuBPifmfm3A6hDmqvsHqpyl3Fn3nS590mnuL6HQWY+DLyi39uVlrXQAf64NvO7iXrGDqp8OY50ivLSUqlUacygvXhbu4k0xAwDqbTUlUKl2UtLF7j5zDMDDTHDQCpVGUCevQN5gfsNPDPQEDMMpFIucIXQfPOvIkoHkLU2GAZSaSUDyAu19cxAQ8wwkEpLPXeoNH9cYc7VRIaBhpdhIJXm30OwkPlfbuPVRFojDAOpVOnS0vkDyL2Po/BqIg0vw0Aqzen/X+TAftwdyDMLv18aMoaBVKryaIkl70A2DDS8DAOp1HtgX+y3/Pl3IFd5jzQEDAOp1Nvls9yZAXS7knxQndYIw0AqzRkzWOSRFL2DxJ2WZwZaMwwDqVTlwN6ePjafbZ9aqjXDMJBK7d5uokUO7O15Vw95ZqA1wjCQSpUGkFtz59teTaS1wTCQSlUGg+efPXhmoDXCMJBKVW4gm9Nm3gCyZwYaYoaBVKpyYG/PQGO0aD9/zMABZA0vw0AqVbqaaAaaRRjMv5qo96xBGjKGgVRqt6C5oTu/2NVEnd4zg9ax0GhugNbR+muUamIYSKVOC0Y2HZufL7O7vjlStGkfOxvYsAVaU/2pU6qBYSCVOjPdgzosfGAvA6J3zKBst/F0zww01AwDqTRzBE47q5g/fPzr5d3HvWMGZQBsPtMzAw01w0CCbhfQzGHY8oLu8vQCYVAe7MtxhU6rGyBQhIFnBhpeI4MuQDollAf6LWPd6fSzx7eZOtSdbtzanc4chZkjZDRoj2whph/nqWen6GSSWQwxZM5ZbjRgQ7PBaLPB6EiDkUawodmg0Yj691FawkDCICKuAD4ENIGPZeb1g6hDwyUzmWp1ODLd5tmpFoeOtjh4dIZDR1scOjrDwSPF/FSLg0dmODLTptVJ2u2knUm7k2TmnM/sJLQ7yeaZJ/kocOu3Zng98P7/dTd79myj1Uk6ne77v3/mET4J/Nm/nssvxz28ddcXuSTv443Njdy+9xl+OJ7gx997+wntW7MRjDajGxLNBqPNYPNok03Fz+bRJps3NHvWNThtQ5PNG0bYPNrszhdtNo022TjSmG23ZeMIp28cYeumbtsIg0fH63sYREQT+G/A5cA+4GsRcWtmPljXNrM4EByeafP0czM8dXiaJw9P88zhGZJk40iTDc0GG0cb3fmRBhtHGnOnzSbRgPK/UUT0zEMQ9P4fK+fL9eVLSfc3xO58HpvP7vKx+W7d5aErs/vmOe/padP7fpLj1s35zJ7jYfZ85rFtZU+d89/fbd/uJK120up0mGl352c6ne66doeZTnfau36m3aFVrJ/pee/h6RZHpjscmWlxZLrNkZn27PTwdJujPcuducfyBY02g00jTUZHGjQiaET3YFv+PfWKgEYEL87HAHg4vw+A53WephHBppHuOzZEi5c2n4RpyE1nwBT80FkdLpia4vD0Nk7fsp2zD36Nn3359tnf8hs9/ybKfy+dPBZMc37mrev9c3puqsVTh6eZKZZn2h2mW53Z5ZVoNoKtG0fYunGE0zf1TDeNzs6XwTG7XLy2tXhtpNmgEcU+FX9+QTENFllnAJ3qBnFmcDHwrcx8GCAi/gK4Elj1MPhPf/0gN935HabbHXJl/2fUB+VBekPRZTLbfdJssGGk+1vy2NaROa9taAajRUhvHCl+Ex7p/ga8abTJxtEGI42VD4Vte+Yoz9zzIl76b17Fs/d8jrcc+Ti/On0zjZyhMe9u5Jd//wuYeXgLO596PwD7vufVPH/sJTz33Xv4sR1baDc3r8qfTxWd7AbxdLvDTKvDdPtY8JYhPNXqMNVqMzXT4ehMm6OtDlMzbaZaHZ48PM3+Z45ytFiearVXHDBVHfsFqVyOecs9YX1c23J59UOlrpxarY/9yNU/xI+fN7ZKn7a4mH/aXPsGI34euCIzf71Yvhr4kcx8+7x2O4GdxeL5wDdrKuks4ImaPnsQ1tL+rKV9AffnVLeW9qfclx/IzEpJcsoOIGfmLmBX3duJiInMHK97O/2ylvZnLe0LuD+nurW0PyeyL4O4tPRR4IU9y+cW6yRJAzKIMPgacF5EvCgiNgC/ANw6gDokSYW+dxNlZisi3g58ke6lpTdm5gP9rqNH7V1RfbaW9mct7Qu4P6e6tbQ/K96Xvg8gS5JOPT6OQpJkGEiS1nEYRMQVEfHNiPhWRFw76HpORkS8MCK+HBEPRsQDEfGOQde0GiKiGRHfiIjbBl3LyYqIMyLi0xHxTxGxNyJ+dNA1naiIeFfx7+z+iLg5IjYNuqaViIgbI+JARNzfs25bROyJiIeK6ZmDrHElFtmfPy7+rd0bEZ+NiDOW+5x1GQY9j8T4aeAC4KqIuGCwVZ2UFvDuzLwAuAR425DvT+kdwN5BF7FKPgT8bWa+BHgFQ7pfEXEO8JvAeGa+jO5FIL8w2KpW7BPAFfPWXQvckZnnAXcUy8PiExy/P3uAl2Xmy4H/B/zuch+yLsOAnkdiZOY0UD4SYyhl5v7M/Hoxf4jugeacwVZ1ciLiXOC1wMcGXcvJiojnAz8B3ACQmdOZ+fRAizo5I8DmiBgBTgP+dcD1rEhmfgV4ct7qK4Hdxfxu4A39rOlkLLQ/mfmlzCy/ru//0L2fa0nrNQzOAf6lZ3kfQ37wLEXEDuAi4M4Bl3Ky/gT4HWCRLyMeKi8CJoGPF91eH4uILYMu6kRk5qPA+4DvAvuBZzLzS4OtalWcnZn7i/nHgLMHWcwq+zXgb5ZrtF7DYE2KiK3AZ4B3ZubBQddzoiLidcCBzLxr0LWskhHglcCHM/Mi4DmGqxtiVtGXfiXdgPs+YEtEvGmwVa2uzPIZwcMvIn6PbjfyTcu1Xa9hsOYeiRERo3SD4KbMvGXQ9ZykS4HXR8QjdLvwXhMRfz7Ykk7KPmBfZpZna5+mGw7D6CeBb2fmZGbOALcArxpwTavh8YjYDlBMDwy4npMWEb8CvA74paxwQ9l6DYM19UiM6D4L+AZgb2Z+YND1nKzM/N3MPDczd9D9u/m7zBza3z4z8zHgXyLi/GLVZdTwyPY++S5wSUScVvy7u4whHQyf51bgmmL+GuDzA6zlpBVfIPY7wOszc4HvcD3eugyDYmClfCTGXuBTA34kxsm6FLia7m/Qdxc/PzPoojTHfwBuioh7gQuB/zzYck5McXbzaeDrwH10jyFD9RiHiLgZ+CpwfkTsi4g3A9cDl0fEQ3TPfobm2xcX2Z8/BU4H9hTHg48s+zk+jkKStC7PDCRJcxkGkiTDQJJkGEiSMAwkSRgGkiQMA0kS8P8BhyT8QCoYfywAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 92 (738143, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[1 2 3 4 5 6 7 8 9]\n",
            "train 492095 valid 246048\n",
            "Model: \"sequential_60\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_240 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_180 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_241 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_181 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_242 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_182 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_243 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "7677/7689 [============================>.] - ETA: 0s - loss: 6.0887 - NN_RMSLE: 2.3540\n",
            "Epoch 1: val_loss improved from inf to 3.41332, saving model to model_92[]\n",
            "INFO:tensorflow:Assets written to: model_92[]/assets\n",
            "7689/7689 [==============================] - 23s 3ms/step - loss: 6.0844 - NN_RMSLE: 2.3532 - val_loss: 3.4133 - val_NN_RMSLE: 1.8341\n",
            "Epoch 2/100\n",
            "7687/7689 [============================>.] - ETA: 0s - loss: 3.1641 - NN_RMSLE: 1.7707\n",
            "Epoch 2: val_loss did not improve from 3.41332\n",
            "7689/7689 [==============================] - 28s 4ms/step - loss: 3.1641 - NN_RMSLE: 1.7707 - val_loss: 3.4242 - val_NN_RMSLE: 1.8371\n",
            "Epoch 3/100\n",
            "7669/7689 [============================>.] - ETA: 0s - loss: 3.1642 - NN_RMSLE: 1.7705\n",
            "Epoch 3: val_loss did not improve from 3.41332\n",
            "7689/7689 [==============================] - 25s 3ms/step - loss: 3.1641 - NN_RMSLE: 1.7705 - val_loss: 3.4212 - val_NN_RMSLE: 1.8363\n",
            "Epoch 4/100\n",
            "7687/7689 [============================>.] - ETA: 0s - loss: 3.1640 - NN_RMSLE: 1.7706\n",
            "Epoch 4: val_loss did not improve from 3.41332\n",
            "7689/7689 [==============================] - 26s 3ms/step - loss: 3.1640 - NN_RMSLE: 1.7706 - val_loss: 3.4266 - val_NN_RMSLE: 1.8377\n",
            "Model: \"sequential_60\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_240 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_180 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_241 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_181 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_242 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_182 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_243 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  3.4266095\n",
            "\n",
            "[ 5  6  7  8  9 10 11]\n",
            "train 492095 valid 246048\n",
            "Model: \"sequential_61\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_244 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_183 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_245 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_184 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_246 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_185 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_247 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "7681/7689 [============================>.] - ETA: 0s - loss: 6.8992 - NN_RMSLE: 2.4876\n",
            "Epoch 1: val_loss improved from inf to 3.46432, saving model to model_92[]\n",
            "INFO:tensorflow:Assets written to: model_92[]/assets\n",
            "7689/7689 [==============================] - 26s 3ms/step - loss: 6.8951 - NN_RMSLE: 2.4867 - val_loss: 3.4643 - val_NN_RMSLE: 1.8510\n",
            "Epoch 2/100\n",
            "7682/7689 [============================>.] - ETA: 0s - loss: 3.1585 - NN_RMSLE: 1.7676\n",
            "Epoch 2: val_loss did not improve from 3.46432\n",
            "7689/7689 [==============================] - 24s 3ms/step - loss: 3.1586 - NN_RMSLE: 1.7676 - val_loss: 3.4945 - val_NN_RMSLE: 1.8590\n",
            "Epoch 3/100\n",
            "7683/7689 [============================>.] - ETA: 0s - loss: 3.1586 - NN_RMSLE: 1.7675\n",
            "Epoch 3: val_loss did not improve from 3.46432\n",
            "7689/7689 [==============================] - 24s 3ms/step - loss: 3.1586 - NN_RMSLE: 1.7675 - val_loss: 3.4783 - val_NN_RMSLE: 1.8547\n",
            "Epoch 4/100\n",
            "7686/7689 [============================>.] - ETA: 0s - loss: 3.1584 - NN_RMSLE: 1.7678\n",
            "Epoch 4: val_loss did not improve from 3.46432\n",
            "7689/7689 [==============================] - 25s 3ms/step - loss: 3.1586 - NN_RMSLE: 1.7678 - val_loss: 3.4799 - val_NN_RMSLE: 1.8551\n",
            "Model: \"sequential_61\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_244 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_183 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_245 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_184 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_246 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_185 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_247 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  3.4799278\n",
            "\n",
            "[ 9 10 11 12]\n",
            "train 492096 valid 246047\n",
            "Model: \"sequential_62\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_248 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_186 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_249 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_187 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_250 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_188 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_251 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "7688/7689 [============================>.] - ETA: 0s - loss: 6.4427 - NN_RMSLE: 2.4222\n",
            "Epoch 1: val_loss improved from inf to 3.07976, saving model to model_92[]\n",
            "INFO:tensorflow:Assets written to: model_92[]/assets\n",
            "7689/7689 [==============================] - 22s 3ms/step - loss: 6.4424 - NN_RMSLE: 2.4221 - val_loss: 3.0798 - val_NN_RMSLE: 1.7473\n",
            "Epoch 2/100\n",
            "7682/7689 [============================>.] - ETA: 0s - loss: 3.3103 - NN_RMSLE: 1.8112\n",
            "Epoch 2: val_loss improved from 3.07976 to 3.07504, saving model to model_92[]\n",
            "INFO:tensorflow:Assets written to: model_92[]/assets\n",
            "7689/7689 [==============================] - 22s 3ms/step - loss: 3.3101 - NN_RMSLE: 1.8112 - val_loss: 3.0750 - val_NN_RMSLE: 1.7460\n",
            "Epoch 3/100\n",
            "7670/7689 [============================>.] - ETA: 0s - loss: 3.3101 - NN_RMSLE: 1.8113\n",
            "Epoch 3: val_loss improved from 3.07504 to 3.07307, saving model to model_92[]\n",
            "INFO:tensorflow:Assets written to: model_92[]/assets\n",
            "7689/7689 [==============================] - 23s 3ms/step - loss: 3.3101 - NN_RMSLE: 1.8113 - val_loss: 3.0731 - val_NN_RMSLE: 1.7455\n",
            "Epoch 4/100\n",
            "7689/7689 [==============================] - ETA: 0s - loss: 3.3102 - NN_RMSLE: 1.8113\n",
            "Epoch 4: val_loss did not improve from 3.07307\n",
            "7689/7689 [==============================] - 25s 3ms/step - loss: 3.3102 - NN_RMSLE: 1.8113 - val_loss: 3.0776 - val_NN_RMSLE: 1.7467\n",
            "Epoch 5/100\n",
            "7687/7689 [============================>.] - ETA: 0s - loss: 3.3102 - NN_RMSLE: 1.8111\n",
            "Epoch 5: val_loss did not improve from 3.07307\n",
            "7689/7689 [==============================] - 24s 3ms/step - loss: 3.3101 - NN_RMSLE: 1.8111 - val_loss: 3.0832 - val_NN_RMSLE: 1.7483\n",
            "Epoch 6/100\n",
            "7672/7689 [============================>.] - ETA: 0s - loss: 3.3100 - NN_RMSLE: 1.8111\n",
            "Epoch 6: val_loss did not improve from 3.07307\n",
            "7689/7689 [==============================] - 23s 3ms/step - loss: 3.3101 - NN_RMSLE: 1.8111 - val_loss: 3.0808 - val_NN_RMSLE: 1.7476\n",
            "Model: \"sequential_62\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_248 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_186 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_249 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_187 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_250 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_188 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_251 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  3.0807889\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 100 (236046, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[1 2 3 4 5 7]\n",
            "train 157364 valid 78682\n",
            "Model: \"sequential_63\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_252 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_189 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_253 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_190 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_254 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_191 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_255 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "2454/2459 [============================>.] - ETA: 0s - loss: 9.2491 - NN_RMSLE: 2.9846\n",
            "Epoch 1: val_loss improved from inf to 4.67177, saving model to model_100[]\n",
            "INFO:tensorflow:Assets written to: model_100[]/assets\n",
            "2459/2459 [==============================] - 9s 4ms/step - loss: 9.2385 - NN_RMSLE: 2.9826 - val_loss: 4.6718 - val_NN_RMSLE: 2.1524\n",
            "Epoch 2/100\n",
            "2443/2459 [============================>.] - ETA: 0s - loss: 2.2691 - NN_RMSLE: 1.4763\n",
            "Epoch 2: val_loss improved from 4.67177 to 1.40222, saving model to model_100[]\n",
            "INFO:tensorflow:Assets written to: model_100[]/assets\n",
            "2459/2459 [==============================] - 11s 5ms/step - loss: 2.2620 - NN_RMSLE: 1.4737 - val_loss: 1.4022 - val_NN_RMSLE: 1.1770\n",
            "Epoch 3/100\n",
            "2453/2459 [============================>.] - ETA: 0s - loss: 1.0881 - NN_RMSLE: 1.0387\n",
            "Epoch 3: val_loss improved from 1.40222 to 1.18688, saving model to model_100[]\n",
            "INFO:tensorflow:Assets written to: model_100[]/assets\n",
            "2459/2459 [==============================] - 8s 3ms/step - loss: 1.0878 - NN_RMSLE: 1.0385 - val_loss: 1.1869 - val_NN_RMSLE: 1.0846\n",
            "Epoch 4/100\n",
            "2452/2459 [============================>.] - ETA: 0s - loss: 1.0604 - NN_RMSLE: 1.0247\n",
            "Epoch 4: val_loss did not improve from 1.18688\n",
            "2459/2459 [==============================] - 8s 3ms/step - loss: 1.0605 - NN_RMSLE: 1.0247 - val_loss: 1.1885 - val_NN_RMSLE: 1.0853\n",
            "Epoch 5/100\n",
            "2436/2459 [============================>.] - ETA: 0s - loss: 1.0603 - NN_RMSLE: 1.0251\n",
            "Epoch 5: val_loss improved from 1.18688 to 1.18592, saving model to model_100[]\n",
            "INFO:tensorflow:Assets written to: model_100[]/assets\n",
            "2459/2459 [==============================] - 8s 3ms/step - loss: 1.0606 - NN_RMSLE: 1.0253 - val_loss: 1.1859 - val_NN_RMSLE: 1.0841\n",
            "Epoch 6/100\n",
            "2450/2459 [============================>.] - ETA: 0s - loss: 1.0607 - NN_RMSLE: 1.0253\n",
            "Epoch 6: val_loss did not improve from 1.18592\n",
            "2459/2459 [==============================] - 7s 3ms/step - loss: 1.0605 - NN_RMSLE: 1.0252 - val_loss: 1.1864 - val_NN_RMSLE: 1.0843\n",
            "Epoch 7/100\n",
            "2448/2459 [============================>.] - ETA: 0s - loss: 1.0604 - NN_RMSLE: 1.0247\n",
            "Epoch 7: val_loss did not improve from 1.18592\n",
            "2459/2459 [==============================] - 8s 3ms/step - loss: 1.0606 - NN_RMSLE: 1.0248 - val_loss: 1.1873 - val_NN_RMSLE: 1.0848\n",
            "Epoch 8/100\n",
            "2458/2459 [============================>.] - ETA: 0s - loss: 1.0605 - NN_RMSLE: 1.0248\n",
            "Epoch 8: val_loss improved from 1.18592 to 1.18465, saving model to model_100[]\n",
            "INFO:tensorflow:Assets written to: model_100[]/assets\n",
            "2459/2459 [==============================] - 8s 3ms/step - loss: 1.0605 - NN_RMSLE: 1.0248 - val_loss: 1.1846 - val_NN_RMSLE: 1.0836\n",
            "Epoch 9/100\n",
            "2443/2459 [============================>.] - ETA: 0s - loss: 1.0607 - NN_RMSLE: 1.0252\n",
            "Epoch 9: val_loss did not improve from 1.18465\n",
            "2459/2459 [==============================] - 8s 3ms/step - loss: 1.0606 - NN_RMSLE: 1.0251 - val_loss: 1.1856 - val_NN_RMSLE: 1.0840\n",
            "Epoch 10/100\n",
            "2459/2459 [==============================] - ETA: 0s - loss: 1.0606 - NN_RMSLE: 1.0245\n",
            "Epoch 10: val_loss did not improve from 1.18465\n",
            "2459/2459 [==============================] - 8s 3ms/step - loss: 1.0606 - NN_RMSLE: 1.0245 - val_loss: 1.1862 - val_NN_RMSLE: 1.0843\n",
            "Epoch 11/100\n",
            "2448/2459 [============================>.] - ETA: 0s - loss: 1.0605 - NN_RMSLE: 1.0249\n",
            "Epoch 11: val_loss did not improve from 1.18465\n",
            "2459/2459 [==============================] - 9s 3ms/step - loss: 1.0606 - NN_RMSLE: 1.0249 - val_loss: 1.1860 - val_NN_RMSLE: 1.0842\n",
            "Model: \"sequential_63\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_252 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_189 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_253 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_190 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_254 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_191 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_255 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.1859666\n",
            "\n",
            "[ 2  3  4  5  6  7  8  9 10]\n",
            "train 157364 valid 78682\n",
            "Model: \"sequential_64\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_256 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_192 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_257 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_193 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_258 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_194 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_259 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "2449/2459 [============================>.] - ETA: 0s - loss: 9.5652 - NN_RMSLE: 3.0377\n",
            "Epoch 1: val_loss improved from inf to 4.19102, saving model to model_100[]\n",
            "INFO:tensorflow:Assets written to: model_100[]/assets\n",
            "2459/2459 [==============================] - 9s 3ms/step - loss: 9.5454 - NN_RMSLE: 3.0340 - val_loss: 4.1910 - val_NN_RMSLE: 2.0314\n",
            "Epoch 2/100\n",
            "2450/2459 [============================>.] - ETA: 0s - loss: 2.4086 - NN_RMSLE: 1.5217\n",
            "Epoch 2: val_loss improved from 4.19102 to 1.16956, saving model to model_100[]\n",
            "INFO:tensorflow:Assets written to: model_100[]/assets\n",
            "2459/2459 [==============================] - 9s 3ms/step - loss: 2.4046 - NN_RMSLE: 1.5203 - val_loss: 1.1696 - val_NN_RMSLE: 1.0727\n",
            "Epoch 3/100\n",
            "2457/2459 [============================>.] - ETA: 0s - loss: 1.1646 - NN_RMSLE: 1.0743\n",
            "Epoch 3: val_loss improved from 1.16956 to 1.03844, saving model to model_100[]\n",
            "INFO:tensorflow:Assets written to: model_100[]/assets\n",
            "2459/2459 [==============================] - 8s 3ms/step - loss: 1.1645 - NN_RMSLE: 1.0742 - val_loss: 1.0384 - val_NN_RMSLE: 1.0130\n",
            "Epoch 4/100\n",
            "2454/2459 [============================>.] - ETA: 0s - loss: 1.1338 - NN_RMSLE: 1.0599\n",
            "Epoch 4: val_loss did not improve from 1.03844\n",
            "2459/2459 [==============================] - 8s 3ms/step - loss: 1.1335 - NN_RMSLE: 1.0597 - val_loss: 1.0392 - val_NN_RMSLE: 1.0134\n",
            "Epoch 5/100\n",
            "2455/2459 [============================>.] - ETA: 0s - loss: 1.1334 - NN_RMSLE: 1.0597\n",
            "Epoch 5: val_loss did not improve from 1.03844\n",
            "2459/2459 [==============================] - 9s 4ms/step - loss: 1.1335 - NN_RMSLE: 1.0597 - val_loss: 1.0396 - val_NN_RMSLE: 1.0136\n",
            "Epoch 6/100\n",
            "2459/2459 [==============================] - ETA: 0s - loss: 1.1335 - NN_RMSLE: 1.0595\n",
            "Epoch 6: val_loss did not improve from 1.03844\n",
            "2459/2459 [==============================] - 8s 3ms/step - loss: 1.1335 - NN_RMSLE: 1.0595 - val_loss: 1.0395 - val_NN_RMSLE: 1.0135\n",
            "Model: \"sequential_64\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_256 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_192 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_257 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_193 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_258 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_194 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_259 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.039521\n",
            "\n",
            "[ 3  4  5  6  7  8  9 10 11 12]\n",
            "train 157364 valid 78682\n",
            "Model: \"sequential_65\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_260 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_195 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_261 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_196 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_262 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_197 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_263 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "2439/2459 [============================>.] - ETA: 0s - loss: 9.5253 - NN_RMSLE: 3.0315\n",
            "Epoch 1: val_loss improved from inf to 4.29649, saving model to model_100[]\n",
            "INFO:tensorflow:Assets written to: model_100[]/assets\n",
            "2459/2459 [==============================] - 9s 3ms/step - loss: 9.4848 - NN_RMSLE: 3.0240 - val_loss: 4.2965 - val_NN_RMSLE: 2.0574\n",
            "Epoch 2/100\n",
            "2437/2459 [============================>.] - ETA: 0s - loss: 2.3803 - NN_RMSLE: 1.5129\n",
            "Epoch 2: val_loss improved from 4.29649 to 1.22964, saving model to model_100[]\n",
            "INFO:tensorflow:Assets written to: model_100[]/assets\n",
            "2459/2459 [==============================] - 8s 3ms/step - loss: 2.3709 - NN_RMSLE: 1.5096 - val_loss: 1.2296 - val_NN_RMSLE: 1.0949\n",
            "Epoch 3/100\n",
            "2458/2459 [============================>.] - ETA: 0s - loss: 1.1414 - NN_RMSLE: 1.0635\n",
            "Epoch 3: val_loss improved from 1.22964 to 1.08454, saving model to model_100[]\n",
            "INFO:tensorflow:Assets written to: model_100[]/assets\n",
            "2459/2459 [==============================] - 8s 3ms/step - loss: 1.1414 - NN_RMSLE: 1.0635 - val_loss: 1.0845 - val_NN_RMSLE: 1.0313\n",
            "Epoch 4/100\n",
            "2441/2459 [============================>.] - ETA: 0s - loss: 1.1109 - NN_RMSLE: 1.0490\n",
            "Epoch 4: val_loss did not improve from 1.08454\n",
            "2459/2459 [==============================] - 7s 3ms/step - loss: 1.1106 - NN_RMSLE: 1.0489 - val_loss: 1.0847 - val_NN_RMSLE: 1.0314\n",
            "Epoch 5/100\n",
            "2456/2459 [============================>.] - ETA: 0s - loss: 1.1107 - NN_RMSLE: 1.0489\n",
            "Epoch 5: val_loss improved from 1.08454 to 1.08449, saving model to model_100[]\n",
            "INFO:tensorflow:Assets written to: model_100[]/assets\n",
            "2459/2459 [==============================] - 8s 3ms/step - loss: 1.1106 - NN_RMSLE: 1.0489 - val_loss: 1.0845 - val_NN_RMSLE: 1.0313\n",
            "Epoch 6/100\n",
            "2455/2459 [============================>.] - ETA: 0s - loss: 1.1107 - NN_RMSLE: 1.0488\n",
            "Epoch 6: val_loss improved from 1.08449 to 1.08426, saving model to model_100[]\n",
            "INFO:tensorflow:Assets written to: model_100[]/assets\n",
            "2459/2459 [==============================] - 8s 3ms/step - loss: 1.1106 - NN_RMSLE: 1.0487 - val_loss: 1.0843 - val_NN_RMSLE: 1.0311\n",
            "Epoch 7/100\n",
            "2435/2459 [============================>.] - ETA: 0s - loss: 1.1100 - NN_RMSLE: 1.0489\n",
            "Epoch 7: val_loss did not improve from 1.08426\n",
            "2459/2459 [==============================] - 7s 3ms/step - loss: 1.1106 - NN_RMSLE: 1.0492 - val_loss: 1.0859 - val_NN_RMSLE: 1.0321\n",
            "Epoch 8/100\n",
            "2454/2459 [============================>.] - ETA: 0s - loss: 1.1105 - NN_RMSLE: 1.0488\n",
            "Epoch 8: val_loss did not improve from 1.08426\n",
            "2459/2459 [==============================] - 8s 3ms/step - loss: 1.1106 - NN_RMSLE: 1.0489 - val_loss: 1.0853 - val_NN_RMSLE: 1.0317\n",
            "Epoch 9/100\n",
            "2443/2459 [============================>.] - ETA: 0s - loss: 1.1101 - NN_RMSLE: 1.0485\n",
            "Epoch 9: val_loss did not improve from 1.08426\n",
            "2459/2459 [==============================] - 7s 3ms/step - loss: 1.1106 - NN_RMSLE: 1.0487 - val_loss: 1.0844 - val_NN_RMSLE: 1.0313\n",
            "Model: \"sequential_65\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_260 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_195 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_261 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_196 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_262 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_197 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_263 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.0844352\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 101 (78935, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[1 2 3 4 5]\n",
            "train 52623 valid 26312\n",
            "Model: \"sequential_66\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_264 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_198 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_265 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_199 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_266 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_200 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_267 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "802/823 [============================>.] - ETA: 0s - loss: 8.7889 - NN_RMSLE: 2.9526\n",
            "Epoch 1: val_loss improved from inf to 1.75040, saving model to model_101[]\n",
            "INFO:tensorflow:Assets written to: model_101[]/assets\n",
            "823/823 [==============================] - 3s 4ms/step - loss: 8.7690 - NN_RMSLE: 2.9497 - val_loss: 1.7504 - val_NN_RMSLE: 1.1819\n",
            "Epoch 2/100\n",
            "812/823 [============================>.] - ETA: 0s - loss: 6.9000 - NN_RMSLE: 2.6186\n",
            "Epoch 2: val_loss did not improve from 1.75040\n",
            "823/823 [==============================] - 4s 4ms/step - loss: 6.8905 - NN_RMSLE: 2.6172 - val_loss: 2.3982 - val_NN_RMSLE: 1.5082\n",
            "Epoch 3/100\n",
            "815/823 [============================>.] - ETA: 0s - loss: 6.0450 - NN_RMSLE: 2.4538\n",
            "Epoch 3: val_loss did not improve from 1.75040\n",
            "823/823 [==============================] - 6s 7ms/step - loss: 6.0522 - NN_RMSLE: 2.4554 - val_loss: 3.2767 - val_NN_RMSLE: 1.7978\n",
            "Epoch 4/100\n",
            "819/823 [============================>.] - ETA: 0s - loss: 5.7757 - NN_RMSLE: 2.3996\n",
            "Epoch 4: val_loss did not improve from 1.75040\n",
            "823/823 [==============================] - 4s 5ms/step - loss: 5.7747 - NN_RMSLE: 2.3991 - val_loss: 3.9549 - val_NN_RMSLE: 1.9832\n",
            "Model: \"sequential_66\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_264 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_198 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_265 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_199 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_266 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_200 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_267 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  3.954857\n",
            "\n",
            "[5 6 7 8]\n",
            "train 52623 valid 26312\n",
            "Model: \"sequential_67\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_268 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_201 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_269 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_202 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_270 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_203 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_271 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "821/823 [============================>.] - ETA: 0s - loss: 4.2588 - NN_RMSLE: 2.0453\n",
            "Epoch 1: val_loss improved from inf to 9.71280, saving model to model_101[]\n",
            "INFO:tensorflow:Assets written to: model_101[]/assets\n",
            "823/823 [==============================] - 4s 4ms/step - loss: 4.2559 - NN_RMSLE: 2.0436 - val_loss: 9.7128 - val_NN_RMSLE: 3.0328\n",
            "Epoch 2/100\n",
            "817/823 [============================>.] - ETA: 0s - loss: 3.7729 - NN_RMSLE: 1.9306\n",
            "Epoch 2: val_loss improved from 9.71280 to 8.57887, saving model to model_101[]\n",
            "INFO:tensorflow:Assets written to: model_101[]/assets\n",
            "823/823 [==============================] - 3s 3ms/step - loss: 3.7706 - NN_RMSLE: 1.9298 - val_loss: 8.5789 - val_NN_RMSLE: 2.8513\n",
            "Epoch 3/100\n",
            "806/823 [============================>.] - ETA: 0s - loss: 3.7047 - NN_RMSLE: 1.9152\n",
            "Epoch 3: val_loss improved from 8.57887 to 8.29755, saving model to model_101[]\n",
            "INFO:tensorflow:Assets written to: model_101[]/assets\n",
            "823/823 [==============================] - 3s 3ms/step - loss: 3.7075 - NN_RMSLE: 1.9159 - val_loss: 8.2975 - val_NN_RMSLE: 2.8051\n",
            "Epoch 4/100\n",
            "817/823 [============================>.] - ETA: 0s - loss: 3.7068 - NN_RMSLE: 1.9163\n",
            "Epoch 4: val_loss improved from 8.29755 to 8.25922, saving model to model_101[]\n",
            "INFO:tensorflow:Assets written to: model_101[]/assets\n",
            "823/823 [==============================] - 3s 3ms/step - loss: 3.7047 - NN_RMSLE: 1.9152 - val_loss: 8.2592 - val_NN_RMSLE: 2.7988\n",
            "Epoch 5/100\n",
            "821/823 [============================>.] - ETA: 0s - loss: 3.7042 - NN_RMSLE: 1.9156\n",
            "Epoch 5: val_loss did not improve from 8.25922\n",
            "823/823 [==============================] - 2s 3ms/step - loss: 3.7047 - NN_RMSLE: 1.9160 - val_loss: 8.2909 - val_NN_RMSLE: 2.8040\n",
            "Epoch 6/100\n",
            "815/823 [============================>.] - ETA: 0s - loss: 3.7063 - NN_RMSLE: 1.9162\n",
            "Epoch 6: val_loss improved from 8.25922 to 8.21315, saving model to model_101[]\n",
            "INFO:tensorflow:Assets written to: model_101[]/assets\n",
            "823/823 [==============================] - 3s 4ms/step - loss: 3.7046 - NN_RMSLE: 1.9166 - val_loss: 8.2132 - val_NN_RMSLE: 2.7912\n",
            "Epoch 7/100\n",
            "801/823 [============================>.] - ETA: 0s - loss: 3.7019 - NN_RMSLE: 1.9148\n",
            "Epoch 7: val_loss improved from 8.21315 to 8.20915, saving model to model_101[]\n",
            "INFO:tensorflow:Assets written to: model_101[]/assets\n",
            "823/823 [==============================] - 3s 3ms/step - loss: 3.7047 - NN_RMSLE: 1.9157 - val_loss: 8.2091 - val_NN_RMSLE: 2.7905\n",
            "Epoch 8/100\n",
            "823/823 [==============================] - ETA: 0s - loss: 3.7048 - NN_RMSLE: 1.9147\n",
            "Epoch 8: val_loss did not improve from 8.20915\n",
            "823/823 [==============================] - 3s 3ms/step - loss: 3.7048 - NN_RMSLE: 1.9147 - val_loss: 8.2547 - val_NN_RMSLE: 2.7981\n",
            "Epoch 9/100\n",
            "807/823 [============================>.] - ETA: 0s - loss: 3.7076 - NN_RMSLE: 1.9160\n",
            "Epoch 9: val_loss did not improve from 8.20915\n",
            "823/823 [==============================] - 3s 3ms/step - loss: 3.7046 - NN_RMSLE: 1.9150 - val_loss: 8.2164 - val_NN_RMSLE: 2.7918\n",
            "Epoch 10/100\n",
            "823/823 [==============================] - ETA: 0s - loss: 3.7047 - NN_RMSLE: 1.9152\n",
            "Epoch 10: val_loss did not improve from 8.20915\n",
            "823/823 [==============================] - 3s 4ms/step - loss: 3.7047 - NN_RMSLE: 1.9152 - val_loss: 8.2718 - val_NN_RMSLE: 2.8009\n",
            "Model: \"sequential_67\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_268 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_201 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_269 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_202 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_270 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_203 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_271 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  8.271754\n",
            "\n",
            "[ 8  9 10 11 12]\n",
            "train 52624 valid 26311\n",
            "Model: \"sequential_68\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_272 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_204 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_273 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_205 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_274 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_206 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_275 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "814/823 [============================>.] - ETA: 0s - loss: 6.3217 - NN_RMSLE: 2.4998\n",
            "Epoch 1: val_loss improved from inf to 5.94134, saving model to model_101[]\n",
            "INFO:tensorflow:Assets written to: model_101[]/assets\n",
            "823/823 [==============================] - 3s 4ms/step - loss: 6.3119 - NN_RMSLE: 2.4982 - val_loss: 5.9413 - val_NN_RMSLE: 2.3738\n",
            "Epoch 2/100\n",
            "812/823 [============================>.] - ETA: 0s - loss: 5.2734 - NN_RMSLE: 2.2869\n",
            "Epoch 2: val_loss improved from 5.94134 to 5.26328, saving model to model_101[]\n",
            "INFO:tensorflow:Assets written to: model_101[]/assets\n",
            "823/823 [==============================] - 3s 3ms/step - loss: 5.2707 - NN_RMSLE: 2.2863 - val_loss: 5.2633 - val_NN_RMSLE: 2.2480\n",
            "Epoch 3/100\n",
            "811/823 [============================>.] - ETA: 0s - loss: 4.9767 - NN_RMSLE: 2.2235\n",
            "Epoch 3: val_loss improved from 5.26328 to 5.08582, saving model to model_101[]\n",
            "INFO:tensorflow:Assets written to: model_101[]/assets\n",
            "823/823 [==============================] - 3s 4ms/step - loss: 4.9777 - NN_RMSLE: 2.2235 - val_loss: 5.0858 - val_NN_RMSLE: 2.2194\n",
            "Epoch 4/100\n",
            "814/823 [============================>.] - ETA: 0s - loss: 4.9334 - NN_RMSLE: 2.2157\n",
            "Epoch 4: val_loss improved from 5.08582 to 5.05032, saving model to model_101[]\n",
            "INFO:tensorflow:Assets written to: model_101[]/assets\n",
            "823/823 [==============================] - 3s 4ms/step - loss: 4.9312 - NN_RMSLE: 2.2147 - val_loss: 5.0503 - val_NN_RMSLE: 2.2154\n",
            "Epoch 5/100\n",
            "818/823 [============================>.] - ETA: 0s - loss: 4.9261 - NN_RMSLE: 2.2142\n",
            "Epoch 5: val_loss improved from 5.05032 to 5.04903, saving model to model_101[]\n",
            "INFO:tensorflow:Assets written to: model_101[]/assets\n",
            "823/823 [==============================] - 3s 4ms/step - loss: 4.9284 - NN_RMSLE: 2.2147 - val_loss: 5.0490 - val_NN_RMSLE: 2.2153\n",
            "Epoch 6/100\n",
            "813/823 [============================>.] - ETA: 0s - loss: 4.9315 - NN_RMSLE: 2.2157\n",
            "Epoch 6: val_loss improved from 5.04903 to 5.04769, saving model to model_101[]\n",
            "INFO:tensorflow:Assets written to: model_101[]/assets\n",
            "823/823 [==============================] - 3s 4ms/step - loss: 4.9284 - NN_RMSLE: 2.2150 - val_loss: 5.0477 - val_NN_RMSLE: 2.2152\n",
            "Epoch 7/100\n",
            "810/823 [============================>.] - ETA: 0s - loss: 4.9264 - NN_RMSLE: 2.2142\n",
            "Epoch 7: val_loss did not improve from 5.04769\n",
            "823/823 [==============================] - 3s 3ms/step - loss: 4.9284 - NN_RMSLE: 2.2147 - val_loss: 5.0486 - val_NN_RMSLE: 2.2153\n",
            "Epoch 8/100\n",
            "801/823 [============================>.] - ETA: 0s - loss: 4.9284 - NN_RMSLE: 2.2143\n",
            "Epoch 8: val_loss did not improve from 5.04769\n",
            "823/823 [==============================] - 3s 3ms/step - loss: 4.9285 - NN_RMSLE: 2.2143 - val_loss: 5.0480 - val_NN_RMSLE: 2.2152\n",
            "Epoch 9/100\n",
            "802/823 [============================>.] - ETA: 0s - loss: 4.9266 - NN_RMSLE: 2.2141\n",
            "Epoch 9: val_loss did not improve from 5.04769\n",
            "823/823 [==============================] - 3s 4ms/step - loss: 4.9284 - NN_RMSLE: 2.2149 - val_loss: 5.0478 - val_NN_RMSLE: 2.2152\n",
            "Model: \"sequential_68\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_272 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_204 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_273 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_205 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_274 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_206 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_275 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  5.0478306\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 103 (95899, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[1 2 3 4 5]\n",
            "train 63932 valid 31967\n",
            "Model: \"sequential_69\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_276 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_207 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_277 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_208 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_278 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_209 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_279 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "980/999 [============================>.] - ETA: 0s - loss: 13.4712 - NN_RMSLE: 3.6442\n",
            "Epoch 1: val_loss improved from inf to 18.94326, saving model to model_103[]\n",
            "INFO:tensorflow:Assets written to: model_103[]/assets\n",
            "999/999 [==============================] - 4s 4ms/step - loss: 13.4441 - NN_RMSLE: 3.6406 - val_loss: 18.9433 - val_NN_RMSLE: 4.3053\n",
            "Epoch 2/100\n",
            "990/999 [============================>.] - ETA: 0s - loss: 10.8645 - NN_RMSLE: 3.2759\n",
            "Epoch 2: val_loss improved from 18.94326 to 14.96471, saving model to model_103[]\n",
            "INFO:tensorflow:Assets written to: model_103[]/assets\n",
            "999/999 [==============================] - 5s 5ms/step - loss: 10.8567 - NN_RMSLE: 3.2747 - val_loss: 14.9647 - val_NN_RMSLE: 3.8273\n",
            "Epoch 3/100\n",
            "990/999 [============================>.] - ETA: 0s - loss: 9.7578 - NN_RMSLE: 3.1080\n",
            "Epoch 3: val_loss improved from 14.96471 to 12.75074, saving model to model_103[]\n",
            "INFO:tensorflow:Assets written to: model_103[]/assets\n",
            "999/999 [==============================] - 7s 7ms/step - loss: 9.7510 - NN_RMSLE: 3.1069 - val_loss: 12.7507 - val_NN_RMSLE: 3.5363\n",
            "Epoch 4/100\n",
            "994/999 [============================>.] - ETA: 0s - loss: 9.4164 - NN_RMSLE: 3.0555\n",
            "Epoch 4: val_loss improved from 12.75074 to 11.73409, saving model to model_103[]\n",
            "INFO:tensorflow:Assets written to: model_103[]/assets\n",
            "999/999 [==============================] - 4s 4ms/step - loss: 9.4173 - NN_RMSLE: 3.0556 - val_loss: 11.7341 - val_NN_RMSLE: 3.3954\n",
            "Epoch 5/100\n",
            "995/999 [============================>.] - ETA: 0s - loss: 9.3699 - NN_RMSLE: 3.0486\n",
            "Epoch 5: val_loss improved from 11.73409 to 11.44164, saving model to model_103[]\n",
            "INFO:tensorflow:Assets written to: model_103[]/assets\n",
            "999/999 [==============================] - 4s 4ms/step - loss: 9.3626 - NN_RMSLE: 3.0474 - val_loss: 11.4416 - val_NN_RMSLE: 3.3539\n",
            "Epoch 6/100\n",
            "998/999 [============================>.] - ETA: 0s - loss: 9.3575 - NN_RMSLE: 3.0477\n",
            "Epoch 6: val_loss improved from 11.44164 to 11.40447, saving model to model_103[]\n",
            "INFO:tensorflow:Assets written to: model_103[]/assets\n",
            "999/999 [==============================] - 4s 4ms/step - loss: 9.3588 - NN_RMSLE: 3.0479 - val_loss: 11.4045 - val_NN_RMSLE: 3.3486\n",
            "Epoch 7/100\n",
            "985/999 [============================>.] - ETA: 0s - loss: 9.3634 - NN_RMSLE: 3.0482\n",
            "Epoch 7: val_loss improved from 11.40447 to 11.39296, saving model to model_103[]\n",
            "INFO:tensorflow:Assets written to: model_103[]/assets\n",
            "999/999 [==============================] - 4s 4ms/step - loss: 9.3587 - NN_RMSLE: 3.0475 - val_loss: 11.3930 - val_NN_RMSLE: 3.3470\n",
            "Epoch 8/100\n",
            "994/999 [============================>.] - ETA: 0s - loss: 9.3518 - NN_RMSLE: 3.0474\n",
            "Epoch 8: val_loss improved from 11.39296 to 11.29709, saving model to model_103[]\n",
            "INFO:tensorflow:Assets written to: model_103[]/assets\n",
            "999/999 [==============================] - 4s 4ms/step - loss: 9.3582 - NN_RMSLE: 3.0484 - val_loss: 11.2971 - val_NN_RMSLE: 3.3332\n",
            "Epoch 9/100\n",
            "994/999 [============================>.] - ETA: 0s - loss: 9.3639 - NN_RMSLE: 3.0480\n",
            "Epoch 9: val_loss did not improve from 11.29709\n",
            "999/999 [==============================] - 3s 3ms/step - loss: 9.3588 - NN_RMSLE: 3.0472 - val_loss: 11.3608 - val_NN_RMSLE: 3.3424\n",
            "Epoch 10/100\n",
            "983/999 [============================>.] - ETA: 0s - loss: 9.3565 - NN_RMSLE: 3.0481\n",
            "Epoch 10: val_loss did not improve from 11.29709\n",
            "999/999 [==============================] - 3s 3ms/step - loss: 9.3586 - NN_RMSLE: 3.0485 - val_loss: 11.3886 - val_NN_RMSLE: 3.3463\n",
            "Epoch 11/100\n",
            "980/999 [============================>.] - ETA: 0s - loss: 9.3495 - NN_RMSLE: 3.0461\n",
            "Epoch 11: val_loss did not improve from 11.29709\n",
            "999/999 [==============================] - 3s 3ms/step - loss: 9.3585 - NN_RMSLE: 3.0475 - val_loss: 11.3306 - val_NN_RMSLE: 3.3380\n",
            "Model: \"sequential_69\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_276 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_207 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_277 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_208 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_278 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_209 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_279 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  11.33064\n",
            "\n",
            "[5 6 7 8 9]\n",
            "train 63933 valid 31966\n",
            "Model: \"sequential_70\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_280 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_210 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_281 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_211 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_282 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_212 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_283 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "999/999 [==============================] - ETA: 0s - loss: 20.0613 - NN_RMSLE: 4.4619\n",
            "Epoch 1: val_loss improved from inf to 7.69175, saving model to model_103[]\n",
            "INFO:tensorflow:Assets written to: model_103[]/assets\n",
            "999/999 [==============================] - 4s 3ms/step - loss: 20.0613 - NN_RMSLE: 4.4619 - val_loss: 7.6917 - val_NN_RMSLE: 2.6957\n",
            "Epoch 2/100\n",
            "978/999 [============================>.] - ETA: 0s - loss: 15.0989 - NN_RMSLE: 3.8696\n",
            "Epoch 2: val_loss improved from 7.69175 to 7.45793, saving model to model_103[]\n",
            "INFO:tensorflow:Assets written to: model_103[]/assets\n",
            "999/999 [==============================] - 3s 3ms/step - loss: 15.0544 - NN_RMSLE: 3.8638 - val_loss: 7.4579 - val_NN_RMSLE: 2.6804\n",
            "Epoch 3/100\n",
            "986/999 [============================>.] - ETA: 0s - loss: 11.9530 - NN_RMSLE: 3.4450\n",
            "Epoch 3: val_loss did not improve from 7.45793\n",
            "999/999 [==============================] - 3s 3ms/step - loss: 11.9434 - NN_RMSLE: 3.4437 - val_loss: 8.3294 - val_NN_RMSLE: 2.8582\n",
            "Epoch 4/100\n",
            "991/999 [============================>.] - ETA: 0s - loss: 10.2297 - NN_RMSLE: 3.1886\n",
            "Epoch 4: val_loss did not improve from 7.45793\n",
            "999/999 [==============================] - 3s 3ms/step - loss: 10.2231 - NN_RMSLE: 3.1875 - val_loss: 9.7720 - val_NN_RMSLE: 3.1094\n",
            "Epoch 5/100\n",
            "998/999 [============================>.] - ETA: 0s - loss: 9.4572 - NN_RMSLE: 3.0677\n",
            "Epoch 5: val_loss did not improve from 7.45793\n",
            "999/999 [==============================] - 3s 3ms/step - loss: 9.4571 - NN_RMSLE: 3.0677 - val_loss: 11.1979 - val_NN_RMSLE: 3.3340\n",
            "Model: \"sequential_70\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_280 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_210 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_281 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_211 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_282 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_212 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_283 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  11.197943\n",
            "\n",
            "[ 8  9 10 11 12]\n",
            "train 63933 valid 31966\n",
            "Model: \"sequential_71\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_284 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_213 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_285 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_214 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_286 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_215 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_287 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "982/999 [============================>.] - ETA: 0s - loss: 15.2045 - NN_RMSLE: 3.8785\n",
            "Epoch 1: val_loss improved from inf to 15.81056, saving model to model_103[]\n",
            "INFO:tensorflow:Assets written to: model_103[]/assets\n",
            "999/999 [==============================] - 4s 4ms/step - loss: 15.1736 - NN_RMSLE: 3.8745 - val_loss: 15.8106 - val_NN_RMSLE: 3.8771\n",
            "Epoch 2/100\n",
            "993/999 [============================>.] - ETA: 0s - loss: 12.0163 - NN_RMSLE: 3.4482\n",
            "Epoch 2: val_loss improved from 15.81056 to 12.61846, saving model to model_103[]\n",
            "INFO:tensorflow:Assets written to: model_103[]/assets\n",
            "999/999 [==============================] - 4s 4ms/step - loss: 12.0143 - NN_RMSLE: 3.4479 - val_loss: 12.6185 - val_NN_RMSLE: 3.4777\n",
            "Epoch 3/100\n",
            "996/999 [============================>.] - ETA: 0s - loss: 10.4770 - NN_RMSLE: 3.2240\n",
            "Epoch 3: val_loss improved from 12.61846 to 10.92473, saving model to model_103[]\n",
            "INFO:tensorflow:Assets written to: model_103[]/assets\n",
            "999/999 [==============================] - 4s 4ms/step - loss: 10.4772 - NN_RMSLE: 3.2240 - val_loss: 10.9247 - val_NN_RMSLE: 3.2528\n",
            "Epoch 4/100\n",
            "994/999 [============================>.] - ETA: 0s - loss: 9.9003 - NN_RMSLE: 3.1369\n",
            "Epoch 4: val_loss improved from 10.92473 to 10.16495, saving model to model_103[]\n",
            "INFO:tensorflow:Assets written to: model_103[]/assets\n",
            "999/999 [==============================] - 4s 4ms/step - loss: 9.9003 - NN_RMSLE: 3.1369 - val_loss: 10.1649 - val_NN_RMSLE: 3.1490\n",
            "Epoch 5/100\n",
            "975/999 [============================>.] - ETA: 0s - loss: 9.7622 - NN_RMSLE: 3.1167\n",
            "Epoch 5: val_loss improved from 10.16495 to 9.91652, saving model to model_103[]\n",
            "INFO:tensorflow:Assets written to: model_103[]/assets\n",
            "999/999 [==============================] - 3s 3ms/step - loss: 9.7666 - NN_RMSLE: 3.1174 - val_loss: 9.9165 - val_NN_RMSLE: 3.1147\n",
            "Epoch 6/100\n",
            "978/999 [============================>.] - ETA: 0s - loss: 9.7560 - NN_RMSLE: 3.1158\n",
            "Epoch 6: val_loss improved from 9.91652 to 9.85594, saving model to model_103[]\n",
            "INFO:tensorflow:Assets written to: model_103[]/assets\n",
            "999/999 [==============================] - 4s 4ms/step - loss: 9.7511 - NN_RMSLE: 3.1150 - val_loss: 9.8559 - val_NN_RMSLE: 3.1064\n",
            "Epoch 7/100\n",
            "992/999 [============================>.] - ETA: 0s - loss: 9.7575 - NN_RMSLE: 3.1159\n",
            "Epoch 7: val_loss improved from 9.85594 to 9.84991, saving model to model_103[]\n",
            "INFO:tensorflow:Assets written to: model_103[]/assets\n",
            "999/999 [==============================] - 3s 3ms/step - loss: 9.7505 - NN_RMSLE: 3.1148 - val_loss: 9.8499 - val_NN_RMSLE: 3.1055\n",
            "Epoch 8/100\n",
            "998/999 [============================>.] - ETA: 0s - loss: 9.7517 - NN_RMSLE: 3.1149\n",
            "Epoch 8: val_loss improved from 9.84991 to 9.83645, saving model to model_103[]\n",
            "INFO:tensorflow:Assets written to: model_103[]/assets\n",
            "999/999 [==============================] - 3s 3ms/step - loss: 9.7505 - NN_RMSLE: 3.1146 - val_loss: 9.8364 - val_NN_RMSLE: 3.1037\n",
            "Epoch 9/100\n",
            "986/999 [============================>.] - ETA: 0s - loss: 9.7618 - NN_RMSLE: 3.1158\n",
            "Epoch 9: val_loss did not improve from 9.83645\n",
            "999/999 [==============================] - 3s 3ms/step - loss: 9.7505 - NN_RMSLE: 3.1138 - val_loss: 9.8517 - val_NN_RMSLE: 3.1058\n",
            "Epoch 10/100\n",
            "994/999 [============================>.] - ETA: 0s - loss: 9.7475 - NN_RMSLE: 3.1145\n",
            "Epoch 10: val_loss did not improve from 9.83645\n",
            "999/999 [==============================] - 3s 3ms/step - loss: 9.7505 - NN_RMSLE: 3.1149 - val_loss: 9.8381 - val_NN_RMSLE: 3.1039\n",
            "Epoch 11/100\n",
            "994/999 [============================>.] - ETA: 0s - loss: 9.7493 - NN_RMSLE: 3.1150\n",
            "Epoch 11: val_loss did not improve from 9.83645\n",
            "999/999 [==============================] - 3s 3ms/step - loss: 9.7505 - NN_RMSLE: 3.1152 - val_loss: 9.8540 - val_NN_RMSLE: 3.1061\n",
            "Model: \"sequential_71\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_284 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_213 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_285 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_214 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_286 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_215 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_287 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  9.854039\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 110 (43400, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[1 2 3 4 5]\n",
            "train 28933 valid 14467\n",
            "Model: \"sequential_72\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_288 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_216 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_289 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_217 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_290 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_218 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_291 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "440/453 [============================>.] - ETA: 0s - loss: 27.2799 - NN_RMSLE: 5.2208\n",
            "Epoch 1: val_loss improved from inf to 22.88451, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 27.2242 - NN_RMSLE: 5.2151 - val_loss: 22.8845 - val_NN_RMSLE: 4.7791\n",
            "Epoch 2/100\n",
            "436/453 [===========================>..] - ETA: 0s - loss: 22.9799 - NN_RMSLE: 4.7916\n",
            "Epoch 2: val_loss improved from 22.88451 to 19.01598, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 22.9044 - NN_RMSLE: 4.7834 - val_loss: 19.0160 - val_NN_RMSLE: 4.3558\n",
            "Epoch 3/100\n",
            "447/453 [============================>.] - ETA: 0s - loss: 19.1304 - NN_RMSLE: 4.3717\n",
            "Epoch 3: val_loss improved from 19.01598 to 15.63488, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 19.1055 - NN_RMSLE: 4.3691 - val_loss: 15.6349 - val_NN_RMSLE: 3.9488\n",
            "Epoch 4/100\n",
            "449/453 [============================>.] - ETA: 0s - loss: 15.7871 - NN_RMSLE: 3.9710\n",
            "Epoch 4: val_loss improved from 15.63488 to 12.69384, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 15.7752 - NN_RMSLE: 3.9684 - val_loss: 12.6938 - val_NN_RMSLE: 3.5572\n",
            "Epoch 5/100\n",
            "451/453 [============================>.] - ETA: 0s - loss: 12.8739 - NN_RMSLE: 3.5856\n",
            "Epoch 5: val_loss improved from 12.69384 to 10.15337, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 12.8717 - NN_RMSLE: 3.5849 - val_loss: 10.1534 - val_NN_RMSLE: 3.1804\n",
            "Epoch 6/100\n",
            "447/453 [============================>.] - ETA: 0s - loss: 10.3692 - NN_RMSLE: 3.2175\n",
            "Epoch 6: val_loss improved from 10.15337 to 7.97995, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 10.3563 - NN_RMSLE: 3.2147 - val_loss: 7.9799 - val_NN_RMSLE: 2.8184\n",
            "Epoch 7/100\n",
            "446/453 [============================>.] - ETA: 0s - loss: 8.2159 - NN_RMSLE: 2.8637\n",
            "Epoch 7: val_loss improved from 7.97995 to 6.14381, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 8.1991 - NN_RMSLE: 2.8596 - val_loss: 6.1438 - val_NN_RMSLE: 2.4716\n",
            "Epoch 8/100\n",
            "431/453 [===========================>..] - ETA: 0s - loss: 6.4077 - NN_RMSLE: 2.5287\n",
            "Epoch 8: val_loss improved from 6.14381 to 4.61961, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 5ms/step - loss: 6.3722 - NN_RMSLE: 2.5216 - val_loss: 4.6196 - val_NN_RMSLE: 2.1415\n",
            "Epoch 9/100\n",
            "450/453 [============================>.] - ETA: 0s - loss: 4.8543 - NN_RMSLE: 2.2000\n",
            "Epoch 9: val_loss improved from 4.61961 to 3.38165, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 5ms/step - loss: 4.8499 - NN_RMSLE: 2.1989 - val_loss: 3.3816 - val_NN_RMSLE: 1.8302\n",
            "Epoch 10/100\n",
            "435/453 [===========================>..] - ETA: 0s - loss: 3.6284 - NN_RMSLE: 1.9014\n",
            "Epoch 10: val_loss improved from 3.38165 to 2.40638, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 3.6088 - NN_RMSLE: 1.8954 - val_loss: 2.4064 - val_NN_RMSLE: 1.5415\n",
            "Epoch 11/100\n",
            "438/453 [============================>.] - ETA: 0s - loss: 2.6379 - NN_RMSLE: 1.6207\n",
            "Epoch 11: val_loss improved from 2.40638 to 1.66670, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 2.6246 - NN_RMSLE: 1.6165 - val_loss: 1.6667 - val_NN_RMSLE: 1.2802\n",
            "Epoch 12/100\n",
            "438/453 [============================>.] - ETA: 0s - loss: 1.8815 - NN_RMSLE: 1.3685\n",
            "Epoch 12: val_loss improved from 1.66670 to 1.13520, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 5ms/step - loss: 1.8709 - NN_RMSLE: 1.3642 - val_loss: 1.1352 - val_NN_RMSLE: 1.0537\n",
            "Epoch 13/100\n",
            "443/453 [============================>.] - ETA: 0s - loss: 1.3247 - NN_RMSLE: 1.1483\n",
            "Epoch 13: val_loss improved from 1.13520 to 0.78120, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 5ms/step - loss: 1.3200 - NN_RMSLE: 1.1455 - val_loss: 0.7812 - val_NN_RMSLE: 0.8724\n",
            "Epoch 14/100\n",
            "443/453 [============================>.] - ETA: 0s - loss: 0.9444 - NN_RMSLE: 0.9695\n",
            "Epoch 14: val_loss improved from 0.78120 to 0.57089, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 0.9414 - NN_RMSLE: 0.9682 - val_loss: 0.5709 - val_NN_RMSLE: 0.7473\n",
            "Epoch 15/100\n",
            "448/453 [============================>.] - ETA: 0s - loss: 0.7025 - NN_RMSLE: 0.8365\n",
            "Epoch 15: val_loss improved from 0.57089 to 0.46758, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 0.7016 - NN_RMSLE: 0.8362 - val_loss: 0.4676 - val_NN_RMSLE: 0.6796\n",
            "Epoch 16/100\n",
            "435/453 [===========================>..] - ETA: 0s - loss: 0.5674 - NN_RMSLE: 0.7521\n",
            "Epoch 16: val_loss improved from 0.46758 to 0.43438, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 0.5654 - NN_RMSLE: 0.7508 - val_loss: 0.4344 - val_NN_RMSLE: 0.6573\n",
            "Epoch 17/100\n",
            "446/453 [============================>.] - ETA: 0s - loss: 0.4986 - NN_RMSLE: 0.7051\n",
            "Epoch 17: val_loss did not improve from 0.43438\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.4985 - NN_RMSLE: 0.7048 - val_loss: 0.4380 - val_NN_RMSLE: 0.6608\n",
            "Epoch 18/100\n",
            "446/453 [============================>.] - ETA: 0s - loss: 0.4714 - NN_RMSLE: 0.6853\n",
            "Epoch 18: val_loss did not improve from 0.43438\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.4715 - NN_RMSLE: 0.6857 - val_loss: 0.4536 - val_NN_RMSLE: 0.6724\n",
            "Epoch 19/100\n",
            "447/453 [============================>.] - ETA: 0s - loss: 0.4629 - NN_RMSLE: 0.6790\n",
            "Epoch 19: val_loss did not improve from 0.43438\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.4631 - NN_RMSLE: 0.6789 - val_loss: 0.4662 - val_NN_RMSLE: 0.6815\n",
            "Model: \"sequential_72\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_288 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_216 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_289 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_217 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_290 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_218 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_291 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  0.46621373\n",
            "\n",
            "[4 5 6 7 8 9]\n",
            "train 28933 valid 14467\n",
            "Model: \"sequential_73\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_292 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_219 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_293 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_220 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_294 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_221 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_295 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "428/453 [===========================>..] - ETA: 0s - loss: 25.6535 - NN_RMSLE: 5.0629\n",
            "Epoch 1: val_loss improved from inf to 26.11936, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 25.5355 - NN_RMSLE: 5.0507 - val_loss: 26.1194 - val_NN_RMSLE: 5.1079\n",
            "Epoch 2/100\n",
            "432/453 [===========================>..] - ETA: 0s - loss: 21.4543 - NN_RMSLE: 4.6296\n",
            "Epoch 2: val_loss improved from 26.11936 to 21.97824, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 21.3644 - NN_RMSLE: 4.6202 - val_loss: 21.9782 - val_NN_RMSLE: 4.6848\n",
            "Epoch 3/100\n",
            "452/453 [============================>.] - ETA: 0s - loss: 17.7130 - NN_RMSLE: 4.2062\n",
            "Epoch 3: val_loss improved from 21.97824 to 18.33790, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 17.7129 - NN_RMSLE: 4.2060 - val_loss: 18.3379 - val_NN_RMSLE: 4.2786\n",
            "Epoch 4/100\n",
            "447/453 [============================>.] - ETA: 0s - loss: 14.5414 - NN_RMSLE: 3.8111\n",
            "Epoch 4: val_loss improved from 18.33790 to 15.14739, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 5ms/step - loss: 14.5272 - NN_RMSLE: 3.8087 - val_loss: 15.1474 - val_NN_RMSLE: 3.8877\n",
            "Epoch 5/100\n",
            "439/453 [============================>.] - ETA: 0s - loss: 11.8084 - NN_RMSLE: 3.4337\n",
            "Epoch 5: val_loss improved from 15.14739 to 12.36883, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 11.7645 - NN_RMSLE: 3.4265 - val_loss: 12.3688 - val_NN_RMSLE: 3.5121\n",
            "Epoch 6/100\n",
            "446/453 [============================>.] - ETA: 0s - loss: 9.4012 - NN_RMSLE: 3.0633\n",
            "Epoch 6: val_loss improved from 12.36883 to 9.96642, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 9.3869 - NN_RMSLE: 3.0613 - val_loss: 9.9664 - val_NN_RMSLE: 3.1514\n",
            "Epoch 7/100\n",
            "448/453 [============================>.] - ETA: 0s - loss: 7.3709 - NN_RMSLE: 2.7120\n",
            "Epoch 7: val_loss improved from 9.96642 to 7.90925, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 7.3613 - NN_RMSLE: 2.7097 - val_loss: 7.9093 - val_NN_RMSLE: 2.8060\n",
            "Epoch 8/100\n",
            "433/453 [===========================>..] - ETA: 0s - loss: 5.6903 - NN_RMSLE: 2.3825\n",
            "Epoch 8: val_loss improved from 7.90925 to 6.17134, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 5.6609 - NN_RMSLE: 2.3757 - val_loss: 6.1713 - val_NN_RMSLE: 2.4769\n",
            "Epoch 9/100\n",
            "444/453 [============================>.] - ETA: 0s - loss: 4.2683 - NN_RMSLE: 2.0630\n",
            "Epoch 9: val_loss improved from 6.17134 to 4.72833, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 4.2586 - NN_RMSLE: 2.0600 - val_loss: 4.7283 - val_NN_RMSLE: 2.1660\n",
            "Epoch 10/100\n",
            "433/453 [===========================>..] - ETA: 0s - loss: 3.1524 - NN_RMSLE: 1.7725\n",
            "Epoch 10: val_loss improved from 4.72833 to 3.55574, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 3.1298 - NN_RMSLE: 1.7660 - val_loss: 3.5557 - val_NN_RMSLE: 1.8759\n",
            "Epoch 11/100\n",
            "437/453 [===========================>..] - ETA: 0s - loss: 2.2578 - NN_RMSLE: 1.4992\n",
            "Epoch 11: val_loss improved from 3.55574 to 2.62917, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 2.2483 - NN_RMSLE: 1.4955 - val_loss: 2.6292 - val_NN_RMSLE: 1.6103\n",
            "Epoch 12/100\n",
            "445/453 [============================>.] - ETA: 0s - loss: 1.5909 - NN_RMSLE: 1.2578\n",
            "Epoch 12: val_loss improved from 2.62917 to 1.92137, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 1.5877 - NN_RMSLE: 1.2564 - val_loss: 1.9214 - val_NN_RMSLE: 1.3737\n",
            "Epoch 13/100\n",
            "439/453 [============================>.] - ETA: 0s - loss: 1.1217 - NN_RMSLE: 1.0563\n",
            "Epoch 13: val_loss improved from 1.92137 to 1.40216, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 5ms/step - loss: 1.1170 - NN_RMSLE: 1.0537 - val_loss: 1.4022 - val_NN_RMSLE: 1.1708\n",
            "Epoch 14/100\n",
            "453/453 [==============================] - ETA: 0s - loss: 0.8045 - NN_RMSLE: 0.8941\n",
            "Epoch 14: val_loss improved from 1.40216 to 1.04228, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 0.8045 - NN_RMSLE: 0.8941 - val_loss: 1.0423 - val_NN_RMSLE: 1.0076\n",
            "Epoch 15/100\n",
            "438/453 [============================>.] - ETA: 0s - loss: 0.6173 - NN_RMSLE: 0.7840\n",
            "Epoch 15: val_loss improved from 1.04228 to 0.80799, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 0.6155 - NN_RMSLE: 0.7829 - val_loss: 0.8080 - val_NN_RMSLE: 0.8866\n",
            "Epoch 16/100\n",
            "440/453 [============================>.] - ETA: 0s - loss: 0.5147 - NN_RMSLE: 0.7162\n",
            "Epoch 16: val_loss improved from 0.80799 to 0.66629, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 0.5147 - NN_RMSLE: 0.7158 - val_loss: 0.6663 - val_NN_RMSLE: 0.8056\n",
            "Epoch 17/100\n",
            "448/453 [============================>.] - ETA: 0s - loss: 0.4689 - NN_RMSLE: 0.6838\n",
            "Epoch 17: val_loss improved from 0.66629 to 0.58686, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 0.4689 - NN_RMSLE: 0.6841 - val_loss: 0.5869 - val_NN_RMSLE: 0.7569\n",
            "Epoch 18/100\n",
            "452/453 [============================>.] - ETA: 0s - loss: 0.4522 - NN_RMSLE: 0.6713\n",
            "Epoch 18: val_loss improved from 0.58686 to 0.54594, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 5ms/step - loss: 0.4521 - NN_RMSLE: 0.6705 - val_loss: 0.5459 - val_NN_RMSLE: 0.7308\n",
            "Epoch 19/100\n",
            "442/453 [============================>.] - ETA: 0s - loss: 0.4471 - NN_RMSLE: 0.6674\n",
            "Epoch 19: val_loss improved from 0.54594 to 0.52828, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 0.4476 - NN_RMSLE: 0.6670 - val_loss: 0.5283 - val_NN_RMSLE: 0.7193\n",
            "Epoch 20/100\n",
            "451/453 [============================>.] - ETA: 0s - loss: 0.4469 - NN_RMSLE: 0.6672\n",
            "Epoch 20: val_loss improved from 0.52828 to 0.51950, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 0.4467 - NN_RMSLE: 0.6673 - val_loss: 0.5195 - val_NN_RMSLE: 0.7135\n",
            "Epoch 21/100\n",
            "445/453 [============================>.] - ETA: 0s - loss: 0.4460 - NN_RMSLE: 0.6663\n",
            "Epoch 21: val_loss improved from 0.51950 to 0.51771, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 0.4466 - NN_RMSLE: 0.6663 - val_loss: 0.5177 - val_NN_RMSLE: 0.7123\n",
            "Epoch 22/100\n",
            "438/453 [============================>.] - ETA: 0s - loss: 0.4459 - NN_RMSLE: 0.6664\n",
            "Epoch 22: val_loss did not improve from 0.51771\n",
            "453/453 [==============================] - 2s 3ms/step - loss: 0.4466 - NN_RMSLE: 0.6669 - val_loss: 0.5179 - val_NN_RMSLE: 0.7124\n",
            "Epoch 23/100\n",
            "452/453 [============================>.] - ETA: 0s - loss: 0.4466 - NN_RMSLE: 0.6668\n",
            "Epoch 23: val_loss did not improve from 0.51771\n",
            "453/453 [==============================] - 2s 3ms/step - loss: 0.4466 - NN_RMSLE: 0.6669 - val_loss: 0.5185 - val_NN_RMSLE: 0.7128\n",
            "Epoch 24/100\n",
            "451/453 [============================>.] - ETA: 0s - loss: 0.4467 - NN_RMSLE: 0.6667\n",
            "Epoch 24: val_loss improved from 0.51771 to 0.51677, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 5ms/step - loss: 0.4466 - NN_RMSLE: 0.6671 - val_loss: 0.5168 - val_NN_RMSLE: 0.7116\n",
            "Epoch 25/100\n",
            "452/453 [============================>.] - ETA: 0s - loss: 0.4466 - NN_RMSLE: 0.6669\n",
            "Epoch 25: val_loss did not improve from 0.51677\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 0.4466 - NN_RMSLE: 0.6673 - val_loss: 0.5201 - val_NN_RMSLE: 0.7139\n",
            "Epoch 26/100\n",
            "442/453 [============================>.] - ETA: 0s - loss: 0.4462 - NN_RMSLE: 0.6666\n",
            "Epoch 26: val_loss improved from 0.51677 to 0.51234, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 0.4466 - NN_RMSLE: 0.6672 - val_loss: 0.5123 - val_NN_RMSLE: 0.7087\n",
            "Epoch 27/100\n",
            "444/453 [============================>.] - ETA: 0s - loss: 0.4458 - NN_RMSLE: 0.6661\n",
            "Epoch 27: val_loss did not improve from 0.51234\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 0.4466 - NN_RMSLE: 0.6660 - val_loss: 0.5218 - val_NN_RMSLE: 0.7150\n",
            "Epoch 28/100\n",
            "451/453 [============================>.] - ETA: 0s - loss: 0.4465 - NN_RMSLE: 0.6667\n",
            "Epoch 28: val_loss did not improve from 0.51234\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.4466 - NN_RMSLE: 0.6674 - val_loss: 0.5155 - val_NN_RMSLE: 0.7108\n",
            "Epoch 29/100\n",
            "442/453 [============================>.] - ETA: 0s - loss: 0.4466 - NN_RMSLE: 0.6669\n",
            "Epoch 29: val_loss did not improve from 0.51234\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.4466 - NN_RMSLE: 0.6673 - val_loss: 0.5132 - val_NN_RMSLE: 0.7093\n",
            "Model: \"sequential_73\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_292 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_219 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_293 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_220 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_294 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_221 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_295 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  0.51324326\n",
            "\n",
            "[ 9 10 11 12]\n",
            "train 28934 valid 14466\n",
            "Model: \"sequential_74\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_296 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_222 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_297 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_223 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_298 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_224 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_299 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "434/453 [===========================>..] - ETA: 0s - loss: 26.8305 - NN_RMSLE: 5.1777\n",
            "Epoch 1: val_loss improved from inf to 23.81063, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 5ms/step - loss: 26.7394 - NN_RMSLE: 5.1684 - val_loss: 23.8106 - val_NN_RMSLE: 4.8743\n",
            "Epoch 2/100\n",
            "439/453 [============================>.] - ETA: 0s - loss: 22.5248 - NN_RMSLE: 4.7439\n",
            "Epoch 2: val_loss improved from 23.81063 to 19.86458, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 22.4624 - NN_RMSLE: 4.7363 - val_loss: 19.8646 - val_NN_RMSLE: 4.4512\n",
            "Epoch 3/100\n",
            "451/453 [============================>.] - ETA: 0s - loss: 18.7110 - NN_RMSLE: 4.3234\n",
            "Epoch 3: val_loss improved from 19.86458 to 16.40876, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 18.7063 - NN_RMSLE: 4.3223 - val_loss: 16.4088 - val_NN_RMSLE: 4.0444\n",
            "Epoch 4/100\n",
            "440/453 [============================>.] - ETA: 0s - loss: 15.4573 - NN_RMSLE: 3.9294\n",
            "Epoch 4: val_loss improved from 16.40876 to 13.39601, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 15.4179 - NN_RMSLE: 3.9239 - val_loss: 13.3960 - val_NN_RMSLE: 3.6530\n",
            "Epoch 5/100\n",
            "437/453 [===========================>..] - ETA: 0s - loss: 12.5902 - NN_RMSLE: 3.5461\n",
            "Epoch 5: val_loss improved from 13.39601 to 10.78613, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 12.5537 - NN_RMSLE: 3.5395 - val_loss: 10.7861 - val_NN_RMSLE: 3.2764\n",
            "Epoch 6/100\n",
            "446/453 [============================>.] - ETA: 0s - loss: 10.0894 - NN_RMSLE: 3.1739\n",
            "Epoch 6: val_loss improved from 10.78613 to 8.54695, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 10.0783 - NN_RMSLE: 3.1704 - val_loss: 8.5470 - val_NN_RMSLE: 2.9148\n",
            "Epoch 7/100\n",
            "433/453 [===========================>..] - ETA: 0s - loss: 8.0001 - NN_RMSLE: 2.8261\n",
            "Epoch 7: val_loss improved from 8.54695 to 6.64640, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 7.9593 - NN_RMSLE: 2.8190 - val_loss: 6.6464 - val_NN_RMSLE: 2.5683\n",
            "Epoch 8/100\n",
            "431/453 [===========================>..] - ETA: 0s - loss: 6.2109 - NN_RMSLE: 2.4894\n",
            "Epoch 8: val_loss improved from 6.64640 to 5.05982, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 6.1679 - NN_RMSLE: 2.4798 - val_loss: 5.0598 - val_NN_RMSLE: 2.2383\n",
            "Epoch 9/100\n",
            "439/453 [============================>.] - ETA: 0s - loss: 4.6979 - NN_RMSLE: 2.1649\n",
            "Epoch 9: val_loss improved from 5.05982 to 3.76200, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 4.6803 - NN_RMSLE: 2.1605 - val_loss: 3.7620 - val_NN_RMSLE: 1.9270\n",
            "Epoch 10/100\n",
            "437/453 [===========================>..] - ETA: 0s - loss: 3.4886 - NN_RMSLE: 1.8646\n",
            "Epoch 10: val_loss improved from 3.76200 to 2.72938, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 3.4717 - NN_RMSLE: 1.8593 - val_loss: 2.7294 - val_NN_RMSLE: 1.6378\n",
            "Epoch 11/100\n",
            "437/453 [===========================>..] - ETA: 0s - loss: 2.5319 - NN_RMSLE: 1.5880\n",
            "Epoch 11: val_loss improved from 2.72938 to 1.93516, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 2.5178 - NN_RMSLE: 1.5815 - val_loss: 1.9352 - val_NN_RMSLE: 1.3751\n",
            "Epoch 12/100\n",
            "431/453 [===========================>..] - ETA: 0s - loss: 1.8056 - NN_RMSLE: 1.3406\n",
            "Epoch 12: val_loss improved from 1.93516 to 1.35219, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 1.7921 - NN_RMSLE: 1.3347 - val_loss: 1.3522 - val_NN_RMSLE: 1.1456\n",
            "Epoch 13/100\n",
            "443/453 [============================>.] - ETA: 0s - loss: 1.2692 - NN_RMSLE: 1.1237\n",
            "Epoch 13: val_loss improved from 1.35219 to 0.94919, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 5ms/step - loss: 1.2651 - NN_RMSLE: 1.1216 - val_loss: 0.9492 - val_NN_RMSLE: 0.9570\n",
            "Epoch 14/100\n",
            "441/453 [============================>.] - ETA: 0s - loss: 0.9106 - NN_RMSLE: 0.9520\n",
            "Epoch 14: val_loss improved from 0.94919 to 0.69332, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 0.9060 - NN_RMSLE: 0.9489 - val_loss: 0.6933 - val_NN_RMSLE: 0.8177\n",
            "Epoch 15/100\n",
            "426/453 [===========================>..] - ETA: 0s - loss: 0.6860 - NN_RMSLE: 0.8266\n",
            "Epoch 15: val_loss improved from 0.69332 to 0.55005, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 0.6813 - NN_RMSLE: 0.8233 - val_loss: 0.5500 - val_NN_RMSLE: 0.7306\n",
            "Epoch 16/100\n",
            "448/453 [============================>.] - ETA: 0s - loss: 0.5562 - NN_RMSLE: 0.7445\n",
            "Epoch 16: val_loss improved from 0.55005 to 0.48242, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 0.5557 - NN_RMSLE: 0.7441 - val_loss: 0.4824 - val_NN_RMSLE: 0.6871\n",
            "Epoch 17/100\n",
            "446/453 [============================>.] - ETA: 0s - loss: 0.4954 - NN_RMSLE: 0.7027\n",
            "Epoch 17: val_loss improved from 0.48242 to 0.45932, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 0.4954 - NN_RMSLE: 0.7030 - val_loss: 0.4593 - val_NN_RMSLE: 0.6722\n",
            "Epoch 18/100\n",
            "435/453 [===========================>..] - ETA: 0s - loss: 0.4717 - NN_RMSLE: 0.6857\n",
            "Epoch 18: val_loss improved from 0.45932 to 0.45580, saving model to model_110[]\n",
            "INFO:tensorflow:Assets written to: model_110[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 0.4718 - NN_RMSLE: 0.6858 - val_loss: 0.4558 - val_NN_RMSLE: 0.6704\n",
            "Epoch 19/100\n",
            "441/453 [============================>.] - ETA: 0s - loss: 0.4647 - NN_RMSLE: 0.6802\n",
            "Epoch 19: val_loss did not improve from 0.45580\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.4646 - NN_RMSLE: 0.6798 - val_loss: 0.4576 - val_NN_RMSLE: 0.6720\n",
            "Epoch 20/100\n",
            "435/453 [===========================>..] - ETA: 0s - loss: 0.4619 - NN_RMSLE: 0.6781\n",
            "Epoch 20: val_loss did not improve from 0.45580\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 0.4629 - NN_RMSLE: 0.6789 - val_loss: 0.4595 - val_NN_RMSLE: 0.6734\n",
            "Epoch 21/100\n",
            "442/453 [============================>.] - ETA: 0s - loss: 0.4631 - NN_RMSLE: 0.6791\n",
            "Epoch 21: val_loss did not improve from 0.45580\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 0.4626 - NN_RMSLE: 0.6787 - val_loss: 0.4602 - val_NN_RMSLE: 0.6739\n",
            "Model: \"sequential_74\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_296 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_222 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_297 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_223 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_298 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_224 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_299 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  0.46022594\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 111 (32656, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[1 2 3 4 5]\n",
            "train 21770 valid 10886\n",
            "Model: \"sequential_75\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_300 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_225 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_301 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_226 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_302 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_227 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_303 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "330/341 [============================>.] - ETA: 0s - loss: 12.0617 - NN_RMSLE: 3.4637\n",
            "Epoch 1: val_loss improved from inf to 0.10652, saving model to model_111[]\n",
            "INFO:tensorflow:Assets written to: model_111[]/assets\n",
            "341/341 [==============================] - 2s 5ms/step - loss: 12.0402 - NN_RMSLE: 3.4596 - val_loss: 0.1065 - val_NN_RMSLE: 0.3264\n",
            "Epoch 2/100\n",
            "338/341 [============================>.] - ETA: 0s - loss: 10.7086 - NN_RMSLE: 3.2638\n",
            "Epoch 2: val_loss did not improve from 0.10652\n",
            "341/341 [==============================] - 1s 4ms/step - loss: 10.7024 - NN_RMSLE: 3.2595 - val_loss: 0.3986 - val_NN_RMSLE: 0.6313\n",
            "Epoch 3/100\n",
            "340/341 [============================>.] - ETA: 0s - loss: 9.6398 - NN_RMSLE: 3.0962\n",
            "Epoch 3: val_loss did not improve from 0.10652\n",
            "341/341 [==============================] - 2s 6ms/step - loss: 9.6402 - NN_RMSLE: 3.0966 - val_loss: 0.8327 - val_NN_RMSLE: 0.9125\n",
            "Epoch 4/100\n",
            "332/341 [============================>.] - ETA: 0s - loss: 8.8021 - NN_RMSLE: 2.9599\n",
            "Epoch 4: val_loss did not improve from 0.10652\n",
            "341/341 [==============================] - 2s 6ms/step - loss: 8.8107 - NN_RMSLE: 2.9627 - val_loss: 1.3735 - val_NN_RMSLE: 1.1719\n",
            "Model: \"sequential_75\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_300 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_225 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_301 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_226 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_302 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_227 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_303 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.3734605\n",
            "\n",
            "[4 5 6 7 8 9]\n",
            "train 21771 valid 10885\n",
            "Model: \"sequential_76\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_304 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_228 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_305 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_229 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_306 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_230 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_307 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "338/341 [============================>.] - ETA: 0s - loss: 3.2619 - NN_RMSLE: 1.7784\n",
            "Epoch 1: val_loss improved from inf to 16.75882, saving model to model_111[]\n",
            "INFO:tensorflow:Assets written to: model_111[]/assets\n",
            "341/341 [==============================] - 3s 7ms/step - loss: 3.2601 - NN_RMSLE: 1.7799 - val_loss: 16.7588 - val_NN_RMSLE: 3.6107\n",
            "Epoch 2/100\n",
            "332/341 [============================>.] - ETA: 0s - loss: 3.0555 - NN_RMSLE: 1.7241\n",
            "Epoch 2: val_loss improved from 16.75882 to 15.53946, saving model to model_111[]\n",
            "INFO:tensorflow:Assets written to: model_111[]/assets\n",
            "341/341 [==============================] - 2s 7ms/step - loss: 3.0555 - NN_RMSLE: 1.7259 - val_loss: 15.5395 - val_NN_RMSLE: 3.5192\n",
            "Epoch 3/100\n",
            "333/341 [============================>.] - ETA: 0s - loss: 2.9872 - NN_RMSLE: 1.7079\n",
            "Epoch 3: val_loss improved from 15.53946 to 14.89176, saving model to model_111[]\n",
            "INFO:tensorflow:Assets written to: model_111[]/assets\n",
            "341/341 [==============================] - 2s 6ms/step - loss: 2.9876 - NN_RMSLE: 1.7088 - val_loss: 14.8918 - val_NN_RMSLE: 3.4690\n",
            "Epoch 4/100\n",
            "341/341 [==============================] - ETA: 0s - loss: 2.9704 - NN_RMSLE: 1.7047\n",
            "Epoch 4: val_loss improved from 14.89176 to 14.58816, saving model to model_111[]\n",
            "INFO:tensorflow:Assets written to: model_111[]/assets\n",
            "341/341 [==============================] - 2s 5ms/step - loss: 2.9704 - NN_RMSLE: 1.7047 - val_loss: 14.5882 - val_NN_RMSLE: 3.4450\n",
            "Epoch 5/100\n",
            "322/341 [===========================>..] - ETA: 0s - loss: 2.9568 - NN_RMSLE: 1.7042\n",
            "Epoch 5: val_loss improved from 14.58816 to 14.44301, saving model to model_111[]\n",
            "INFO:tensorflow:Assets written to: model_111[]/assets\n",
            "341/341 [==============================] - 1s 4ms/step - loss: 2.9669 - NN_RMSLE: 1.7063 - val_loss: 14.4430 - val_NN_RMSLE: 3.4334\n",
            "Epoch 6/100\n",
            "335/341 [============================>.] - ETA: 0s - loss: 2.9674 - NN_RMSLE: 1.7044\n",
            "Epoch 6: val_loss improved from 14.44301 to 14.35599, saving model to model_111[]\n",
            "INFO:tensorflow:Assets written to: model_111[]/assets\n",
            "341/341 [==============================] - 2s 4ms/step - loss: 2.9663 - NN_RMSLE: 1.7035 - val_loss: 14.3560 - val_NN_RMSLE: 3.4264\n",
            "Epoch 7/100\n",
            "335/341 [============================>.] - ETA: 0s - loss: 2.9563 - NN_RMSLE: 1.7009\n",
            "Epoch 7: val_loss did not improve from 14.35599\n",
            "341/341 [==============================] - 1s 3ms/step - loss: 2.9664 - NN_RMSLE: 1.7044 - val_loss: 14.3735 - val_NN_RMSLE: 3.4278\n",
            "Epoch 8/100\n",
            "328/341 [===========================>..] - ETA: 0s - loss: 2.9639 - NN_RMSLE: 1.7058\n",
            "Epoch 8: val_loss improved from 14.35599 to 14.32774, saving model to model_111[]\n",
            "INFO:tensorflow:Assets written to: model_111[]/assets\n",
            "341/341 [==============================] - 2s 5ms/step - loss: 2.9663 - NN_RMSLE: 1.7060 - val_loss: 14.3277 - val_NN_RMSLE: 3.4241\n",
            "Epoch 9/100\n",
            "338/341 [============================>.] - ETA: 0s - loss: 2.9689 - NN_RMSLE: 1.7038\n",
            "Epoch 9: val_loss did not improve from 14.32774\n",
            "341/341 [==============================] - 1s 4ms/step - loss: 2.9664 - NN_RMSLE: 1.7006 - val_loss: 14.3282 - val_NN_RMSLE: 3.4242\n",
            "Epoch 10/100\n",
            "329/341 [===========================>..] - ETA: 0s - loss: 2.9746 - NN_RMSLE: 1.7056\n",
            "Epoch 10: val_loss did not improve from 14.32774\n",
            "341/341 [==============================] - 1s 3ms/step - loss: 2.9664 - NN_RMSLE: 1.7030 - val_loss: 14.3491 - val_NN_RMSLE: 3.4258\n",
            "Epoch 11/100\n",
            "326/341 [===========================>..] - ETA: 0s - loss: 2.9780 - NN_RMSLE: 1.7112\n",
            "Epoch 11: val_loss did not improve from 14.32774\n",
            "341/341 [==============================] - 1s 3ms/step - loss: 2.9664 - NN_RMSLE: 1.7108 - val_loss: 14.3429 - val_NN_RMSLE: 3.4254\n",
            "Model: \"sequential_76\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_304 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_228 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_305 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_229 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_306 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_230 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_307 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  14.342952\n",
            "\n",
            "[ 8  9 10 11 12]\n",
            "train 21771 valid 10885\n",
            "Model: \"sequential_77\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_308 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_231 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_309 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_232 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_310 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_233 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_311 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "338/341 [============================>.] - ETA: 0s - loss: 8.8266 - NN_RMSLE: 2.9559\n",
            "Epoch 1: val_loss improved from inf to 6.10061, saving model to model_111[]\n",
            "INFO:tensorflow:Assets written to: model_111[]/assets\n",
            "341/341 [==============================] - 2s 5ms/step - loss: 8.8223 - NN_RMSLE: 2.9525 - val_loss: 6.1006 - val_NN_RMSLE: 1.6233\n",
            "Epoch 2/100\n",
            "317/341 [==========================>...] - ETA: 0s - loss: 7.9955 - NN_RMSLE: 2.8155\n",
            "Epoch 2: val_loss improved from 6.10061 to 5.57522, saving model to model_111[]\n",
            "INFO:tensorflow:Assets written to: model_111[]/assets\n",
            "341/341 [==============================] - 1s 4ms/step - loss: 7.9515 - NN_RMSLE: 2.8039 - val_loss: 5.5752 - val_NN_RMSLE: 1.7243\n",
            "Epoch 3/100\n",
            "324/341 [===========================>..] - ETA: 0s - loss: 7.3620 - NN_RMSLE: 2.7028\n",
            "Epoch 3: val_loss improved from 5.57522 to 5.24718, saving model to model_111[]\n",
            "INFO:tensorflow:Assets written to: model_111[]/assets\n",
            "341/341 [==============================] - 1s 4ms/step - loss: 7.3332 - NN_RMSLE: 2.6982 - val_loss: 5.2472 - val_NN_RMSLE: 1.8164\n",
            "Epoch 4/100\n",
            "325/341 [===========================>..] - ETA: 0s - loss: 6.8895 - NN_RMSLE: 2.6146\n",
            "Epoch 4: val_loss improved from 5.24718 to 5.06687, saving model to model_111[]\n",
            "INFO:tensorflow:Assets written to: model_111[]/assets\n",
            "341/341 [==============================] - 2s 5ms/step - loss: 6.9085 - NN_RMSLE: 2.6186 - val_loss: 5.0669 - val_NN_RMSLE: 1.8983\n",
            "Epoch 5/100\n",
            "316/341 [==========================>...] - ETA: 0s - loss: 6.6488 - NN_RMSLE: 2.5703\n",
            "Epoch 5: val_loss improved from 5.06687 to 4.98996, saving model to model_111[]\n",
            "INFO:tensorflow:Assets written to: model_111[]/assets\n",
            "341/341 [==============================] - 1s 4ms/step - loss: 6.6361 - NN_RMSLE: 2.5679 - val_loss: 4.9900 - val_NN_RMSLE: 1.9689\n",
            "Epoch 6/100\n",
            "328/341 [===========================>..] - ETA: 0s - loss: 6.4671 - NN_RMSLE: 2.5350\n",
            "Epoch 6: val_loss improved from 4.98996 to 4.97779, saving model to model_111[]\n",
            "INFO:tensorflow:Assets written to: model_111[]/assets\n",
            "341/341 [==============================] - 1s 4ms/step - loss: 6.4738 - NN_RMSLE: 2.5371 - val_loss: 4.9778 - val_NN_RMSLE: 2.0266\n",
            "Epoch 7/100\n",
            "318/341 [==========================>...] - ETA: 0s - loss: 6.4057 - NN_RMSLE: 2.5249\n",
            "Epoch 7: val_loss did not improve from 4.97779\n",
            "341/341 [==============================] - 1s 3ms/step - loss: 6.3847 - NN_RMSLE: 2.5223 - val_loss: 4.9989 - val_NN_RMSLE: 2.0723\n",
            "Epoch 8/100\n",
            "332/341 [============================>.] - ETA: 0s - loss: 6.3384 - NN_RMSLE: 2.5130\n",
            "Epoch 8: val_loss did not improve from 4.97779\n",
            "341/341 [==============================] - 1s 3ms/step - loss: 6.3409 - NN_RMSLE: 2.5129 - val_loss: 5.0296 - val_NN_RMSLE: 2.1046\n",
            "Epoch 9/100\n",
            "321/341 [===========================>..] - ETA: 0s - loss: 6.3245 - NN_RMSLE: 2.5102\n",
            "Epoch 9: val_loss did not improve from 4.97779\n",
            "341/341 [==============================] - 1s 3ms/step - loss: 6.3219 - NN_RMSLE: 2.5098 - val_loss: 5.0589 - val_NN_RMSLE: 2.1275\n",
            "Model: \"sequential_77\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_308 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_231 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_309 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_232 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_310 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_233 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_311 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  5.058918\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 113 (43403, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[1 2 3 4 5]\n",
            "train 28935 valid 14468\n",
            "Model: \"sequential_78\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_312 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_234 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_313 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_235 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_314 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_236 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_315 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "438/453 [============================>.] - ETA: 0s - loss: 10.4125 - NN_RMSLE: 3.2195\n",
            "Epoch 1: val_loss improved from inf to 21.98124, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 10.4004 - NN_RMSLE: 3.2142 - val_loss: 21.9812 - val_NN_RMSLE: 4.6482\n",
            "Epoch 2/100\n",
            "442/453 [============================>.] - ETA: 0s - loss: 8.5203 - NN_RMSLE: 2.9120\n",
            "Epoch 2: val_loss improved from 21.98124 to 18.50589, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 5ms/step - loss: 8.4904 - NN_RMSLE: 2.9064 - val_loss: 18.5059 - val_NN_RMSLE: 4.2613\n",
            "Epoch 3/100\n",
            "449/453 [============================>.] - ETA: 0s - loss: 7.0483 - NN_RMSLE: 2.6479\n",
            "Epoch 3: val_loss improved from 18.50589 to 15.61619, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 7.0477 - NN_RMSLE: 2.6485 - val_loss: 15.6162 - val_NN_RMSLE: 3.9112\n",
            "Epoch 4/100\n",
            "443/453 [============================>.] - ETA: 0s - loss: 5.9909 - NN_RMSLE: 2.4423\n",
            "Epoch 4: val_loss improved from 15.61619 to 13.22341, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 5.9866 - NN_RMSLE: 2.4422 - val_loss: 13.2234 - val_NN_RMSLE: 3.5965\n",
            "Epoch 5/100\n",
            "444/453 [============================>.] - ETA: 0s - loss: 5.2438 - NN_RMSLE: 2.2858\n",
            "Epoch 5: val_loss improved from 13.22341 to 11.28107, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 5ms/step - loss: 5.2387 - NN_RMSLE: 2.2855 - val_loss: 11.2811 - val_NN_RMSLE: 3.3200\n",
            "Epoch 6/100\n",
            "449/453 [============================>.] - ETA: 0s - loss: 4.7431 - NN_RMSLE: 2.1742\n",
            "Epoch 6: val_loss improved from 11.28107 to 9.73477, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 5ms/step - loss: 4.7406 - NN_RMSLE: 2.1732 - val_loss: 9.7348 - val_NN_RMSLE: 3.0829\n",
            "Epoch 7/100\n",
            "432/453 [===========================>..] - ETA: 0s - loss: 4.4408 - NN_RMSLE: 2.1048\n",
            "Epoch 7: val_loss improved from 9.73477 to 8.54921, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 4.4339 - NN_RMSLE: 2.1021 - val_loss: 8.5492 - val_NN_RMSLE: 2.8886\n",
            "Epoch 8/100\n",
            "434/453 [===========================>..] - ETA: 0s - loss: 4.2628 - NN_RMSLE: 2.0626\n",
            "Epoch 8: val_loss improved from 8.54921 to 7.67818, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 4.2627 - NN_RMSLE: 2.0624 - val_loss: 7.6782 - val_NN_RMSLE: 2.7375\n",
            "Epoch 9/100\n",
            "439/453 [============================>.] - ETA: 0s - loss: 4.1836 - NN_RMSLE: 2.0436\n",
            "Epoch 9: val_loss improved from 7.67818 to 7.06842, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 4.1792 - NN_RMSLE: 2.0426 - val_loss: 7.0684 - val_NN_RMSLE: 2.6267\n",
            "Epoch 10/100\n",
            "446/453 [============================>.] - ETA: 0s - loss: 4.1463 - NN_RMSLE: 2.0345\n",
            "Epoch 10: val_loss improved from 7.06842 to 6.67684, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 4.1457 - NN_RMSLE: 2.0343 - val_loss: 6.6768 - val_NN_RMSLE: 2.5532\n",
            "Epoch 11/100\n",
            "445/453 [============================>.] - ETA: 0s - loss: 4.1354 - NN_RMSLE: 2.0321\n",
            "Epoch 11: val_loss improved from 6.67684 to 6.47278, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 4.1349 - NN_RMSLE: 2.0320 - val_loss: 6.4728 - val_NN_RMSLE: 2.5140\n",
            "Epoch 12/100\n",
            "448/453 [============================>.] - ETA: 0s - loss: 4.1305 - NN_RMSLE: 2.0308\n",
            "Epoch 12: val_loss improved from 6.47278 to 6.36921, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 4.1325 - NN_RMSLE: 2.0306 - val_loss: 6.3692 - val_NN_RMSLE: 2.4939\n",
            "Epoch 13/100\n",
            "447/453 [============================>.] - ETA: 0s - loss: 4.1329 - NN_RMSLE: 2.0313\n",
            "Epoch 13: val_loss improved from 6.36921 to 6.34404, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 4.1322 - NN_RMSLE: 2.0312 - val_loss: 6.3440 - val_NN_RMSLE: 2.4890\n",
            "Epoch 14/100\n",
            "443/453 [============================>.] - ETA: 0s - loss: 4.1339 - NN_RMSLE: 2.0318\n",
            "Epoch 14: val_loss improved from 6.34404 to 6.33767, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 4.1322 - NN_RMSLE: 2.0305 - val_loss: 6.3377 - val_NN_RMSLE: 2.4878\n",
            "Epoch 15/100\n",
            "449/453 [============================>.] - ETA: 0s - loss: 4.1317 - NN_RMSLE: 2.0311\n",
            "Epoch 15: val_loss did not improve from 6.33767\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 4.1322 - NN_RMSLE: 2.0310 - val_loss: 6.3509 - val_NN_RMSLE: 2.4903\n",
            "Epoch 16/100\n",
            "448/453 [============================>.] - ETA: 0s - loss: 4.1316 - NN_RMSLE: 2.0311\n",
            "Epoch 16: val_loss improved from 6.33767 to 6.31788, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 5ms/step - loss: 4.1322 - NN_RMSLE: 2.0316 - val_loss: 6.3179 - val_NN_RMSLE: 2.4839\n",
            "Epoch 17/100\n",
            "437/453 [===========================>..] - ETA: 0s - loss: 4.1306 - NN_RMSLE: 2.0307\n",
            "Epoch 17: val_loss did not improve from 6.31788\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 4.1322 - NN_RMSLE: 2.0315 - val_loss: 6.3427 - val_NN_RMSLE: 2.4888\n",
            "Epoch 18/100\n",
            "449/453 [============================>.] - ETA: 0s - loss: 4.1351 - NN_RMSLE: 2.0320\n",
            "Epoch 18: val_loss did not improve from 6.31788\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 4.1322 - NN_RMSLE: 2.0313 - val_loss: 6.3450 - val_NN_RMSLE: 2.4892\n",
            "Epoch 19/100\n",
            "448/453 [============================>.] - ETA: 0s - loss: 4.1335 - NN_RMSLE: 2.0317\n",
            "Epoch 19: val_loss did not improve from 6.31788\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 4.1322 - NN_RMSLE: 2.0312 - val_loss: 6.3190 - val_NN_RMSLE: 2.4841\n",
            "Model: \"sequential_78\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_312 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_234 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_313 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_235 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_314 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_236 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_315 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  6.319031\n",
            "\n",
            "[4 5 6 7 8 9]\n",
            "train 28935 valid 14468\n",
            "Model: \"sequential_79\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_316 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_237 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_317 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_238 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_318 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_239 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_319 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "442/453 [============================>.] - ETA: 0s - loss: 19.8588 - NN_RMSLE: 4.4524\n",
            "Epoch 1: val_loss improved from inf to 4.48728, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 19.8258 - NN_RMSLE: 4.4484 - val_loss: 4.4873 - val_NN_RMSLE: 1.9913\n",
            "Epoch 2/100\n",
            "449/453 [============================>.] - ETA: 0s - loss: 16.4777 - NN_RMSLE: 4.0556\n",
            "Epoch 2: val_loss improved from 4.48728 to 3.52877, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 16.4708 - NN_RMSLE: 4.0558 - val_loss: 3.5288 - val_NN_RMSLE: 1.7635\n",
            "Epoch 3/100\n",
            "432/453 [===========================>..] - ETA: 0s - loss: 13.6953 - NN_RMSLE: 3.6974\n",
            "Epoch 3: val_loss improved from 3.52877 to 2.94476, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 13.6213 - NN_RMSLE: 3.6865 - val_loss: 2.9448 - val_NN_RMSLE: 1.6255\n",
            "Epoch 4/100\n",
            "448/453 [============================>.] - ETA: 0s - loss: 11.2380 - NN_RMSLE: 3.3489\n",
            "Epoch 4: val_loss improved from 2.94476 to 2.68658, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 11.2233 - NN_RMSLE: 3.3464 - val_loss: 2.6866 - val_NN_RMSLE: 1.5814\n",
            "Epoch 5/100\n",
            "435/453 [===========================>..] - ETA: 0s - loss: 9.2538 - NN_RMSLE: 3.0392\n",
            "Epoch 5: val_loss did not improve from 2.68658\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 9.2238 - NN_RMSLE: 3.0345 - val_loss: 2.7103 - val_NN_RMSLE: 1.6189\n",
            "Epoch 6/100\n",
            "452/453 [============================>.] - ETA: 0s - loss: 7.5793 - NN_RMSLE: 2.7505\n",
            "Epoch 6: val_loss did not improve from 2.68658\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 7.5794 - NN_RMSLE: 2.7507 - val_loss: 2.9752 - val_NN_RMSLE: 1.7165\n",
            "Epoch 7/100\n",
            "439/453 [============================>.] - ETA: 0s - loss: 6.2712 - NN_RMSLE: 2.5022\n",
            "Epoch 7: val_loss did not improve from 2.68658\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.2532 - NN_RMSLE: 2.4985 - val_loss: 3.4419 - val_NN_RMSLE: 1.8530\n",
            "Model: \"sequential_79\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_316 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_237 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_317 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_238 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_318 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_239 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_319 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  3.4418879\n",
            "\n",
            "[ 8  9 10 11 12]\n",
            "train 28936 valid 14467\n",
            "Model: \"sequential_80\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_320 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_240 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_321 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_241 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_322 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_242 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_323 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "439/453 [============================>.] - ETA: 0s - loss: 14.5921 - NN_RMSLE: 3.8142\n",
            "Epoch 1: val_loss improved from inf to 14.17073, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 5ms/step - loss: 14.5641 - NN_RMSLE: 3.8103 - val_loss: 14.1707 - val_NN_RMSLE: 3.5804\n",
            "Epoch 2/100\n",
            "449/453 [============================>.] - ETA: 0s - loss: 12.0632 - NN_RMSLE: 3.4670\n",
            "Epoch 2: val_loss improved from 14.17073 to 11.70883, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 12.0456 - NN_RMSLE: 3.4643 - val_loss: 11.7088 - val_NN_RMSLE: 3.2451\n",
            "Epoch 3/100\n",
            "445/453 [============================>.] - ETA: 0s - loss: 10.0415 - NN_RMSLE: 3.1633\n",
            "Epoch 3: val_loss improved from 11.70883 to 9.71315, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 10.0229 - NN_RMSLE: 3.1606 - val_loss: 9.7131 - val_NN_RMSLE: 2.9568\n",
            "Epoch 4/100\n",
            "452/453 [============================>.] - ETA: 0s - loss: 8.4154 - NN_RMSLE: 2.8966\n",
            "Epoch 4: val_loss improved from 9.71315 to 8.11326, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 5ms/step - loss: 8.4147 - NN_RMSLE: 2.8954 - val_loss: 8.1133 - val_NN_RMSLE: 2.7150\n",
            "Epoch 5/100\n",
            "446/453 [============================>.] - ETA: 0s - loss: 7.1702 - NN_RMSLE: 2.6740\n",
            "Epoch 5: val_loss improved from 8.11326 to 6.86178, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 7.1666 - NN_RMSLE: 2.6728 - val_loss: 6.8618 - val_NN_RMSLE: 2.5186\n",
            "Epoch 6/100\n",
            "448/453 [============================>.] - ETA: 0s - loss: 6.2260 - NN_RMSLE: 2.4923\n",
            "Epoch 6: val_loss improved from 6.86178 to 5.90771, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 6.2277 - NN_RMSLE: 2.4916 - val_loss: 5.9077 - val_NN_RMSLE: 2.3626\n",
            "Epoch 7/100\n",
            "447/453 [============================>.] - ETA: 0s - loss: 5.5547 - NN_RMSLE: 2.3545\n",
            "Epoch 7: val_loss improved from 5.90771 to 5.20442, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 5ms/step - loss: 5.5479 - NN_RMSLE: 2.3535 - val_loss: 5.2044 - val_NN_RMSLE: 2.2408\n",
            "Epoch 8/100\n",
            "445/453 [============================>.] - ETA: 0s - loss: 5.0820 - NN_RMSLE: 2.2525\n",
            "Epoch 8: val_loss improved from 5.20442 to 4.70871, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 5.0805 - NN_RMSLE: 2.2516 - val_loss: 4.7087 - val_NN_RMSLE: 2.1479\n",
            "Epoch 9/100\n",
            "453/453 [==============================] - ETA: 0s - loss: 4.7836 - NN_RMSLE: 2.1859\n",
            "Epoch 9: val_loss improved from 4.70871 to 4.37973, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 5ms/step - loss: 4.7836 - NN_RMSLE: 2.1859 - val_loss: 4.3797 - val_NN_RMSLE: 2.0795\n",
            "Epoch 10/100\n",
            "452/453 [============================>.] - ETA: 0s - loss: 4.6107 - NN_RMSLE: 2.1458\n",
            "Epoch 10: val_loss improved from 4.37973 to 4.17209, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 5ms/step - loss: 4.6106 - NN_RMSLE: 2.1456 - val_loss: 4.1721 - val_NN_RMSLE: 2.0303\n",
            "Epoch 11/100\n",
            "440/453 [============================>.] - ETA: 0s - loss: 4.5236 - NN_RMSLE: 2.1252\n",
            "Epoch 11: val_loss improved from 4.17209 to 4.05239, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 4.5231 - NN_RMSLE: 2.1248 - val_loss: 4.0524 - val_NN_RMSLE: 1.9975\n",
            "Epoch 12/100\n",
            "430/453 [===========================>..] - ETA: 0s - loss: 4.4841 - NN_RMSLE: 2.1154\n",
            "Epoch 12: val_loss improved from 4.05239 to 3.99004, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 4.4853 - NN_RMSLE: 2.1155 - val_loss: 3.9900 - val_NN_RMSLE: 1.9776\n",
            "Epoch 13/100\n",
            "438/453 [============================>.] - ETA: 0s - loss: 4.4661 - NN_RMSLE: 2.1113\n",
            "Epoch 13: val_loss improved from 3.99004 to 3.96040, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 4.4729 - NN_RMSLE: 2.1129 - val_loss: 3.9604 - val_NN_RMSLE: 1.9670\n",
            "Epoch 14/100\n",
            "442/453 [============================>.] - ETA: 0s - loss: 4.4677 - NN_RMSLE: 2.1115\n",
            "Epoch 14: val_loss improved from 3.96040 to 3.94411, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 4.4690 - NN_RMSLE: 2.1113 - val_loss: 3.9441 - val_NN_RMSLE: 1.9606\n",
            "Epoch 15/100\n",
            "442/453 [============================>.] - ETA: 0s - loss: 4.4686 - NN_RMSLE: 2.1118\n",
            "Epoch 15: val_loss improved from 3.94411 to 3.93553, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 4.4681 - NN_RMSLE: 2.1107 - val_loss: 3.9355 - val_NN_RMSLE: 1.9570\n",
            "Epoch 16/100\n",
            "450/453 [============================>.] - ETA: 0s - loss: 4.4684 - NN_RMSLE: 2.1115\n",
            "Epoch 16: val_loss improved from 3.93553 to 3.93372, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 4.4681 - NN_RMSLE: 2.1129 - val_loss: 3.9337 - val_NN_RMSLE: 1.9562\n",
            "Epoch 17/100\n",
            "447/453 [============================>.] - ETA: 0s - loss: 4.4691 - NN_RMSLE: 2.1119\n",
            "Epoch 17: val_loss did not improve from 3.93372\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 4.4681 - NN_RMSLE: 2.1122 - val_loss: 3.9347 - val_NN_RMSLE: 1.9566\n",
            "Epoch 18/100\n",
            "442/453 [============================>.] - ETA: 0s - loss: 4.4656 - NN_RMSLE: 2.1106\n",
            "Epoch 18: val_loss improved from 3.93372 to 3.93305, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 5ms/step - loss: 4.4681 - NN_RMSLE: 2.1109 - val_loss: 3.9330 - val_NN_RMSLE: 1.9560\n",
            "Epoch 19/100\n",
            "439/453 [============================>.] - ETA: 0s - loss: 4.4664 - NN_RMSLE: 2.1111\n",
            "Epoch 19: val_loss improved from 3.93305 to 3.92794, saving model to model_113[]\n",
            "INFO:tensorflow:Assets written to: model_113[]/assets\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 4.4679 - NN_RMSLE: 2.1116 - val_loss: 3.9279 - val_NN_RMSLE: 1.9537\n",
            "Epoch 20/100\n",
            "439/453 [============================>.] - ETA: 0s - loss: 4.4694 - NN_RMSLE: 2.1118\n",
            "Epoch 20: val_loss did not improve from 3.92794\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 4.4682 - NN_RMSLE: 2.1117 - val_loss: 3.9328 - val_NN_RMSLE: 1.9558\n",
            "Epoch 21/100\n",
            "452/453 [============================>.] - ETA: 0s - loss: 4.4678 - NN_RMSLE: 2.1116\n",
            "Epoch 21: val_loss did not improve from 3.92794\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 4.4681 - NN_RMSLE: 2.1121 - val_loss: 3.9331 - val_NN_RMSLE: 1.9560\n",
            "Epoch 22/100\n",
            "442/453 [============================>.] - ETA: 0s - loss: 4.4685 - NN_RMSLE: 2.1115\n",
            "Epoch 22: val_loss did not improve from 3.92794\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 4.4683 - NN_RMSLE: 2.1122 - val_loss: 3.9338 - val_NN_RMSLE: 1.9563\n",
            "Model: \"sequential_80\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_320 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_240 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_321 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_241 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_322 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_242 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_323 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  3.9337819\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 120 (315909, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[1 2 3 4 5]\n",
            "train 210606 valid 105303\n",
            "Model: \"sequential_81\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_324 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_243 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_325 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_244 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_326 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_245 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_327 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "3279/3291 [============================>.] - ETA: 0s - loss: 8.4624 - NN_RMSLE: 2.8219\n",
            "Epoch 1: val_loss improved from inf to 3.21639, saving model to model_120[]\n",
            "INFO:tensorflow:Assets written to: model_120[]/assets\n",
            "3291/3291 [==============================] - 12s 4ms/step - loss: 8.4430 - NN_RMSLE: 2.8180 - val_loss: 3.2164 - val_NN_RMSLE: 1.7747\n",
            "Epoch 2/100\n",
            "3280/3291 [============================>.] - ETA: 0s - loss: 1.8700 - NN_RMSLE: 1.3551\n",
            "Epoch 2: val_loss improved from 3.21639 to 1.54436, saving model to model_120[]\n",
            "INFO:tensorflow:Assets written to: model_120[]/assets\n",
            "3291/3291 [==============================] - 16s 5ms/step - loss: 1.8687 - NN_RMSLE: 1.3546 - val_loss: 1.5444 - val_NN_RMSLE: 1.2365\n",
            "Epoch 3/100\n",
            "3272/3291 [============================>.] - ETA: 0s - loss: 1.4891 - NN_RMSLE: 1.2166\n",
            "Epoch 3: val_loss improved from 1.54436 to 1.53934, saving model to model_120[]\n",
            "INFO:tensorflow:Assets written to: model_120[]/assets\n",
            "3291/3291 [==============================] - 10s 3ms/step - loss: 1.4888 - NN_RMSLE: 1.2165 - val_loss: 1.5393 - val_NN_RMSLE: 1.2348\n",
            "Epoch 4/100\n",
            "3279/3291 [============================>.] - ETA: 0s - loss: 1.4884 - NN_RMSLE: 1.2161\n",
            "Epoch 4: val_loss did not improve from 1.53934\n",
            "3291/3291 [==============================] - 10s 3ms/step - loss: 1.4887 - NN_RMSLE: 1.2162 - val_loss: 1.5405 - val_NN_RMSLE: 1.2352\n",
            "Epoch 5/100\n",
            "3284/3291 [============================>.] - ETA: 0s - loss: 1.4884 - NN_RMSLE: 1.2162\n",
            "Epoch 5: val_loss did not improve from 1.53934\n",
            "3291/3291 [==============================] - 11s 3ms/step - loss: 1.4887 - NN_RMSLE: 1.2163 - val_loss: 1.5403 - val_NN_RMSLE: 1.2351\n",
            "Epoch 6/100\n",
            "3285/3291 [============================>.] - ETA: 0s - loss: 1.4883 - NN_RMSLE: 1.2162\n",
            "Epoch 6: val_loss did not improve from 1.53934\n",
            "3291/3291 [==============================] - 9s 3ms/step - loss: 1.4887 - NN_RMSLE: 1.2163 - val_loss: 1.5398 - val_NN_RMSLE: 1.2350\n",
            "Model: \"sequential_81\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_324 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_243 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_325 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_244 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_326 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_245 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_327 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.5397917\n",
            "\n",
            "[5 6 7 8 9]\n",
            "train 210606 valid 105303\n",
            "Model: \"sequential_82\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_328 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_246 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_329 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_247 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_330 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_248 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_331 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "3276/3291 [============================>.] - ETA: 0s - loss: 8.6325 - NN_RMSLE: 2.8511\n",
            "Epoch 1: val_loss improved from inf to 3.02643, saving model to model_120[]\n",
            "INFO:tensorflow:Assets written to: model_120[]/assets\n",
            "3291/3291 [==============================] - 11s 3ms/step - loss: 8.6078 - NN_RMSLE: 2.8461 - val_loss: 3.0264 - val_NN_RMSLE: 1.7247\n",
            "Epoch 2/100\n",
            "3276/3291 [============================>.] - ETA: 0s - loss: 1.9049 - NN_RMSLE: 1.3673\n",
            "Epoch 2: val_loss improved from 3.02643 to 1.50774, saving model to model_120[]\n",
            "INFO:tensorflow:Assets written to: model_120[]/assets\n",
            "3291/3291 [==============================] - 11s 3ms/step - loss: 1.9028 - NN_RMSLE: 1.3665 - val_loss: 1.5077 - val_NN_RMSLE: 1.2241\n",
            "Epoch 3/100\n",
            "3281/3291 [============================>.] - ETA: 0s - loss: 1.5034 - NN_RMSLE: 1.2221\n",
            "Epoch 3: val_loss did not improve from 1.50774\n",
            "3291/3291 [==============================] - 10s 3ms/step - loss: 1.5037 - NN_RMSLE: 1.2223 - val_loss: 1.5116 - val_NN_RMSLE: 1.2255\n",
            "Epoch 4/100\n",
            "3280/3291 [============================>.] - ETA: 0s - loss: 1.5038 - NN_RMSLE: 1.2222\n",
            "Epoch 4: val_loss did not improve from 1.50774\n",
            "3291/3291 [==============================] - 11s 3ms/step - loss: 1.5035 - NN_RMSLE: 1.2221 - val_loss: 1.5121 - val_NN_RMSLE: 1.2256\n",
            "Epoch 5/100\n",
            "3278/3291 [============================>.] - ETA: 0s - loss: 1.5038 - NN_RMSLE: 1.2224\n",
            "Epoch 5: val_loss did not improve from 1.50774\n",
            "3291/3291 [==============================] - 10s 3ms/step - loss: 1.5035 - NN_RMSLE: 1.2223 - val_loss: 1.5112 - val_NN_RMSLE: 1.2253\n",
            "Model: \"sequential_82\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_328 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_246 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_329 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_247 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_330 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_248 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_331 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.5112355\n",
            "\n",
            "[ 8  9 10 11 12]\n",
            "train 210606 valid 105303\n",
            "Model: \"sequential_83\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_332 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_249 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_333 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_250 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_334 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_251 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_335 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "3283/3291 [============================>.] - ETA: 0s - loss: 8.4853 - NN_RMSLE: 2.8263\n",
            "Epoch 1: val_loss improved from inf to 3.15643, saving model to model_120[]\n",
            "INFO:tensorflow:Assets written to: model_120[]/assets\n",
            "3291/3291 [==============================] - 11s 3ms/step - loss: 8.4724 - NN_RMSLE: 2.8237 - val_loss: 3.1564 - val_NN_RMSLE: 1.7577\n",
            "Epoch 2/100\n",
            "3286/3291 [============================>.] - ETA: 0s - loss: 1.9009 - NN_RMSLE: 1.3667\n",
            "Epoch 2: val_loss improved from 3.15643 to 1.47322, saving model to model_120[]\n",
            "INFO:tensorflow:Assets written to: model_120[]/assets\n",
            "3291/3291 [==============================] - 11s 3ms/step - loss: 1.9005 - NN_RMSLE: 1.3665 - val_loss: 1.4732 - val_NN_RMSLE: 1.2099\n",
            "Epoch 3/100\n",
            "3279/3291 [============================>.] - ETA: 0s - loss: 1.5244 - NN_RMSLE: 1.2305\n",
            "Epoch 3: val_loss improved from 1.47322 to 1.46890, saving model to model_120[]\n",
            "INFO:tensorflow:Assets written to: model_120[]/assets\n",
            "3291/3291 [==============================] - 11s 3ms/step - loss: 1.5244 - NN_RMSLE: 1.2306 - val_loss: 1.4689 - val_NN_RMSLE: 1.2083\n",
            "Epoch 4/100\n",
            "3284/3291 [============================>.] - ETA: 0s - loss: 1.5243 - NN_RMSLE: 1.2305\n",
            "Epoch 4: val_loss improved from 1.46890 to 1.46882, saving model to model_120[]\n",
            "INFO:tensorflow:Assets written to: model_120[]/assets\n",
            "3291/3291 [==============================] - 11s 3ms/step - loss: 1.5243 - NN_RMSLE: 1.2305 - val_loss: 1.4688 - val_NN_RMSLE: 1.2082\n",
            "Epoch 5/100\n",
            "3288/3291 [============================>.] - ETA: 0s - loss: 1.5243 - NN_RMSLE: 1.2306\n",
            "Epoch 5: val_loss did not improve from 1.46882\n",
            "3291/3291 [==============================] - 11s 3ms/step - loss: 1.5243 - NN_RMSLE: 1.2306 - val_loss: 1.4697 - val_NN_RMSLE: 1.2086\n",
            "Epoch 6/100\n",
            "3272/3291 [============================>.] - ETA: 0s - loss: 1.5244 - NN_RMSLE: 1.2306\n",
            "Epoch 6: val_loss did not improve from 1.46882\n",
            "3291/3291 [==============================] - 11s 3ms/step - loss: 1.5243 - NN_RMSLE: 1.2305 - val_loss: 1.4692 - val_NN_RMSLE: 1.2084\n",
            "Epoch 7/100\n",
            "3280/3291 [============================>.] - ETA: 0s - loss: 1.5240 - NN_RMSLE: 1.2305\n",
            "Epoch 7: val_loss did not improve from 1.46882\n",
            "3291/3291 [==============================] - 9s 3ms/step - loss: 1.5243 - NN_RMSLE: 1.2306 - val_loss: 1.4699 - val_NN_RMSLE: 1.2086\n",
            "Model: \"sequential_83\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_332 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_249 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_333 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_250 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_334 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_251 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_335 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.4699337\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 130 (1205327, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[ 1  2  3  4  5  7  8  9 10 11]\n",
            "train 803551 valid 401776\n",
            "Model: \"sequential_84\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_336 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_252 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_337 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_253 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_338 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_254 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_339 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12551/12556 [============================>.] - ETA: 0s - loss: 5.0263 - NN_RMSLE: 2.0124\n",
            "Epoch 1: val_loss improved from inf to 1.66079, saving model to model_130[]\n",
            "INFO:tensorflow:Assets written to: model_130[]/assets\n",
            "12556/12556 [==============================] - 37s 3ms/step - loss: 5.0253 - NN_RMSLE: 2.0121 - val_loss: 1.6608 - val_NN_RMSLE: 1.2849\n",
            "Epoch 2/100\n",
            "12555/12556 [============================>.] - ETA: 0s - loss: 1.9056 - NN_RMSLE: 1.3744\n",
            "Epoch 2: val_loss did not improve from 1.66079\n",
            "12556/12556 [==============================] - 45s 4ms/step - loss: 1.9056 - NN_RMSLE: 1.3744 - val_loss: 1.6620 - val_NN_RMSLE: 1.2852\n",
            "Epoch 3/100\n",
            "12540/12556 [============================>.] - ETA: 0s - loss: 1.9058 - NN_RMSLE: 1.3744\n",
            "Epoch 3: val_loss did not improve from 1.66079\n",
            "12556/12556 [==============================] - 36s 3ms/step - loss: 1.9056 - NN_RMSLE: 1.3743 - val_loss: 1.6614 - val_NN_RMSLE: 1.2850\n",
            "Epoch 4/100\n",
            "12554/12556 [============================>.] - ETA: 0s - loss: 1.9056 - NN_RMSLE: 1.3743\n",
            "Epoch 4: val_loss did not improve from 1.66079\n",
            "12556/12556 [==============================] - 37s 3ms/step - loss: 1.9056 - NN_RMSLE: 1.3743 - val_loss: 1.6637 - val_NN_RMSLE: 1.2858\n",
            "Model: \"sequential_84\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_336 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_252 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_337 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_253 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_338 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_254 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_339 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.6637074\n",
            "\n",
            "[ 4  5  6  7  8  9 10 11 12]\n",
            "train 803551 valid 401776\n",
            "Model: \"sequential_85\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_340 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_255 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_341 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_256 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_342 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_257 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_343 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12545/12556 [============================>.] - ETA: 0s - loss: 4.7727 - NN_RMSLE: 1.9466\n",
            "Epoch 1: val_loss improved from inf to 2.03812, saving model to model_130[]\n",
            "INFO:tensorflow:Assets written to: model_130[]/assets\n",
            "12556/12556 [==============================] - 41s 3ms/step - loss: 4.7701 - NN_RMSLE: 1.9460 - val_loss: 2.0381 - val_NN_RMSLE: 1.4223\n",
            "Epoch 2/100\n",
            "12543/12556 [============================>.] - ETA: 0s - loss: 1.7173 - NN_RMSLE: 1.3052\n",
            "Epoch 2: val_loss did not improve from 2.03812\n",
            "12556/12556 [==============================] - 40s 3ms/step - loss: 1.7173 - NN_RMSLE: 1.3052 - val_loss: 2.0386 - val_NN_RMSLE: 1.4225\n",
            "Epoch 3/100\n",
            "12543/12556 [============================>.] - ETA: 0s - loss: 1.7173 - NN_RMSLE: 1.3050\n",
            "Epoch 3: val_loss did not improve from 2.03812\n",
            "12556/12556 [==============================] - 44s 3ms/step - loss: 1.7173 - NN_RMSLE: 1.3051 - val_loss: 2.0388 - val_NN_RMSLE: 1.4225\n",
            "Epoch 4/100\n",
            "12554/12556 [============================>.] - ETA: 0s - loss: 1.7173 - NN_RMSLE: 1.3051\n",
            "Epoch 4: val_loss did not improve from 2.03812\n",
            "12556/12556 [==============================] - 46s 4ms/step - loss: 1.7173 - NN_RMSLE: 1.3051 - val_loss: 2.0383 - val_NN_RMSLE: 1.4224\n",
            "Model: \"sequential_85\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_340 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_255 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_341 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_256 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_342 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_257 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_343 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  2.0383444\n",
            "\n",
            "[ 8  9 10 11 12]\n",
            "train 803552 valid 401775\n",
            "Model: \"sequential_86\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_344 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_258 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_345 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_259 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_346 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_260 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_347 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "12540/12556 [============================>.] - ETA: 0s - loss: 4.9544 - NN_RMSLE: 1.9933\n",
            "Epoch 1: val_loss improved from inf to 1.77428, saving model to model_130[]\n",
            "INFO:tensorflow:Assets written to: model_130[]/assets\n",
            "12556/12556 [==============================] - 37s 3ms/step - loss: 4.9505 - NN_RMSLE: 1.9924 - val_loss: 1.7743 - val_NN_RMSLE: 1.3298\n",
            "Epoch 2/100\n",
            "12545/12556 [============================>.] - ETA: 0s - loss: 1.8491 - NN_RMSLE: 1.3536\n",
            "Epoch 2: val_loss improved from 1.77428 to 1.77390, saving model to model_130[]\n",
            "INFO:tensorflow:Assets written to: model_130[]/assets\n",
            "12556/12556 [==============================] - 39s 3ms/step - loss: 1.8492 - NN_RMSLE: 1.3537 - val_loss: 1.7739 - val_NN_RMSLE: 1.3298\n",
            "Epoch 3/100\n",
            "12553/12556 [============================>.] - ETA: 0s - loss: 1.8493 - NN_RMSLE: 1.3537\n",
            "Epoch 3: val_loss did not improve from 1.77390\n",
            "12556/12556 [==============================] - 37s 3ms/step - loss: 1.8492 - NN_RMSLE: 1.3537 - val_loss: 1.7740 - val_NN_RMSLE: 1.3298\n",
            "Epoch 4/100\n",
            "12548/12556 [============================>.] - ETA: 0s - loss: 1.8493 - NN_RMSLE: 1.3537\n",
            "Epoch 4: val_loss did not improve from 1.77390\n",
            "12556/12556 [==============================] - 38s 3ms/step - loss: 1.8493 - NN_RMSLE: 1.3537 - val_loss: 1.7744 - val_NN_RMSLE: 1.3299\n",
            "Epoch 5/100\n",
            "12545/12556 [============================>.] - ETA: 0s - loss: 1.8493 - NN_RMSLE: 1.3539\n",
            "Epoch 5: val_loss did not improve from 1.77390\n",
            "12556/12556 [==============================] - 41s 3ms/step - loss: 1.8493 - NN_RMSLE: 1.3539 - val_loss: 1.7739 - val_NN_RMSLE: 1.3298\n",
            "Model: \"sequential_86\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_344 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_258 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_345 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_259 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_346 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_260 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_347 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.7739506\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 131 (702607, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[1 2 3 4 5]\n",
            "train 468404 valid 234203\n",
            "Model: \"sequential_87\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_348 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_261 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_349 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_262 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_350 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_263 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_351 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "7318/7319 [============================>.] - ETA: 0s - loss: 8.6089 - NN_RMSLE: 2.8845\n",
            "Epoch 1: val_loss improved from inf to 7.72134, saving model to model_131[]\n",
            "INFO:tensorflow:Assets written to: model_131[]/assets\n",
            "7319/7319 [==============================] - 24s 3ms/step - loss: 8.6087 - NN_RMSLE: 2.8845 - val_loss: 7.7213 - val_NN_RMSLE: 2.7733\n",
            "Epoch 2/100\n",
            "7315/7319 [============================>.] - ETA: 0s - loss: 6.3002 - NN_RMSLE: 2.5057\n",
            "Epoch 2: val_loss did not improve from 7.72134\n",
            "7319/7319 [==============================] - 27s 4ms/step - loss: 6.3002 - NN_RMSLE: 2.5057 - val_loss: 7.7277 - val_NN_RMSLE: 2.7745\n",
            "Epoch 3/100\n",
            "7297/7319 [============================>.] - ETA: 0s - loss: 6.3002 - NN_RMSLE: 2.5057\n",
            "Epoch 3: val_loss did not improve from 7.72134\n",
            "7319/7319 [==============================] - 21s 3ms/step - loss: 6.3001 - NN_RMSLE: 2.5057 - val_loss: 7.7223 - val_NN_RMSLE: 2.7735\n",
            "Epoch 4/100\n",
            "7310/7319 [============================>.] - ETA: 0s - loss: 6.3001 - NN_RMSLE: 2.5056\n",
            "Epoch 4: val_loss improved from 7.72134 to 7.59696, saving model to model_131[]\n",
            "INFO:tensorflow:Assets written to: model_131[]/assets\n",
            "7319/7319 [==============================] - 25s 3ms/step - loss: 6.3001 - NN_RMSLE: 2.5056 - val_loss: 7.5970 - val_NN_RMSLE: 2.7512\n",
            "Epoch 5/100\n",
            "7303/7319 [============================>.] - ETA: 0s - loss: 6.3001 - NN_RMSLE: 2.5057\n",
            "Epoch 5: val_loss did not improve from 7.59696\n",
            "7319/7319 [==============================] - 23s 3ms/step - loss: 6.3001 - NN_RMSLE: 2.5058 - val_loss: 7.7022 - val_NN_RMSLE: 2.7700\n",
            "Epoch 6/100\n",
            "7316/7319 [============================>.] - ETA: 0s - loss: 6.3000 - NN_RMSLE: 2.5056\n",
            "Epoch 6: val_loss did not improve from 7.59696\n",
            "7319/7319 [==============================] - 23s 3ms/step - loss: 6.3001 - NN_RMSLE: 2.5056 - val_loss: 7.6862 - val_NN_RMSLE: 2.7671\n",
            "Epoch 7/100\n",
            "7304/7319 [============================>.] - ETA: 0s - loss: 6.3007 - NN_RMSLE: 2.5058\n",
            "Epoch 7: val_loss did not improve from 7.59696\n",
            "7319/7319 [==============================] - 22s 3ms/step - loss: 6.3001 - NN_RMSLE: 2.5057 - val_loss: 7.7852 - val_NN_RMSLE: 2.7847\n",
            "Model: \"sequential_87\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_348 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_261 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_349 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_262 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_350 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_263 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_351 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  7.7851987\n",
            "\n",
            "[4 5 6 7 8 9]\n",
            "train 468405 valid 234202\n",
            "Model: \"sequential_88\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_352 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_264 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_353 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_265 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_354 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_266 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_355 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "7307/7319 [============================>.] - ETA: 0s - loss: 5.9027 - NN_RMSLE: 2.4131\n",
            "Epoch 1: val_loss improved from inf to 10.04408, saving model to model_131[]\n",
            "INFO:tensorflow:Assets written to: model_131[]/assets\n",
            "7319/7319 [==============================] - 23s 3ms/step - loss: 5.9018 - NN_RMSLE: 2.4129 - val_loss: 10.0441 - val_NN_RMSLE: 3.1360\n",
            "Epoch 2/100\n",
            "7301/7319 [============================>.] - ETA: 0s - loss: 5.3438 - NN_RMSLE: 2.3059\n",
            "Epoch 2: val_loss did not improve from 10.04408\n",
            "7319/7319 [==============================] - 22s 3ms/step - loss: 5.3435 - NN_RMSLE: 2.3058 - val_loss: 10.0460 - val_NN_RMSLE: 3.1362\n",
            "Epoch 3/100\n",
            "7304/7319 [============================>.] - ETA: 0s - loss: 5.3433 - NN_RMSLE: 2.3057\n",
            "Epoch 3: val_loss improved from 10.04408 to 10.01005, saving model to model_131[]\n",
            "INFO:tensorflow:Assets written to: model_131[]/assets\n",
            "7319/7319 [==============================] - 22s 3ms/step - loss: 5.3434 - NN_RMSLE: 2.3057 - val_loss: 10.0101 - val_NN_RMSLE: 3.1307\n",
            "Epoch 4/100\n",
            "7301/7319 [============================>.] - ETA: 0s - loss: 5.3431 - NN_RMSLE: 2.3057\n",
            "Epoch 4: val_loss did not improve from 10.01005\n",
            "7319/7319 [==============================] - 23s 3ms/step - loss: 5.3434 - NN_RMSLE: 2.3058 - val_loss: 10.0898 - val_NN_RMSLE: 3.1429\n",
            "Epoch 5/100\n",
            "7297/7319 [============================>.] - ETA: 0s - loss: 5.3434 - NN_RMSLE: 2.3058\n",
            "Epoch 5: val_loss did not improve from 10.01005\n",
            "7319/7319 [==============================] - 23s 3ms/step - loss: 5.3435 - NN_RMSLE: 2.3058 - val_loss: 10.0138 - val_NN_RMSLE: 3.1313\n",
            "Epoch 6/100\n",
            "7308/7319 [============================>.] - ETA: 0s - loss: 5.3435 - NN_RMSLE: 2.3060\n",
            "Epoch 6: val_loss improved from 10.01005 to 9.94002, saving model to model_131[]\n",
            "INFO:tensorflow:Assets written to: model_131[]/assets\n",
            "7319/7319 [==============================] - 24s 3ms/step - loss: 5.3434 - NN_RMSLE: 2.3060 - val_loss: 9.9400 - val_NN_RMSLE: 3.1200\n",
            "Epoch 7/100\n",
            "7308/7319 [============================>.] - ETA: 0s - loss: 5.3434 - NN_RMSLE: 2.3059\n",
            "Epoch 7: val_loss did not improve from 9.94002\n",
            "7319/7319 [==============================] - 21s 3ms/step - loss: 5.3435 - NN_RMSLE: 2.3059 - val_loss: 9.9891 - val_NN_RMSLE: 3.1275\n",
            "Epoch 8/100\n",
            "7314/7319 [============================>.] - ETA: 0s - loss: 5.3436 - NN_RMSLE: 2.3057\n",
            "Epoch 8: val_loss did not improve from 9.94002\n",
            "7319/7319 [==============================] - 21s 3ms/step - loss: 5.3435 - NN_RMSLE: 2.3057 - val_loss: 9.9899 - val_NN_RMSLE: 3.1277\n",
            "Epoch 9/100\n",
            "7303/7319 [============================>.] - ETA: 0s - loss: 5.3435 - NN_RMSLE: 2.3058\n",
            "Epoch 9: val_loss did not improve from 9.94002\n",
            "7319/7319 [==============================] - 21s 3ms/step - loss: 5.3434 - NN_RMSLE: 2.3058 - val_loss: 9.9826 - val_NN_RMSLE: 3.1265\n",
            "Model: \"sequential_88\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_352 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_264 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_353 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_265 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_354 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_266 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_355 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  9.982597\n",
            "\n",
            "[ 8  9 10 11 12]\n",
            "train 468405 valid 234202\n",
            "Model: \"sequential_89\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_356 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_267 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_357 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_268 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_358 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_269 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_359 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "7312/7319 [============================>.] - ETA: 0s - loss: 8.0676 - NN_RMSLE: 2.8105\n",
            "Epoch 1: val_loss improved from inf to 5.96821, saving model to model_131[]\n",
            "INFO:tensorflow:Assets written to: model_131[]/assets\n",
            "7319/7319 [==============================] - 24s 3ms/step - loss: 8.0661 - NN_RMSLE: 2.8102 - val_loss: 5.9682 - val_NN_RMSLE: 2.4350\n",
            "Epoch 2/100\n",
            "7304/7319 [============================>.] - ETA: 0s - loss: 6.6116 - NN_RMSLE: 2.5676\n",
            "Epoch 2: val_loss did not improve from 5.96821\n",
            "7319/7319 [==============================] - 23s 3ms/step - loss: 6.6113 - NN_RMSLE: 2.5675 - val_loss: 5.9766 - val_NN_RMSLE: 2.4369\n",
            "Epoch 3/100\n",
            "7311/7319 [============================>.] - ETA: 0s - loss: 6.6110 - NN_RMSLE: 2.5674\n",
            "Epoch 3: val_loss did not improve from 5.96821\n",
            "7319/7319 [==============================] - 22s 3ms/step - loss: 6.6112 - NN_RMSLE: 2.5675 - val_loss: 5.9884 - val_NN_RMSLE: 2.4396\n",
            "Epoch 4/100\n",
            "7308/7319 [============================>.] - ETA: 0s - loss: 6.6115 - NN_RMSLE: 2.5676\n",
            "Epoch 4: val_loss did not improve from 5.96821\n",
            "7319/7319 [==============================] - 23s 3ms/step - loss: 6.6112 - NN_RMSLE: 2.5676 - val_loss: 5.9849 - val_NN_RMSLE: 2.4388\n",
            "Model: \"sequential_89\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_356 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_267 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_357 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_268 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_358 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_269 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_359 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  5.9849324\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 132 (763712, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[1 2 3 4 5]\n",
            "train 509141 valid 254571\n",
            "Model: \"sequential_90\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_360 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_270 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_361 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_271 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_362 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_272 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_363 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "7945/7956 [============================>.] - ETA: 0s - loss: 17.6213 - NN_RMSLE: 4.0553\n",
            "Epoch 1: val_loss improved from inf to 7.50988, saving model to model_132[]\n",
            "INFO:tensorflow:Assets written to: model_132[]/assets\n",
            "7956/7956 [==============================] - 25s 3ms/step - loss: 17.6099 - NN_RMSLE: 4.0538 - val_loss: 7.5099 - val_NN_RMSLE: 2.7326\n",
            "Epoch 2/100\n",
            "7948/7956 [============================>.] - ETA: 0s - loss: 8.5216 - NN_RMSLE: 2.9096\n",
            "Epoch 2: val_loss improved from 7.50988 to 6.95378, saving model to model_132[]\n",
            "INFO:tensorflow:Assets written to: model_132[]/assets\n",
            "7956/7956 [==============================] - 31s 4ms/step - loss: 8.5219 - NN_RMSLE: 2.9096 - val_loss: 6.9538 - val_NN_RMSLE: 2.6291\n",
            "Epoch 3/100\n",
            "7943/7956 [============================>.] - ETA: 0s - loss: 8.5197 - NN_RMSLE: 2.9091\n",
            "Epoch 3: val_loss did not improve from 6.95378\n",
            "7956/7956 [==============================] - 29s 4ms/step - loss: 8.5198 - NN_RMSLE: 2.9091 - val_loss: 6.9741 - val_NN_RMSLE: 2.6329\n",
            "Epoch 4/100\n",
            "7938/7956 [============================>.] - ETA: 0s - loss: 8.5197 - NN_RMSLE: 2.9094\n",
            "Epoch 4: val_loss did not improve from 6.95378\n",
            "7956/7956 [==============================] - 24s 3ms/step - loss: 8.5199 - NN_RMSLE: 2.9095 - val_loss: 7.0070 - val_NN_RMSLE: 2.6392\n",
            "Epoch 5/100\n",
            "7945/7956 [============================>.] - ETA: 0s - loss: 8.5205 - NN_RMSLE: 2.9092\n",
            "Epoch 5: val_loss did not improve from 6.95378\n",
            "7956/7956 [==============================] - 26s 3ms/step - loss: 8.5199 - NN_RMSLE: 2.9091 - val_loss: 7.0181 - val_NN_RMSLE: 2.6413\n",
            "Model: \"sequential_90\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_360 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_270 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_361 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_271 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_362 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_272 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_363 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  7.0180817\n",
            "\n",
            "[5 6 7 8 9]\n",
            "train 509141 valid 254571\n",
            "Model: \"sequential_91\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_364 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_273 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_365 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_274 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_366 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_275 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_367 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "7945/7956 [============================>.] - ETA: 0s - loss: 20.3053 - NN_RMSLE: 4.2867\n",
            "Epoch 1: val_loss improved from inf to 10.38940, saving model to model_132[]\n",
            "INFO:tensorflow:Assets written to: model_132[]/assets\n",
            "7956/7956 [==============================] - 26s 3ms/step - loss: 20.2882 - NN_RMSLE: 4.2844 - val_loss: 10.3894 - val_NN_RMSLE: 3.2113\n",
            "Epoch 2/100\n",
            "7950/7956 [============================>.] - ETA: 0s - loss: 6.2880 - NN_RMSLE: 2.4912\n",
            "Epoch 2: val_loss did not improve from 10.38940\n",
            "7956/7956 [==============================] - 23s 3ms/step - loss: 6.2882 - NN_RMSLE: 2.4913 - val_loss: 11.8606 - val_NN_RMSLE: 3.4280\n",
            "Epoch 3/100\n",
            "7945/7956 [============================>.] - ETA: 0s - loss: 6.2667 - NN_RMSLE: 2.4863\n",
            "Epoch 3: val_loss did not improve from 10.38940\n",
            "7956/7956 [==============================] - 24s 3ms/step - loss: 6.2666 - NN_RMSLE: 2.4863 - val_loss: 11.8873 - val_NN_RMSLE: 3.4318\n",
            "Epoch 4/100\n",
            "7942/7956 [============================>.] - ETA: 0s - loss: 6.2659 - NN_RMSLE: 2.4863\n",
            "Epoch 4: val_loss did not improve from 10.38940\n",
            "7956/7956 [==============================] - 26s 3ms/step - loss: 6.2666 - NN_RMSLE: 2.4864 - val_loss: 11.9606 - val_NN_RMSLE: 3.4423\n",
            "Model: \"sequential_91\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_364 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_273 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_365 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_274 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_366 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_275 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_367 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  11.96055\n",
            "\n",
            "[ 9 10 11 12]\n",
            "train 509142 valid 254570\n",
            "Model: \"sequential_92\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_368 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_276 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_369 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_277 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_370 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_278 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_371 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "7955/7956 [============================>.] - ETA: 0s - loss: 18.5473 - NN_RMSLE: 4.1495\n",
            "Epoch 1: val_loss improved from inf to 7.31379, saving model to model_132[]\n",
            "INFO:tensorflow:Assets written to: model_132[]/assets\n",
            "7956/7956 [==============================] - 24s 3ms/step - loss: 18.5469 - NN_RMSLE: 4.1494 - val_loss: 7.3138 - val_NN_RMSLE: 2.6892\n",
            "Epoch 2/100\n",
            "7949/7956 [============================>.] - ETA: 0s - loss: 8.3244 - NN_RMSLE: 2.8743\n",
            "Epoch 2: val_loss improved from 7.31379 to 6.98348, saving model to model_132[]\n",
            "INFO:tensorflow:Assets written to: model_132[]/assets\n",
            "7956/7956 [==============================] - 26s 3ms/step - loss: 8.3250 - NN_RMSLE: 2.8744 - val_loss: 6.9835 - val_NN_RMSLE: 2.6163\n",
            "Epoch 3/100\n",
            "7948/7956 [============================>.] - ETA: 0s - loss: 8.3210 - NN_RMSLE: 2.8736\n",
            "Epoch 3: val_loss improved from 6.98348 to 6.97139, saving model to model_132[]\n",
            "INFO:tensorflow:Assets written to: model_132[]/assets\n",
            "7956/7956 [==============================] - 25s 3ms/step - loss: 8.3210 - NN_RMSLE: 2.8736 - val_loss: 6.9714 - val_NN_RMSLE: 2.6133\n",
            "Epoch 4/100\n",
            "7945/7956 [============================>.] - ETA: 0s - loss: 8.3210 - NN_RMSLE: 2.8740\n",
            "Epoch 4: val_loss did not improve from 6.97139\n",
            "7956/7956 [==============================] - 25s 3ms/step - loss: 8.3209 - NN_RMSLE: 2.8740 - val_loss: 6.9820 - val_NN_RMSLE: 2.6159\n",
            "Epoch 5/100\n",
            "7950/7956 [============================>.] - ETA: 0s - loss: 8.3208 - NN_RMSLE: 2.8740\n",
            "Epoch 5: val_loss did not improve from 6.97139\n",
            "7956/7956 [==============================] - 23s 3ms/step - loss: 8.3209 - NN_RMSLE: 2.8740 - val_loss: 6.9943 - val_NN_RMSLE: 2.6189\n",
            "Epoch 6/100\n",
            "7949/7956 [============================>.] - ETA: 0s - loss: 8.3211 - NN_RMSLE: 2.8740\n",
            "Epoch 6: val_loss did not improve from 6.97139\n",
            "7956/7956 [==============================] - 25s 3ms/step - loss: 8.3209 - NN_RMSLE: 2.8740 - val_loss: 6.9876 - val_NN_RMSLE: 2.6173\n",
            "Model: \"sequential_92\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_368 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_276 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_369 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_277 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_370 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_278 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_371 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  6.9875884\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 140 (850670, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[1 2 3 4 5 6 7 8]\n",
            "train 567113 valid 283557\n",
            "Model: \"sequential_93\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_372 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_279 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_373 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_280 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_374 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_281 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_375 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "8848/8862 [============================>.] - ETA: 0s - loss: 5.7526 - NN_RMSLE: 2.1177\n",
            "Epoch 1: val_loss improved from inf to 1.18567, saving model to model_140[]\n",
            "INFO:tensorflow:Assets written to: model_140[]/assets\n",
            "8862/8862 [==============================] - 26s 3ms/step - loss: 5.7461 - NN_RMSLE: 2.1162 - val_loss: 1.1857 - val_NN_RMSLE: 1.0849\n",
            "Epoch 2/100\n",
            "8844/8862 [============================>.] - ETA: 0s - loss: 1.3083 - NN_RMSLE: 1.1388\n",
            "Epoch 2: val_loss improved from 1.18567 to 1.18552, saving model to model_140[]\n",
            "INFO:tensorflow:Assets written to: model_140[]/assets\n",
            "8862/8862 [==============================] - 29s 3ms/step - loss: 1.3084 - NN_RMSLE: 1.1388 - val_loss: 1.1855 - val_NN_RMSLE: 1.0849\n",
            "Epoch 3/100\n",
            "8852/8862 [============================>.] - ETA: 0s - loss: 1.3085 - NN_RMSLE: 1.1389\n",
            "Epoch 3: val_loss did not improve from 1.18552\n",
            "8862/8862 [==============================] - 25s 3ms/step - loss: 1.3084 - NN_RMSLE: 1.1389 - val_loss: 1.1855 - val_NN_RMSLE: 1.0849\n",
            "Epoch 4/100\n",
            "8848/8862 [============================>.] - ETA: 0s - loss: 1.3082 - NN_RMSLE: 1.1387\n",
            "Epoch 4: val_loss improved from 1.18552 to 1.18501, saving model to model_140[]\n",
            "INFO:tensorflow:Assets written to: model_140[]/assets\n",
            "8862/8862 [==============================] - 29s 3ms/step - loss: 1.3084 - NN_RMSLE: 1.1389 - val_loss: 1.1850 - val_NN_RMSLE: 1.0846\n",
            "Epoch 5/100\n",
            "8850/8862 [============================>.] - ETA: 0s - loss: 1.3083 - NN_RMSLE: 1.1388\n",
            "Epoch 5: val_loss did not improve from 1.18501\n",
            "8862/8862 [==============================] - 28s 3ms/step - loss: 1.3084 - NN_RMSLE: 1.1388 - val_loss: 1.1872 - val_NN_RMSLE: 1.0856\n",
            "Epoch 6/100\n",
            "8851/8862 [============================>.] - ETA: 0s - loss: 1.3083 - NN_RMSLE: 1.1387\n",
            "Epoch 6: val_loss did not improve from 1.18501\n",
            "8862/8862 [==============================] - 26s 3ms/step - loss: 1.3084 - NN_RMSLE: 1.1387 - val_loss: 1.1853 - val_NN_RMSLE: 1.0847\n",
            "Epoch 7/100\n",
            "8855/8862 [============================>.] - ETA: 0s - loss: 1.3084 - NN_RMSLE: 1.1389\n",
            "Epoch 7: val_loss improved from 1.18501 to 1.18500, saving model to model_140[]\n",
            "INFO:tensorflow:Assets written to: model_140[]/assets\n",
            "8862/8862 [==============================] - 27s 3ms/step - loss: 1.3084 - NN_RMSLE: 1.1388 - val_loss: 1.1850 - val_NN_RMSLE: 1.0846\n",
            "Epoch 8/100\n",
            "8853/8862 [============================>.] - ETA: 0s - loss: 1.3085 - NN_RMSLE: 1.1388\n",
            "Epoch 8: val_loss did not improve from 1.18500\n",
            "8862/8862 [==============================] - 28s 3ms/step - loss: 1.3084 - NN_RMSLE: 1.1388 - val_loss: 1.1856 - val_NN_RMSLE: 1.0849\n",
            "Epoch 9/100\n",
            "8844/8862 [============================>.] - ETA: 0s - loss: 1.3085 - NN_RMSLE: 1.1387\n",
            "Epoch 9: val_loss did not improve from 1.18500\n",
            "8862/8862 [==============================] - 28s 3ms/step - loss: 1.3084 - NN_RMSLE: 1.1386 - val_loss: 1.1867 - val_NN_RMSLE: 1.0854\n",
            "Epoch 10/100\n",
            "8851/8862 [============================>.] - ETA: 0s - loss: 1.3085 - NN_RMSLE: 1.1388\n",
            "Epoch 10: val_loss improved from 1.18500 to 1.18451, saving model to model_140[]\n",
            "INFO:tensorflow:Assets written to: model_140[]/assets\n",
            "8862/8862 [==============================] - 29s 3ms/step - loss: 1.3084 - NN_RMSLE: 1.1387 - val_loss: 1.1845 - val_NN_RMSLE: 1.0844\n",
            "Epoch 11/100\n",
            "8845/8862 [============================>.] - ETA: 0s - loss: 1.3083 - NN_RMSLE: 1.1387\n",
            "Epoch 11: val_loss did not improve from 1.18451\n",
            "8862/8862 [==============================] - 25s 3ms/step - loss: 1.3084 - NN_RMSLE: 1.1387 - val_loss: 1.1861 - val_NN_RMSLE: 1.0851\n",
            "Epoch 12/100\n",
            "8859/8862 [============================>.] - ETA: 0s - loss: 1.3084 - NN_RMSLE: 1.1388\n",
            "Epoch 12: val_loss did not improve from 1.18451\n",
            "8862/8862 [==============================] - 28s 3ms/step - loss: 1.3084 - NN_RMSLE: 1.1388 - val_loss: 1.1854 - val_NN_RMSLE: 1.0848\n",
            "Epoch 13/100\n",
            "8853/8862 [============================>.] - ETA: 0s - loss: 1.3083 - NN_RMSLE: 1.1387\n",
            "Epoch 13: val_loss did not improve from 1.18451\n",
            "8862/8862 [==============================] - 28s 3ms/step - loss: 1.3084 - NN_RMSLE: 1.1388 - val_loss: 1.1858 - val_NN_RMSLE: 1.0850\n",
            "Model: \"sequential_93\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_372 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_279 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_373 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_280 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_374 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_281 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_375 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.1857984\n",
            "\n",
            "[ 3  4  5  6  7  8  9 10]\n",
            "train 567113 valid 283557\n",
            "Model: \"sequential_94\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_376 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_282 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_377 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_283 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_378 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_284 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_379 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "8851/8862 [============================>.] - ETA: 0s - loss: 5.7677 - NN_RMSLE: 2.1121\n",
            "Epoch 1: val_loss improved from inf to 1.30672, saving model to model_140[]\n",
            "INFO:tensorflow:Assets written to: model_140[]/assets\n",
            "8862/8862 [==============================] - 28s 3ms/step - loss: 5.7623 - NN_RMSLE: 2.1107 - val_loss: 1.3067 - val_NN_RMSLE: 1.1383\n",
            "Epoch 2/100\n",
            "8862/8862 [==============================] - ETA: 0s - loss: 1.2475 - NN_RMSLE: 1.1122\n",
            "Epoch 2: val_loss did not improve from 1.30672\n",
            "8862/8862 [==============================] - 28s 3ms/step - loss: 1.2475 - NN_RMSLE: 1.1122 - val_loss: 1.3076 - val_NN_RMSLE: 1.1387\n",
            "Epoch 3/100\n",
            "8861/8862 [============================>.] - ETA: 0s - loss: 1.2475 - NN_RMSLE: 1.1122\n",
            "Epoch 3: val_loss did not improve from 1.30672\n",
            "8862/8862 [==============================] - 28s 3ms/step - loss: 1.2475 - NN_RMSLE: 1.1122 - val_loss: 1.3070 - val_NN_RMSLE: 1.1384\n",
            "Epoch 4/100\n",
            "8862/8862 [==============================] - ETA: 0s - loss: 1.2475 - NN_RMSLE: 1.1120\n",
            "Epoch 4: val_loss did not improve from 1.30672\n",
            "8862/8862 [==============================] - 28s 3ms/step - loss: 1.2475 - NN_RMSLE: 1.1120 - val_loss: 1.3069 - val_NN_RMSLE: 1.1384\n",
            "Model: \"sequential_94\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_376 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_282 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_377 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_283 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_378 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_284 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_379 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.3068655\n",
            "\n",
            "[ 6  7  8  9 10 11 12]\n",
            "train 567114 valid 283556\n",
            "Model: \"sequential_95\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_380 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_285 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_381 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_286 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_382 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_287 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_383 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "8851/8862 [============================>.] - ETA: 0s - loss: 5.7358 - NN_RMSLE: 2.1072\n",
            "Epoch 1: val_loss improved from inf to 1.31079, saving model to model_140[]\n",
            "INFO:tensorflow:Assets written to: model_140[]/assets\n",
            "8862/8862 [==============================] - 28s 3ms/step - loss: 5.7307 - NN_RMSLE: 2.1060 - val_loss: 1.3108 - val_NN_RMSLE: 1.1398\n",
            "Epoch 2/100\n",
            "8851/8862 [============================>.] - ETA: 0s - loss: 1.2456 - NN_RMSLE: 1.1116\n",
            "Epoch 2: val_loss improved from 1.31079 to 1.31072, saving model to model_140[]\n",
            "INFO:tensorflow:Assets written to: model_140[]/assets\n",
            "8862/8862 [==============================] - 28s 3ms/step - loss: 1.2456 - NN_RMSLE: 1.1116 - val_loss: 1.3107 - val_NN_RMSLE: 1.1398\n",
            "Epoch 3/100\n",
            "8861/8862 [============================>.] - ETA: 0s - loss: 1.2456 - NN_RMSLE: 1.1114\n",
            "Epoch 3: val_loss improved from 1.31072 to 1.31061, saving model to model_140[]\n",
            "INFO:tensorflow:Assets written to: model_140[]/assets\n",
            "8862/8862 [==============================] - 27s 3ms/step - loss: 1.2456 - NN_RMSLE: 1.1114 - val_loss: 1.3106 - val_NN_RMSLE: 1.1398\n",
            "Epoch 4/100\n",
            "8859/8862 [============================>.] - ETA: 0s - loss: 1.2456 - NN_RMSLE: 1.1117\n",
            "Epoch 4: val_loss did not improve from 1.31061\n",
            "8862/8862 [==============================] - 26s 3ms/step - loss: 1.2456 - NN_RMSLE: 1.1118 - val_loss: 1.3106 - val_NN_RMSLE: 1.1398\n",
            "Epoch 5/100\n",
            "8855/8862 [============================>.] - ETA: 0s - loss: 1.2456 - NN_RMSLE: 1.1116\n",
            "Epoch 5: val_loss improved from 1.31061 to 1.31059, saving model to model_140[]\n",
            "INFO:tensorflow:Assets written to: model_140[]/assets\n",
            "8862/8862 [==============================] - 28s 3ms/step - loss: 1.2456 - NN_RMSLE: 1.1116 - val_loss: 1.3106 - val_NN_RMSLE: 1.1398\n",
            "Epoch 6/100\n",
            "8852/8862 [============================>.] - ETA: 0s - loss: 1.2456 - NN_RMSLE: 1.1115\n",
            "Epoch 6: val_loss improved from 1.31059 to 1.31056, saving model to model_140[]\n",
            "INFO:tensorflow:Assets written to: model_140[]/assets\n",
            "8862/8862 [==============================] - 28s 3ms/step - loss: 1.2456 - NN_RMSLE: 1.1115 - val_loss: 1.3106 - val_NN_RMSLE: 1.1398\n",
            "Epoch 7/100\n",
            "8846/8862 [============================>.] - ETA: 0s - loss: 1.2455 - NN_RMSLE: 1.1114\n",
            "Epoch 7: val_loss did not improve from 1.31056\n",
            "8862/8862 [==============================] - 28s 3ms/step - loss: 1.2456 - NN_RMSLE: 1.1115 - val_loss: 1.3106 - val_NN_RMSLE: 1.1398\n",
            "Epoch 8/100\n",
            "8844/8862 [============================>.] - ETA: 0s - loss: 1.2458 - NN_RMSLE: 1.1117\n",
            "Epoch 8: val_loss did not improve from 1.31056\n",
            "8862/8862 [==============================] - 31s 4ms/step - loss: 1.2456 - NN_RMSLE: 1.1116 - val_loss: 1.3106 - val_NN_RMSLE: 1.1398\n",
            "Epoch 9/100\n",
            "8848/8862 [============================>.] - ETA: 0s - loss: 1.2456 - NN_RMSLE: 1.1116\n",
            "Epoch 9: val_loss improved from 1.31056 to 1.31055, saving model to model_140[]\n",
            "INFO:tensorflow:Assets written to: model_140[]/assets\n",
            "8862/8862 [==============================] - 28s 3ms/step - loss: 1.2456 - NN_RMSLE: 1.1116 - val_loss: 1.3106 - val_NN_RMSLE: 1.1398\n",
            "Epoch 10/100\n",
            "8845/8862 [============================>.] - ETA: 0s - loss: 1.2455 - NN_RMSLE: 1.1115\n",
            "Epoch 10: val_loss did not improve from 1.31055\n",
            "8862/8862 [==============================] - 30s 3ms/step - loss: 1.2456 - NN_RMSLE: 1.1116 - val_loss: 1.3106 - val_NN_RMSLE: 1.1398\n",
            "Epoch 11/100\n",
            "8853/8862 [============================>.] - ETA: 0s - loss: 1.2456 - NN_RMSLE: 1.1116\n",
            "Epoch 11: val_loss did not improve from 1.31055\n",
            "8862/8862 [==============================] - 28s 3ms/step - loss: 1.2456 - NN_RMSLE: 1.1115 - val_loss: 1.3106 - val_NN_RMSLE: 1.1398\n",
            "Epoch 12/100\n",
            "8860/8862 [============================>.] - ETA: 0s - loss: 1.2456 - NN_RMSLE: 1.1115\n",
            "Epoch 12: val_loss improved from 1.31055 to 1.31055, saving model to model_140[]\n",
            "INFO:tensorflow:Assets written to: model_140[]/assets\n",
            "8862/8862 [==============================] - 31s 3ms/step - loss: 1.2456 - NN_RMSLE: 1.1115 - val_loss: 1.3106 - val_NN_RMSLE: 1.1398\n",
            "Epoch 13/100\n",
            "8855/8862 [============================>.] - ETA: 0s - loss: 1.2457 - NN_RMSLE: 1.1115\n",
            "Epoch 13: val_loss did not improve from 1.31055\n",
            "8862/8862 [==============================] - 26s 3ms/step - loss: 1.2456 - NN_RMSLE: 1.1115 - val_loss: 1.3107 - val_NN_RMSLE: 1.1398\n",
            "Epoch 14/100\n",
            "8858/8862 [============================>.] - ETA: 0s - loss: 1.2455 - NN_RMSLE: 1.1115\n",
            "Epoch 14: val_loss did not improve from 1.31055\n",
            "8862/8862 [==============================] - 30s 3ms/step - loss: 1.2456 - NN_RMSLE: 1.1115 - val_loss: 1.3106 - val_NN_RMSLE: 1.1398\n",
            "Epoch 15/100\n",
            "8862/8862 [==============================] - ETA: 0s - loss: 1.2456 - NN_RMSLE: 1.1116\n",
            "Epoch 15: val_loss did not improve from 1.31055\n",
            "8862/8862 [==============================] - 27s 3ms/step - loss: 1.2456 - NN_RMSLE: 1.1116 - val_loss: 1.3107 - val_NN_RMSLE: 1.1398\n",
            "Model: \"sequential_95\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_380 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_285 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_381 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_286 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_382 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_287 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_383 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.3107207\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 141 (717154, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[1 2 3 4 5 6]\n",
            "train 478102 valid 239052\n",
            "Model: \"sequential_96\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_384 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_288 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_385 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_289 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_386 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_290 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_387 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "7460/7471 [============================>.] - ETA: 0s - loss: 14.9914 - NN_RMSLE: 3.7043\n",
            "Epoch 1: val_loss improved from inf to 7.93170, saving model to model_141[]\n",
            "INFO:tensorflow:Assets written to: model_141[]/assets\n",
            "7471/7471 [==============================] - 23s 3ms/step - loss: 14.9792 - NN_RMSLE: 3.7025 - val_loss: 7.9317 - val_NN_RMSLE: 2.7635\n",
            "Epoch 2/100\n",
            "7453/7471 [============================>.] - ETA: 0s - loss: 5.9427 - NN_RMSLE: 2.4252\n",
            "Epoch 2: val_loss did not improve from 7.93170\n",
            "7471/7471 [==============================] - 29s 4ms/step - loss: 5.9432 - NN_RMSLE: 2.4253 - val_loss: 8.5242 - val_NN_RMSLE: 2.8513\n",
            "Epoch 3/100\n",
            "7467/7471 [============================>.] - ETA: 0s - loss: 5.9391 - NN_RMSLE: 2.4246\n",
            "Epoch 3: val_loss did not improve from 7.93170\n",
            "7471/7471 [==============================] - 24s 3ms/step - loss: 5.9390 - NN_RMSLE: 2.4245 - val_loss: 8.5240 - val_NN_RMSLE: 2.8513\n",
            "Epoch 4/100\n",
            "7464/7471 [============================>.] - ETA: 0s - loss: 5.9393 - NN_RMSLE: 2.4245\n",
            "Epoch 4: val_loss did not improve from 7.93170\n",
            "7471/7471 [==============================] - 23s 3ms/step - loss: 5.9390 - NN_RMSLE: 2.4244 - val_loss: 8.5243 - val_NN_RMSLE: 2.8513\n",
            "Model: \"sequential_96\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_384 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_288 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_385 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_289 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_386 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_290 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_387 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  8.524246\n",
            "\n",
            "[ 4  5  6  7  8  9 10]\n",
            "train 478103 valid 239051\n",
            "Model: \"sequential_97\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_388 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_291 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_389 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_292 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_390 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_293 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_391 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "7458/7471 [============================>.] - ETA: 0s - loss: 12.4917 - NN_RMSLE: 3.4356\n",
            "Epoch 1: val_loss improved from inf to 6.71100, saving model to model_141[]\n",
            "INFO:tensorflow:Assets written to: model_141[]/assets\n",
            "7471/7471 [==============================] - 25s 3ms/step - loss: 12.4837 - NN_RMSLE: 3.4344 - val_loss: 6.7110 - val_NN_RMSLE: 2.5783\n",
            "Epoch 2/100\n",
            "7454/7471 [============================>.] - ETA: 0s - loss: 7.1831 - NN_RMSLE: 2.6734\n",
            "Epoch 2: val_loss improved from 6.71100 to 6.45439, saving model to model_141[]\n",
            "INFO:tensorflow:Assets written to: model_141[]/assets\n",
            "7471/7471 [==============================] - 25s 3ms/step - loss: 7.1827 - NN_RMSLE: 2.6734 - val_loss: 6.4544 - val_NN_RMSLE: 2.5284\n",
            "Epoch 3/100\n",
            "7464/7471 [============================>.] - ETA: 0s - loss: 7.1823 - NN_RMSLE: 2.6733\n",
            "Epoch 3: val_loss improved from 6.45439 to 6.43919, saving model to model_141[]\n",
            "INFO:tensorflow:Assets written to: model_141[]/assets\n",
            "7471/7471 [==============================] - 25s 3ms/step - loss: 7.1824 - NN_RMSLE: 2.6733 - val_loss: 6.4392 - val_NN_RMSLE: 2.5254\n",
            "Epoch 4/100\n",
            "7459/7471 [============================>.] - ETA: 0s - loss: 7.1825 - NN_RMSLE: 2.6733\n",
            "Epoch 4: val_loss did not improve from 6.43919\n",
            "7471/7471 [==============================] - 25s 3ms/step - loss: 7.1824 - NN_RMSLE: 2.6733 - val_loss: 6.5070 - val_NN_RMSLE: 2.5387\n",
            "Epoch 5/100\n",
            "7461/7471 [============================>.] - ETA: 0s - loss: 7.1830 - NN_RMSLE: 2.6734\n",
            "Epoch 5: val_loss improved from 6.43919 to 6.38477, saving model to model_141[]\n",
            "INFO:tensorflow:Assets written to: model_141[]/assets\n",
            "7471/7471 [==============================] - 26s 3ms/step - loss: 7.1824 - NN_RMSLE: 2.6732 - val_loss: 6.3848 - val_NN_RMSLE: 2.5147\n",
            "Epoch 6/100\n",
            "7457/7471 [============================>.] - ETA: 0s - loss: 7.1815 - NN_RMSLE: 2.6731\n",
            "Epoch 6: val_loss did not improve from 6.38477\n",
            "7471/7471 [==============================] - 22s 3ms/step - loss: 7.1824 - NN_RMSLE: 2.6733 - val_loss: 6.4274 - val_NN_RMSLE: 2.5231\n",
            "Epoch 7/100\n",
            "7468/7471 [============================>.] - ETA: 0s - loss: 7.1825 - NN_RMSLE: 2.6732\n",
            "Epoch 7: val_loss did not improve from 6.38477\n",
            "7471/7471 [==============================] - 24s 3ms/step - loss: 7.1824 - NN_RMSLE: 2.6732 - val_loss: 6.4095 - val_NN_RMSLE: 2.5196\n",
            "Epoch 8/100\n",
            "7465/7471 [============================>.] - ETA: 0s - loss: 7.1824 - NN_RMSLE: 2.6732\n",
            "Epoch 8: val_loss did not improve from 6.38477\n",
            "7471/7471 [==============================] - 23s 3ms/step - loss: 7.1823 - NN_RMSLE: 2.6732 - val_loss: 6.4480 - val_NN_RMSLE: 2.5271\n",
            "Model: \"sequential_97\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_388 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_291 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_389 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_292 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_390 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_293 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_391 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  6.4479938\n",
            "\n",
            "[ 7  8  9 10 11 12]\n",
            "train 478103 valid 239051\n",
            "Model: \"sequential_98\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_392 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_294 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_393 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_295 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_394 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_296 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_395 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "7466/7471 [============================>.] - ETA: 0s - loss: 14.2594 - NN_RMSLE: 3.6280\n",
            "Epoch 1: val_loss improved from inf to 7.19168, saving model to model_141[]\n",
            "INFO:tensorflow:Assets written to: model_141[]/assets\n",
            "7471/7471 [==============================] - 28s 4ms/step - loss: 14.2549 - NN_RMSLE: 3.6273 - val_loss: 7.1917 - val_NN_RMSLE: 2.6278\n",
            "Epoch 2/100\n",
            "7461/7471 [============================>.] - ETA: 0s - loss: 6.3313 - NN_RMSLE: 2.5056\n",
            "Epoch 2: val_loss did not improve from 7.19168\n",
            "7471/7471 [==============================] - 24s 3ms/step - loss: 6.3310 - NN_RMSLE: 2.5055 - val_loss: 7.3326 - val_NN_RMSLE: 2.6342\n",
            "Epoch 3/100\n",
            "7461/7471 [============================>.] - ETA: 0s - loss: 6.3284 - NN_RMSLE: 2.5049\n",
            "Epoch 3: val_loss did not improve from 7.19168\n",
            "7471/7471 [==============================] - 24s 3ms/step - loss: 6.3287 - NN_RMSLE: 2.5050 - val_loss: 7.3146 - val_NN_RMSLE: 2.6330\n",
            "Epoch 4/100\n",
            "7462/7471 [============================>.] - ETA: 0s - loss: 6.3292 - NN_RMSLE: 2.5049\n",
            "Epoch 4: val_loss did not improve from 7.19168\n",
            "7471/7471 [==============================] - 25s 3ms/step - loss: 6.3287 - NN_RMSLE: 2.5048 - val_loss: 7.3371 - val_NN_RMSLE: 2.6345\n",
            "Model: \"sequential_98\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_392 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_294 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_393 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_295 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_394 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_296 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_395 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  7.3370833\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 143 (487253, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[1 2 3 4 5 6 7]\n",
            "train 324835 valid 162418\n",
            "Model: \"sequential_99\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_396 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_297 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_397 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_298 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_398 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_299 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_399 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "5072/5076 [============================>.] - ETA: 0s - loss: 11.9480 - NN_RMSLE: 3.3879\n",
            "Epoch 1: val_loss improved from inf to 7.54049, saving model to model_143[]\n",
            "INFO:tensorflow:Assets written to: model_143[]/assets\n",
            "5076/5076 [==============================] - 17s 3ms/step - loss: 11.9442 - NN_RMSLE: 3.3872 - val_loss: 7.5405 - val_NN_RMSLE: 2.7373\n",
            "Epoch 2/100\n",
            "5066/5076 [============================>.] - ETA: 0s - loss: 6.5728 - NN_RMSLE: 2.5597\n",
            "Epoch 2: val_loss improved from 7.54049 to 6.41263, saving model to model_143[]\n",
            "INFO:tensorflow:Assets written to: model_143[]/assets\n",
            "5076/5076 [==============================] - 22s 4ms/step - loss: 6.5730 - NN_RMSLE: 2.5598 - val_loss: 6.4126 - val_NN_RMSLE: 2.5216\n",
            "Epoch 3/100\n",
            "5050/5076 [============================>.] - ETA: 0s - loss: 6.5511 - NN_RMSLE: 2.5550\n",
            "Epoch 3: val_loss did not improve from 6.41263\n",
            "5076/5076 [==============================] - 16s 3ms/step - loss: 6.5515 - NN_RMSLE: 2.5551 - val_loss: 6.4136 - val_NN_RMSLE: 2.5218\n",
            "Epoch 4/100\n",
            "5065/5076 [============================>.] - ETA: 0s - loss: 6.5519 - NN_RMSLE: 2.5551\n",
            "Epoch 4: val_loss improved from 6.41263 to 6.37809, saving model to model_143[]\n",
            "INFO:tensorflow:Assets written to: model_143[]/assets\n",
            "5076/5076 [==============================] - 17s 3ms/step - loss: 6.5516 - NN_RMSLE: 2.5551 - val_loss: 6.3781 - val_NN_RMSLE: 2.5146\n",
            "Epoch 5/100\n",
            "5056/5076 [============================>.] - ETA: 0s - loss: 6.5524 - NN_RMSLE: 2.5553\n",
            "Epoch 5: val_loss improved from 6.37809 to 6.33802, saving model to model_143[]\n",
            "INFO:tensorflow:Assets written to: model_143[]/assets\n",
            "5076/5076 [==============================] - 17s 3ms/step - loss: 6.5516 - NN_RMSLE: 2.5552 - val_loss: 6.3380 - val_NN_RMSLE: 2.5063\n",
            "Epoch 6/100\n",
            "5055/5076 [============================>.] - ETA: 0s - loss: 6.5515 - NN_RMSLE: 2.5552\n",
            "Epoch 6: val_loss did not improve from 6.33802\n",
            "5076/5076 [==============================] - 15s 3ms/step - loss: 6.5515 - NN_RMSLE: 2.5552 - val_loss: 6.4253 - val_NN_RMSLE: 2.5242\n",
            "Epoch 7/100\n",
            "5062/5076 [============================>.] - ETA: 0s - loss: 6.5517 - NN_RMSLE: 2.5552\n",
            "Epoch 7: val_loss did not improve from 6.33802\n",
            "5076/5076 [==============================] - 16s 3ms/step - loss: 6.5516 - NN_RMSLE: 2.5553 - val_loss: 6.3751 - val_NN_RMSLE: 2.5140\n",
            "Epoch 8/100\n",
            "5062/5076 [============================>.] - ETA: 0s - loss: 6.5516 - NN_RMSLE: 2.5549\n",
            "Epoch 8: val_loss did not improve from 6.33802\n",
            "5076/5076 [==============================] - 16s 3ms/step - loss: 6.5515 - NN_RMSLE: 2.5549 - val_loss: 6.4120 - val_NN_RMSLE: 2.5215\n",
            "Model: \"sequential_99\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_396 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_297 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_397 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_298 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_398 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_299 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_399 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  6.4120173\n",
            "\n",
            "[ 4  5  6  7  8  9 10]\n",
            "train 324835 valid 162418\n",
            "Model: \"sequential_100\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_400 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_300 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_401 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_301 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_402 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_302 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_403 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "5065/5076 [============================>.] - ETA: 0s - loss: 14.2813 - NN_RMSLE: 3.6830\n",
            "Epoch 1: val_loss improved from inf to 6.73734, saving model to model_143[]\n",
            "INFO:tensorflow:Assets written to: model_143[]/assets\n",
            "5076/5076 [==============================] - 17s 3ms/step - loss: 14.2655 - NN_RMSLE: 3.6806 - val_loss: 6.7373 - val_NN_RMSLE: 2.5904\n",
            "Epoch 2/100\n",
            "5059/5076 [============================>.] - ETA: 0s - loss: 5.9518 - NN_RMSLE: 2.4321\n",
            "Epoch 2: val_loss did not improve from 6.73734\n",
            "5076/5076 [==============================] - 17s 3ms/step - loss: 5.9531 - NN_RMSLE: 2.4324 - val_loss: 7.8076 - val_NN_RMSLE: 2.7791\n",
            "Epoch 3/100\n",
            "5060/5076 [============================>.] - ETA: 0s - loss: 5.8559 - NN_RMSLE: 2.4114\n",
            "Epoch 3: val_loss did not improve from 6.73734\n",
            "5076/5076 [==============================] - 15s 3ms/step - loss: 5.8560 - NN_RMSLE: 2.4114 - val_loss: 7.7834 - val_NN_RMSLE: 2.7749\n",
            "Epoch 4/100\n",
            "5073/5076 [============================>.] - ETA: 0s - loss: 5.8557 - NN_RMSLE: 2.4115\n",
            "Epoch 4: val_loss did not improve from 6.73734\n",
            "5076/5076 [==============================] - 19s 4ms/step - loss: 5.8559 - NN_RMSLE: 2.4116 - val_loss: 7.8165 - val_NN_RMSLE: 2.7807\n",
            "Model: \"sequential_100\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_400 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_300 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_401 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_301 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_402 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_302 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_403 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  7.8165426\n",
            "\n",
            "[ 8  9 10 11 12]\n",
            "train 324836 valid 162417\n",
            "Model: \"sequential_101\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_404 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_303 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_405 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_304 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_406 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_305 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_407 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "5065/5076 [============================>.] - ETA: 0s - loss: 13.2513 - NN_RMSLE: 3.5601\n",
            "Epoch 1: val_loss improved from inf to 6.61085, saving model to model_143[]\n",
            "INFO:tensorflow:Assets written to: model_143[]/assets\n",
            "5076/5076 [==============================] - 16s 3ms/step - loss: 13.2378 - NN_RMSLE: 3.5580 - val_loss: 6.6109 - val_NN_RMSLE: 2.5653\n",
            "Epoch 2/100\n",
            "5074/5076 [============================>.] - ETA: 0s - loss: 6.5565 - NN_RMSLE: 2.5553\n",
            "Epoch 2: val_loss improved from 6.61085 to 6.13241, saving model to model_143[]\n",
            "INFO:tensorflow:Assets written to: model_143[]/assets\n",
            "5076/5076 [==============================] - 15s 3ms/step - loss: 6.5564 - NN_RMSLE: 2.5553 - val_loss: 6.1324 - val_NN_RMSLE: 2.4573\n",
            "Epoch 3/100\n",
            "5061/5076 [============================>.] - ETA: 0s - loss: 6.5106 - NN_RMSLE: 2.5457\n",
            "Epoch 3: val_loss did not improve from 6.13241\n",
            "5076/5076 [==============================] - 15s 3ms/step - loss: 6.5108 - NN_RMSLE: 2.5457 - val_loss: 6.1342 - val_NN_RMSLE: 2.4582\n",
            "Epoch 4/100\n",
            "5076/5076 [==============================] - ETA: 0s - loss: 6.5109 - NN_RMSLE: 2.5459\n",
            "Epoch 4: val_loss improved from 6.13241 to 6.13234, saving model to model_143[]\n",
            "INFO:tensorflow:Assets written to: model_143[]/assets\n",
            "5076/5076 [==============================] - 15s 3ms/step - loss: 6.5109 - NN_RMSLE: 2.5459 - val_loss: 6.1323 - val_NN_RMSLE: 2.4573\n",
            "Epoch 5/100\n",
            "5056/5076 [============================>.] - ETA: 0s - loss: 6.5104 - NN_RMSLE: 2.5456\n",
            "Epoch 5: val_loss improved from 6.13234 to 6.13103, saving model to model_143[]\n",
            "INFO:tensorflow:Assets written to: model_143[]/assets\n",
            "5076/5076 [==============================] - 15s 3ms/step - loss: 6.5108 - NN_RMSLE: 2.5457 - val_loss: 6.1310 - val_NN_RMSLE: 2.4565\n",
            "Epoch 6/100\n",
            "5062/5076 [============================>.] - ETA: 0s - loss: 6.5117 - NN_RMSLE: 2.5459\n",
            "Epoch 6: val_loss did not improve from 6.13103\n",
            "5076/5076 [==============================] - 17s 3ms/step - loss: 6.5108 - NN_RMSLE: 2.5457 - val_loss: 6.1322 - val_NN_RMSLE: 2.4572\n",
            "Epoch 7/100\n",
            "5071/5076 [============================>.] - ETA: 0s - loss: 6.5107 - NN_RMSLE: 2.5459\n",
            "Epoch 7: val_loss did not improve from 6.13103\n",
            "5076/5076 [==============================] - 16s 3ms/step - loss: 6.5107 - NN_RMSLE: 2.5459 - val_loss: 6.1325 - val_NN_RMSLE: 2.4573\n",
            "Epoch 8/100\n",
            "5058/5076 [============================>.] - ETA: 0s - loss: 6.5105 - NN_RMSLE: 2.5459\n",
            "Epoch 8: val_loss did not improve from 6.13103\n",
            "5076/5076 [==============================] - 16s 3ms/step - loss: 6.5108 - NN_RMSLE: 2.5460 - val_loss: 6.1318 - val_NN_RMSLE: 2.4570\n",
            "Model: \"sequential_101\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_404 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_303 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_405 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_304 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_406 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_305 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_407 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  6.1318135\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 142 (346087, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[ 1  2  3  4  5  6  7  8 12]\n",
            "train 230724 valid 115363\n",
            "Model: \"sequential_102\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_408 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_306 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_409 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_307 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_410 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_308 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_411 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "3596/3606 [============================>.] - ETA: 0s - loss: 22.8993 - NN_RMSLE: 4.7155\n",
            "Epoch 1: val_loss improved from inf to 14.04784, saving model to model_142[]\n",
            "INFO:tensorflow:Assets written to: model_142[]/assets\n",
            "3606/3606 [==============================] - 13s 4ms/step - loss: 22.8708 - NN_RMSLE: 4.7119 - val_loss: 14.0478 - val_NN_RMSLE: 3.7366\n",
            "Epoch 2/100\n",
            "3596/3606 [============================>.] - ETA: 0s - loss: 7.5208 - NN_RMSLE: 2.7152\n",
            "Epoch 2: val_loss improved from 14.04784 to 5.36516, saving model to model_142[]\n",
            "INFO:tensorflow:Assets written to: model_142[]/assets\n",
            "3606/3606 [==============================] - 17s 5ms/step - loss: 7.5156 - NN_RMSLE: 2.7143 - val_loss: 5.3652 - val_NN_RMSLE: 2.3000\n",
            "Epoch 3/100\n",
            "3585/3606 [============================>.] - ETA: 0s - loss: 5.1834 - NN_RMSLE: 2.2635\n",
            "Epoch 3: val_loss improved from 5.36516 to 4.79337, saving model to model_142[]\n",
            "INFO:tensorflow:Assets written to: model_142[]/assets\n",
            "3606/3606 [==============================] - 11s 3ms/step - loss: 5.1837 - NN_RMSLE: 2.2638 - val_loss: 4.7934 - val_NN_RMSLE: 2.1659\n",
            "Epoch 4/100\n",
            "3604/3606 [============================>.] - ETA: 0s - loss: 5.1601 - NN_RMSLE: 2.2576\n",
            "Epoch 4: val_loss improved from 4.79337 to 4.77831, saving model to model_142[]\n",
            "INFO:tensorflow:Assets written to: model_142[]/assets\n",
            "3606/3606 [==============================] - 12s 3ms/step - loss: 5.1601 - NN_RMSLE: 2.2578 - val_loss: 4.7783 - val_NN_RMSLE: 2.1621\n",
            "Epoch 5/100\n",
            "3595/3606 [============================>.] - ETA: 0s - loss: 5.1603 - NN_RMSLE: 2.2576\n",
            "Epoch 5: val_loss did not improve from 4.77831\n",
            "3606/3606 [==============================] - 11s 3ms/step - loss: 5.1601 - NN_RMSLE: 2.2572 - val_loss: 4.7943 - val_NN_RMSLE: 2.1661\n",
            "Epoch 6/100\n",
            "3606/3606 [==============================] - ETA: 0s - loss: 5.1602 - NN_RMSLE: 2.2575\n",
            "Epoch 6: val_loss improved from 4.77831 to 4.77272, saving model to model_142[]\n",
            "INFO:tensorflow:Assets written to: model_142[]/assets\n",
            "3606/3606 [==============================] - 13s 4ms/step - loss: 5.1602 - NN_RMSLE: 2.2575 - val_loss: 4.7727 - val_NN_RMSLE: 2.1607\n",
            "Epoch 7/100\n",
            "3600/3606 [============================>.] - ETA: 0s - loss: 5.1616 - NN_RMSLE: 2.2579\n",
            "Epoch 7: val_loss did not improve from 4.77272\n",
            "3606/3606 [==============================] - 11s 3ms/step - loss: 5.1601 - NN_RMSLE: 2.2579 - val_loss: 4.7816 - val_NN_RMSLE: 2.1629\n",
            "Epoch 8/100\n",
            "3592/3606 [============================>.] - ETA: 0s - loss: 5.1595 - NN_RMSLE: 2.2574\n",
            "Epoch 8: val_loss did not improve from 4.77272\n",
            "3606/3606 [==============================] - 12s 3ms/step - loss: 5.1602 - NN_RMSLE: 2.2577 - val_loss: 4.7847 - val_NN_RMSLE: 2.1637\n",
            "Epoch 9/100\n",
            "3603/3606 [============================>.] - ETA: 0s - loss: 5.1607 - NN_RMSLE: 2.2569\n",
            "Epoch 9: val_loss did not improve from 4.77272\n",
            "3606/3606 [==============================] - 12s 3ms/step - loss: 5.1601 - NN_RMSLE: 2.2564 - val_loss: 4.7775 - val_NN_RMSLE: 2.1619\n",
            "Model: \"sequential_102\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_408 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_306 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_409 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_307 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_410 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_308 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_411 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  4.7774634\n",
            "\n",
            "[ 4  5  6  7  8  9 10 12]\n",
            "train 230725 valid 115362\n",
            "Model: \"sequential_103\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_412 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_309 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_413 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_310 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_414 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_311 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_415 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "3586/3606 [============================>.] - ETA: 0s - loss: 25.5261 - NN_RMSLE: 4.9822\n",
            "Epoch 1: val_loss improved from inf to 10.70655, saving model to model_142[]\n",
            "INFO:tensorflow:Assets written to: model_142[]/assets\n",
            "3606/3606 [==============================] - 11s 3ms/step - loss: 25.4627 - NN_RMSLE: 4.9747 - val_loss: 10.7066 - val_NN_RMSLE: 3.2661\n",
            "Epoch 2/100\n",
            "3599/3606 [============================>.] - ETA: 0s - loss: 7.9952 - NN_RMSLE: 2.7919\n",
            "Epoch 2: val_loss improved from 10.70655 to 5.25658, saving model to model_142[]\n",
            "INFO:tensorflow:Assets written to: model_142[]/assets\n",
            "3606/3606 [==============================] - 11s 3ms/step - loss: 7.9898 - NN_RMSLE: 2.7905 - val_loss: 5.2566 - val_NN_RMSLE: 2.2778\n",
            "Epoch 3/100\n",
            "3589/3606 [============================>.] - ETA: 0s - loss: 4.8229 - NN_RMSLE: 2.1802\n",
            "Epoch 3: val_loss did not improve from 5.25658\n",
            "3606/3606 [==============================] - 10s 3ms/step - loss: 4.8211 - NN_RMSLE: 2.1800 - val_loss: 5.6029 - val_NN_RMSLE: 2.3430\n",
            "Epoch 4/100\n",
            "3589/3606 [============================>.] - ETA: 0s - loss: 4.7669 - NN_RMSLE: 2.1665\n",
            "Epoch 4: val_loss did not improve from 5.25658\n",
            "3606/3606 [==============================] - 11s 3ms/step - loss: 4.7677 - NN_RMSLE: 2.1668 - val_loss: 5.6009 - val_NN_RMSLE: 2.3426\n",
            "Epoch 5/100\n",
            "3603/3606 [============================>.] - ETA: 0s - loss: 4.7683 - NN_RMSLE: 2.1665\n",
            "Epoch 5: val_loss did not improve from 5.25658\n",
            "3606/3606 [==============================] - 11s 3ms/step - loss: 4.7677 - NN_RMSLE: 2.1665 - val_loss: 5.5889 - val_NN_RMSLE: 2.3402\n",
            "Model: \"sequential_103\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_412 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_309 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_413 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_310 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_414 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_311 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_415 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  5.588871\n",
            "\n",
            "[ 8  9 10 11 12]\n",
            "train 230725 valid 115362\n",
            "Model: \"sequential_104\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_416 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_312 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_417 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_313 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_418 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_314 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_419 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "3586/3606 [============================>.] - ETA: 0s - loss: 23.7699 - NN_RMSLE: 4.8063\n",
            "Epoch 1: val_loss improved from inf to 12.86943, saving model to model_142[]\n",
            "INFO:tensorflow:Assets written to: model_142[]/assets\n",
            "3606/3606 [==============================] - 13s 3ms/step - loss: 23.7097 - NN_RMSLE: 4.7992 - val_loss: 12.8694 - val_NN_RMSLE: 3.5727\n",
            "Epoch 2/100\n",
            "3586/3606 [============================>.] - ETA: 0s - loss: 7.6714 - NN_RMSLE: 2.7406\n",
            "Epoch 2: val_loss improved from 12.86943 to 5.30374, saving model to model_142[]\n",
            "INFO:tensorflow:Assets written to: model_142[]/assets\n",
            "3606/3606 [==============================] - 13s 4ms/step - loss: 7.6604 - NN_RMSLE: 2.7381 - val_loss: 5.3037 - val_NN_RMSLE: 2.2928\n",
            "Epoch 3/100\n",
            "3594/3606 [============================>.] - ETA: 0s - loss: 5.0639 - NN_RMSLE: 2.2364\n",
            "Epoch 3: val_loss improved from 5.30374 to 4.96939, saving model to model_142[]\n",
            "INFO:tensorflow:Assets written to: model_142[]/assets\n",
            "3606/3606 [==============================] - 11s 3ms/step - loss: 5.0616 - NN_RMSLE: 2.2357 - val_loss: 4.9694 - val_NN_RMSLE: 2.2181\n",
            "Epoch 4/100\n",
            "3588/3606 [============================>.] - ETA: 0s - loss: 5.0308 - NN_RMSLE: 2.2276\n",
            "Epoch 4: val_loss improved from 4.96939 to 4.96636, saving model to model_142[]\n",
            "INFO:tensorflow:Assets written to: model_142[]/assets\n",
            "3606/3606 [==============================] - 11s 3ms/step - loss: 5.0301 - NN_RMSLE: 2.2272 - val_loss: 4.9664 - val_NN_RMSLE: 2.2174\n",
            "Epoch 5/100\n",
            "3605/3606 [============================>.] - ETA: 0s - loss: 5.0302 - NN_RMSLE: 2.2278\n",
            "Epoch 5: val_loss improved from 4.96636 to 4.96543, saving model to model_142[]\n",
            "INFO:tensorflow:Assets written to: model_142[]/assets\n",
            "3606/3606 [==============================] - 11s 3ms/step - loss: 5.0301 - NN_RMSLE: 2.2274 - val_loss: 4.9654 - val_NN_RMSLE: 2.2171\n",
            "Epoch 6/100\n",
            "3595/3606 [============================>.] - ETA: 0s - loss: 5.0290 - NN_RMSLE: 2.2275\n",
            "Epoch 6: val_loss improved from 4.96543 to 4.96463, saving model to model_142[]\n",
            "INFO:tensorflow:Assets written to: model_142[]/assets\n",
            "3606/3606 [==============================] - 12s 3ms/step - loss: 5.0301 - NN_RMSLE: 2.2280 - val_loss: 4.9646 - val_NN_RMSLE: 2.2169\n",
            "Epoch 7/100\n",
            "3605/3606 [============================>.] - ETA: 0s - loss: 5.0300 - NN_RMSLE: 2.2275\n",
            "Epoch 7: val_loss did not improve from 4.96463\n",
            "3606/3606 [==============================] - 11s 3ms/step - loss: 5.0301 - NN_RMSLE: 2.2277 - val_loss: 4.9682 - val_NN_RMSLE: 2.2178\n",
            "Epoch 8/100\n",
            "3605/3606 [============================>.] - ETA: 0s - loss: 5.0301 - NN_RMSLE: 2.2277\n",
            "Epoch 8: val_loss did not improve from 4.96463\n",
            "3606/3606 [==============================] - 12s 3ms/step - loss: 5.0301 - NN_RMSLE: 2.2276 - val_loss: 4.9693 - val_NN_RMSLE: 2.2181\n",
            "Epoch 9/100\n",
            "3591/3606 [============================>.] - ETA: 0s - loss: 5.0308 - NN_RMSLE: 2.2281\n",
            "Epoch 9: val_loss did not improve from 4.96463\n",
            "3606/3606 [==============================] - 13s 4ms/step - loss: 5.0301 - NN_RMSLE: 2.2281 - val_loss: 4.9656 - val_NN_RMSLE: 2.2172\n",
            "Model: \"sequential_104\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_416 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_312 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_417 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_313 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_418 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_314 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_419 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  4.9656124\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 153 (14797, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[1 2 3 4 5 6]\n",
            "train 9864 valid 4933\n",
            "Model: \"sequential_105\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_420 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_315 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_421 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_316 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_422 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_317 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_423 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "152/155 [============================>.] - ETA: 0s - loss: 28925.0820 - NN_RMSLE: 20.4150\n",
            "Epoch 1: val_loss improved from inf to 52.37059, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 28526.8945 - NN_RMSLE: 20.1469 - val_loss: 52.3706 - val_NN_RMSLE: 7.2080\n",
            "Epoch 2/100\n",
            "153/155 [============================>.] - ETA: 0s - loss: 36.3603 - NN_RMSLE: 6.0175\n",
            "Epoch 2: val_loss improved from 52.37059 to 35.04841, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 36.2907 - NN_RMSLE: 6.0002 - val_loss: 35.0484 - val_NN_RMSLE: 5.8876\n",
            "Epoch 3/100\n",
            "151/155 [============================>.] - ETA: 0s - loss: 17.3794 - NN_RMSLE: 4.1157\n",
            "Epoch 3: val_loss improved from 35.04841 to 11.09928, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 10ms/step - loss: 17.2343 - NN_RMSLE: 4.0849 - val_loss: 11.0993 - val_NN_RMSLE: 3.2803\n",
            "Epoch 4/100\n",
            "147/155 [===========================>..] - ETA: 0s - loss: 8.2986 - NN_RMSLE: 2.8698\n",
            "Epoch 4: val_loss improved from 11.09928 to 5.42581, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 8.3061 - NN_RMSLE: 2.8707 - val_loss: 5.4258 - val_NN_RMSLE: 2.2586\n",
            "Epoch 5/100\n",
            "141/155 [==========================>...] - ETA: 0s - loss: 8.0142 - NN_RMSLE: 2.8190\n",
            "Epoch 5: val_loss improved from 5.42581 to 5.23487, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 7.9994 - NN_RMSLE: 2.8148 - val_loss: 5.2349 - val_NN_RMSLE: 2.2163\n",
            "Epoch 6/100\n",
            "152/155 [============================>.] - ETA: 0s - loss: 7.9502 - NN_RMSLE: 2.8091\n",
            "Epoch 6: val_loss did not improve from 5.23487\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 7.9383 - NN_RMSLE: 2.8089 - val_loss: 5.2621 - val_NN_RMSLE: 2.2224\n",
            "Epoch 7/100\n",
            "144/155 [==========================>...] - ETA: 0s - loss: 7.6169 - NN_RMSLE: 2.7479\n",
            "Epoch 7: val_loss improved from 5.23487 to 5.08141, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 7.6160 - NN_RMSLE: 2.7554 - val_loss: 5.0814 - val_NN_RMSLE: 2.1818\n",
            "Epoch 8/100\n",
            "151/155 [============================>.] - ETA: 0s - loss: 7.6257 - NN_RMSLE: 2.7489\n",
            "Epoch 8: val_loss improved from 5.08141 to 4.97526, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 7.6414 - NN_RMSLE: 2.7505 - val_loss: 4.9753 - val_NN_RMSLE: 2.1576\n",
            "Epoch 9/100\n",
            "153/155 [============================>.] - ETA: 0s - loss: 7.3468 - NN_RMSLE: 2.7002\n",
            "Epoch 9: val_loss did not improve from 4.97526\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 7.3452 - NN_RMSLE: 2.6982 - val_loss: 5.0373 - val_NN_RMSLE: 2.1718\n",
            "Epoch 10/100\n",
            "145/155 [===========================>..] - ETA: 0s - loss: 7.1881 - NN_RMSLE: 2.6701\n",
            "Epoch 10: val_loss did not improve from 4.97526\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 7.1727 - NN_RMSLE: 2.6693 - val_loss: 5.1066 - val_NN_RMSLE: 2.1875\n",
            "Epoch 11/100\n",
            "155/155 [==============================] - ETA: 0s - loss: 7.3240 - NN_RMSLE: 2.6930\n",
            "Epoch 11: val_loss improved from 4.97526 to 4.94336, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 7.3240 - NN_RMSLE: 2.6930 - val_loss: 4.9434 - val_NN_RMSLE: 2.1503\n",
            "Epoch 12/100\n",
            "147/155 [===========================>..] - ETA: 0s - loss: 7.0574 - NN_RMSLE: 2.6451\n",
            "Epoch 12: val_loss improved from 4.94336 to 4.86404, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 7.0610 - NN_RMSLE: 2.6456 - val_loss: 4.8640 - val_NN_RMSLE: 2.1320\n",
            "Epoch 13/100\n",
            "155/155 [==============================] - ETA: 0s - loss: 6.8054 - NN_RMSLE: 2.5920\n",
            "Epoch 13: val_loss improved from 4.86404 to 4.66395, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 6.8054 - NN_RMSLE: 2.5920 - val_loss: 4.6639 - val_NN_RMSLE: 2.0853\n",
            "Epoch 14/100\n",
            "136/155 [=========================>....] - ETA: 0s - loss: 6.7266 - NN_RMSLE: 2.5812\n",
            "Epoch 14: val_loss did not improve from 4.66395\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 6.7280 - NN_RMSLE: 2.5794 - val_loss: 4.9732 - val_NN_RMSLE: 2.1571\n",
            "Epoch 15/100\n",
            "142/155 [==========================>...] - ETA: 0s - loss: 6.7612 - NN_RMSLE: 2.5885\n",
            "Epoch 15: val_loss did not improve from 4.66395\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 6.7428 - NN_RMSLE: 2.5886 - val_loss: 4.8345 - val_NN_RMSLE: 2.1252\n",
            "Epoch 16/100\n",
            "147/155 [===========================>..] - ETA: 0s - loss: 6.5009 - NN_RMSLE: 2.5394\n",
            "Epoch 16: val_loss improved from 4.66395 to 4.64249, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 6.4921 - NN_RMSLE: 2.5364 - val_loss: 4.6425 - val_NN_RMSLE: 2.0802\n",
            "Epoch 17/100\n",
            "143/155 [==========================>...] - ETA: 0s - loss: 6.2282 - NN_RMSLE: 2.4850\n",
            "Epoch 17: val_loss did not improve from 4.64249\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 6.2302 - NN_RMSLE: 2.4833 - val_loss: 4.6777 - val_NN_RMSLE: 2.0885\n",
            "Epoch 18/100\n",
            "147/155 [===========================>..] - ETA: 0s - loss: 6.1446 - NN_RMSLE: 2.4691\n",
            "Epoch 18: val_loss improved from 4.64249 to 4.63392, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 6.1667 - NN_RMSLE: 2.4718 - val_loss: 4.6339 - val_NN_RMSLE: 2.0782\n",
            "Epoch 19/100\n",
            "154/155 [============================>.] - ETA: 0s - loss: 5.8357 - NN_RMSLE: 2.4072\n",
            "Epoch 19: val_loss improved from 4.63392 to 4.59914, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 5.8341 - NN_RMSLE: 2.4045 - val_loss: 4.5991 - val_NN_RMSLE: 2.0699\n",
            "Epoch 20/100\n",
            "154/155 [============================>.] - ETA: 0s - loss: 5.8431 - NN_RMSLE: 2.4069\n",
            "Epoch 20: val_loss improved from 4.59914 to 4.27231, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 5.8396 - NN_RMSLE: 2.3990 - val_loss: 4.2723 - val_NN_RMSLE: 1.9917\n",
            "Epoch 21/100\n",
            "140/155 [==========================>...] - ETA: 0s - loss: 5.7386 - NN_RMSLE: 2.3858\n",
            "Epoch 21: val_loss did not improve from 4.27231\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 5.7031 - NN_RMSLE: 2.3760 - val_loss: 4.4353 - val_NN_RMSLE: 2.0308\n",
            "Epoch 22/100\n",
            "140/155 [==========================>...] - ETA: 0s - loss: 5.6182 - NN_RMSLE: 2.3605\n",
            "Epoch 22: val_loss improved from 4.27231 to 4.22813, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 5.6740 - NN_RMSLE: 2.3747 - val_loss: 4.2281 - val_NN_RMSLE: 1.9811\n",
            "Epoch 23/100\n",
            "141/155 [==========================>...] - ETA: 0s - loss: 5.4230 - NN_RMSLE: 2.3195\n",
            "Epoch 23: val_loss did not improve from 4.22813\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 5.4074 - NN_RMSLE: 2.3142 - val_loss: 4.2307 - val_NN_RMSLE: 1.9817\n",
            "Epoch 24/100\n",
            "151/155 [============================>.] - ETA: 0s - loss: 5.3690 - NN_RMSLE: 2.3088\n",
            "Epoch 24: val_loss did not improve from 4.22813\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 5.3762 - NN_RMSLE: 2.3151 - val_loss: 4.2362 - val_NN_RMSLE: 1.9830\n",
            "Epoch 25/100\n",
            "150/155 [============================>.] - ETA: 0s - loss: 5.2630 - NN_RMSLE: 2.2845\n",
            "Epoch 25: val_loss improved from 4.22813 to 4.15535, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 5.2520 - NN_RMSLE: 2.2857 - val_loss: 4.1554 - val_NN_RMSLE: 1.9637\n",
            "Epoch 26/100\n",
            "149/155 [===========================>..] - ETA: 0s - loss: 5.1381 - NN_RMSLE: 2.2573\n",
            "Epoch 26: val_loss did not improve from 4.15535\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 5.1288 - NN_RMSLE: 2.2546 - val_loss: 4.2930 - val_NN_RMSLE: 1.9966\n",
            "Epoch 27/100\n",
            "126/155 [=======================>......] - ETA: 0s - loss: 5.1479 - NN_RMSLE: 2.2585\n",
            "Epoch 27: val_loss improved from 4.15535 to 4.14576, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 5.1384 - NN_RMSLE: 2.2507 - val_loss: 4.1458 - val_NN_RMSLE: 1.9614\n",
            "Epoch 28/100\n",
            "148/155 [===========================>..] - ETA: 0s - loss: 5.1044 - NN_RMSLE: 2.2504\n",
            "Epoch 28: val_loss did not improve from 4.14576\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 5.0640 - NN_RMSLE: 2.2397 - val_loss: 4.1986 - val_NN_RMSLE: 1.9741\n",
            "Epoch 29/100\n",
            "151/155 [============================>.] - ETA: 0s - loss: 4.8765 - NN_RMSLE: 2.1987\n",
            "Epoch 29: val_loss did not improve from 4.14576\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 4.8732 - NN_RMSLE: 2.1961 - val_loss: 4.1500 - val_NN_RMSLE: 1.9624\n",
            "Epoch 30/100\n",
            "138/155 [=========================>....] - ETA: 0s - loss: 4.8456 - NN_RMSLE: 2.1924\n",
            "Epoch 30: val_loss improved from 4.14576 to 4.02870, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 4.8881 - NN_RMSLE: 2.2073 - val_loss: 4.0287 - val_NN_RMSLE: 1.9333\n",
            "Epoch 31/100\n",
            "140/155 [==========================>...] - ETA: 0s - loss: 4.7740 - NN_RMSLE: 2.1746\n",
            "Epoch 31: val_loss did not improve from 4.02870\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 4.8098 - NN_RMSLE: 2.1830 - val_loss: 4.0941 - val_NN_RMSLE: 1.9490\n",
            "Epoch 32/100\n",
            "138/155 [=========================>....] - ETA: 0s - loss: 4.6929 - NN_RMSLE: 2.1580\n",
            "Epoch 32: val_loss improved from 4.02870 to 3.91033, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 4.6571 - NN_RMSLE: 2.1485 - val_loss: 3.9103 - val_NN_RMSLE: 1.9046\n",
            "Epoch 33/100\n",
            "136/155 [=========================>....] - ETA: 0s - loss: 4.5400 - NN_RMSLE: 2.1232\n",
            "Epoch 33: val_loss did not improve from 3.91033\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 4.5345 - NN_RMSLE: 2.1233 - val_loss: 4.0599 - val_NN_RMSLE: 1.9408\n",
            "Epoch 34/100\n",
            "139/155 [=========================>....] - ETA: 0s - loss: 4.5893 - NN_RMSLE: 2.1332\n",
            "Epoch 34: val_loss did not improve from 3.91033\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 4.5448 - NN_RMSLE: 2.1290 - val_loss: 4.1239 - val_NN_RMSLE: 1.9562\n",
            "Epoch 35/100\n",
            "151/155 [============================>.] - ETA: 0s - loss: 4.5407 - NN_RMSLE: 2.1225\n",
            "Epoch 35: val_loss did not improve from 3.91033\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 4.5397 - NN_RMSLE: 2.1239 - val_loss: 4.0047 - val_NN_RMSLE: 1.9275\n",
            "Model: \"sequential_105\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_420 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_315 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_421 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_316 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_422 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_317 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_423 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  4.0047083\n",
            "\n",
            "[5 6 7 8 9]\n",
            "train 9865 valid 4932\n",
            "Model: \"sequential_106\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_424 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_318 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_425 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_319 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_426 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_320 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_427 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "155/155 [==============================] - ETA: 0s - loss: 85226.7266 - NN_RMSLE: 30.6123\n",
            "Epoch 1: val_loss improved from inf to 40.96362, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 2s 8ms/step - loss: 85226.7266 - NN_RMSLE: 30.6123 - val_loss: 40.9636 - val_NN_RMSLE: 6.4033\n",
            "Epoch 2/100\n",
            "133/155 [========================>.....] - ETA: 0s - loss: 53.0254 - NN_RMSLE: 7.2781\n",
            "Epoch 2: val_loss improved from 40.96362 to 40.85599, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 52.9936 - NN_RMSLE: 7.2771 - val_loss: 40.8560 - val_NN_RMSLE: 6.3948\n",
            "Epoch 3/100\n",
            "150/155 [============================>.] - ETA: 0s - loss: 52.8522 - NN_RMSLE: 7.2670\n",
            "Epoch 3: val_loss improved from 40.85599 to 40.73358, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 52.8677 - NN_RMSLE: 7.2641 - val_loss: 40.7336 - val_NN_RMSLE: 6.3853\n",
            "Epoch 4/100\n",
            "143/155 [==========================>...] - ETA: 0s - loss: 52.6621 - NN_RMSLE: 7.2538\n",
            "Epoch 4: val_loss improved from 40.73358 to 40.58314, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 52.7143 - NN_RMSLE: 7.2600 - val_loss: 40.5831 - val_NN_RMSLE: 6.3734\n",
            "Epoch 5/100\n",
            "146/155 [===========================>..] - ETA: 0s - loss: 52.4457 - NN_RMSLE: 7.2385\n",
            "Epoch 5: val_loss improved from 40.58314 to 40.40577, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 52.5304 - NN_RMSLE: 7.2425 - val_loss: 40.4058 - val_NN_RMSLE: 6.3595\n",
            "Epoch 6/100\n",
            "153/155 [============================>.] - ETA: 0s - loss: 52.3051 - NN_RMSLE: 7.2287\n",
            "Epoch 6: val_loss improved from 40.40577 to 40.20172, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 52.3166 - NN_RMSLE: 7.2311 - val_loss: 40.2017 - val_NN_RMSLE: 6.3434\n",
            "Epoch 7/100\n",
            "136/155 [=========================>....] - ETA: 0s - loss: 51.9878 - NN_RMSLE: 7.2068\n",
            "Epoch 7: val_loss improved from 40.20172 to 39.93739, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 52.0687 - NN_RMSLE: 7.2131 - val_loss: 39.9374 - val_NN_RMSLE: 6.3225\n",
            "Epoch 8/100\n",
            "139/155 [=========================>....] - ETA: 0s - loss: 51.5810 - NN_RMSLE: 7.1787\n",
            "Epoch 8: val_loss improved from 39.93739 to 38.91632, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 51.4646 - NN_RMSLE: 7.1737 - val_loss: 38.9163 - val_NN_RMSLE: 6.2411\n",
            "Epoch 9/100\n",
            "147/155 [===========================>..] - ETA: 0s - loss: 49.9117 - NN_RMSLE: 7.0614\n",
            "Epoch 9: val_loss improved from 38.91632 to 37.10890, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 49.8287 - NN_RMSLE: 7.0508 - val_loss: 37.1089 - val_NN_RMSLE: 6.0943\n",
            "Epoch 10/100\n",
            "139/155 [=========================>....] - ETA: 0s - loss: 47.6827 - NN_RMSLE: 6.9010\n",
            "Epoch 10: val_loss improved from 37.10890 to 34.95370, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 47.6130 - NN_RMSLE: 6.8957 - val_loss: 34.9537 - val_NN_RMSLE: 5.9144\n",
            "Epoch 11/100\n",
            "155/155 [==============================] - ETA: 0s - loss: 45.0072 - NN_RMSLE: 6.7088\n",
            "Epoch 11: val_loss improved from 34.95370 to 32.49637, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 45.0072 - NN_RMSLE: 6.7088 - val_loss: 32.4964 - val_NN_RMSLE: 5.7025\n",
            "Epoch 12/100\n",
            "150/155 [============================>.] - ETA: 0s - loss: 42.1955 - NN_RMSLE: 6.4919\n",
            "Epoch 12: val_loss improved from 32.49637 to 29.78587, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 42.1381 - NN_RMSLE: 6.4910 - val_loss: 29.7859 - val_NN_RMSLE: 5.4592\n",
            "Epoch 13/100\n",
            "134/155 [========================>.....] - ETA: 0s - loss: 39.4039 - NN_RMSLE: 6.2737\n",
            "Epoch 13: val_loss improved from 29.78587 to 26.86886, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 39.0587 - NN_RMSLE: 6.2442 - val_loss: 26.8689 - val_NN_RMSLE: 5.1845\n",
            "Epoch 14/100\n",
            "145/155 [===========================>..] - ETA: 0s - loss: 35.8626 - NN_RMSLE: 5.9836\n",
            "Epoch 14: val_loss improved from 26.86886 to 23.81181, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 35.7381 - NN_RMSLE: 5.9730 - val_loss: 23.8118 - val_NN_RMSLE: 4.8801\n",
            "Epoch 15/100\n",
            "140/155 [==========================>...] - ETA: 0s - loss: 32.7347 - NN_RMSLE: 5.7170\n",
            "Epoch 15: val_loss improved from 23.81181 to 20.72878, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 32.5946 - NN_RMSLE: 5.7081 - val_loss: 20.7288 - val_NN_RMSLE: 4.5526\n",
            "Epoch 16/100\n",
            "137/155 [=========================>....] - ETA: 0s - loss: 29.0368 - NN_RMSLE: 5.3841\n",
            "Epoch 16: val_loss improved from 20.72878 to 17.63490, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 9ms/step - loss: 28.8190 - NN_RMSLE: 5.3596 - val_loss: 17.6349 - val_NN_RMSLE: 4.1982\n",
            "Epoch 17/100\n",
            "145/155 [===========================>..] - ETA: 0s - loss: 25.9180 - NN_RMSLE: 5.0840\n",
            "Epoch 17: val_loss improved from 17.63490 to 14.69967, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 25.7170 - NN_RMSLE: 5.0683 - val_loss: 14.6997 - val_NN_RMSLE: 3.8319\n",
            "Epoch 18/100\n",
            "134/155 [========================>.....] - ETA: 0s - loss: 22.8996 - NN_RMSLE: 4.7786\n",
            "Epoch 18: val_loss improved from 14.69967 to 12.00212, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 22.7150 - NN_RMSLE: 4.7608 - val_loss: 12.0021 - val_NN_RMSLE: 3.4611\n",
            "Epoch 19/100\n",
            "145/155 [===========================>..] - ETA: 0s - loss: 20.0683 - NN_RMSLE: 4.4720\n",
            "Epoch 19: val_loss improved from 12.00212 to 9.61132, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 19.9509 - NN_RMSLE: 4.4553 - val_loss: 9.6113 - val_NN_RMSLE: 3.0955\n",
            "Epoch 20/100\n",
            "149/155 [===========================>..] - ETA: 0s - loss: 18.0900 - NN_RMSLE: 4.2443\n",
            "Epoch 20: val_loss improved from 9.61132 to 7.60538, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 18.0956 - NN_RMSLE: 4.2504 - val_loss: 7.6054 - val_NN_RMSLE: 2.7515\n",
            "Epoch 21/100\n",
            "134/155 [========================>.....] - ETA: 0s - loss: 16.3189 - NN_RMSLE: 4.0298\n",
            "Epoch 21: val_loss improved from 7.60538 to 5.95561, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 16.2690 - NN_RMSLE: 4.0218 - val_loss: 5.9556 - val_NN_RMSLE: 2.4322\n",
            "Epoch 22/100\n",
            "146/155 [===========================>..] - ETA: 0s - loss: 14.8937 - NN_RMSLE: 3.8464\n",
            "Epoch 22: val_loss improved from 5.95561 to 4.67350, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 14.8415 - NN_RMSLE: 3.8390 - val_loss: 4.6735 - val_NN_RMSLE: 2.1510\n",
            "Epoch 23/100\n",
            "153/155 [============================>.] - ETA: 0s - loss: 13.9373 - NN_RMSLE: 3.7190\n",
            "Epoch 23: val_loss improved from 4.67350 to 3.71181, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 13.9599 - NN_RMSLE: 3.7236 - val_loss: 3.7118 - val_NN_RMSLE: 1.9125\n",
            "Epoch 24/100\n",
            "143/155 [==========================>...] - ETA: 0s - loss: 13.2485 - NN_RMSLE: 3.6272\n",
            "Epoch 24: val_loss improved from 3.71181 to 3.01777, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 13.2098 - NN_RMSLE: 3.6264 - val_loss: 3.0178 - val_NN_RMSLE: 1.7192\n",
            "Epoch 25/100\n",
            "150/155 [============================>.] - ETA: 0s - loss: 12.8148 - NN_RMSLE: 3.5638\n",
            "Epoch 25: val_loss improved from 3.01777 to 2.54692, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 12.7571 - NN_RMSLE: 3.5607 - val_loss: 2.5469 - val_NN_RMSLE: 1.5740\n",
            "Epoch 26/100\n",
            "142/155 [==========================>...] - ETA: 0s - loss: 12.4164 - NN_RMSLE: 3.5106\n",
            "Epoch 26: val_loss improved from 2.54692 to 2.21146, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 12.3777 - NN_RMSLE: 3.5137 - val_loss: 2.2115 - val_NN_RMSLE: 1.4615\n",
            "Epoch 27/100\n",
            "143/155 [==========================>...] - ETA: 0s - loss: 12.0198 - NN_RMSLE: 3.4531\n",
            "Epoch 27: val_loss improved from 2.21146 to 1.99081, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 12.0268 - NN_RMSLE: 3.4557 - val_loss: 1.9908 - val_NN_RMSLE: 1.3824\n",
            "Epoch 28/100\n",
            "127/155 [=======================>......] - ETA: 0s - loss: 11.9073 - NN_RMSLE: 3.4378\n",
            "Epoch 28: val_loss improved from 1.99081 to 1.85043, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 11.9471 - NN_RMSLE: 3.4433 - val_loss: 1.8504 - val_NN_RMSLE: 1.3297\n",
            "Epoch 29/100\n",
            "152/155 [============================>.] - ETA: 0s - loss: 12.0119 - NN_RMSLE: 3.4529\n",
            "Epoch 29: val_loss improved from 1.85043 to 1.75508, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 12.0086 - NN_RMSLE: 3.4554 - val_loss: 1.7551 - val_NN_RMSLE: 1.2928\n",
            "Epoch 30/100\n",
            "152/155 [============================>.] - ETA: 0s - loss: 11.4932 - NN_RMSLE: 3.3789\n",
            "Epoch 30: val_loss improved from 1.75508 to 1.67437, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 11.4845 - NN_RMSLE: 3.3821 - val_loss: 1.6744 - val_NN_RMSLE: 1.2607\n",
            "Epoch 31/100\n",
            "132/155 [========================>.....] - ETA: 0s - loss: 11.4209 - NN_RMSLE: 3.3688\n",
            "Epoch 31: val_loss improved from 1.67437 to 1.61606, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 11.4169 - NN_RMSLE: 3.3607 - val_loss: 1.6161 - val_NN_RMSLE: 1.2370\n",
            "Epoch 32/100\n",
            "155/155 [==============================] - ETA: 0s - loss: 10.9737 - NN_RMSLE: 3.3042\n",
            "Epoch 32: val_loss improved from 1.61606 to 1.58003, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 10.9737 - NN_RMSLE: 3.3042 - val_loss: 1.5800 - val_NN_RMSLE: 1.2221\n",
            "Epoch 33/100\n",
            "147/155 [===========================>..] - ETA: 0s - loss: 10.7317 - NN_RMSLE: 3.2653\n",
            "Epoch 33: val_loss improved from 1.58003 to 1.55393, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 10.7712 - NN_RMSLE: 3.2765 - val_loss: 1.5539 - val_NN_RMSLE: 1.2112\n",
            "Epoch 34/100\n",
            "151/155 [============================>.] - ETA: 0s - loss: 10.6762 - NN_RMSLE: 3.2572\n",
            "Epoch 34: val_loss improved from 1.55393 to 1.52315, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 10.6796 - NN_RMSLE: 3.2496 - val_loss: 1.5232 - val_NN_RMSLE: 1.1982\n",
            "Epoch 35/100\n",
            "142/155 [==========================>...] - ETA: 0s - loss: 10.6171 - NN_RMSLE: 3.2447\n",
            "Epoch 35: val_loss improved from 1.52315 to 1.51010, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 10.6138 - NN_RMSLE: 3.2464 - val_loss: 1.5101 - val_NN_RMSLE: 1.1926\n",
            "Epoch 36/100\n",
            "128/155 [=======================>......] - ETA: 0s - loss: 10.6283 - NN_RMSLE: 3.2506\n",
            "Epoch 36: val_loss improved from 1.51010 to 1.49109, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 10.5321 - NN_RMSLE: 3.2341 - val_loss: 1.4911 - val_NN_RMSLE: 1.1845\n",
            "Epoch 37/100\n",
            "145/155 [===========================>..] - ETA: 0s - loss: 10.2160 - NN_RMSLE: 3.1850\n",
            "Epoch 37: val_loss improved from 1.49109 to 1.47340, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 10.2337 - NN_RMSLE: 3.1874 - val_loss: 1.4734 - val_NN_RMSLE: 1.1769\n",
            "Epoch 38/100\n",
            "153/155 [============================>.] - ETA: 0s - loss: 9.9883 - NN_RMSLE: 3.1467 \n",
            "Epoch 38: val_loss improved from 1.47340 to 1.43537, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 9.9821 - NN_RMSLE: 3.1444 - val_loss: 1.4354 - val_NN_RMSLE: 1.1603\n",
            "Epoch 39/100\n",
            "142/155 [==========================>...] - ETA: 0s - loss: 9.6368 - NN_RMSLE: 3.0949\n",
            "Epoch 39: val_loss improved from 1.43537 to 1.41885, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 9.6392 - NN_RMSLE: 3.0936 - val_loss: 1.4189 - val_NN_RMSLE: 1.1530\n",
            "Epoch 40/100\n",
            "140/155 [==========================>...] - ETA: 0s - loss: 9.4564 - NN_RMSLE: 3.0662\n",
            "Epoch 40: val_loss improved from 1.41885 to 1.38265, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 9.4261 - NN_RMSLE: 3.0532 - val_loss: 1.3827 - val_NN_RMSLE: 1.1368\n",
            "Epoch 41/100\n",
            "147/155 [===========================>..] - ETA: 0s - loss: 9.1292 - NN_RMSLE: 3.0120\n",
            "Epoch 41: val_loss improved from 1.38265 to 1.36077, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 9.0952 - NN_RMSLE: 3.0059 - val_loss: 1.3608 - val_NN_RMSLE: 1.1269\n",
            "Epoch 42/100\n",
            "137/155 [=========================>....] - ETA: 0s - loss: 8.8631 - NN_RMSLE: 2.9660\n",
            "Epoch 42: val_loss improved from 1.36077 to 1.33789, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 8.8456 - NN_RMSLE: 2.9687 - val_loss: 1.3379 - val_NN_RMSLE: 1.1163\n",
            "Epoch 43/100\n",
            "143/155 [==========================>...] - ETA: 0s - loss: 8.4743 - NN_RMSLE: 2.9000\n",
            "Epoch 43: val_loss improved from 1.33789 to 1.32167, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 8.5063 - NN_RMSLE: 2.9054 - val_loss: 1.3217 - val_NN_RMSLE: 1.1088\n",
            "Epoch 44/100\n",
            "139/155 [=========================>....] - ETA: 0s - loss: 8.3600 - NN_RMSLE: 2.8820\n",
            "Epoch 44: val_loss improved from 1.32167 to 1.29657, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 8.3594 - NN_RMSLE: 2.8800 - val_loss: 1.2966 - val_NN_RMSLE: 1.0969\n",
            "Epoch 45/100\n",
            "145/155 [===========================>..] - ETA: 0s - loss: 8.0417 - NN_RMSLE: 2.8245\n",
            "Epoch 45: val_loss improved from 1.29657 to 1.28607, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 8.0558 - NN_RMSLE: 2.8246 - val_loss: 1.2861 - val_NN_RMSLE: 1.0919\n",
            "Epoch 46/100\n",
            "144/155 [==========================>...] - ETA: 0s - loss: 7.8337 - NN_RMSLE: 2.7886\n",
            "Epoch 46: val_loss improved from 1.28607 to 1.27038, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 7.7903 - NN_RMSLE: 2.7789 - val_loss: 1.2704 - val_NN_RMSLE: 1.0842\n",
            "Epoch 47/100\n",
            "137/155 [=========================>....] - ETA: 0s - loss: 7.5058 - NN_RMSLE: 2.7287\n",
            "Epoch 47: val_loss improved from 1.27038 to 1.25403, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 7.4670 - NN_RMSLE: 2.7196 - val_loss: 1.2540 - val_NN_RMSLE: 1.0761\n",
            "Epoch 48/100\n",
            "136/155 [=========================>....] - ETA: 0s - loss: 7.4820 - NN_RMSLE: 2.7270\n",
            "Epoch 48: val_loss improved from 1.25403 to 1.23779, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 7.5000 - NN_RMSLE: 2.7311 - val_loss: 1.2378 - val_NN_RMSLE: 1.0678\n",
            "Epoch 49/100\n",
            "147/155 [===========================>..] - ETA: 0s - loss: 7.0566 - NN_RMSLE: 2.6470\n",
            "Epoch 49: val_loss improved from 1.23779 to 1.22747, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 7.0704 - NN_RMSLE: 2.6490 - val_loss: 1.2275 - val_NN_RMSLE: 1.0622\n",
            "Epoch 50/100\n",
            "142/155 [==========================>...] - ETA: 0s - loss: 6.6745 - NN_RMSLE: 2.5748\n",
            "Epoch 50: val_loss improved from 1.22747 to 1.22375, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 10ms/step - loss: 6.6461 - NN_RMSLE: 2.5680 - val_loss: 1.2237 - val_NN_RMSLE: 1.0601\n",
            "Epoch 51/100\n",
            "152/155 [============================>.] - ETA: 0s - loss: 6.4843 - NN_RMSLE: 2.5374\n",
            "Epoch 51: val_loss improved from 1.22375 to 1.21791, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 6.4963 - NN_RMSLE: 2.5382 - val_loss: 1.2179 - val_NN_RMSLE: 1.0563\n",
            "Epoch 52/100\n",
            "140/155 [==========================>...] - ETA: 0s - loss: 6.2521 - NN_RMSLE: 2.4928\n",
            "Epoch 52: val_loss improved from 1.21791 to 1.21764, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 6.2487 - NN_RMSLE: 2.4927 - val_loss: 1.2176 - val_NN_RMSLE: 1.0553\n",
            "Epoch 53/100\n",
            "139/155 [=========================>....] - ETA: 0s - loss: 6.0877 - NN_RMSLE: 2.4583\n",
            "Epoch 53: val_loss did not improve from 1.21764\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 6.1087 - NN_RMSLE: 2.4569 - val_loss: 1.2187 - val_NN_RMSLE: 1.0554\n",
            "Epoch 54/100\n",
            "147/155 [===========================>..] - ETA: 0s - loss: 5.9629 - NN_RMSLE: 2.4335\n",
            "Epoch 54: val_loss did not improve from 1.21764\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 5.9559 - NN_RMSLE: 2.4324 - val_loss: 1.2263 - val_NN_RMSLE: 1.0576\n",
            "Epoch 55/100\n",
            "143/155 [==========================>...] - ETA: 0s - loss: 5.7675 - NN_RMSLE: 2.3942\n",
            "Epoch 55: val_loss did not improve from 1.21764\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 5.7883 - NN_RMSLE: 2.3986 - val_loss: 1.2306 - val_NN_RMSLE: 1.0592\n",
            "Model: \"sequential_106\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_424 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_318 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_425 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_319 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_426 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_320 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_427 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.2306296\n",
            "\n",
            "[ 9 10 11 12]\n",
            "train 9865 valid 4932\n",
            "Model: \"sequential_107\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_428 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_321 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_429 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_322 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_430 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_323 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_431 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "134/155 [========================>.....] - ETA: 0s - loss: 13461.6055 - NN_RMSLE: 16.7762\n",
            "Epoch 1: val_loss improved from inf to 45.24654, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 11708.4863 - NN_RMSLE: 15.4114 - val_loss: 45.2465 - val_NN_RMSLE: 6.7035\n",
            "Epoch 2/100\n",
            "143/155 [==========================>...] - ETA: 0s - loss: 38.7206 - NN_RMSLE: 6.2145\n",
            "Epoch 2: val_loss improved from 45.24654 to 32.80368, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 38.2174 - NN_RMSLE: 6.1665 - val_loss: 32.8037 - val_NN_RMSLE: 5.6991\n",
            "Epoch 3/100\n",
            "134/155 [========================>.....] - ETA: 0s - loss: 24.8225 - NN_RMSLE: 4.9600\n",
            "Epoch 3: val_loss improved from 32.80368 to 16.11485, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 23.8619 - NN_RMSLE: 4.8560 - val_loss: 16.1149 - val_NN_RMSLE: 3.9700\n",
            "Epoch 4/100\n",
            "146/155 [===========================>..] - ETA: 0s - loss: 12.9708 - NN_RMSLE: 3.5802\n",
            "Epoch 4: val_loss improved from 16.11485 to 7.02441, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 12.8021 - NN_RMSLE: 3.5510 - val_loss: 7.0244 - val_NN_RMSLE: 2.5805\n",
            "Epoch 5/100\n",
            "145/155 [===========================>..] - ETA: 0s - loss: 9.9629 - NN_RMSLE: 3.1422 \n",
            "Epoch 5: val_loss improved from 7.02441 to 5.24735, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 9.9610 - NN_RMSLE: 3.1354 - val_loss: 5.2474 - val_NN_RMSLE: 2.2179\n",
            "Epoch 6/100\n",
            "137/155 [=========================>....] - ETA: 0s - loss: 9.7263 - NN_RMSLE: 3.1039\n",
            "Epoch 6: val_loss improved from 5.24735 to 5.01926, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 9.7505 - NN_RMSLE: 3.1092 - val_loss: 5.0193 - val_NN_RMSLE: 2.1682\n",
            "Epoch 7/100\n",
            "152/155 [============================>.] - ETA: 0s - loss: 9.5523 - NN_RMSLE: 3.0785\n",
            "Epoch 7: val_loss improved from 5.01926 to 4.94926, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 9.5398 - NN_RMSLE: 3.0744 - val_loss: 4.9493 - val_NN_RMSLE: 2.1527\n",
            "Epoch 8/100\n",
            "155/155 [==============================] - ETA: 0s - loss: 9.2054 - NN_RMSLE: 3.0234\n",
            "Epoch 8: val_loss improved from 4.94926 to 4.85562, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 9.2054 - NN_RMSLE: 3.0234 - val_loss: 4.8556 - val_NN_RMSLE: 2.1320\n",
            "Epoch 9/100\n",
            "137/155 [=========================>....] - ETA: 0s - loss: 8.8701 - NN_RMSLE: 2.9655\n",
            "Epoch 9: val_loss improved from 4.85562 to 4.73763, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 8.8467 - NN_RMSLE: 2.9590 - val_loss: 4.7376 - val_NN_RMSLE: 2.1056\n",
            "Epoch 10/100\n",
            "147/155 [===========================>..] - ETA: 0s - loss: 8.6458 - NN_RMSLE: 2.9265\n",
            "Epoch 10: val_loss improved from 4.73763 to 4.71206, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 8.6019 - NN_RMSLE: 2.9118 - val_loss: 4.7121 - val_NN_RMSLE: 2.0999\n",
            "Epoch 11/100\n",
            "141/155 [==========================>...] - ETA: 0s - loss: 8.4943 - NN_RMSLE: 2.9025\n",
            "Epoch 11: val_loss improved from 4.71206 to 4.62063, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 8.4655 - NN_RMSLE: 2.8995 - val_loss: 4.6206 - val_NN_RMSLE: 2.0793\n",
            "Epoch 12/100\n",
            "135/155 [=========================>....] - ETA: 0s - loss: 8.1231 - NN_RMSLE: 2.8389\n",
            "Epoch 12: val_loss improved from 4.62063 to 4.53478, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 8.0364 - NN_RMSLE: 2.8222 - val_loss: 4.5348 - val_NN_RMSLE: 2.0598\n",
            "Epoch 13/100\n",
            "147/155 [===========================>..] - ETA: 0s - loss: 7.9790 - NN_RMSLE: 2.8127\n",
            "Epoch 13: val_loss improved from 4.53478 to 4.45393, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 7.9023 - NN_RMSLE: 2.7967 - val_loss: 4.4539 - val_NN_RMSLE: 2.0414\n",
            "Epoch 14/100\n",
            "149/155 [===========================>..] - ETA: 0s - loss: 7.4750 - NN_RMSLE: 2.7188\n",
            "Epoch 14: val_loss improved from 4.45393 to 4.43429, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 7.4296 - NN_RMSLE: 2.7082 - val_loss: 4.4343 - val_NN_RMSLE: 2.0369\n",
            "Epoch 15/100\n",
            "144/155 [==========================>...] - ETA: 0s - loss: 7.0564 - NN_RMSLE: 2.6469\n",
            "Epoch 15: val_loss improved from 4.43429 to 4.34477, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 7.0700 - NN_RMSLE: 2.6493 - val_loss: 4.3448 - val_NN_RMSLE: 2.0163\n",
            "Epoch 16/100\n",
            "141/155 [==========================>...] - ETA: 0s - loss: 6.6223 - NN_RMSLE: 2.5614\n",
            "Epoch 16: val_loss improved from 4.34477 to 4.23833, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 6.6765 - NN_RMSLE: 2.5762 - val_loss: 4.2383 - val_NN_RMSLE: 1.9918\n",
            "Epoch 17/100\n",
            "149/155 [===========================>..] - ETA: 0s - loss: 6.4506 - NN_RMSLE: 2.5282\n",
            "Epoch 17: val_loss improved from 4.23833 to 4.14392, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 6.4680 - NN_RMSLE: 2.5323 - val_loss: 4.1439 - val_NN_RMSLE: 1.9698\n",
            "Epoch 18/100\n",
            "144/155 [==========================>...] - ETA: 0s - loss: 6.1311 - NN_RMSLE: 2.4664\n",
            "Epoch 18: val_loss improved from 4.14392 to 4.07105, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 6.1647 - NN_RMSLE: 2.4712 - val_loss: 4.0711 - val_NN_RMSLE: 1.9528\n",
            "Epoch 19/100\n",
            "150/155 [============================>.] - ETA: 0s - loss: 6.0572 - NN_RMSLE: 2.4496\n",
            "Epoch 19: val_loss improved from 4.07105 to 4.04853, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 8ms/step - loss: 6.0474 - NN_RMSLE: 2.4531 - val_loss: 4.0485 - val_NN_RMSLE: 1.9476\n",
            "Epoch 20/100\n",
            "147/155 [===========================>..] - ETA: 0s - loss: 5.8956 - NN_RMSLE: 2.4168\n",
            "Epoch 20: val_loss improved from 4.04853 to 4.01331, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 5.9122 - NN_RMSLE: 2.4204 - val_loss: 4.0133 - val_NN_RMSLE: 1.9393\n",
            "Epoch 21/100\n",
            "137/155 [=========================>....] - ETA: 0s - loss: 5.6020 - NN_RMSLE: 2.3577\n",
            "Epoch 21: val_loss improved from 4.01331 to 3.92480, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 5.5953 - NN_RMSLE: 2.3575 - val_loss: 3.9248 - val_NN_RMSLE: 1.9186\n",
            "Epoch 22/100\n",
            "144/155 [==========================>...] - ETA: 0s - loss: 5.3767 - NN_RMSLE: 2.3085\n",
            "Epoch 22: val_loss improved from 3.92480 to 3.84651, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 5.3216 - NN_RMSLE: 2.2939 - val_loss: 3.8465 - val_NN_RMSLE: 1.9003\n",
            "Epoch 23/100\n",
            "144/155 [==========================>...] - ETA: 0s - loss: 5.1612 - NN_RMSLE: 2.2640\n",
            "Epoch 23: val_loss improved from 3.84651 to 3.80730, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 5.1424 - NN_RMSLE: 2.2611 - val_loss: 3.8073 - val_NN_RMSLE: 1.8911\n",
            "Epoch 24/100\n",
            "149/155 [===========================>..] - ETA: 0s - loss: 5.0391 - NN_RMSLE: 2.2354\n",
            "Epoch 24: val_loss improved from 3.80730 to 3.74176, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 5.0372 - NN_RMSLE: 2.2327 - val_loss: 3.7418 - val_NN_RMSLE: 1.8757\n",
            "Epoch 25/100\n",
            "137/155 [=========================>....] - ETA: 0s - loss: 4.7958 - NN_RMSLE: 2.1810\n",
            "Epoch 25: val_loss improved from 3.74176 to 3.71291, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 4.7790 - NN_RMSLE: 2.1776 - val_loss: 3.7129 - val_NN_RMSLE: 1.8690\n",
            "Epoch 26/100\n",
            "154/155 [============================>.] - ETA: 0s - loss: 4.6781 - NN_RMSLE: 2.1531\n",
            "Epoch 26: val_loss improved from 3.71291 to 3.69253, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 4.6770 - NN_RMSLE: 2.1512 - val_loss: 3.6925 - val_NN_RMSLE: 1.8643\n",
            "Epoch 27/100\n",
            "148/155 [===========================>..] - ETA: 0s - loss: 4.5908 - NN_RMSLE: 2.1336\n",
            "Epoch 27: val_loss improved from 3.69253 to 3.64897, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 4.5797 - NN_RMSLE: 2.1276 - val_loss: 3.6490 - val_NN_RMSLE: 1.8542\n",
            "Epoch 28/100\n",
            "146/155 [===========================>..] - ETA: 0s - loss: 4.5099 - NN_RMSLE: 2.1147\n",
            "Epoch 28: val_loss improved from 3.64897 to 3.61311, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 4.5132 - NN_RMSLE: 2.1181 - val_loss: 3.6131 - val_NN_RMSLE: 1.8459\n",
            "Epoch 29/100\n",
            "151/155 [============================>.] - ETA: 0s - loss: 4.4533 - NN_RMSLE: 2.1001\n",
            "Epoch 29: val_loss did not improve from 3.61311\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 4.4473 - NN_RMSLE: 2.1011 - val_loss: 3.6164 - val_NN_RMSLE: 1.8467\n",
            "Epoch 30/100\n",
            "144/155 [==========================>...] - ETA: 0s - loss: 4.4299 - NN_RMSLE: 2.0964\n",
            "Epoch 30: val_loss improved from 3.61311 to 3.60417, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 4.4067 - NN_RMSLE: 2.0880 - val_loss: 3.6042 - val_NN_RMSLE: 1.8439\n",
            "Epoch 31/100\n",
            "138/155 [=========================>....] - ETA: 0s - loss: 4.2423 - NN_RMSLE: 2.0521\n",
            "Epoch 31: val_loss improved from 3.60417 to 3.57717, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 4.2405 - NN_RMSLE: 2.0501 - val_loss: 3.5772 - val_NN_RMSLE: 1.8377\n",
            "Epoch 32/100\n",
            "137/155 [=========================>....] - ETA: 0s - loss: 4.0638 - NN_RMSLE: 2.0093\n",
            "Epoch 32: val_loss improved from 3.57717 to 3.57601, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 4.0493 - NN_RMSLE: 2.0040 - val_loss: 3.5760 - val_NN_RMSLE: 1.8375\n",
            "Epoch 33/100\n",
            "139/155 [=========================>....] - ETA: 0s - loss: 4.0468 - NN_RMSLE: 2.0046\n",
            "Epoch 33: val_loss improved from 3.57601 to 3.56894, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 4.0456 - NN_RMSLE: 2.0037 - val_loss: 3.5689 - val_NN_RMSLE: 1.8359\n",
            "Epoch 34/100\n",
            "148/155 [===========================>..] - ETA: 0s - loss: 4.0196 - NN_RMSLE: 1.9959\n",
            "Epoch 34: val_loss improved from 3.56894 to 3.50749, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 4.0002 - NN_RMSLE: 1.9893 - val_loss: 3.5075 - val_NN_RMSLE: 1.8222\n",
            "Epoch 35/100\n",
            "149/155 [===========================>..] - ETA: 0s - loss: 4.0177 - NN_RMSLE: 1.9965\n",
            "Epoch 35: val_loss did not improve from 3.50749\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 4.0107 - NN_RMSLE: 1.9904 - val_loss: 3.5415 - val_NN_RMSLE: 1.8297\n",
            "Epoch 36/100\n",
            "140/155 [==========================>...] - ETA: 0s - loss: 4.0620 - NN_RMSLE: 2.0068\n",
            "Epoch 36: val_loss did not improve from 3.50749\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 4.0371 - NN_RMSLE: 1.9967 - val_loss: 3.5123 - val_NN_RMSLE: 1.8232\n",
            "Epoch 37/100\n",
            "139/155 [=========================>....] - ETA: 0s - loss: 3.8833 - NN_RMSLE: 1.9644\n",
            "Epoch 37: val_loss improved from 3.50749 to 3.48968, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 3.8639 - NN_RMSLE: 1.9547 - val_loss: 3.4897 - val_NN_RMSLE: 1.8183\n",
            "Epoch 38/100\n",
            "140/155 [==========================>...] - ETA: 0s - loss: 3.8491 - NN_RMSLE: 1.9555\n",
            "Epoch 38: val_loss did not improve from 3.48968\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 3.8143 - NN_RMSLE: 1.9487 - val_loss: 3.4954 - val_NN_RMSLE: 1.8195\n",
            "Epoch 39/100\n",
            "144/155 [==========================>...] - ETA: 0s - loss: 3.8389 - NN_RMSLE: 1.9512\n",
            "Epoch 39: val_loss improved from 3.48968 to 3.48596, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 7ms/step - loss: 3.8231 - NN_RMSLE: 1.9429 - val_loss: 3.4860 - val_NN_RMSLE: 1.8175\n",
            "Epoch 40/100\n",
            "144/155 [==========================>...] - ETA: 0s - loss: 3.7997 - NN_RMSLE: 1.9398\n",
            "Epoch 40: val_loss did not improve from 3.48596\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 3.7871 - NN_RMSLE: 1.9351 - val_loss: 3.4953 - val_NN_RMSLE: 1.8195\n",
            "Epoch 41/100\n",
            "144/155 [==========================>...] - ETA: 0s - loss: 3.7844 - NN_RMSLE: 1.9374\n",
            "Epoch 41: val_loss did not improve from 3.48596\n",
            "155/155 [==============================] - 0s 3ms/step - loss: 3.7945 - NN_RMSLE: 1.9421 - val_loss: 3.4916 - val_NN_RMSLE: 1.8187\n",
            "Epoch 42/100\n",
            "136/155 [=========================>....] - ETA: 0s - loss: 3.6393 - NN_RMSLE: 1.9014\n",
            "Epoch 42: val_loss improved from 3.48596 to 3.47752, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 3.6405 - NN_RMSLE: 1.8968 - val_loss: 3.4775 - val_NN_RMSLE: 1.8157\n",
            "Epoch 43/100\n",
            "152/155 [============================>.] - ETA: 0s - loss: 3.5795 - NN_RMSLE: 1.8846\n",
            "Epoch 43: val_loss improved from 3.47752 to 3.44628, saving model to model_153[]\n",
            "INFO:tensorflow:Assets written to: model_153[]/assets\n",
            "155/155 [==============================] - 1s 6ms/step - loss: 3.5802 - NN_RMSLE: 1.8831 - val_loss: 3.4463 - val_NN_RMSLE: 1.8091\n",
            "Epoch 44/100\n",
            "145/155 [===========================>..] - ETA: 0s - loss: 3.6646 - NN_RMSLE: 1.9062\n",
            "Epoch 44: val_loss did not improve from 3.44628\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 3.6711 - NN_RMSLE: 1.9093 - val_loss: 3.4796 - val_NN_RMSLE: 1.8161\n",
            "Epoch 45/100\n",
            "134/155 [========================>.....] - ETA: 0s - loss: 3.5519 - NN_RMSLE: 1.8761\n",
            "Epoch 45: val_loss did not improve from 3.44628\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 3.5437 - NN_RMSLE: 1.8718 - val_loss: 3.4500 - val_NN_RMSLE: 1.8099\n",
            "Epoch 46/100\n",
            "146/155 [===========================>..] - ETA: 0s - loss: 3.5578 - NN_RMSLE: 1.8788\n",
            "Epoch 46: val_loss did not improve from 3.44628\n",
            "155/155 [==============================] - 1s 3ms/step - loss: 3.5633 - NN_RMSLE: 1.8767 - val_loss: 3.4576 - val_NN_RMSLE: 1.8115\n",
            "Model: \"sequential_107\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_428 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_321 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_429 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_322 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_430 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_323 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_431 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  3.4576063\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 150 (837587, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[ 1  2  3  4  5  6  7  9 10]\n",
            "train 558391 valid 279196\n",
            "Model: \"sequential_108\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_432 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_324 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_433 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_325 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_434 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_326 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_435 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "8715/8725 [============================>.] - ETA: 0s - loss: 109.1180 - NN_RMSLE: 1.9326\n",
            "Epoch 1: val_loss improved from inf to 1.95385, saving model to model_150[]\n",
            "INFO:tensorflow:Assets written to: model_150[]/assets\n",
            "8725/8725 [==============================] - 27s 3ms/step - loss: 108.9970 - NN_RMSLE: 1.9320 - val_loss: 1.9538 - val_NN_RMSLE: 1.3874\n",
            "Epoch 2/100\n",
            "8725/8725 [==============================] - ETA: 0s - loss: 2.0665 - NN_RMSLE: 1.4323\n",
            "Epoch 2: val_loss improved from 1.95385 to 1.93612, saving model to model_150[]\n",
            "INFO:tensorflow:Assets written to: model_150[]/assets\n",
            "8725/8725 [==============================] - 33s 4ms/step - loss: 2.0665 - NN_RMSLE: 1.4323 - val_loss: 1.9361 - val_NN_RMSLE: 1.3808\n",
            "Epoch 3/100\n",
            "8714/8725 [============================>.] - ETA: 0s - loss: 1.9796 - NN_RMSLE: 1.4018\n",
            "Epoch 3: val_loss improved from 1.93612 to 1.93156, saving model to model_150[]\n",
            "INFO:tensorflow:Assets written to: model_150[]/assets\n",
            "8725/8725 [==============================] - 27s 3ms/step - loss: 1.9798 - NN_RMSLE: 1.4019 - val_loss: 1.9316 - val_NN_RMSLE: 1.3790\n",
            "Epoch 4/100\n",
            "8717/8725 [============================>.] - ETA: 0s - loss: 1.9740 - NN_RMSLE: 1.4000\n",
            "Epoch 4: val_loss did not improve from 1.93156\n",
            "8725/8725 [==============================] - 27s 3ms/step - loss: 1.9742 - NN_RMSLE: 1.4001 - val_loss: 1.9344 - val_NN_RMSLE: 1.3801\n",
            "Epoch 5/100\n",
            "8714/8725 [============================>.] - ETA: 0s - loss: 1.9737 - NN_RMSLE: 1.4000\n",
            "Epoch 5: val_loss did not improve from 1.93156\n",
            "8725/8725 [==============================] - 27s 3ms/step - loss: 1.9736 - NN_RMSLE: 1.4000 - val_loss: 1.9325 - val_NN_RMSLE: 1.3794\n",
            "Epoch 6/100\n",
            "8712/8725 [============================>.] - ETA: 0s - loss: 1.9734 - NN_RMSLE: 1.3998\n",
            "Epoch 6: val_loss did not improve from 1.93156\n",
            "8725/8725 [==============================] - 27s 3ms/step - loss: 1.9735 - NN_RMSLE: 1.3998 - val_loss: 1.9321 - val_NN_RMSLE: 1.3792\n",
            "Model: \"sequential_108\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_432 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_324 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_433 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_325 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_434 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_326 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_435 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.9320804\n",
            "\n",
            "[ 5  6  7  8  9 10 11]\n",
            "train 558391 valid 279196\n",
            "Model: \"sequential_109\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_436 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_327 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_437 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_328 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_438 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_329 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_439 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "8715/8725 [============================>.] - ETA: 0s - loss: 509.0116 - NN_RMSLE: 2.2278\n",
            "Epoch 1: val_loss improved from inf to 2.02922, saving model to model_150[]\n",
            "INFO:tensorflow:Assets written to: model_150[]/assets\n",
            "8725/8725 [==============================] - 27s 3ms/step - loss: 508.4392 - NN_RMSLE: 2.2271 - val_loss: 2.0292 - val_NN_RMSLE: 1.4176\n",
            "Epoch 2/100\n",
            "8720/8725 [============================>.] - ETA: 0s - loss: 2.1238 - NN_RMSLE: 1.4513\n",
            "Epoch 2: val_loss improved from 2.02922 to 2.02685, saving model to model_150[]\n",
            "INFO:tensorflow:Assets written to: model_150[]/assets\n",
            "8725/8725 [==============================] - 28s 3ms/step - loss: 2.1236 - NN_RMSLE: 1.4512 - val_loss: 2.0269 - val_NN_RMSLE: 1.4169\n",
            "Epoch 3/100\n",
            "8714/8725 [============================>.] - ETA: 0s - loss: 1.9380 - NN_RMSLE: 1.3869\n",
            "Epoch 3: val_loss did not improve from 2.02685\n",
            "8725/8725 [==============================] - 25s 3ms/step - loss: 1.9381 - NN_RMSLE: 1.3870 - val_loss: 2.0346 - val_NN_RMSLE: 1.4196\n",
            "Epoch 4/100\n",
            "8706/8725 [============================>.] - ETA: 0s - loss: 1.9273 - NN_RMSLE: 1.3830\n",
            "Epoch 4: val_loss did not improve from 2.02685\n",
            "8725/8725 [==============================] - 25s 3ms/step - loss: 1.9272 - NN_RMSLE: 1.3830 - val_loss: 2.0312 - val_NN_RMSLE: 1.4184\n",
            "Epoch 5/100\n",
            "8724/8725 [============================>.] - ETA: 0s - loss: 1.9261 - NN_RMSLE: 1.3828\n",
            "Epoch 5: val_loss did not improve from 2.02685\n",
            "8725/8725 [==============================] - 27s 3ms/step - loss: 1.9261 - NN_RMSLE: 1.3827 - val_loss: 2.0290 - val_NN_RMSLE: 1.4176\n",
            "Model: \"sequential_109\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_436 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_327 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_437 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_328 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_438 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_329 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_439 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  2.0289543\n",
            "\n",
            "[ 7  8  9 10 11 12]\n",
            "train 558392 valid 279195\n",
            "Model: \"sequential_110\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_440 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_330 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_441 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_331 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_442 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_332 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_443 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "8721/8725 [============================>.] - ETA: 0s - loss: 48.9251 - NN_RMSLE: 1.8657\n",
            "Epoch 1: val_loss improved from inf to 1.92800, saving model to model_150[]\n",
            "INFO:tensorflow:Assets written to: model_150[]/assets\n",
            "8725/8725 [==============================] - 29s 3ms/step - loss: 48.9043 - NN_RMSLE: 1.8655 - val_loss: 1.9280 - val_NN_RMSLE: 1.3818\n",
            "Epoch 2/100\n",
            "8720/8725 [============================>.] - ETA: 0s - loss: 2.0655 - NN_RMSLE: 1.4320\n",
            "Epoch 2: val_loss did not improve from 1.92800\n",
            "8725/8725 [==============================] - 27s 3ms/step - loss: 2.0656 - NN_RMSLE: 1.4320 - val_loss: 1.9283 - val_NN_RMSLE: 1.3819\n",
            "Epoch 3/100\n",
            "8722/8725 [============================>.] - ETA: 0s - loss: 1.9882 - NN_RMSLE: 1.4051\n",
            "Epoch 3: val_loss improved from 1.92800 to 1.92547, saving model to model_150[]\n",
            "INFO:tensorflow:Assets written to: model_150[]/assets\n",
            "8725/8725 [==============================] - 28s 3ms/step - loss: 1.9881 - NN_RMSLE: 1.4051 - val_loss: 1.9255 - val_NN_RMSLE: 1.3809\n",
            "Epoch 4/100\n",
            "8714/8725 [============================>.] - ETA: 0s - loss: 1.9809 - NN_RMSLE: 1.4025\n",
            "Epoch 4: val_loss improved from 1.92547 to 1.91976, saving model to model_150[]\n",
            "INFO:tensorflow:Assets written to: model_150[]/assets\n",
            "8725/8725 [==============================] - 29s 3ms/step - loss: 1.9808 - NN_RMSLE: 1.4024 - val_loss: 1.9198 - val_NN_RMSLE: 1.3791\n",
            "Epoch 5/100\n",
            "8725/8725 [==============================] - ETA: 0s - loss: 1.9796 - NN_RMSLE: 1.4020\n",
            "Epoch 5: val_loss did not improve from 1.91976\n",
            "8725/8725 [==============================] - 25s 3ms/step - loss: 1.9796 - NN_RMSLE: 1.4020 - val_loss: 1.9218 - val_NN_RMSLE: 1.3797\n",
            "Epoch 6/100\n",
            "8716/8725 [============================>.] - ETA: 0s - loss: 1.9790 - NN_RMSLE: 1.4017\n",
            "Epoch 6: val_loss did not improve from 1.91976\n",
            "8725/8725 [==============================] - 26s 3ms/step - loss: 1.9791 - NN_RMSLE: 1.4017 - val_loss: 1.9223 - val_NN_RMSLE: 1.3799\n",
            "Epoch 7/100\n",
            "8715/8725 [============================>.] - ETA: 0s - loss: 1.9790 - NN_RMSLE: 1.4018\n",
            "Epoch 7: val_loss did not improve from 1.91976\n",
            "8725/8725 [==============================] - 28s 3ms/step - loss: 1.9789 - NN_RMSLE: 1.4018 - val_loss: 1.9231 - val_NN_RMSLE: 1.3802\n",
            "Model: \"sequential_110\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_440 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_330 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_441 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_331 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_442 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_332 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_443 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  1.9231017\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 151 (464951, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[ 1  2  3  4  5  6 11 12]\n",
            "train 309967 valid 154984\n",
            "Model: \"sequential_111\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_444 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_333 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_445 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_334 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_446 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_335 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_447 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4831/4844 [============================>.] - ETA: 0s - loss: 1154.5254 - NN_RMSLE: 2.7494\n",
            "Epoch 1: val_loss improved from inf to 2.85648, saving model to model_151[]\n",
            "INFO:tensorflow:Assets written to: model_151[]/assets\n",
            "4844/4844 [==============================] - 17s 4ms/step - loss: 1151.6188 - NN_RMSLE: 2.7473 - val_loss: 2.8565 - val_NN_RMSLE: 1.6838\n",
            "Epoch 2/100\n",
            "4833/4844 [============================>.] - ETA: 0s - loss: 3.2981 - NN_RMSLE: 1.8102\n",
            "Epoch 2: val_loss did not improve from 2.85648\n",
            "4844/4844 [==============================] - 20s 4ms/step - loss: 3.2975 - NN_RMSLE: 1.8101 - val_loss: 3.0739 - val_NN_RMSLE: 1.7450\n",
            "Epoch 3/100\n",
            "4832/4844 [============================>.] - ETA: 0s - loss: 2.9285 - NN_RMSLE: 1.7068\n",
            "Epoch 3: val_loss did not improve from 2.85648\n",
            "4844/4844 [==============================] - 16s 3ms/step - loss: 2.9282 - NN_RMSLE: 1.7068 - val_loss: 3.1972 - val_NN_RMSLE: 1.7782\n",
            "Epoch 4/100\n",
            "4830/4844 [============================>.] - ETA: 0s - loss: 2.8353 - NN_RMSLE: 1.6795\n",
            "Epoch 4: val_loss did not improve from 2.85648\n",
            "4844/4844 [==============================] - 17s 3ms/step - loss: 2.8347 - NN_RMSLE: 1.6793 - val_loss: 3.2022 - val_NN_RMSLE: 1.7795\n",
            "Model: \"sequential_111\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_444 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_333 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_445 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_334 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_446 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_335 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_447 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  3.202173\n",
            "\n",
            "[ 4  5  6  7  8  9 12]\n",
            "train 309967 valid 154984\n",
            "Model: \"sequential_112\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_448 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_336 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_449 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_337 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_450 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_338 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_451 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4834/4844 [============================>.] - ETA: 0s - loss: 127.9648 - NN_RMSLE: 1.9199\n",
            "Epoch 1: val_loss improved from inf to 4.45672, saving model to model_151[]\n",
            "INFO:tensorflow:Assets written to: model_151[]/assets\n",
            "4844/4844 [==============================] - 15s 3ms/step - loss: 127.7258 - NN_RMSLE: 1.9193 - val_loss: 4.4567 - val_NN_RMSLE: 2.0791\n",
            "Epoch 2/100\n",
            "4839/4844 [============================>.] - ETA: 0s - loss: 2.7152 - NN_RMSLE: 1.6438\n",
            "Epoch 2: val_loss improved from 4.45672 to 4.21535, saving model to model_151[]\n",
            "INFO:tensorflow:Assets written to: model_151[]/assets\n",
            "4844/4844 [==============================] - 18s 4ms/step - loss: 2.7153 - NN_RMSLE: 1.6439 - val_loss: 4.2154 - val_NN_RMSLE: 2.0232\n",
            "Epoch 3/100\n",
            "4842/4844 [============================>.] - ETA: 0s - loss: 2.6102 - NN_RMSLE: 1.6119\n",
            "Epoch 3: val_loss improved from 4.21535 to 4.19375, saving model to model_151[]\n",
            "INFO:tensorflow:Assets written to: model_151[]/assets\n",
            "4844/4844 [==============================] - 18s 4ms/step - loss: 2.6100 - NN_RMSLE: 1.6118 - val_loss: 4.1938 - val_NN_RMSLE: 2.0182\n",
            "Epoch 4/100\n",
            "4832/4844 [============================>.] - ETA: 0s - loss: 2.5783 - NN_RMSLE: 1.6021\n",
            "Epoch 4: val_loss did not improve from 4.19375\n",
            "4844/4844 [==============================] - 16s 3ms/step - loss: 2.5784 - NN_RMSLE: 1.6022 - val_loss: 4.2929 - val_NN_RMSLE: 2.0413\n",
            "Epoch 5/100\n",
            "4838/4844 [============================>.] - ETA: 0s - loss: 2.5708 - NN_RMSLE: 1.5999\n",
            "Epoch 5: val_loss improved from 4.19375 to 4.14998, saving model to model_151[]\n",
            "INFO:tensorflow:Assets written to: model_151[]/assets\n",
            "4844/4844 [==============================] - 16s 3ms/step - loss: 2.5707 - NN_RMSLE: 1.5998 - val_loss: 4.1500 - val_NN_RMSLE: 2.0078\n",
            "Epoch 6/100\n",
            "4832/4844 [============================>.] - ETA: 0s - loss: 2.5683 - NN_RMSLE: 1.5990\n",
            "Epoch 6: val_loss improved from 4.14998 to 4.03577, saving model to model_151[]\n",
            "INFO:tensorflow:Assets written to: model_151[]/assets\n",
            "4844/4844 [==============================] - 17s 3ms/step - loss: 2.5679 - NN_RMSLE: 1.5989 - val_loss: 4.0358 - val_NN_RMSLE: 1.9807\n",
            "Epoch 7/100\n",
            "4831/4844 [============================>.] - ETA: 0s - loss: 2.5673 - NN_RMSLE: 1.5988\n",
            "Epoch 7: val_loss did not improve from 4.03577\n",
            "4844/4844 [==============================] - 16s 3ms/step - loss: 2.5672 - NN_RMSLE: 1.5987 - val_loss: 4.3049 - val_NN_RMSLE: 2.0441\n",
            "Epoch 8/100\n",
            "4837/4844 [============================>.] - ETA: 0s - loss: 2.5666 - NN_RMSLE: 1.5986\n",
            "Epoch 8: val_loss did not improve from 4.03577\n",
            "4844/4844 [==============================] - 15s 3ms/step - loss: 2.5668 - NN_RMSLE: 1.5986 - val_loss: 4.0525 - val_NN_RMSLE: 1.9847\n",
            "Epoch 9/100\n",
            "4835/4844 [============================>.] - ETA: 0s - loss: 2.5671 - NN_RMSLE: 1.5987\n",
            "Epoch 9: val_loss did not improve from 4.03577\n",
            "4844/4844 [==============================] - 18s 4ms/step - loss: 2.5667 - NN_RMSLE: 1.5986 - val_loss: 4.0634 - val_NN_RMSLE: 1.9873\n",
            "Model: \"sequential_112\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_448 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_336 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_449 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_337 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_450 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_338 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_451 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  4.0633984\n",
            "\n",
            "[ 6  7  8  9 10 11 12]\n",
            "train 309968 valid 154983\n",
            "Model: \"sequential_113\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_452 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_339 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_453 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_340 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_454 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_341 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_455 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4829/4844 [============================>.] - ETA: 0s - loss: 539.9196 - NN_RMSLE: 2.6337\n",
            "Epoch 1: val_loss improved from inf to 2.64747, saving model to model_151[]\n",
            "INFO:tensorflow:Assets written to: model_151[]/assets\n",
            "4844/4844 [==============================] - 16s 3ms/step - loss: 538.3417 - NN_RMSLE: 2.6315 - val_loss: 2.6475 - val_NN_RMSLE: 1.6212\n",
            "Epoch 2/100\n",
            "4843/4844 [============================>.] - ETA: 0s - loss: 3.2544 - NN_RMSLE: 1.7988\n",
            "Epoch 2: val_loss did not improve from 2.64747\n",
            "4844/4844 [==============================] - 16s 3ms/step - loss: 3.2543 - NN_RMSLE: 1.7987 - val_loss: 2.8365 - val_NN_RMSLE: 1.6742\n",
            "Epoch 3/100\n",
            "4832/4844 [============================>.] - ETA: 0s - loss: 3.0211 - NN_RMSLE: 1.7337\n",
            "Epoch 3: val_loss did not improve from 2.64747\n",
            "4844/4844 [==============================] - 15s 3ms/step - loss: 3.0210 - NN_RMSLE: 1.7337 - val_loss: 2.8590 - val_NN_RMSLE: 1.6803\n",
            "Epoch 4/100\n",
            "4834/4844 [============================>.] - ETA: 0s - loss: 2.9507 - NN_RMSLE: 1.7134\n",
            "Epoch 4: val_loss did not improve from 2.64747\n",
            "4844/4844 [==============================] - 16s 3ms/step - loss: 2.9507 - NN_RMSLE: 1.7134 - val_loss: 2.8895 - val_NN_RMSLE: 1.6886\n",
            "Model: \"sequential_113\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_452 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_339 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_453 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_340 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_454 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_341 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_455 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  2.8895335\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n",
            "groupNum_train 152 (493598, 38)\n",
            "cat_features [33, 34, 35, 36, 37]\n",
            "[ 1  2  3  4  5  6  7  8  9 10 12]\n",
            "train 329065 valid 164533\n",
            "Model: \"sequential_114\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_456 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_342 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_457 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_343 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_458 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_344 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_459 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "5140/5142 [============================>.] - ETA: 0s - loss: 514.0330 - NN_RMSLE: 2.9946\n",
            "Epoch 1: val_loss improved from inf to 3.75852, saving model to model_152[]\n",
            "INFO:tensorflow:Assets written to: model_152[]/assets\n",
            "5142/5142 [==============================] - 17s 3ms/step - loss: 513.8708 - NN_RMSLE: 2.9944 - val_loss: 3.7585 - val_NN_RMSLE: 1.8839\n",
            "Epoch 2/100\n",
            "5127/5142 [============================>.] - ETA: 0s - loss: 4.6763 - NN_RMSLE: 2.1505\n",
            "Epoch 2: val_loss improved from 3.75852 to 3.61533, saving model to model_152[]\n",
            "INFO:tensorflow:Assets written to: model_152[]/assets\n",
            "5142/5142 [==============================] - 22s 4ms/step - loss: 4.6752 - NN_RMSLE: 2.1502 - val_loss: 3.6153 - val_NN_RMSLE: 1.8434\n",
            "Epoch 3/100\n",
            "5124/5142 [============================>.] - ETA: 0s - loss: 4.0294 - NN_RMSLE: 1.9950\n",
            "Epoch 3: val_loss improved from 3.61533 to 3.49007, saving model to model_152[]\n",
            "INFO:tensorflow:Assets written to: model_152[]/assets\n",
            "5142/5142 [==============================] - 16s 3ms/step - loss: 4.0288 - NN_RMSLE: 1.9948 - val_loss: 3.4901 - val_NN_RMSLE: 1.8065\n",
            "Epoch 4/100\n",
            "5135/5142 [============================>.] - ETA: 0s - loss: 3.8461 - NN_RMSLE: 1.9483\n",
            "Epoch 4: val_loss improved from 3.49007 to 3.39964, saving model to model_152[]\n",
            "INFO:tensorflow:Assets written to: model_152[]/assets\n",
            "5142/5142 [==============================] - 15s 3ms/step - loss: 3.8451 - NN_RMSLE: 1.9480 - val_loss: 3.3996 - val_NN_RMSLE: 1.7788\n",
            "Epoch 5/100\n",
            "5132/5142 [============================>.] - ETA: 0s - loss: 3.7861 - NN_RMSLE: 1.9324\n",
            "Epoch 5: val_loss did not improve from 3.39964\n",
            "5142/5142 [==============================] - 16s 3ms/step - loss: 3.7865 - NN_RMSLE: 1.9325 - val_loss: 3.5681 - val_NN_RMSLE: 1.8297\n",
            "Epoch 6/100\n",
            "5136/5142 [============================>.] - ETA: 0s - loss: 3.7622 - NN_RMSLE: 1.9264\n",
            "Epoch 6: val_loss did not improve from 3.39964\n",
            "5142/5142 [==============================] - 15s 3ms/step - loss: 3.7625 - NN_RMSLE: 1.9265 - val_loss: 3.4588 - val_NN_RMSLE: 1.7971\n",
            "Epoch 7/100\n",
            "5118/5142 [============================>.] - ETA: 0s - loss: 3.7530 - NN_RMSLE: 1.9245\n",
            "Epoch 7: val_loss did not improve from 3.39964\n",
            "5142/5142 [==============================] - 15s 3ms/step - loss: 3.7531 - NN_RMSLE: 1.9246 - val_loss: 3.4774 - val_NN_RMSLE: 1.8027\n",
            "Model: \"sequential_114\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_456 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_342 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_457 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_343 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_458 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_344 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_459 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  3.4774256\n",
            "\n",
            "[ 5  6  7  8  9 10 11 12]\n",
            "train 329065 valid 164533\n",
            "Model: \"sequential_115\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_460 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_345 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_461 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_346 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_462 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_347 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_463 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "5131/5142 [============================>.] - ETA: 0s - loss: 505.0742 - NN_RMSLE: 5.6501\n",
            "Epoch 1: val_loss improved from inf to 8.84991, saving model to model_152[]\n",
            "INFO:tensorflow:Assets written to: model_152[]/assets\n",
            "5142/5142 [==============================] - 17s 3ms/step - loss: 504.0613 - NN_RMSLE: 5.6465 - val_loss: 8.8499 - val_NN_RMSLE: 2.9670\n",
            "Epoch 2/100\n",
            "5140/5142 [============================>.] - ETA: 0s - loss: 6.7608 - NN_RMSLE: 2.5124\n",
            "Epoch 2: val_loss improved from 8.84991 to 4.82501, saving model to model_152[]\n",
            "INFO:tensorflow:Assets written to: model_152[]/assets\n",
            "5142/5142 [==============================] - 18s 3ms/step - loss: 6.7594 - NN_RMSLE: 2.5120 - val_loss: 4.8250 - val_NN_RMSLE: 2.1489\n",
            "Epoch 3/100\n",
            "5135/5142 [============================>.] - ETA: 0s - loss: 2.8927 - NN_RMSLE: 1.6835\n",
            "Epoch 3: val_loss did not improve from 4.82501\n",
            "5142/5142 [==============================] - 17s 3ms/step - loss: 2.8929 - NN_RMSLE: 1.6836 - val_loss: 5.5920 - val_NN_RMSLE: 2.3131\n",
            "Epoch 4/100\n",
            "5127/5142 [============================>.] - ETA: 0s - loss: 2.8848 - NN_RMSLE: 1.6807\n",
            "Epoch 4: val_loss did not improve from 4.82501\n",
            "5142/5142 [==============================] - 16s 3ms/step - loss: 2.8843 - NN_RMSLE: 1.6806 - val_loss: 5.5518 - val_NN_RMSLE: 2.3048\n",
            "Epoch 5/100\n",
            "5122/5142 [============================>.] - ETA: 0s - loss: 2.8848 - NN_RMSLE: 1.6805\n",
            "Epoch 5: val_loss did not improve from 4.82501\n",
            "5142/5142 [==============================] - 15s 3ms/step - loss: 2.8843 - NN_RMSLE: 1.6804 - val_loss: 5.5386 - val_NN_RMSLE: 2.3020\n",
            "Model: \"sequential_115\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_460 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_345 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_461 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_346 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_462 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_347 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_463 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  5.5386157\n",
            "\n",
            "[ 9 10 11 12]\n",
            "train 329066 valid 164532\n",
            "Model: \"sequential_116\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_464 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_348 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_465 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_349 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_466 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_350 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_467 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "5133/5142 [============================>.] - ETA: 0s - loss: 521.4562 - NN_RMSLE: 2.8650\n",
            "Epoch 1: val_loss improved from inf to 3.31713, saving model to model_152[]\n",
            "INFO:tensorflow:Assets written to: model_152[]/assets\n",
            "5142/5142 [==============================] - 15s 3ms/step - loss: 520.5854 - NN_RMSLE: 2.8635 - val_loss: 3.3171 - val_NN_RMSLE: 1.8117\n",
            "Epoch 2/100\n",
            "5139/5142 [============================>.] - ETA: 0s - loss: 4.4485 - NN_RMSLE: 2.0974\n",
            "Epoch 2: val_loss improved from 3.31713 to 3.21514, saving model to model_152[]\n",
            "INFO:tensorflow:Assets written to: model_152[]/assets\n",
            "5142/5142 [==============================] - 16s 3ms/step - loss: 4.4478 - NN_RMSLE: 2.0973 - val_loss: 3.2151 - val_NN_RMSLE: 1.7832\n",
            "Epoch 3/100\n",
            "5131/5142 [============================>.] - ETA: 0s - loss: 4.1446 - NN_RMSLE: 2.0234\n",
            "Epoch 3: val_loss did not improve from 3.21514\n",
            "5142/5142 [==============================] - 16s 3ms/step - loss: 4.1442 - NN_RMSLE: 2.0233 - val_loss: 3.2406 - val_NN_RMSLE: 1.7904\n",
            "Epoch 4/100\n",
            "5139/5142 [============================>.] - ETA: 0s - loss: 3.9860 - NN_RMSLE: 1.9838\n",
            "Epoch 4: val_loss improved from 3.21514 to 3.12971, saving model to model_152[]\n",
            "INFO:tensorflow:Assets written to: model_152[]/assets\n",
            "5142/5142 [==============================] - 16s 3ms/step - loss: 3.9859 - NN_RMSLE: 1.9838 - val_loss: 3.1297 - val_NN_RMSLE: 1.7587\n",
            "Epoch 5/100\n",
            "5130/5142 [============================>.] - ETA: 0s - loss: 3.9182 - NN_RMSLE: 1.9663\n",
            "Epoch 5: val_loss did not improve from 3.12971\n",
            "5142/5142 [==============================] - 15s 3ms/step - loss: 3.9180 - NN_RMSLE: 1.9663 - val_loss: 3.2021 - val_NN_RMSLE: 1.7795\n",
            "Epoch 6/100\n",
            "5123/5142 [============================>.] - ETA: 0s - loss: 3.8926 - NN_RMSLE: 1.9602\n",
            "Epoch 6: val_loss did not improve from 3.12971\n",
            "5142/5142 [==============================] - 16s 3ms/step - loss: 3.8926 - NN_RMSLE: 1.9602 - val_loss: 3.1776 - val_NN_RMSLE: 1.7725\n",
            "Epoch 7/100\n",
            "5140/5142 [============================>.] - ETA: 0s - loss: 3.8819 - NN_RMSLE: 1.9577\n",
            "Epoch 7: val_loss did not improve from 3.12971\n",
            "5142/5142 [==============================] - 16s 3ms/step - loss: 3.8820 - NN_RMSLE: 1.9577 - val_loss: 3.2167 - val_NN_RMSLE: 1.7837\n",
            "Model: \"sequential_116\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_464 (Dense)           (None, 64)                2496      \n",
            "                                                                 \n",
            " dropout_348 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_465 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_349 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_466 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_350 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_467 (Dense)           (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------- Evaluation on Training Data ----------\n",
            "MSE:  3.2166672\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for groupNum_train in building_meta_df['groupNum_train'].unique():\n",
        "    X_train, y_train = create_X_y(train_df, groupNum_train=groupNum_train)\n",
        "    y_valid_pred_total = np.zeros(X_train.shape[0])\n",
        "    gc.collect()\n",
        "    print('groupNum_train', groupNum_train, X_train.shape)\n",
        "\n",
        "    cat_features = [X_train.columns.get_loc(\n",
        "        cat_col) for cat_col in category_cols]\n",
        "    print('cat_features', cat_features)\n",
        "\n",
        "    exec('models' + str(groupNum_train) + '=[]')\n",
        "\n",
        "    train_df_site = train_df[train_df['groupNum_train']\n",
        "                             == groupNum_train].copy()\n",
        "\n",
        "    \n",
        "    for train_idx, valid_idx in kf.split(train_df_site, train_df_site['building_id']):\n",
        "        train_data = X_train.iloc[train_idx, :], y_train[train_idx]\n",
        "        valid_data = X_train.iloc[valid_idx, :], y_train[valid_idx]\n",
        "\n",
        "        mindex = train_df_site.iloc[valid_idx, :].month.unique()\n",
        "        print(mindex)\n",
        "\n",
        "        print('train', len(train_idx), 'valid', len(valid_idx))\n",
        "    \n",
        "        model, y_pred_valid= RNN_LSTM(train_data, valid_data) # How to pass and train the categorical data\n",
        "        \n",
        "        \n",
        "        y_valid_pred_total[valid_idx] = y_pred_valid.reshape(-1)\n",
        "        exec('models' + str(groupNum_train) + '.append([mindex, model])')\n",
        "        gc.collect()\n",
        "        if debug:\n",
        "            break\n",
        "\n",
        "    try:\n",
        "        sns.distplot(y_train)\n",
        "        sns.distplot(y_valid_pred_total)\n",
        "        plt.show()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    del X_train, y_train\n",
        "    gc.collect()\n",
        "\n",
        "    print('-------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading...\n",
            "Before Preprocessing ....\n",
            "Shape of test data:  (41697600, 4)\n",
            "Shape of Weather test data:  (277243, 9)\n",
            "preprocessing building...\n",
            "preprocessing weather...\n",
            "reduce mem usage...\n",
            "Memory usage of dataframe is 3698.23 MB\n",
            "Memory usage after optimization is: 1590.66 MB\n",
            "Decreased by 57.0%\n",
            "Memory usage of dataframe is 48.12 MB\n",
            "Memory usage after optimization is: 41.51 MB\n",
            "Decreased by 13.7%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Prediction on test data¶\n",
        "\n",
        "print('loading...')\n",
        "test_df = pd.read_feather(root/'test.feather')\n",
        "weather_test_df = pd.read_feather(root/'weather_test.feather')\n",
        "\n",
        "print('Before Preprocessing ....')\n",
        "print('Shape of test data: ', test_df.shape)\n",
        "print('Shape of Weather test data: ', weather_test_df.shape)\n",
        "\n",
        "weather_test_df = weather_test_df.drop_duplicates(['timestamp', 'site_id'])\n",
        "set_local(weather_test_df)\n",
        "add_holiyday(weather_test_df)\n",
        "\n",
        "print('preprocessing building...')\n",
        "test_df['date'] = test_df['timestamp'].dt.date\n",
        "preprocess(test_df)\n",
        "\n",
        "\n",
        "print('preprocessing weather...')\n",
        "weather_test_df = weather_test_df.groupby('site_id').apply(\n",
        "    lambda group: group.interpolate(method='ffill', limit_direction='forward'))\n",
        "weather_test_df.groupby('site_id').apply(lambda group: group.isna().sum())\n",
        "\n",
        "add_sg(weather_test_df)\n",
        "\n",
        "add_lag_feature(weather_test_df, window=3)\n",
        "add_lag_feature(weather_test_df, window=72)\n",
        "\n",
        "test_df['bid_cnt'] = test_df.building_id.map(bid_map)\n",
        "\n",
        "test_df = test_df.merge(building_meta_df[['building_id', 'meter', 'groupNum_train','square_feet']], on=[\n",
        "                        'building_id', 'meter'], how='left')\n",
        "\n",
        "test_df['square_feet_np_log1p'] = np.log1p(test_df['square_feet'])\n",
        "\n",
        "print('reduce mem usage...')\n",
        "test_df = reduce_mem_usage(test_df, use_float16=True)\n",
        "weather_test_df = reduce_mem_usage(weather_test_df, use_float16=True)\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 636.26 MB\n",
            "Memory usage after optimization is: 198.83 MB\n",
            "Decreased by 68.7%\n",
            "(41697600, 2)\n"
          ]
        }
      ],
      "source": [
        "# %% [code]\n",
        "sample_submission = pd.read_feather(\n",
        "    os.path.join(root, 'sample_submission.feather'))\n",
        "reduce_mem_usage(sample_submission)\n",
        "\n",
        "print(sample_submission.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_X(test_df, groupNum_train):\n",
        "\n",
        "    target_test_df = test_df[test_df['groupNum_train']\n",
        "                             == groupNum_train].copy()\n",
        "    # target_test_df = target_test_df.merge(df_groupNum_median, on=['timestamp'], how='left')\n",
        "    target_test_df = target_test_df.merge(\n",
        "        building_meta_df, on=['building_id', 'meter', 'groupNum_train'], how='left')\n",
        "    target_test_df = target_test_df.merge(\n",
        "        weather_test_df, on=['site_id', 'timestamp'], how='left')\n",
        "    #target_test_df['group_median_'+str(groupNum_train)] = np.nan\n",
        "\n",
        "    X_test = target_test_df[feature_cols + category_cols]\n",
        "\n",
        "    return X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def pred_all(X_test, models, batch_size=10000):\n",
        "    iterations = (X_test.shape[1] + batch_size - 1) // batch_size\n",
        "    print('iterations', iterations)\n",
        "\n",
        "    y_test_pred_total = np.zeros(X_test.shape[0])\n",
        "    for i, (mindex, model) in enumerate(models):\n",
        "        print(f'predicting {i}-th model')\n",
        "        for k in tqdm(range(iterations)):\n",
        "            y_pred_test = model.predict(\n",
        "                X_test[k*batch_size:(k+1)*batch_size]) #num_iteration=model.best_iteration\n",
        "            y_test_pred_total[k*batch_size:(k+1)*batch_size] += y_pred_test.reshape(-1)\n",
        "\n",
        "    y_test_pred_total /= len(models)\n",
        "    return y_test_pred_total\n",
        "\n",
        "\n",
        "def pred(X_test, models, batch_size=10000):\n",
        "        print('all pred')\n",
        "        return pred_all(X_test, models, batch_size=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "groupNum_train:  0\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba944785723b4103bfb746b79ced93fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70f536a572014db0b98798a45f9010d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34ba3a674f9a488abc0af4dfa6847151",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1839600, 38) (1839600,)\n",
            "groupNum_train:  1\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2fe4d70676d4beeadc8abed4f8656bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "438bd68bbb79483ab29a95201f85604e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9925ee3e4f2b4a0cae89501c187a0a52",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(420480, 38) (420480,)\n",
            "groupNum_train:  10\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c6c48bcfc9c46a9a12fddffd2e278cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fac7b675d89747b08797f9cff35c04f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "795523a8bbfd4396af943ebebaf8b0d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAVvElEQVR4nO3de5BkZXnH8d+vLzu7y4IoO6ACcY0xmxCiYk3EhCpTAS8bIZJUUilRjLe4VkoTNFYoMKnyUqnEigmllasrEIkiJioatYyKihIriM4CQVhQLEDALOygwHKbS3c/+aO7Z2dnumea3TnnsPN8P1VbM3OmZ963FX778LzveY8jQgCAPGpVTwAAUC6CHwCSIfgBIBmCHwCSIfgBIJlG1RMYxebNm2PLli1VTwMADik7d+68LyLGF18/JIJ/y5YtmpycrHoaAHBIsf2jQddp9QBAMgQ/ACRD8ANAMgQ/ACRD8ANAMgQ/ACRD8ANAMgQ/ACSTMvi/dONunfp331Cr3al6KgBQupTBf8s9D+m2qUf02Fy76qkAQOlSBv/0XLfSn2vz9DEA+SQN/m6lP0erB0BCKYN/ptUN/tkWwQ8gn5TB/9hsL/ip+AEklDL49/X4CX4A+eQM/l6rZ67F4i6AfAoLftsX295j+8YF195v+xbbN9j+jO0jixp/Of3F3dk22zkB5FNkxf8RSdsWXbtC0okR8RxJP5B0foHjD9Vv9cxS8QNIqLDgj4irJP100bWvRESr9+W3JR1X1PjLYTsngMyq7PG/QdJ/Dfum7e22J21PTk1NrerAMy0WdwHkVUnw2/5zSS1Jlw57TUTsiIiJiJgYH1/ykPiDMt/jZx8/gIQaZQ9o+3WSzpB0WkRU0mTft7hL8APIp9Tgt71N0rmSfj0iHi1z7IU4qwdAZkVu57xM0tWSttq+2/YbJf2DpMMlXWH7etv/UtT4w0TEvn38VPwAEiqs4o+IswZcvqio8UY12+6o32Cixw8go3R37vbbPBIVP4Cc0gX/zIKHr7C4CyCjdMG/X8XPnbsAEsoX/K2FFT9n9QDIJ1/wL2j1sJ0TQEYJg39fq4ddPQAyShj8LO4CyC118M9R8QNIKF3wP7Zfj5/gB5BPuuCf6fX41zdrLO4CSCld8Pe3cx6xvjl/Lj8AZJIv+HutniM2NGn1AEgpYfB3w/7w9Q2CH0BKCYO/rUbN2tCsE/wAUir9CVxVm57raH2zrvsentGjs219/Jo79/v+q07+mYpmBgDlyFfxt9pa36ypbqvdYVcPgHzyBf9cW2ONuur1mloEP4CE0gX/zFxH65s1NWpU/AByShf803NtrW/WafUASCvf4m6rF/w10+oBkFK+4O+1ejohtTts5wSQT85WT6OuBq0eAEnlDP5eq4fgB5BRwuDvaKxZU71udULqBOEPIJfCgt/2xbb32L5xwbWn2L7C9q29j08uavxhZnqLuw1bkqj6AaRTZMX/EUnbFl07T9LXIuLZkr7W+7pU03MdrW90Wz0SwQ8gn8KCPyKukvTTRZfPlHRJ7/NLJP12UeMP0+3x1+aDny2dALIpu8d/TETs7n1+j6Rjhr3Q9nbbk7Ynp6amVmXwTifU6oTWNWpq1LpvnYofQDaVLe5GREgamroRsSMiJiJiYnx8fFXGbPcWchs10+oBkFbZwX+v7adJUu/jnjIHb/WesVuvLWz1cBMXgFzKDv7PSXpt7/PXSvrPMgfvh3yzTsUPIK8it3NeJulqSVtt3237jZLeJ+kltm+V9OLe16Xph3y9ZjUIfgBJFXZWT0ScNeRbpxU15kr6O3jo8QPILNWdu4N7/AQ/gFxyBX+vx9+o0+oBkFeq4G/v1+phHz+AnFIFf2vB4i6tHgBZ5Qr+dr/ir7G4CyCtXMFPjx8AcgV/m+2cAJAr+Af3+DmyAUAuuYKfHj8AJAt+evwAkCv4F/b4awQ/gKRSBf/CHn/NVs3s4weQT67gX9Dj73+k4geQTargby/o8UtSrUarB0A+qYJ/4bHMklS31QmCH0AuqYJ/4YNYJKlWMxU/gHRSBf/coh5/t+KvckYAUL5Uwb+0x0+rB0A+qYJ/cY+/ZhZ3AeSTKviX9PhZ3AWQUKrgX9Ljr1kdKn4AyaQK/iU9fhZ3ASSUKvhbS1o9otUDIJ1Uwd9uL1rcZR8/gIQqCX7bb7d9k+0bbV9me30Z484tqvi5cxdARqUHv+1jJf2JpImIOFFSXdIryxi73emoUbNsKn4AeVXV6mlI2mC7IWmjpP8rY9BWJ+arfYk7dwHkVHrwR8SPJf2tpDsl7Zb0YER8ZfHrbG+3PWl7cmpqalXGbrdjvr8vsbgLIKcqWj1PlnSmpGdKerqkw2yfvfh1EbEjIiYiYmJ8fHxVxl5c8dPqAZBRFa2eF0u6PSKmImJO0uWSfq2MgVudjpr1fW+ZffwAMqoi+O+U9ELbG91dZT1N0s1lDNxe3OPnkDYACVXR479G0qckXSvpe7057Chj7NaSHj9HNgDIp1HFoBHxLknvKnvcVidUr++/uNum4geQzEgVv+3LbZ9u+5C+07fVCTVrC3r8HNIGIKFRg/yfJL1K0q2232d7a4FzKky702EfP4D0Rgr+iPhqRLxa0vMl3SHpq7b/x/brbTeLnOBqarUXbeek1QMgoZFbN7aPkvQ6SX8o6TpJH1T3L4IrCplZAVqdmD+SWeI8fgA5jbS4a/szkrZK+qik34qI3b1v/bvtyaImt9panZh/CIvEE7gA5DTqrp4PR8QXF16wPRYRMxExUcC8CtE/pK2v+7B1KSLmD24DgLVu1FbPXw64dvVqTqQMS3v83c/p9gDIZNmK3/ZTJR2r7kmaJ0nqp+YR6p6qeUhpdULrm/v+ruu3+zsRqouKH0AOK7V6Xqbugu5xki5YcP0hSe8saE6FWdLj71X/nU50nwoAAAksG/wRcYmkS2z/bkR8uqQ5FWZJj7/X6mFLJ4BMVmr1nB0RH5O0xfafLv5+RFww4MeesJb0+Gv0+AHks1Kr57Dex01FT6QMS/bxe0GrBwCSWKnV86Hex/eUM51itZfs4+9dp9UDIJFRD2n7G9tH2G7a/prtqUFPzXqiay3q8ddrVPwA8hl1H/9LI2KvpDPUPavn5yT9WVGTKkp7yD5+Kn4AmYwa/P2W0OmSPhkRDxY0n0LNLerxs7gLIKNRj2z4gu1bJD0m6Y9sj0uaLm5axVjc45+/gYvkB5DIqMcyn6fuA9Eneg9If0TSmUVOrAitdmfIkQ0EP4A8Hs+jF39B3f38C3/m31Z5PoXqVvwDWj1U/AASGfVY5o9Kepak6yW1e5dDh1jwzy155m5/cbeqGQFA+Uat+CcknRBxaPdE2kueudv9SKsHQCaj7uq5UdJTi5xI0SJC7U4seeauRKsHQC6jVvybJe2y/R1JM/2LEfGKQmZVgHYv3DmkDUB2owb/u1dzUNtHSrpQ0onqrhW8ISIKfbBLqxf89fqgO3eLHBkAnlhGCv6I+KbtZ0h6dkR81fZGHdwJ9h+U9KWI+D3b61TCQ136wd9c9MxdiYofQC6jntXzJkmfkvSh3qVjJX32QAa0/SRJL5J0kSRFxGxEPHAgv+vxaPe27uy/j7/7kcVdAJmMurj7FkmnSNorSRFxq6SjD3DMZ0qakvSvtq+zfaHtw1b6oYPV6vVzGgNbPQQ/gDxGDf6ZiJjtf9G7ietA07Ih6fmS/jkiTlL3LuDzFr/I9nbbk7Ynp6amDnCofeZ7/Ny5CyC5UYP/m7bfqe5D118i6ZOSPn+AY94t6e6IuKb39afU/YtgPxGxIyImImJifHz8AIfaZ2CPn8VdAAmNGvznqdue+Z6kN0v6oqS/OJABI+IeSXfZ3tq7dJqkXQfyux6P5Xr8LO4CyGTUXT0d25+V9NmIOPi+i/THki7t7ei5TdLrV+F3Lmtgj59WD4CEVnrYuiW9S9Jb1fuvA9ttSX8fEe890EEj4np1j4EozcAeP4u7ABJaqdXzdnV38/xKRDwlIp4i6WRJp9h+e+GzW0Wtdv/O3UH7+CuZEgBUYqXgf42ksyLi9v6FiLhN0tmS/qDIia22QUc2zG/npNUDIJGVgr8ZEfctvtjr8zeLmVIx+j3+hUc2uL+4S6sHQCIrBf/sAX7vCac15JA2i4ofQC4r7ep5ru29A65b0voC5lOYQT1+qdvuYR8/gEyWDf6IOJiD2J5Q5nv8C1o9Urfqp+IHkMmoN3Ad8uZ7/LVFwV/jBi4AueQJ/vbSHr/Uq/hZ3AWQSJ7g7wzp8dPqAZBMmuAf2uNncRdAMmmCf2iP3/T4AeSSJ/iH9PjrNVo9AHJJE/z7Wj37v+WazZ27AFJJE/yD7tyV+vv4q5gRAFQjTfC3h/T4u3fukvwA8kgT/HND9/FzVg+AXNIE/9Aef83s6gGQSprgX7bHT6sHQCJpgn9oj5/FXQDJpAn+oT3+Gj1+ALmkCf52J1SvWfbSVg/7+AFkkib459qdJW0eiTt3AeSTJvhnWh2NNZa+3W7FX8GEAKAiaYJ/tj0s+OnxA8ilsuC3Xbd9ne0vlDHebKujdfWlb5dWD4Bsqqz4z5F0c1mDzbY6Wjek1cM+fgCZVBL8to+TdLqkC8sac6bV1lhj6bPju3fuljULAKheVRX/BySdK2nosqrt7bYnbU9OTU0d9IBU/ADQVXrw2z5D0p6I2Lnc6yJiR0RMRMTE+Pj4QY872x4c/HUWdwEkU0XFf4qkV9i+Q9InJJ1q+2NFDzpscbfG4i6AZEoP/og4PyKOi4gtkl4p6esRcXbR4y7X6uHOXQCZpNnHP+wGru52Timo+gEk0ahy8Ij4hqRvlDHW8Iq/+7ET3X4/AKx1qSr+wYu73bSnzw8gizTBP/TIhhrBDyCXPME/bFdPv+LnoDYASaQJ/plWW2PNwXfuSuK5uwDSSBP8wyr+Rq/iZ0sngCxSBH+r3VEnNHBxt9HbyjPHofwAkkgR/LO9UB8U/M3efwUQ/ACyyBH8rV7wD2j1NHsVf4sjOgEkkSr4x5qDWj1U/ABySRH8M8tV/LV+j5+KH0AOuYJ/4OIuFT+AXFIE/3yrZ5nF3RbbOQEkkSP42/3gX3oD177FXSp+ADnkCH5aPQAwL0Xwz7Takobt42dxF0AuKYJ/+X38vYqfU9oAJJEr+Ic8erFucwMXgDRyBH97+K4eqXteDz1+AFmkCP7l9vFL3XYPPX4AWRD86i7wsp0TQBYpgn/+Bq760n38UndLJ60eAFmkCv7lKn5aPQCyIPglNWs1tnMCSCNH8LfbatSseu8kzsWa9RrbOQGkUXrw2z7e9pW2d9m+yfY5RY85M9cZWu1L3e2cLO4CyKJRwZgtSe+IiGttHy5pp+0rImJXUQPOtlcKfrZzAsij9Io/InZHxLW9zx+SdLOkY4scc7bVGXhcQ1+zZnr8ANKotMdve4ukkyRdM+B7221P2p6cmpo6qHFmW52Bj13s4wYuAJlUFvy2N0n6tKS3RcTexd+PiB0RMRERE+Pj4wc11kx7hYqfHj+ARCoJfttNdUP/0oi4vOjxuou7g2/ekriBC0AuVezqsaSLJN0cEReUMeZKi7vNutUJqc3jFwEkUEXFf4qk10g61fb1vT8vL3LA2VZbY8u2enrP3aXqB5BA6ds5I+JbkgbfSVWQ2VZHh40Nf6vzj1+k4geQQJI7d1fezinx3F0AOaQI/pXu3G3ywHUAiaQI/lEWdyVxXg+AFHIEf6sz9LGL0oIePxU/gATSBP9orR4qfgBrX57gH/L0LWlBq4fzegAkkCL4Z1ao+Bs1Kn4Aeaz54I+Ix7G4S8UPYO1b88E/2wvz0RZ3qfgBrH1rPvinZ1cO/n7Fz64eABms+eCfenhakjR++NjQ13BWD4BM1nzw37t3RpJ0zBHrh76m0T+ygbN6ACSQIPi7Ff9ywW9bjZpp9QBIIUHw9yv+4a0eiccvAsgjQfBP6/D1DW1ct/wJ1Dx+EUAWaz749zw0vWybp2/TWEN7p+dKmBEAVGvNB/89D06v2OaRpKM2jem+h2dLmBEAVGvNB/+9e2d0zOErV/ybN63T/Y/MarZFuwfA2ramgz8itOehaR09QqvnqE1jCkl33f9o8RMDgAqt6eC//9E5zbVjpFbP5k3d19xx3yNFTwsAKrWmg3+UPfx9mw9bJ0m6neAHsMYlCf6VK/6NYw1taNYJfgBr3poO/j29m7eOHmFxV+ou8BL8ANa6NR38/Yr/6BEqfqm7wEuPH0CZpufa2vmj+zU91y5tzOVvZy2I7W2SPiipLunCiHhfEePc+9C0nryxqbHG8McuLnTUpnW6/q4H9NhsWxvWjfYzAHAg5todXfSt2/Xhq27TTx6Z1cZ1df3+xPE6d9vWFU8aOFilB7/tuqR/lPQSSXdL+q7tz0XErtUe680vepbOfN6xI7/+2CM3SJLOu/wG/dXv/LI2rqvL9mpPC0BSEaGL/vt23Tr1sK76wZR2Pzitnz9mk077xaMVIV1y9R36+i179KYX/axeesIxGt80plpt9TPIEeUeTGb7VyW9OyJe1vv6fEmKiL8e9jMTExMxOTm5qvP4+DV3LrkWEXrgsTm9/8vfn7+2rlGbP7YZXSX/I3NICPE/ymL8c7JUqxNq945/f9KGps54ztP0S09/kiTpVSf/jL5920/03s/v0q7deyV1j4z/8Gsn9Btbjz6g8WzvjIiJxderaPUcK+muBV/fLenkxS+yvV3S9t6XD9v+/uLXHKTNku5b5d95KOH98/55/xW7YcHnrx7ymlOHlsQjecagi5X0+EcRETsk7Sjq99ueHPQ3YRa8f94/7z/v+69iV8+PJR2/4OvjetcAACWoIvi/K+nZtp9pe52kV0r6XAXzAICUSm/1RETL9lslfVnd7ZwXR8RNZc9DBbaRDhG8/9x4/4mVvqsHAFCtNX3nLgBgKYIfAJJJGfy2t9n+vu0f2j6v6vmUyfbFtvfYvrHquVTB9vG2r7S9y/ZNts+pek5lsr3e9nds/2/v/b+n6jmVzXbd9nW2v1D1XKqSLvgXHBnxm5JOkHSW7ROqnVWpPiJpW9WTqFBL0jsi4gRJL5T0lmT//89IOjUinivpeZK22X5htVMq3TmSbq56ElVKF/ySXiDphxFxW0TMSvqEpDMrnlNpIuIqST+teh5ViYjdEXFt7/OH1A2A0Q90OsRF18O9L5u9P2l2eNg+TtLpki6sei5Vyhj8g46MSPMvPvaxvUXSSZKuqXgqpeq1Oq6XtEfSFRGR6f1/QNK5kjoVz6NSGYMfkO1Nkj4t6W0Rsbfq+ZQpItoR8Tx175p/ge0TK55SKWyfIWlPROysei5Vyxj8HBmRnO2muqF/aURcXvV8qhIRD0i6UnnWfE6R9Arbd6jb4j3V9seqnVI1MgY/R0Yk5u4DFi6SdHNEXFD1fMpme9z2kb3PN6j7XIxbKp1USSLi/Ig4LiK2qPvv/dcj4uyKp1WJdMEfES1J/SMjbpb0HxUdGVEJ25dJulrSVtt3235j1XMq2SmSXqNutXd978/Lq55UiZ4m6UrbN6hbBF0REWm3NWbFkQ0AkEy6ih8AsiP4ASAZgh8AkiH4ASAZgh8AkiH4ASAZgh8Akvl/4kBV+D+TZUMAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(893520, 38) (893520,)\n",
            "groupNum_train:  13\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4094c28882784c67aea763448c09808d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01f67c8fbac64dd7bdbb6266cf527b8d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "722d7438e8ed425293a9c6341aa0b749",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(210240, 38) (210240,)\n",
            "groupNum_train:  20\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d9a03769f48422c8953889111d60203",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e7cff28408c4a6bae794dc9c8a9499f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "934d20dc4e2240f6a11311cb7cc51088",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2365200, 38) (2365200,)\n",
            "groupNum_train:  21\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b5cdb03c65b417689b6a9f84ff95697",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f66cdde3f60740ccbb298803dab1a90f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cbef5a0a55084981a5f0d6f801397ef9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1734480, 38) (1734480,)\n",
            "groupNum_train:  23\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54b60c8caeb6436ab9c8f7084cfb409e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef81e66daa3c4c15a0a49f621af3319f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a8a3fdea46f4c208d5e19d0baa3e162",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(963600, 38) (963600,)\n",
            "groupNum_train:  30\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0cdbadc57ee4ed48c05a06c0f9d4c1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d75c63a8ec94dd7b8f855e6aac1a95b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "168a1e1ed91a4c828b96ac70b4aca249",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4800480, 38) (4800480,)\n",
            "groupNum_train:  40\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f05b6933c584b7d858a5f8dfa85d8eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "988940ae278f4ddbb745122f806ba444",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1be90bf1b4341f49d00f28b8daf306e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1594320, 38) (1594320,)\n",
            "groupNum_train:  50\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ced8c2597d454edb80cc17da49f441e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "607a983f426e4cf69a6f8ddec7e164d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91a1f32ec4e94ac59ec4a9b320961277",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAWg0lEQVR4nO3de5BkZX3G8e/TM7PLLmgEGZFwW6MWxlSFixNQSVmowRBNREsrBV5AC7OWl4oYK1WUqSimrJRJecnFREWhXIkRDCiihSZILC1LBYeLXCUggi4iO6BcZIednT6//HFOz/T0zsz2zvTpnunf86na2u7T3XPel9Zn3v2973mPIgIzM8ujMegGmJlZfzn4zcyScfCbmSXj4DczS8bBb2aWzOigG9CNgw8+OLZs2TLoZpiZrSvXXXfdgxEx3nl8XQT/li1bmJycHHQzzMzWFUn3LnbcpR4zs2Qc/GZmyTj4zcyScfCbmSXj4DczS8bBb2aWjIPfzCwZB7+ZWTKpgj8iOPWfvsPlN9w36KaYmQ1MquDf3Qx+/MvHuGvHbwbdFDOzgUkV/NO7mwA0fdcxM0ssVfDvqoK/KBz8ZpZXbcEvaT9J10r6kaRbJX2gOv4MSddIukvSJZI21NWGTnMjfge/mSVW54h/F/CSiDgGOBY4VdLzgX8APhYRzwJ+DZxdYxsWeGJ3AbjUY2a51Rb8UWrNoo5VfwJ4CXBpdXwb8Kq62tBp2qUeM7N6a/ySRiTdCOwArgJ+AjwcEbPVW7YDhy3x2a2SJiVNTk1N9aQ9T3hy18ys3uCPiGZEHAscDpwAPGcfPnt+RExExMT4+B43kFmR+Rp/T36cmdm61JdVPRHxMPAt4AXAUyS17vx1ONC3q6m8qsfMrN5VPeOSnlI93gScAtxO+QvgtdXbzgK+UlcbOnkdv5lZvffcPRTYJmmE8hfMFyPia5JuAy6W9EHgBuCCGtuwQGtVj0f8ZpZZbcEfETcBxy1y/G7Ken/fTc94xG9mlurK3Sdmqxq/c9/MEssV/DOe3DUzyxX8s9WVuw5+M0ssVfC7xm9mliz4n/A6fjOzXMHvdfxmZsmCf253To/4zSyxZMHfWs7p4DezvFIGv0f8ZpZZquCf349/wA0xMxugVMHv/fjNzNIFvyd3zcySBb8nd83MUgX/tCd3zczyBH9EeFWPmRmJgn+mWcxtx+xKj5lllib4WxO74FU9ZpZbouBvzj32Jm1mllnK4PeI38wySxP8rRU9+401PLlrZqmlCf5WjX//DaMu9ZhZammCv3X3rf03jrrUY2appQn+J2bL4N+8YYSmN2kzs8TSBP+uqsZ/wMZRb9lgZqmlCf7W5O7mjaOe3DWz1GoLfklHSPqWpNsk3SrpXdXx8yTdJ+nG6s/L62pDu9bk7gEbRzy5a2apjdb4s2eB90TE9ZKeBFwn6arqtY9FxIdrPPceWpO7mzd4ctfMcqst+CPifuD+6vFjkm4HDqvrfHvTmtw9wKUeM0uuLzV+SVuA44BrqkPvlHSTpAslHbjEZ7ZKmpQ0OTU1teo2PDHTuoBrxJO7ZpZa7cEv6QDgMuCciHgU+ATwTOBYyn8RfGSxz0XE+RExERET4+Pjq27HTDPYMNJgtCE84DezzGoNfkljlKH/+Yj4EkBEPBARzYgogE8DJ9TZhpZmUdBoQKMhl3rMLLU6V/UIuAC4PSI+2nb80La3vRq4pa42tGsWMNpoMCIB3qHTzPKqc1XPScAbgZsl3Vgdey9whqRjgQDuAd5aYxvmFBE0BCPVr7pmBA3Uj1Obma0pda7q+S4smqxX1nXO5TSLYKQhVI34m0UwNjKIlpiZDVaaK3ebUQb/SKMq9Xhlj5kllSb4iyJoSHM1fk/wmllWaYK/VepptEb83qHTzJLKE/zRGvHPPzczyyhN8BfFwhq/Sz1mllWa4G8GC0s9HvGbWVJpgr+c3MWTu2aWXprg75zcdfCbWVZ5gj8WLud0qcfMskoT/J7cNTMrpQn+1pW785O7A26QmdmA5An+wqUeMzNIFPzF3F495XOXeswsqzTB3yyCES3cndPMLKNUwd9o4FKPmaWXKvhHGw2v6jGz9PIEf5T32/WWDWaWXZrgL4pgZMGWDQNukJnZgKQJ/vktG+afm5lllCb4C2/ZYGYGJAr+prdsMDMDMgV/xILJXd+By8yyShP8RXUB11ypxyN+M0sqTfA3w6UeMzOoMfglHSHpW5Juk3SrpHdVxw+SdJWkO6u/D6yrDe2KAhoSDXl3TjPLrc4R/yzwnoh4LvB84B2SngucC1wdEc8Grq6e166c3GVuxO9VPWaWVW3BHxH3R8T11ePHgNuBw4DTgG3V27YBr6qrDe2a3p3TzAzoU41f0hbgOOAa4JCIuL966ZfAIUt8ZqukSUmTU1NTq25DUe3HL6/jN7Pkag9+SQcAlwHnRMSj7a9FRACLJnBEnB8RExExMT4+vup2zI34vS2zmSVXa/BLGqMM/c9HxJeqww9IOrR6/VBgR51taJm7A5dX9ZhZcnWu6hFwAXB7RHy07aUrgLOqx2cBX6mrDe2KovOeuw5+M8tptMaffRLwRuBmSTdWx94LfAj4oqSzgXuBP6+xDXP2LPX046xmZmtPbcEfEd8FtMTLL63rvEtplXrmduf0iN/MkqpzxL+mlHfgEpff8AsArr37obnRP8DrTjxyUE0zM+urFFs2RARF6w5cVdZ7btfMskoR/K2QH2nbsiFc6jGzpLoKfklfkvQKSevyF0Vr6eZIA+QRv5kl122Q/zvwOuBOSR+SdHSNbeq51tLNstTjEb+Z5dZV8EfENyPi9cDxwD3ANyV9T9Kbq4u01rS5Eb80P+IfYHvMzAap69KNpKcCbwLeAtwA/DPlL4KramlZD7WWbo54xG9m1t1yTklfBo4GLgL+rG2TtUskTdbVuF5p3W2rIc1dWOAav5ll1e06/k9HxJXtByRtjIhdETFRQ7t6an5yt9ydU3jEb2Z5dVvq+eAix77fy4bUqdk2uQvlyh6P+M0sq2VH/JKeTnnzlE2SjmN+C4YnA5trblvPFNVMbutK3YbkEb+ZpbW3Us8fU07oHg6077D5GOWGa+vC/ORuuTmbR/xmltmywR8R24Btkl4TEZf1qU091z652yQ84jez1PZW6nlDRPwHsEXSX3W+3rHP/prVPrm7uxke8ZtZansr9exf/X1A3Q2pU/s6fihH/r4Ri5lltbdSz6eqvz/Qn+bUo73UAyAJ576ZZdXtJm3/KOnJksYkXS1pStIb6m5cr+w54vetF80sr27X8b8sIh4F/pRyr55nAX9dV6N6bba5cMTf8IjfzBLrNvhbJaFXAP8VEY/U1J5atEb3owsu4HLym1lO3W7Z8DVJPwamgbdJGgeeqK9ZvdW+qgeqEf8gG2RmNkDdbst8LvBCYCIidgOPA6fV2bBeKjq3bMAjfjPLa19utv4cyvX87Z/5XI/bU4vmols2DLBBZmYD1O22zBcBzwRuBJrV4WDdBH9rxF8+d43fzDLrdsQ/ATw31uk+B62Q94jfzKz7VT23AE/flx8s6UJJOyTd0nbsPEn3Sbqx+vPyffmZK9U5uesRv5ll1u2I/2DgNknXArtaByPilct85rPAx9mzHPSxiPjwvjRytTr34/eI38wy6zb4z9vXHxwR35G0ZV8/V4eiWFjq8YjfzDLrdjnntymv2B2rHv8QuH6F53ynpJuqUtCBK/wZ+2TRdfzOfTNLqtu9ev4CuBT4VHXoMODyFZzvE5Srg44F7gc+ssw5t0qalDQ5NTW1glPNm1vH7xG/mVnXk7vvAE4CHgWIiDuBp+3rySLigYhoRkQBfBo4YZn3nh8RExExMT4+vq+nWmBuHf+CbZlX9SPNzNatboN/V0TMtJ5UF3Htc3RKOrTt6aspVwvVrv3Wi2U78B24zCytbid3vy3pvZQ3XT8FeDvw1eU+IOkLwMnAwZK2A+8HTpZ0LOUvjXuAt66s2fumcz/+hsTuKPpxajOzNafb4D8XOBu4mTKsrwQ+s9wHIuKMRQ5fsE+t65E9J3dX8M8VM7Mh0VXwR0Qh6XLg8ohY3UzrADQ7J3fxrRfNLK9la/wqnSfpQeAO4I7q7lvv60/zeqNYbMTv3DezpPY2uftuytU8fxARB0XEQcCJwEmS3l1763pkdo8tG7yO38zy2lvwvxE4IyJ+2joQEXcDbwDOrLNhvVSE9+oxM2vZW/CPRcSDnQerOv9YPU3qvWax5+6cXsdvZlntLfhnVvjamjK/H//8iN/r+M0sq72t6jlG0qOLHBewXw3tqUVnqacc8Tv4zSynZYM/Ikb61ZA67XnrRa/qMbO8ut2yYV2bv9l6+Vwe8ZtZYimCf8/JXY/4zSyvXMHfto7fI34zyypF8BcRSGXgQzni93JOM8sqRfA3i5gr80B15a63aTOzpHIEf8TcGn4oO+0Rv5lllSL4i44Rf3nPXSe/meWUIvibxfzELrQmdwfYIDOzAUoR/EUEbblfLed08ptZTimCv1lEx4jf6/jNLK8cwR+dwS8Cj/rNLKcUwV8UMXfbRWCu7OM6v5lllCL4ZztKPa1fAh7xm1lGKYK/WCL4mw5+M0soRfB31vhbj4tiUC0yMxucHMHfcQFXK/hnnfxmllCK4C86tmwYrR43PbtrZgnVFvySLpS0Q9ItbccOknSVpDurvw+s6/ztOkf8DQe/mSVW54j/s8CpHcfOBa6OiGcDV1fPa9csWDDiH3Hwm1litQV/RHwH+FXH4dOAbdXjbcCr6jp/uyKCkbaejnhVj5kl1u8a/yERcX/1+JfAIUu9UdJWSZOSJqemplZ10s5Sj2v8ZpbZwCZ3o7x6asnkjYjzI2IiIibGx8dXda7OyV2Xeswss34H/wOSDgWo/t7Rj5MutZzTwW9mGfU7+K8AzqoenwV8pR8nbRYe8ZuZtdS5nPMLwPeBoyVtl3Q28CHgFEl3An9UPa9dER7xm5m1jNb1gyPijCVeemld51xKswg2ji525a6D38zySXHlbjOWWMfv5ZxmllCK4C9vtj7/fLRRdtulHjPLKEXwd9560TV+M8ssRfCXN1vf8w5cDn4zyyhF8HfegculHjPLLEXwd96By6UeM8ssRfAvdQcur+oxs4xyBH/nfvyu8ZtZYimCv+jYskESIw05+M0spRTB3+zYsgFw8JtZWjmCv+MOXFDejMVbNphZRimCv/MOXFDejMUjfjPLKEXwd07ugks9ZpZXiuDvnNyFVvAXA2qRmdngpAh+T+6amc3LEfwdV+5CFfzOfTNLKEXwd95sHVzqMbO8UgT/opO7cqnHzHIa+uCPCIpYZB2/a/xmltTQB38r2z25a2ZWGvrgb4V75wVcDn4zy2rog7+otl5erNTjLRvMLKOhD/5WuLvUY2ZWGvrgn5ktl2xuGF3Y1dGGfCMWM0tpdBAnlXQP8BjQBGYjYqKuc+2cmQVg84aRBcc94jezrAYS/JUXR8SDdZ9keqYJwOYNC7vq4DezrIa+1LNzLvg7Rvy+gMvMkhpU8AfwP5Kuk7R1sTdI2ippUtLk1NTUik/UCv5NLvWYmQGDC/4/jIjjgT8B3iHpRZ1viIjzI2IiIibGx8dXfKLp3a0av0s9ZmYwoOCPiPuqv3cAXwZOqOtcS5Z6GiKYX+dvZpZF34Nf0v6SntR6DLwMuKWu882VesY6g7/sukf9ZpbNIFb1HAJ8WeUFVaPAf0bEN+o62fQyI34og7/jd4KZ2VDre/BHxN3AMf063+MzS9f4AW/bYGbpDP1yzumZJhLsN9Zx5a7mR/xmZpkMffDvnGmyaWwELbJXDzj4zSyfFMHfWd8HB7+Z5TX0wT89M7vHxVvg4DezvIY++HfONNk8tucctoPfzLIa+uCf3t1k88ZlRvy+gMvMkhn64HeN38xsoRTBv2mxUo+Xc5pZUkMf/NMzs3sZ8Rf9bpKZ2UANffC71GNmttDQB//0THPZ5ZzessHMshnq4I8IHl+i1DPqEb+ZJTXUwb9rtqCIPTdoA5d6zCyvoQ7+6SX24gev4zezvIY6+HfuXnwvfvCI38zyGurgn6724vdePWZm84Y6+Ofvt+sav5lZS5LgX2TE7yt3zSypoQ7+pe63CyCJEcnBb2bpDHXwL1fqAWg0POI3s3yGPPhbN1rfc8QPsN/oCI9XvxzMzLIY6uCfrpZzLraqB+C3n7KJ+x7e2c8mmZkN3FAH/3KTuwCHH7iJHY/uYtduj/rNLI/hDv5dZalnv9Glgn8zAdz3yHQfW2VmNljDHfwzTTaNjdCo1ux3OvzATQBs/5WD38zyGEjwSzpV0h2S7pJ0bl3n2bl78b34W/bfOMpB+29g+69d5zezwfrZQzu5afvDc8vQ67T4OscaSRoB/g04BdgO/FDSFRFxW6/P9Tcv/13Oeemzl33P4Qdu4t6HdrJrtsnGJUpCZmZ1KIrgll88wsU//DkXX/szioCxEfH6E4/irBdu4ciDNs/tMtBLfQ9+4ATgroi4G0DSxcBpQM+Df/+No+y/cfkuHnnQZm7a/gjP+dtvLLqLp619q9lgNVjZh1d3zlVY4YdX2k9YeV9X089YxX/glX5ykBv1NgQnPOOpnPmCo/j2HVNc9IN7+ez37mHDSINPnfk8Xnz003p6vkEE/2HAz9uebwdO7HyTpK3A1urpbyTd0aPzHww82KOftVa5j8PBfRwOXfXxp8Alixx/yd+v6txHLXZwEMHflYg4Hzi/1z9X0mRETPT6564l7uNwcB+Hw1rs4yAmd+8Djmh7fnh1zMzM+mAQwf9D4NmSniFpA3A6cMUA2mFmllLfSz0RMSvpncB/AyPAhRFxax+b0PPy0RrkPg4H93E4rLk+ajWz52Zmtv4M9ZW7Zma2Jwe/mVkyQxv8e9sWQtJGSZdUr18jacsAmrkqXfTxTZKmJN1Y/XnLINq5UpIulLRD0i1LvC5J/1L1/yZJx/e7javVRR9PlvRI23f4vn63cbUkHSHpW5Juk3SrpHct8p51/V122ce1811GxND9oZw0/gnwO8AG4EfAczve83bgk9Xj04FLBt3uGvr4JuDjg27rKvr4IuB44JYlXn858HVAwPOBawbd5hr6eDLwtUG3c5V9PBQ4vnr8JOD/Fvnf6rr+Lrvs45r5Lod1xD+3LUREzACtbSHanQZsqx5fCrxUUu83xahPN31c1yLiO8CvlnnLacDnovQD4CmSDu1P63qjiz6uexFxf0RcXz1+DLid8gr+duv6u+yyj2vGsAb/YttCdH4Jc++JiFngEeCpfWldb3TTR4DXVP90vlTSEYu8vp51+99gvXuBpB9J+rqk3xt0Y1ajKqkeB1zT8dLQfJfL9BHWyHc5rMFvpa8CWyLi94GrmP8Xjq0f1wNHRcQxwL8Clw+2OSsn6QDgMuCciHh00O2pw176uGa+y2EN/m62hZh7j6RR4LeAh/rSut7Yax8j4qGI2FU9/QzwvD61rV+GfvuPiHg0In5TPb4SGJN08ICbtc8kjVEG4ucj4kuLvGXdf5d76+Na+i6HNfi72RbiCuCs6vFrgf+NagZmndhrHztqpK+krDsOkyuAM6sVIc8HHomI+wfdqF6S9PTW3JOkEyj/P7ueBihU7b8AuD0iPrrE29b1d9lNH9fSd7lmd+dcjVhiWwhJfwdMRsQVlF/SRZLuopxcO31wLd53XfbxLyW9Epil7OObBtbgFZD0BcqVEAdL2g68HxgDiIhPAldSrga5C9gJvHkwLV25Lvr4WuBtkmaBaeD0dTZAATgJeCNws6Qbq2PvBY6Eofkuu+njmvkuvWWDmVkyw1rqMTOzJTj4zcyScfCbmSXj4DczS8bBb2aWjIPfzCwZB7+ZWTL/D3T59tvZOxk1AAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1559280, 38) (1559280,)\n",
            "groupNum_train:  60\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ee22f95dc594fd6ae35f93e370cd0d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f78d6d18c5f04f6b95367a6d23014a18",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a9b76a9c4a34c0f8ec33c8a310df648",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(630720, 38) (630720,)\n",
            "groupNum_train:  62\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5c8e6aa1b634283b7952f358259e00a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8567327b4ee2455384839767c76df523",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b4f21b8e7f44e91b589832b372fcad0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(402960, 38) (402960,)\n",
            "groupNum_train:  61\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30222aae7f884fd68c3de267486d9326",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21b08c6f69744730b8d79d9c8c79b1bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f4897a1f6de4d40b56f0ba5cfd8a376",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(367920, 38) (367920,)\n",
            "groupNum_train:  71\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3363e5f3c0e41f8aa1c4a2ff3a0475d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ebd5b0aec4984b1cbe2e46646d5e4c5f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76c74a54a8f348a9b300b11ccc8c2d86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(262800, 38) (262800,)\n",
            "groupNum_train:  72\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ffa757590dc4eb29a77405f527751f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b5f736ff00a4d0ca100e7e2e960f52b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a3a3cb8cc494f63929515dcc692f7ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(210240, 38) (210240,)\n",
            "groupNum_train:  70\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54cbd1a230ce460d83ade1795883ea5c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5dafa1819c04430b2559fdf8954b80b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "67e32297ec454680a99f4a37fc500bd0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD4CAYAAADmWv3KAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAXXElEQVR4nO3de3Cd9X3n8fdH94sly7Zk+Y5MoCYu1JhVIAlZNoFCIdDAzGZmkzTpJNPWvdBMLjvN0EzbbWZ2ZzK7O5lmZ7tNXEjIBZImBJIuk6VJGkpKk5jIQIgBA4ltbINtyTckWdb9u3+cc4wQsnQknUfnnOd8XjMaS895Ll/AfPzz9/k9v0cRgZmZpU9VsQswM7NkOODNzFLKAW9mllIOeDOzlHLAm5mlVE2xC5iqvb09urq6il2GmVnZ2L179/GI6Jjps5IK+K6uLnp6eopdhplZ2ZD04vk+c4vGzCylHPBmZinlgDczSykHvJlZSjngzcxSygFvZpZSDngzs5RywJuZpZQD3swspUrqSdZiuXfXwddte99Vm4pQiZlZ4XgEb2aWUg54M7OUcsCbmaWUA97MLKUc8GZmKeWANzNLKQe8mVlKOeDNzFLKAW9mllIOeDOzlHLAm5mllAPezCylHPBmZimVaMBLapN0n6S9kp6V9JYkr2dmZq9KerngzwIPRcS7JdUBTQlfz8zMshILeEnLgWuADwJExCgwmtT1zMzstZJs0WwG+oAvSnpC0p2SmqfvJGmHpB5JPX19fQmWY2ZWWZIM+BrgCuDvImI7cAa4Y/pOEbEzIrojorujoyPBcszMKkuSAX8YOBwRu7I/30cm8M3MbAkkFvARcRQ4JGlLdtN1wDNJXc/MzF4r6Vk0Hwbuyc6g2Qd8KOHrmZlZVqIBHxFPAt1JXsPMzGbmJ1nNzFLKAW9mllIOeDOzlHLAm5mllAPezCylHPBmZinlgDczSykHvJlZSjngzcxSygFvZpZSDngzs5RywJuZpZQD3swspRzwZmYp5YA3M0spB7yZWUo54M3MUsoBb2aWUg54M7OUcsCbmaWUA97MLKUc8GZmKVWT5MklHQAGgAlgPCK6k7yemZm9KtGAz3pHRBxfguuYmdkUbtGYmaVU0gEfwPck7Za0Y6YdJO2Q1COpp6+vL+FyzMwqR9IB/7aIuAK4Cbhd0jXTd4iInRHRHRHdHR0dCZdjZlY5Eg34iHgp+2sv8ABwZZLXMzOzVyUW8JKaJbXkvgduAPYkdT0zM3utJGfRdAIPSMpd596IeCjB65mZ2RSJBXxE7AO2JXV+MzObnadJmpmllAPezCylHPBmZinlgDczSykHvJlZSjngzcxSygFvZpZSDngzs5RywJuZpZQD3swspRzwZmYp5YA3M0spB7yZWUo54M3MUsoBb2aWUg54M7OUcsCbmaWUA97MLKUc8GZmKeWANzNLKQe8mVlKOeDNzFLKAW9mllKJB7ykaklPSHow6WuZmdmrlmIE/xHg2SW4jpmZTZFowEvaANwM3JnkdczM7PWSHsH/DfAJYPJ8O0jaIalHUk9fX1/C5ZiZVY7EAl7SLUBvROyebb+I2BkR3RHR3dHRkVQ5ZmYVJ6+Al3S/pJslzecPhKuBd0k6AHwduFbSVxdQo5mZLUC+gf1/gPcBL0j6tKQtcx0QEX8eERsiogt4D/DDiHj/wks1M7P5yCvgI+IHEfE7wBXAAeAHkn4s6UOSapMs0MzMFibvloukVcAHgd8HngA+Sybwvz/XsRHxLxFxywJrNDOzBajJZydJDwBbgK8Avx0RR7If/YOknqSKMzOzhcsr4IG/j4jvTt0gqT4iRiKiO4G6zMxskfJt0fzXGbb9pJCFmJlZYc06gpe0BlgPNEraDij7USvQlHBtZma2CHO1aH6LzI3VDcBnpmwfAD6ZUE1mZlYAswZ8RHwJ+JKk/xgR31qimszMrADmatG8PyK+CnRJ+vj0zyPiMzMcZmZmJWCuFk1z9tdlSRdiZmaFNVeL5vPZXz+1NOWYmVmh5LvY2H+X1CqpVtI/S+qT5HVlzMxKWL7z4G+IiH7gFjJr0VwE/FlSRZmZ2eLlG/C5Vs7NwDcj4pWE6jEzswLJd6mCByXtBc4CfyypAxhOriwzM1usfJcLvgN4K9AdEWPAGeDWJAszM7PFyXcED3AJmfnwU4/5coHrMTOzAsl3ueCvAG8AngQmspsDB7yZWcnKdwTfDWyNiEiyGDMzK5x8Z9HsAdYkWYiZmRVWviP4duAZSY8BI7mNEfGuRKoyM7NFyzfg/zrJIszMrPDyCviIeETSBcDFEfEDSU1AdbKlmZnZYuS7Fs0fAPcBn89uWg98O6GazMysAPK9yXo7cDXQDxARLwCrkyrKzMwWL9+AH4mI0dwP2YedZp0yKalB0mOSfi7paUlectjMbAnlG/CPSPokmZdvXw98E/i/cxwzAlwbEduAy4EbJb15wZWamdm85BvwdwB9wC+APwS+C/zFbAdExmD2x9rslx+UMjNbIvnOopmU9G3g2xHRl+/JJVUDu8msH/+3EbFrhn12ADsANm3alO+pzcxsDrOO4JXx15KOA88Bz2Xf5vRX+Zw8IiYi4nJgA3ClpEtn2GdnRHRHRHdHR8cC/hHMzGwmc7VoPkZm9sybImJlRKwErgKulvSxfC8SEaeBh4EbF1qomZnNz1wB/wHgvRGxP7chIvYB7wd+d7YDJXVIast+3whcD+xdVLVmZpa3uQK+NiKOT9+Y7cPXznHsWuBhSU8BPwO+HxEPLqzM5PyPf9rLN3oOFbsMM7OCm+sm6+gCPyMingK2z7uiJXTwxBCff2QfE5PBOy9by7L6+bz/xMystM2VaNsk9c+wXUBDAvUsqf/1wxeYjCCA544O8O8uWFHskszMCmbWFk1EVEdE6wxfLRExV4umpL18+iz3P36YD751M60NNew9OtOfY2Zm5SvfB51S5+mX+5kM+O1ta7lkTSsv9A4yPjFZ7LLMzAqmYgN+//HMQ7YXti/jkrUtjI5Psv/EmSJXZWZWOBUc8GdY1VzH8qZaLljZDMCxV4aLXJWZWeFUbMDv6zvD5vZMsDfWVdNQW8XJobEiV2VmVjgVG/D7j78a8AArmuo4dWbWmZ9mZmWlIgN+cGSc3oERNndMC/ghB7yZpUdFBvyB45mbqRe+ZgRfy6mhUSK8orGZpUNFBvy+bMBvbl92btuK5jrGJoIzoxPFKsvMrKAqMuBzI/gLVjWd27ayqQ7AfXgzS42KDPj9x8+wvq2Rhtrqc9tWNGcC/qT78GaWEhUZ8IdODrFxZeNrtq3wCN7MUqYiA/7YwDBrWl+7VlpdTRXN9TWeSWNmqVFxAR8RHOsfobP19Ythrmyq5dQZP+xkZulQcQH/ytkxRscnWT1DwLc11bkHb2apUXEBf6x/BIDO1vrXfdbWWEv/2THPhTezVKjAgM8sKDZTi6aloYbxyWB4zMsGm1n5q9yAb5kh4Bsz7zDpH3Yf3szKX8UFfO9ApkWzeoYWTUtD5g2GA8PjS1qTmVkSKi7gj/UPs7yx9jUPOeW01mdG8AMewZtZClRkwM90gxU8gjezdEks4CVtlPSwpGckPS3pI0ldaz7ONwceoL62mrqaKo/gzSwVkhzBjwP/OSK2Am8Gbpe0NcHr5aW3f5jVM9xgzWltqKHfI3gzS4HEAj4ijkTE49nvB4BngfVJXS8fk5NB78DIeVs0AC0NtR7Bm1kqLEkPXlIXsB3YNcNnOyT1SOrp6+tLtI5TQ6OMT8Z5WzSQ6cO7B29maZB4wEtaBnwL+GhE9E//PCJ2RkR3RHR3dHQkWstsT7HmtDbU0j/sp1nNrPwlGvCSasmE+z0RcX+S18rHsYHMQ04dLbO1aGoYmwgGRzyKN7PyluQsGgF3Ac9GxGeSus589OUecprlJmtuqmTugSgzs3KV5Aj+auADwLWSnsx+vTPB683p+GAmtNuXzX6TFV5d0sDMrFzVJHXiiHgUUFLnX4i+gRGW1dfQWPf6p1hzciP4Po/gzazMVdSTrH0DI7P23yFzkxWgt98Bb2blrfICfpb2DEB9TRW11XKLxszKXkUF/PHBuUfwkmhpqPVNVjMrexUV8Pm0aCDTh+8d8AjezMpbxQT88NgE/cPjtC+rm3Pf1oZa9+DNrOxVTMDnpkjmP4J3wJtZeauYgM9Ne8wv4GsZHBnnjJ9mNbMyVjEBf3xwFICOZed/ijWn1U+zmlkKVEzAz3cED5m1483MylXFBfyqPG6y5p5mPeYRvJmVscoJ+MFhVjTVUls99z9yq0fwZpYClRPwec6BB2ioraKupsrr0ZhZWauogJ9tFcmpJNHZWu/lCsysrFVMwGfexTr3DJqc1S0NnkVjZmWtIgI+IujtH2H1LK/qm251S70D3szKWkUE/OmhMUYnJumc5U1O03W2NrhFY2ZlrSIC/mg2qOfTouloqWdgeJzhsYmkyjIzS1RFBHxuJL5m+fxaNOAXf5hZ+aqIgM+F9Gwv254uN9o/5mWDzaxMVUTA50bw87rJ2uoRvJmVt8oI+IHMU6z1Ned/2fZ0udG+X/xhZuWqMgK+f35z4IHssgbimEfwZlamKiLge/uHWT3PgJeUfdjJI3gzK0+JBbykL0jqlbQnqWvk61j/CJ15rkMzVUdLvXvwZla2khzB3w3cmOD58zIxGfQNzr9FA9DZWu8RvJmVrcQCPiJ+BJxM6vz5OjE4wsRk0DmPGTQ5Xo/GzMpZ0XvwknZI6pHU09fXV/Dz526SzrcHD5kR/OmhMT/NamZlqegBHxE7I6I7Iro7OjoKfv6FLFOQk5sq6XXhzawcFT3gk3b41BAA69sa531sR+5hJwe8mZWh1Af8oZNnaaytpj2Pd7FOl1t90q/uM7NylOQ0ya8BPwG2SDos6feSutZsDp0aYuPKRiTN+9jVHsGbWRmrSerEEfHepM49H4dODrFxRdOCjl3ZVEddTRUvnT5b4KrMzJKX6hZNRHD41Fk2rlxYwFdViU0rm3jxxJkCV2ZmlrxUB/ypoTEGR8bZsGL+N1hzulY18+KJoQJWZWa2NFId8IdOZoJ50wJH8ABdq5o4cOIMEVGosszMlkS6Az47RXKhLRqAC9qbGR6b9KqSZlZ20h3wJzM3RxcT8F2rMscecB/ezMpMugP+1BArmmpZVr/wyUJdq5oBfKPVzMpOugP+5NCi+u8A69oaqa0WB3yj1czKTKoD/sCJM4tqzwBUV4mNnippZmUotQHfPzzGoZNneePa1kWfq2tVM/uPewRvZuUltQG/98gAAFsLEPAXrMqM4D1V0szKSWoD/pmXXwFg67rFB/yvdbYwNDrhB57MrKykN+CP9LOquY7VC3gX63TbNrQB8PPDpxd9LjOzpZLqgN+6rnVBq0hO92udy2ioreLJQ6cXX5iZ2RJJZcCPTUzy/NHBgvTfAWqqq7hs/XJ+7oA3szKSyoD/Vd8goxOTBem/52zb0Mael/sZm5gs2DnNzJKU2HrwxfTUoewN1gKN4AG2bWxj9NH9PHd0gEvXLy/Yec2s/Ny76+Drtr3vqk1FqGR2qRzB/3BvL2taG7ho9bKCnTN3o9V9eDMrF6kL+OGxCX70Qh/XvXF1QW6w5mxc2cjqlnoeeb6vYOc0M0tS6gL+p/tOMDQ6wW9u7SzoeSVxy2+s45Hn+nhlaKyg5zYzS0LqAv4Hzx6jqa6at1y4quDnvm37OkYnJnno6SMFP7eZWaGl6ibr2dEJHtpzjH9/cTsNtdUFP/9l65ezub2Z7zz5Mv/pTaV3Q8XMltbEZHD41BC9AyNUCTasaOJNm1dQX1P4/FmIVAX8XY/u4/jgCL/3tgsTOb8kbr18HZ/95xfY89Irnk1jVqGGRsZ59JfH6XnxFIMj4wA88MRLALQ01HDb5evZcc2Fi17NdrFSE/DHB0f43CP7uH5rJ1duXpnYdT741i7u2XWQP7vvKb5z+9XU1aSuy2Vm53F6aJS7Ht3Pzh/tY3R8kkvWtLB90wrWtTVy2/Z1PH9sgAefOsI//OwQ9z52kFu3reOP3/4GLu5sKUq9iQa8pBuBzwLVwJ0R8ekkrtM3MMKH7n6MkfEJ7rjpkiQucU5bUx3/7bZL2fGV3fzVd/bwqVt/vWT+OmZmyegbGOHLPznAF//tAIMj41y6rpXr3thJZ2vDuX02rGhiw4omrr2kk0/81iX8/b/u495dB7n/iZe4YWsnt7/jIrZtbFvSuhMLeEnVwN8C1wOHgZ9J+seIeKaQ1zl1ZpR3f+7H9PaPsPN3u3lDR+Hmvp/PDb++hj/6D2/gc4/8iicPneZ3rtrEmzavZO3yRuprqqirrqKqqnBTNM2WwkzLYZ9vheyZNp9vOe2Z9z3fefOvYcbjC3DeMyPjHHllmKP9wzx/dICf7DvBT/edYDLg5svW8uHrLuLxF0/PWsea5Q385S1buf0dF3H3v+3n7h8f4HvPHOPyjW1cc3E7W9ctZ+PKRtqa6ljeWEtzXXVBp3XnJDmCvxL4ZUTsA5D0deBWoKAB39ZUyzsvW8sNWzvZvmlFIU89qztuuoQrNrXx6Yf28pffefp1n1cps4ZNtUQC/92sQAoRCDNuTui8hQhRm58tnS38ydsv4rbt6889PDlXwOesbK7j4zds4Q+uuZB7dx3k/+05yv9++JdMTvtv076sjp6/uL7AlYOSeomFpHcDN0bE72d//gBwVUT86bT9dgA7sj9uAZ5LpKDZtQPHi3DduZRiXaVYE5RmXaVYE7iu+SjFmuC1dV0QER0z7VT0m6wRsRPYWcwaJPVERHcxa5hJKdZVijVBadZVijWB65qPUqwJ8q8rySkgLwEbp/y8IbvNzMyWQJIB/zPgYkmbJdUB7wH+McHrmZnZFIm1aCJiXNKfAv9EZprkFyLi9XcjS0NRW0SzKMW6SrEmKM26SrEmcF3zUYo1QZ51JXaT1czMisuPYZqZpZQD3swspSo64CXdKOk5Sb+UdEex6wGQ9AVJvZL2FLuWqSRtlPSwpGckPS3pIyVQU4OkxyT9PFvTp4pd01SSqiU9IenBYteSI+mApF9IelJST7HrAZDUJuk+SXslPSvpLSVQ05bsv6PcV7+kj5ZAXR/L/l7fI+lrkhpm3b9Se/DZpRSeZ8pSCsB7C72UwgLqugYYBL4cEZcWs5apJK0F1kbE45JagN3AbcX896XMs93NETEoqRZ4FPhIRPy0WDVNJenjQDfQGhG3FLseyAQ80B0RJfPwjqQvAf8aEXdmZ9w1RcTpIpd1TjYrXiLzoOaLRaxjPZnf41sj4qykbwDfjYi7z3dMJY/gzy2lEBGjQG4phaKKiB8BJ4tdx3QRcSQiHs9+PwA8C6wvck0REYPZH2uzXyUxYpG0AbgZuLPYtZQyScuBa4C7ACJitJTCPes64FfFDPcpaoBGSTVAE/DybDtXcsCvBw5N+fkwRQ6sciGpC9gO7CpyKbk2yJNAL/D9iCh6TVl/A3wCmCxyHdMF8D1Ju7PLhBTbZqAP+GK2nXWnpOZiFzXNe4CvFbuIiHgJ+J/AQeAI8EpEfG+2Yyo54G0BJC0DvgV8NCL6i11PRExExOVknpS+UlLR21qSbgF6I2J3sWuZwdsi4grgJuD2bEuwmGqAK4C/i4jtwBmgJO6HAWRbRu8CvlkCtawg02XYDKwDmiW9f7ZjKjngvZTCPGX73N8C7omI+4tdz1TZv9Y/DNxY5FIArgbele13fx24VtJXi1tSRnYUSET0Ag+QaVUW02Hg8JS/ed1HJvBLxU3A4xFxrNiFAL8J7I+IvogYA+4H3jrbAZUc8F5KYR6yNzTvAp6NiM8Uux4ASR2S2rLfN5K5Yb63qEUBEfHnEbEhIrrI/L76YUTMOtJaCpKaszfIybZBbgCKOlsrIo4ChyRtyW66jgIvKb5I76UE2jNZB4E3S2rK/v94HZl7YedV9NUki6VUl1KQ9DXg7UC7pMPAf4mIu4pbFZAZlX4A+EW25w3wyYj4bvFKYi3wpewshyrgGxFRMlMSS1An8ED2xRI1wL0R8VBxSwLgw8A92YHWPuBDRa4HOPeH4PXAHxa7FoCI2CXpPuBxYBx4gjmWLKjYaZJmZmlXyS0aM7NUc8CbmaWUA97MLKUc8GZmKeWANzNLKQe8mVlKOeDNzFLq/wNe7BwrG0+MXAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(210240, 38) (210240,)\n",
            "groupNum_train:  73\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cdb133260bca4b55abe45f4fdac4beca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "260a035e5c01440aa7ce1869ad68069b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db77cf46101c4e03a90e4367646577fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(52560, 38) (52560,)\n",
            "groupNum_train:  80\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88b42950eb0c4a2a8ce111f1ddecb2f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08c954cd9865461383c466a8b444a34e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b1c2a07098d4af2aef4a324ff9cccf8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1226400, 38) (1226400,)\n",
            "groupNum_train:  90\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04688cb635894a3bae82d63269ef0efe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2feac7eb809e45dfbf53621ed726e9f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b6bd87782df4dc7b1c742fdf0d8ea1e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2137440, 38) (2137440,)\n",
            "groupNum_train:  91\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70154e4a688d4fc49ba05f566c9460c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "231126f876104a53ba038210b0d3dc91",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b45d48d2cdf45fa9f6708ff7f47c03d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1664400, 38) (1664400,)\n",
            "groupNum_train:  92\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "560cc45173d0426cb413c1606264d9bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2bc84af8bcb34b56bdf42e6d2b803b01",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf8675bc530749eba0ea7c124c7d0ec8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1559280, 38) (1559280,)\n",
            "groupNum_train:  100\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "025b3cbed20e4d24b5c4d93eecf24ef0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d5577b9b1df4ec587256ad74aa30299",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "812b95cdb7554fad87f4859c69e40008",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(525600, 38) (525600,)\n",
            "groupNum_train:  101\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ac01efeb8874e1797d6d0186f9a3fcd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41cf0685aad24b6e8fdd98445e12d94a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca9c49747c0140c7bd1f5947e8f573da",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(157680, 38) (157680,)\n",
            "groupNum_train:  103\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59926676c76e4d7187c132bdfa73aab5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3ea60d0ae0240799b59f6f2ddcf1205",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dafce771c550431191478b8b8dc1a3ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAY/ElEQVR4nO3de3RedZ3v8fcntyZpmzZt02taQ8ttAQNSotRhdEBkpks9cJbyB3BghKPW8TI6zpzxOM5Zo551/lDH5dx0hunBjqjIqIgcZKGAinLmDBRSBOVSgXIpaZs2vSW9JGmTfM8fz/OUkObyNH32s/N0f15rdfXJ3jv79+1e7ae//PZv758iAjMzy46qtAswM7PycvCbmWWMg9/MLGMc/GZmGePgNzPLmJq0CyjGggULoq2tLe0yzMwqyqZNm3ZHRMvo7RUR/G1tbXR0dKRdhplZRZH0yljbPdRjZpYxDn4zs4xx8JuZZYyD38wsYxz8ZmYZ4+A3M8sYB7+ZWcY4+M3MMsbBb2aWMRXx5G6avrNx65jbr7t4RZkrMTMrjcR6/JI2SNol6alR2/9E0mZJT0v6UlLtm5nZ2JIc6vkGsHbkBkmXAVcBF0TEucCXE2zfzMzGkFjwR8RDwN5Rmz8MfCEiBvLH7EqqfTMzG1u5b+6eCbxV0kZJv5T0pvEOlLROUoekju7u7jKWaGZ2ait38NcA84A1wF8A35OksQ6MiPUR0R4R7S0tx71O2szMpqjcwd8J3Bk5jwLDwIIy12BmlmnlDv67gMsAJJ0J1AG7y1yDmVmmJTaPX9LtwKXAAkmdwGeBDcCG/BTPI8D7IiKSqsHMzI6XWPBHxLXj7Lo+qTbNzGxyfmWDmVnGOPjNzDLGwW9mljEOfjOzjHHwm5lljIPfzCxjHPxmZhnj4DczyxgHv5lZxjj4zcwyxsFvZpYxDn4zs4xx8JuZZYyD38wsYxz8ZmYZ4+A3M8uYxIJf0gZJu/KrbY3e9+eSQpLX2zUzK7Mke/zfANaO3ihpOfAHwNYE2zYzs3EkFvwR8RCwd4xdfwt8CvBau2ZmKSjrGL+kq4BtEfFkOds1M7PXJLbY+miSGoHPkBvmKeb4dcA6gBUrViRYmZlZtpSzx78KOA14UtLLQCvwuKTFYx0cEesjoj0i2ltaWspYppnZqa1sPf6I+A2wsPB1PvzbI2J3uWowM7Nkp3PeDjwMnCWpU9L7k2rLzMyKl1iPPyKunWR/W1Jtm5nZ+PzkrplZxjj4zcwyxsFvZpYxDn4zs4xx8JuZZYyD38wsYxz8ZmYZ4+A3M8sYB7+ZWcY4+M3MMsbBb2aWMQ5+M7OMcfCbmWWMg9/MLGMc/GZmGePgNzPLGAe/mVnGJLn04gZJuyQ9NWLb30jaLOnXkn4oaW5S7ZuZ2diS7PF/A1g7atsDwHkRcT7wHPCXCbZvZmZjSCz4I+IhYO+obfdHxGD+y0eA1qTaNzOzsaU5xv9fgR+Pt1PSOkkdkjq6u7vLWJaZ2aktleCX9FfAIHDbeMdExPqIaI+I9paWlvIVZ2Z2iqspd4OSbgTeDVweEVHu9s3Msq6swS9pLfAp4Pcj4nA52zYzs5wkp3PeDjwMnCWpU9L7ga8Cs4EHJD0h6eak2jczs7El1uOPiGvH2Pz1pNozM7Pi+MldM7OMcfCbmWWMg9/MLGMc/GZmGePgNzPLGAe/mVnGOPjNzDLGwW9mljEOfjOzjHHwm5lljIPfzCxjHPxmZhnj4DczyxgHv5lZxjj4zcwyxsFvZpYxSa7AtUHSLklPjdg2T9IDkp7P/96cVPtmZja2JHv83wDWjtr2aeBnEXEG8LP812ZmVkaJBX9EPATsHbX5KuDW/Odbgf+cVPtmZja2co/xL4qIHfnPXcCi8Q6UtE5Sh6SO7u7u8lRnZpYBqd3cjYgAYoL96yOiPSLaW1payliZmdmprajgl3SnpHdJOtn/KHZKWpI/5xJg10mez8zMTlCxQf5PwHXA85K+IOmsKbZ3N/C+/Of3Af9niucxM7MpKir4I+KnEfFfgNXAy8BPJf2HpJsk1Y71PZJuBx4GzpLUKen9wBeAKyQ9D7wj/7WZmZVRTbEHSpoPXA/cAPwKuA34PXI990tHHx8R145zqstPuEozMyuZooJf0g+Bs4BvAf9pxMyc70rqSKo4MzMrvWJ7/P87Iu4duUHSjIgYiIj2BOoyM7OEFHtz93+Nse3hUhZiZmblMWGPX9JiYBnQIOlCQPldTUBjwrWZmVkCJhvq+UPgRqAV+MqI7QeAzyRUk5mZJWjC4I+IW4FbJb03In5QpprMzCxBkw31XB8R3wbaJP3Z6P0R8ZUxvs3MzKaxyYZ6ZuZ/n5V0IWZmVh6TDfX8S/73z5enHDMzS1qxL2n7kqQmSbWSfiapW9L1SRdnZmalV+w8/j+IiF7g3eTe1XM68BdJFWVmZskpNvgLQ0LvAr4fET0J1WNmZgkr9pUN90jaDPQBH5bUAvQnV5aZmSWl2Ncyfxr4XaA9Io4Ch8itn2tmZhWm6NcyA2eTm88/8nu+WeJ6zMwsYcW+lvlbwCrgCWAovzlw8JuZVZxie/ztwDn5BdJPmqRPAh8g95/Hb4CbIsL3DMzMyqDYWT1PAYtL0aCkZcDHyd0vOA+oBq4pxbnNzGxyxfb4FwDPSHoUGChsjIgrT6LdBklHyb3eefsUz2NmZieo2OD/XKkajIhtkr4MbCU3PfT+iLi/VOc3M7OJFTud85fkntitzX9+DHh8Kg1KaiY3FfQ0YCkwc6zXP0haJ6lDUkd3d/dUmjIzszEU+66eDwJ3AP+S37QMuGuKbb4DeCkiuvPPBNxJ7hmB14mI9RHRHhHtLS0tU2zKzMxGK/bm7keBS4BegIh4Hlg4xTa3AmskNUoScDnw7BTPZWZmJ6jY4B+IiCOFL/IPcU1pamdEbCT308Pj5KZyVgHrp3IuMzM7ccXe3P2lpM+Qm4lzBfAR4EdTbTQiPgt8dqrfb2ZmU1dsj//TQDe5HvqHgHuB/5FUUWZmlpyievwRMSzpLuCuiPAUGzOzCjZhj185n5O0G/gt8Nv86lt/XZ7yzMys1CYb6vkkudk8b4qIeRExD7gYuCT/vh0zM6swkwX/DcC1EfFSYUNEvAhcD/xRkoWZmVkyJgv+2ojYPXpjfpy/NpmSzMwsSZMF/5Ep7jMzs2lqslk9F0jqHWO7gPoE6jEzs4RNGPwRUV2uQszMrDyKfYDLzMxOEQ7+cUQEj728l8Gh4bRLMTMrqWLf1ZM59z29kz/+9iZmz6jhyjcu5dylc9IuycysJNzjH8e/v9BNY101M2qruf+ZnWmXY2ZWMg7+cTzy4l7efNo83rh8DrsPDNB/dCjtkszMSsLBP4buAwO8sOsga1bOp7W5kQC27e9Luywzs5Jw8I9h40t7AHLBP7cBgG37HPxmdmpw8I/h4S17mDWjhvOWNtE4o4Z5M+t4dd/htMsyMyuJVIJf0lxJd0jaLOlZSW9Jo47xbHplH6vf0ExNde7ytDY3uMdvZqeMtHr8fw/8JCLOBi5gGi22HhG8sucwZyycdWxb69wG9vcd5UD/0RQrMzMrjbIHv6Q5wNuArwNExJGI2F/uOsaz++AR+o4OsWJe47FtS5tz4/w7evrTKsvMrGTS6PGfRm793n+V9CtJt0iaOfogSeskdUjq6O4u32qPW/fmxvJHBv/8mTMA2HfYLyQ1s8qXRvDXAKuBf46IC4FD5BZzf52IWB8R7RHR3tLSUrbitu49BMDyEcE/u76Gaol9hzzUY2aVL43g7wQ6I2Jj/us7yP1HMC1s3dOHlLuhW1AlMbex1j1+MzsllD34I6ILeFXSWflNlwPPlLuO8Wzde5jFTfXU177+jdTNjXXsd/Cb2SkgrZe0/Qlwm6Q64EXgppTqOM6rew+/bpinYG5jLZu7fHPXzCpfKsEfEU8A7Wm0PZmtew/ze2csOG5788w6Dg4McnRomNpqP/dmZpXLCTZC/9Ehunr7Xzejp6C5Mbe2vMf5zazSOfhH6Nx3/FTOgubGOgD2H/bMHjOrbA7+EY7N4Z8/1hh/Lvjd4zezSufgH2Hb/tzN22VzG47b57n8ZnaqcPCPsLOnn+oqsWDWjOP2eS6/mZ0qHPwjdPX2s3D2DKqrNOb+uY21nstvZhXPwT/Czt5+FjXVj7t/TkMdPX0e6jGzyubgH2FHTz+LJwj+poYaDg4MMhxRxqrMzErLwT/Czp5+Fs+ZIPjraxkOONg/WMaqzMxKy8Gfd2hgkAMDg5MM9eQe4ur1gixmVsEc/HldvbmpnIvnHD+jp6CpPhf8Huc3s0rm4M/bmV9da6Ief1ND7tVGvQ5+M6tgDv68Yz3+CYJ/5owaqgS9HuM3swrm4M97bahn/OCvkphdX+sev5lVNAd/3s6efprqa2ism/hN1U31NfT45q6ZVTAHf15X78RTOQuaGmrp7fNQj5lVrtSCX1K1pF9JuietGkbq6h2Y8MZuwZyGWk/nNLOKlmaP/xPAsym2/zpdPX0T3tgtaKqv5cjgMAcc/mZWoVIJfkmtwLuAW9Jof7TBoWG6DwwUPdQDuff6mJlVorR6/H8HfAoYHu8ASeskdUjq6O7uTrSY3QePMBwTz+EvKMzl7+oZSLQmM7OklD34Jb0b2BURmyY6LiLWR0R7RLS3tLQkWlMxc/gL5uSf3t3R05doTWZmSUmjx38JcKWkl4F/A94u6dsp1HFMV8/kc/gLPNRjZpWu7MEfEX8ZEa0R0QZcA/w8Iq4vdx0j7Szi4a2C2uoqGmqrj/2UYGZWaTyPn9xQT221mJdfUH0yTQ01HuM3s4o18WOqCYuIXwC/SLMGyD21u3B2PVXjLLk4WlN9rYd6zKxiucdP8U/tFjQ11Hqox8wqloOf3M3dYmb0FMxpqGX3wQGODo07G9XMbNrKfPBHBF2TLLI+WlN9LRHQfcDj/GZWeTIf/AcGBjl8ZGjClbdGO/YQl4d7zKwCZT74i1l5a7TCEoyF7zUzqySZD/5Cr33JnIaiv6fwEJd7/GZWiRz8PcW/rqFgZl01ddVVx77XzKySZD74t+/PD/WcwBi/JBY2zXCP38wqUuaDf9v+wyycPYMZNdUn9H2Lm+rd4zeziuTg39/H0rnFj+8XLJ5T7x6/mVWkzAf/9v39LGs+8eBf1tzAjv39DA9HAlWZmSUn08E/PBxs299H6xR6/K3NjRwZGmaXH+IyswqT6eDffWiAI4PDU+rxt+a/p3Pf4VKXZWaWqEwH/7Z9uVW0lk2hx7+8uRGAzn1eicvMKku2g39/LrSncnPXPX4zq1SZDv7t+eCfylBPfW01C2bNcI/fzCpOGoutL5f0oKRnJD0t6RPlrqFg274+ZtfXHHv3zolqbW7gVff4zazCpNHjHwT+PCLOAdYAH5V0Tgp1sG1/35TG9wtamxvc4zezipPGYus7IuLx/OcDwLPAsnLXAbkbs61TGOYpWD6vke37+xjyXH4zqyCpjvFLagMuBDaOsW+dpA5JHd3d3SVvOyLYtm9qT+0WtDY3cHQo2HXAT/CaWeVILfglzQJ+APxpRPSO3h8R6yOiPSLaW1paSt5+98EBDgwMsnLBzCmfo9VTOs2sAqUS/JJqyYX+bRFxZxo1bNl1CIBVC2dN+RyFYaKte3yD18wqRxqzegR8HXg2Ir5S7vYLtnQfBGBVy9SDf3lzIzVVOnYuM7NKkEaP/xLgBuDtkp7I/3pnuYvY0n2QxrrqE1qAZbS6miraFszk+V0OfjOrHDXlbjAi/h1QudsdbUv3IVa2zKSq6uRKOXPRLJ7ZftwtCjOzaSuzT+5u2XXwpIZ5Cs5YOJtX9h6m/+hQCaoyM0teJoO/78gQ23v6ShP8i2YRgcf5zaxiZDL4X9p9iIiTu7FbcOai2QA8v9PBb2aVIZPBf2xGz8Kpz+EvaJs/k5oq8fyuAyd9LjOzcshk8G/u6qW6SrTNP/ngL8zsec49fjOrEJkM/k2v7OPcpU3U11aX5HxnLprFczvd4zezypC54D86NMyTr/awekVzyc553rI5vLLnMLsPev1dM5v+Mhf8m3ccoO/oEBe9oXTBf/Fp8wF49KW9JTunmVlSyv4AV9o2vZIL51IG//mtc2iorWbji3t45+8sKdl5zaxyfGfj1jG3X3fxijJXMrnM9fg3bd3Pkjn1J/U65tFqq6tob2tmo3v8ZlYBMhX8EcGml/eyuoS9/YKLT5vH5q4D7D10pOTnNjMrpUwF/9Pbe9ne08/vrppf8nNfvLIwzr+n5Oc2MyulTAX/nY9vo666inclMA5/Qetc5jTU8qNf7yj5uc3MSikzwT84NMzdT27jsrNbmNtYV/Lz19VUcfVFrdz3VBfdBzyt08ymr8wE//99fje7Dx7hPatbE2vjuotXMDgcfK/j1cTaMLPpbWg4eGn3IX6+eRf3/mYHf3PfZu57uouDA4Npl3ZMJqZzDg4N87c/fY4Fs2Zw2VkLE2tnVcss3rJyPt/ZuJWbLmmjsS4Tl9fMgIHBITa+uJeHX9xDT99RBNTWVPHIi3sYHA5m1lXzntWtfOj3Vx5brzstmUimDf/vJX7d2cNXr7uQuppkf8j5+OVncN0tj/D5u5/hi1efn2hbZpa+gwOD3L5xK3/30+c4dGSIVS0zeefvLOH0llk01FXzntXLeOLV/Xy/o5PvPvYqtz+6lasvauWjl53O8nnp/AeQSvBLWgv8PVAN3BIRX0iqrR9s6uTL9z/HFecsSuSm7mhvWTWfj1y6iq89uIW2BTP50NtWnvQqX2Y2/ew+OMA3H36FW//jZXr6jnJ6yyzecc4iVowK8/raatasnM+alfP5b394Jjf/Ygu3P/Yqd2zq5D2rl/HBt67kjPzr3cul7MEvqRr4GnAF0Ak8JunuiHim1G196Seb+adfbGHNynl88b3nk1vnPXmffMeZvLDrIF/8yWbuf6aLqy9q5cLlzSydW09DXTV11VVlq8Wmp4go4phJ9p9kG5NXUEwNk7RRTCMn+f0nW0Mx17G3f5Cunn529vazuesAG1/cw2Mv72U44IpzFvGRS1fx7I7JX9S4ZE4Dn7/qPD586enc/MstfOfRrXyvo5OzF8/mktMXcM6SJpbObWDZ3Abmzaqjobaa6gQ6jmn0+N8MvBARLwJI+jfgKqDkwf+mtnl88K3D/Pe1Z1NTXb772DXVVdx8/UV8f1MnX3vwBf7qh0+9br9EPvzHP4cmWJb4ZP7PSPof8qT/TqfJP+TJa5jsHJOewk5RVYKzFjfx0ctO56o3LuX0hbneejHBX7B4Tj2fu/JcPvb207nnye385Okuvv3IKwwMDh937L/e+CYuO7u09yZVzD+CkjYoXQ2sjYgP5L++Abg4Ij426rh1wLr8l2cBvy1roa9ZAOxOqe2T5drT4drT4dqP94aIaBm9cdre3I2I9cD6tOuQ1BER7WnXMRWuPR2uPR2uvXhpzOPfBiwf8XVrfpuZmZVBGsH/GHCGpNMk1QHXAHenUIeZWSaVfagnIgYlfQy4j9x0zg0R8XS56zgBqQ83nQTXng7Xng7XXqSy39w1M7N0ZeZdPWZmluPgNzPLGAd/nqS1kn4r6QVJnx5j/wxJ383v3yipLYUyx1RE7TdK6pb0RP7XB9KoczRJGyTtkvTUOPsl6R/yf65fS1pd7hrHU0Ttl0rqGXHN/7rcNY5H0nJJD0p6RtLTkj4xxjHT8toXWfu0vPaS6iU9KunJfO2fH+OY8uRMRGT+F7mbzFuAlUAd8CRwzqhjPgLcnP98DfDdtOs+gdpvBL6adq1j1P42YDXw1Dj73wn8GBCwBtiYds0nUPulwD1p1zlObUuA1fnPs4Hnxvg7My2vfZG1T8trn7+Ws/Kfa4GNwJpRx5QlZ9zjzzn2GomIOAIUXiMx0lXArfnPdwCXa3q8cKeY2qeliHgImGiF+quAb0bOI8BcScm/aa8IRdQ+bUXEjoh4PP/5APAssGzUYdPy2hdZ+7SUv5YH81/W5n+Nnl1Tlpxx8OcsA0auntLJ8X+Zjh0TEYNAD1D6xXtPXDG1A7w3/yP7HZKWj7F/Oir2zzZdvSX/Y/2PJZ2bdjFjyQ8lXEiu9znStL/2E9QO0/TaS6qW9ASwC3ggIsa97knmjIM/G34EtEXE+cADvNajsOQ8Tu49KRcA/wjclW45x5M0C/gB8KcR0Zt2PSdiktqn7bWPiKGIeCO5Nxa8WdJ5adTh4M8p5jUSx46RVAPMAfaUpbqJTVp7ROyJiMJCwLcAF5WptpNVsa/3iIjewo/1EXEvUCtpQcplHSOpllxw3hYRd45xyLS99pPVPt2vPUBE7AceBNaO2lWWnHHw5xTzGom7gfflP18N/Dzyd2BSNmnto8ZmryQ3LloJ7gb+KD/DZA3QExE70i6qGJIWF8ZmJb2Z3L+16dBRIF/X14FnI+Ir4xw2La99MbVP12svqUXS3PznBnJrkmwedVhZcmbavp2znGKc10hI+p9AR0TcTe4v27ckvUDupt416VX8miJr/7ikK4FBcrXfmFrBI0i6ndwMjAWSOoHPkrvhRUTcDNxLbnbJC8Bh4KZ0Kj1eEbVfDXxY0iDQB1wzTToKAJcANwC/yY83A3wGWAHT/toXU/t0vfZLgFuVW4yqCvheRNyTRs74lQ1mZhnjoR4zs4xx8JuZZYyD38wsYxz8ZmYZ4+A3M8sYB7+ZWcY4+M3MMub/Awtfq1D2gN0tAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(192720, 38) (192720,)\n",
            "groupNum_train:  110\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc32ebaa9ed848d591441254e194ea9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c0721c12f614a96a5c3e8fb969fd017",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df9857000454412f84f5a679ddca4b93",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(87600, 38) (87600,)\n",
            "groupNum_train:  111\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b16bdc1893ae4cfd90f0450a5a425533",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3d19408200c4f5e9abf346599ac87d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69d4ceb60c8746c2acde3dacbdea4029",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(70080, 38) (70080,)\n",
            "groupNum_train:  113\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2972cebcb9034234bd2b7375baaf2b47",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8523a97fa294fe5ab1908b68fe6063d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e936ab1b11da49978f4ca13398ce012f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(87600, 38) (87600,)\n",
            "groupNum_train:  120\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "850719e52fa546989ea85f50ba48fbf5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d176d2b934c54007b6e47e82d075e65c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e9eb69290674c28a24261911ccb9270",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(630720, 38) (630720,)\n",
            "groupNum_train:  130\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "291f7d6e3fea4726b0e153b202877ae5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5375251313ad4bd08502211e83f459d5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a77bdeda60a041bb8b7f9e9f4b3be55b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2470320, 38) (2470320,)\n",
            "groupNum_train:  131\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "972a4a0dbc834d1082e3366f2028deed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "620bdd0b5d1540a3adaa750782025b92",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a964875293714ec0a8e333f458e51b2e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1401600, 38) (1401600,)\n",
            "groupNum_train:  132\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8822bb8c013a495e9618237353395677",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78e264bb690f4a0ca10f736012868af8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb79b2e0071d41cf8a8b60300777e013",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1541760, 38) (1541760,)\n",
            "groupNum_train:  140\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0118038fee344d828aeabc645e39f6c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a90251b02e2a41079a118eb5e95b3b2a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10640c7b0c4b4bb4a7d8d4a5a3ef0d60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1787040, 38) (1787040,)\n",
            "groupNum_train:  141\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a871d29c31b74fd29cfb20d99e1d62d5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c538588cbd5437d8de5fe2e2ee3a7d5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0689712d34d540879c04a914244cc93f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1506720, 38) (1506720,)\n",
            "groupNum_train:  143\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0ab4a350f544ec98e080adb6b942504",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23cea09e5d264b50bfa88e76cc904587",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90fd67b3ae774e01beacfc979024170d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(998640, 38) (998640,)\n",
            "groupNum_train:  142\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd549ef1399343959f3208cbfb3364c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62b5c427592a43dcbcd7e41f63337f89",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2388cf2220884a04b6f2715c931691d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(753360, 38) (753360,)\n",
            "groupNum_train:  153\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b07d7c78637f4f61a52a5158039ccfcf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4887c6b1bccb4f219901f57795a28aad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64987dfde33247bc875f91aa77f2f505",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(35040, 38) (35040,)\n",
            "groupNum_train:  150\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a39d99839ef44cf808997a8af8e5fb5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2282265e5dc47a88e762030614c2cb3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f572d3a4dd924b129851efff5a1dc2c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1997280, 38) (1997280,)\n",
            "groupNum_train:  151\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f714774afc64aedb187e9ac90e7718f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0be7597d0ce44317ab45ba0573907942",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e182c8534d3c4786829a61a0a4321ad3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1138800, 38) (1138800,)\n",
            "groupNum_train:  152\n",
            "all pred\n",
            "iterations 1\n",
            "predicting 0-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9521cbe7b4e64f10ad8fb281c04d5701",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 1-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "909c0f210f1e46d289c212ddee7469d1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predicting 2-th model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1d28600098a4a6aafbd1344e208293a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAVqElEQVR4nO3de4yldX3H8c/nXHaB5doyKC7YxUuwjalCRm1LYyNWi0LFpIkRxUu13aa1LWpTg7apmhhjL0FJa9WtUFEJtnKxVK26ImptEZ2FVS4LgoqCBXeQwILi7pzn+faPc87sXM7MHHbOc56d+b5fyWZnnjl7fr8D4bM/vr/v83scEQIA5NGoewIAgPEi+AEgGYIfAJIh+AEgGYIfAJJp1T2BYRx77LGxZcuWuqcBAGvKjh077o+IiYXX10Twb9myRVNTU3VPAwDWFNs/GHSdUg8AJEPwA0AyBD8AJEPwA0AyBD8AJEPwA0AyBD8AJEPwA0Ay6YL/RRf+t6668Z66pwEAtUkV/GUZ2nXvHt1+3yN1TwUAapMq+Dtl92lj+zplzTMBgPokC/5u4O/tFDXPBADqkyz4uyv+vaz4ASSWKviLglIPAKQK/hlKPQCQK/gLSj0AkCv4O5R6AKC64Ld9se3dtm+ec+3vbd9m+9u2r7J9dFXjD8LmLgBUu+L/iKQzFlzbLunpEfGrkr4j6a0Vjr9I0avxs+IHkFllwR8RX5X0wIJrX4iITu/br0s6oarxB9m/4mdzF0Beddb4Xyfpv8Y5YL/GT6kHQGa1BL/tv5LUkXTpMq/ZanvK9tT09PRIxuXIBgCoIfhtv1bSWZJeGRGx1OsiYltETEbE5MTExEjGLmb7+Al+AHm1xjmY7TMkvUXSb0XEz8Y5tkQ7JwBI1bZzXibpOkkn277H9usl/ZOkIyRtt73T9gerGn8QNncBoMIVf0ScM+DyRVWNN4x+8M8UobIMNRquczoAUItUd+72a/yStK+g3AMgp1TBP1Ps30veO0PwA8gpVfD3D2mTpL0FdX4AOaUK/k7Jih8AcgX/nLo+vfwAssoV/HNW/PTyA8gqVfDPq/HTyw8gqVTBT6kHALIFP6UeAMgV/PNLPQQ/gJxSBT8rfgDIFvzzavxs7gLIKVfwU+oBgFzBX1DqAYBcwT/vkDZKPQCSShX8RVlqQ7P7kVnxA8gqVfB3ytDGdkM2NX4AeeUK/iLUbja0sdUg+AGklSv4y1CzYW1sNSn1AEirsmfuHoyKslSrYanVYHMXQFqpgr9TdFf8zYYp9QBIK1fwl90aP5u7ADJLFfxFr8bfbjZ49CKAtJJt7nZr/BtbDe0rCH4AOVUW/LYvtr3b9s1zrv2C7e227+j9fkxV4w/SKUKtprWh1dDeGTZ3AeRU5Yr/I5LOWHDtfEnXRMRTJV3T+35suu2c9PEDyK2y4I+Ir0p6YMHlsyVd0vv6EkkvrWr8QYoyeqUe+vgB5DXuGv/jIuLe3tf3SXrcUi+0vdX2lO2p6enpkQw+U+yv8dPHDyCr2jZ3IyIkxTI/3xYRkxExOTExMZIxi7Jb42dzF0Bm4w7+H9s+XpJ6v+8e5+D9Gn93c5fgB5DTuIP/akmv6X39Gkn/Mc7BO2Wp9myph+AHkFOV7ZyXSbpO0sm277H9eknvkfQC23dI+u3e92PTP7JhY5vNXQB5VXbnbkScs8SPnl/VmCvp1/g3NNncBZBXsjt3Q61eH38ZUocNXgAJJQv+bjtnu9V7/CLBDyChVMFf9I9ltrvfl0t2kwLAupUq+Du9Gn+zQfADyCtf8DcaajUJfgB55Qr+olSzYTUo9QBILFXw9w9pa/VLPUHwA8gnVfDPlKFWszFb4+8UBD+AfFIFf3/Fz+YugMzSBH9EzD5zt0mpB0BiaYK/01vdt5tWq9H92Kz4AWSUJvj7Id9sNNTsfWpq/AAyquyQtoNNf8Xfalj/c+dPJEmfuele7bz7wdnXvOI5T6xjagAwVmlW/P0D2VpNq1fiV0mpB0BCeYJ/zorfvRu4SjZ3ASSUJvjn1vgbs8Ff54wAoB5pgn92xT+31MOKH0BCeYK/X+Ofc1YPwQ8gozzBP1vqsRq9JT+5DyCjNMFfzG7uNujqAZBamuCfmdfOyeYugLzSBH8xp52TGj+AzNIE/9wav+nqAZBYLcFv+022b7F9s+3LbB9S9Zj9c3nazcbsw9Yp9QDIaOzBb3uzpD+XNBkRT5fUlPTyqsftlN0a/9yuHlb8ADKqq9TTknSo7ZakwyT9X9UDFvOObOheo6sHQEZjD/6I+JGkf5D0Q0n3SnooIr5Q9bj9Uk+ruf/IBhb8ADKqo9RzjKSzJZ0k6QmSNtk+d8Drttqesj01PT296nE787p6utd4AheAjOoo9fy2pO9HxHREzEi6UtJvLHxRRGyLiMmImJyYmFj1oMXcGj/tnAASqyP4fyjp12wf5u75yM+XtKvqQec+epFSD4DM6qjxXy/pckk3SLqpN4dtVY/br/E35x7ZQPIDSKiWRy9GxNslvX2cY86r8ffbOenqAZDQUCt+21faPtP2mr3Tt1/jn3dWT50TAoCaDBvk/yzpFZLusP0e2ydXOKdKzBQDjmxgxQ8goaGCPyK+GBGvlHSqpLskfdH2/9r+fdvtKic4KvOPZbYsjmwAkNPQpRvbvyjptZL+QNKNki5U9y+C7ZXMbMTmHtImSQ2bzV0AKQ21uWv7KkknS/qYpN+NiHt7P/o321NVTW6U+o9ebDe7wW/T1QMgp2G7ev4lIj4794LtjRGxNyImK5jXyC1a8TdMHz+AlIYt9bxrwLXrRjmRqs2t8UtSwxzZACCnZVf8th8vabO6J2meIqnXD6Mj1T1Vc83oFKXsBTV+dncBJLRSqed31N3QPUHSBXOuPyzpbRXNqRKdMtTq37KrbvCz4AeQ0bLBHxGXSLrE9u9FxBVjmlMlijJmV/tSt9TD5i6AjFYq9ZwbER+XtMX2mxf+PCIuGPDHDkozRajd2L+lQTsngKxWKvVs6v1+eNUTqVpRlmo256z4G+YGLgAprVTq+VDv93eOZzrVWVjj7965S/IDyGfYQ9r+zvaRttu2r7E9PeipWQezoozZVk6pt+JnyQ8goWH7+F8YEXsknaXuWT1PkfSXVU2qCjPF/M3dpin1AMhp2ODvl4TOlPTJiHioovlUpihLtebU+DmyAUBWwx7Z8Gnbt0l6VNIf256Q9PPqpjV69PEDQNewxzKfr+4D0Sd7D0j/qaSzq5zYqHWKBTV+VvwAknosj158mrr9/HP/zEdHPJ/KdBbdwGXO6gGQ0rDHMn9M0pMl7ZRU9C6H1lDwL6zxczongKyGXfFPSvqViLUblYtr/N3yDwBkM2xXz82SHl/lRKq2uMbPkQ0Achp2xX+spFttf0PS3v7FiHhJJbOqwOJD2ujjB5DTsMH/jionMQ4zZamN7f0flz5+AFkN2875FXXv2G33vv6mpBsOdFDbR9u+3PZttnfZ/vUDfa9hFQP6+Al+ABkNe1bPH0q6XNKHepc2S/rUKsa9UNLnIuJpkp4hadcq3msonSLUXHhWD7kPIKFhN3ffIOk0SXskKSLukHTcgQxo+yhJz5V0Ue+99kXEgwfyXo9FUYbazQUPYiH5ASQ0bPDvjYh9/W96N3EdaGqeJGla0r/avtH2h21vWvgi21ttT9memp6ePsCh9pspywGbuwQ/gHyGDf6v2H6bug9df4GkT0r6zwMcsyXpVEkfiIhT1D3+4fyFL4qIbRExGRGTExMTBzjUfoNq/OQ+gIyGDf7z1V2l3yTpjyR9VtJfH+CY90i6JyKu731/ubp/EVSqU4RaTc7qAYCh2jkjorT9KUmfiohV1V0i4j7bd9s+OSJul/R8Sbeu5j2H0SnLAV09VY8KAAefZVf87nqH7fsl3S7p9t7Tt/5mleP+maRLbX9b0jMlvXuV77eiRTdwNVjxA8hppRX/m9Tt5nlWRHxfkmw/SdIHbL8pIt57IINGxE51z/8Zm04Zas8p9ZjNXQBJrVTjf5Wkc/qhL0kR8T1J50p6dZUTG7UOj14EAEkrB387Iu5feLFX529XM6VqLK7x08cPIKeVgn/fAf7soLOwxk+pB0BWK9X4n2F7z4DrlnRIBfOpRERoZlE7J338AHJaNvgjojmuiVSpX9FZWOoJdTt7GvbgPwgA69CwN3CtaZ2ylKQF7Zzdryn3AMgmRfAXvSX//EPaul+T+wCySRH8M71n6847lrn3dwCdPQCySRH8/RX/wiMbJNHLDyCdFMHfr/G3FpzHL1HjB5BPjuAvFq/4bTZ3AeSUIvj7pZ65Nf4mpR4ASaUI/s6grp7eJ2fFDyCbHMFfLO7jny31sOQHkEyO4F+mq4cFP4BsUgT//nbOxX38BckPIJkUwT/TL/UMuHOXGj+AbFIE/3I3cJH7ALJJEfyd2XZObuACgBTBv/+Qtjk1/gZdPQByShH8MwPaOTmrB0BWKYJ/UI3flHoAJJUi+DsD2zlZ8QPIKUfw9w9pm9PO2WTFDyCp2oLfdtP2jbY/XfVYgx69yOmcALKqc8V/nqRd4xhotqunsbirh9wHkE0twW/7BElnSvrwOMbrl3qaAx7EUlDkB5BMXSv+90l6i6RyqRfY3mp7yvbU9PT0qgZb7pA2Sj0Ashl78Ns+S9LuiNix3OsiYltETEbE5MTExKrGLPqPXuTIBgCoZcV/mqSX2L5L0icknW7741UOOFMsfTonK34A2Yw9+CPirRFxQkRskfRySV+KiHOrHHP20YuczgkASfr4B9X4G9zABSCnVp2DR8SXJX256nH6j17kyAYASLbiH3hIG0t+AMmkCP6iDDUbnr1bV5KanNUDIKkUwd8pY16ZR6LUAyCvHMFflIuCnz5+AFnlCP5eqWeufks/K34A2aQI/qKMeY9dlPav+AuCH0AyKYK/U5aLVvz978h9ANnkCP5i0Oau1TDtnADySRH8RRlqNRd/1IZNjR9AOimCf2ZAO6fUD/4aJgQANUoR/MWAGr/U7exhcxdANimCv1MMLvU0Gw0VBcEPIJccwb9EqWdD05oplnwIGACsS2mCf1Cpp9VsEPwA0kkR/EW5+MgGSWo3Pft0LgDIIkXwd2v8g4KfFT+AfHIEfxnznrfbR/ADyChN8A+q8bcbnn1ICwBkkSL4i7JUe0Cph81dABmlCP5OMXjFv6HZYHMXQDo5gn+JGn+LPn4ACaUI/u4hbXT1AICUJPhnisFn9bR7pZ7gvB4AiYw9+G2faPta27favsX2eVWPWSxxZEN/w5fOHgCZtGoYsyPpLyLiBttHSNphe3tE3FrZgEucx99/HGOnCLWbVY0OAAeXsa/4I+LeiLih9/XDknZJ2lzlmJ1iqSMbuh9/H3V+AInUWuO3vUXSKZKuH/CzrbanbE9NT0+vapwlb+Dql3oIfgCJ1Bb8tg+XdIWkN0bEnoU/j4htETEZEZMTExOrGqsoY3Z1P1e//EMvP4BMagl+2211Q//SiLiy6vGWWvFv6K34aekEkEkdXT2WdJGkXRFxwTjGXKrGv3/FT/ADyKOOFf9pkl4l6XTbO3u/XlzVYGUZKkNL9vFLlHoA5DL2ds6I+JqkxSlckf7D1AfV+NuUegAktO7v3O30VvPLr/gJfgB5rPvg7/foL9fH36HUAyCRdR/8ex6dkSQdeWh70c/avb8MZkpW/ADyWPfB/1Av+I8aFPytXqmnQ/ADyGPdB/+eZYK/Nbvip9QDII91H/zLrfhtq9XgYSwAckkd/BIPYwGQD8HfNDdwAUglRfC3GtZhGwYfuM+KH0A2KYL/qEPb6h4RtFj/8YsAkMW6D/4He8G/lHbTnMcPIJV1H/x7Hp0ZePNWX4tSD4Bk1n3wP7TCin8DpR4AyaQP/laTPn4AuaQPfrp6AGSzroO/LEN7htrcpdQDII91HfyP7OuojKVv3pK6K/59rPgBJLKug/+hny1/167UDX5W/AAyWd/Bv8xZ/H2tplVEqOCETgBJrOvgX+5I5r4Ns0/hotwDIId1HfwrHdAm7X/84s95GAuAJHIE/2FLB/8TjjpEkvTDB342ljkBQN1yBP8yK/7Nxxymja2Gvrv7kXFNCwBqte6Dv9mwNi1xJLMkNRvWk47dpDunCX4AOdQS/LbPsH277Tttn1/VOCsdydz35OMO1wM/3ae7KfcAGLNOUeqLt/5Y77j6Fr3/2jtnKxVValU+wgK2m5LeL+kFku6R9E3bV0fEraMe60+e9xS9bPLEFV/35InDJUmfv+U+ve60k9RoLP8XBQCs1kOPzujr3/uJ3rv9O7rtvod1SLuhn8+U+uBXvqvXnXaSXvasE3X8kYdUkkdjD35Jz5Z0Z0R8T5Jsf0LS2ZJGHvybjz5Um48+dMXXHXfERh19aFvv+swu/e3nblOr8dj/R2iF/6moXIzwNoTQaO9pGOXcJI14dqN9w2z/7GKEExz93Eb8hhU5+rC2znn2E/XLxx+hU594jP7xS3fowmu6v9pNa9urJ/W8k48b6Zh1BP9mSXfP+f4eSc9Z+CLbWyVt7X37iO3bRziHYyXdP8L3OxjwmdYGPtPaMLbP9ANJ31rm56e/e1Vv/0uDLtYR/EOJiG2StlXx3ranImKyiveuC59pbeAzrQ3r8TPNVcfm7o8kzS28n9C7BgAYgzqC/5uSnmr7JNsbJL1c0tU1zAMAUhp7qSciOrb/VNLnJTUlXRwRt4x5GpWUkGrGZ1ob+Exrw3r8TLM8yl15AMDBb13fuQsAWIzgB4Bk0gX/uI6LGBfbF9vebfvmuucyCrZPtH2t7Vtt32L7vLrntFq2D7H9Ddvf6n2md9Y9p1Gx3bR9o+1P1z2XUbB9l+2bbO+0PVX3fKqSqsbfOy7iO5pzXISkc6o4LmJcbD9X0iOSPhoRT697Pqtl+3hJx0fEDbaPkLRD0kvX+L8jS9oUEY/Ybkv6mqTzIuLrNU9t1Wy/WdKkpCMj4qy657Natu+SNBkR6+2GtHmyrfhnj4uIiH2S+sdFrFkR8VVJD9Q9j1GJiHsj4obe1w9L2qXu3d5rVnT1j39t936t+RWX7RMknSnpw3XPBY9NtuAfdFzEmg6V9cz2FkmnSLq+5qmsWq8kslPSbknbI2LNfyZJ75P0Fknr6fF1IekLtnf0jo1Zl7IFP9YI24dLukLSGyNiT93zWa2IKCLimereqf5s22u6LGf7LEm7I2JH3XMZsd+MiFMlvUjSG3ql1HUnW/BzXMQa0KuDXyHp0oi4su75jFJEPCjpWkln1DyV1TpN0kt6NfFPSDrd9sfrndLqRcSPer/vlnSVuuXhdSdb8HNcxEGutxF6kaRdEXFB3fMZBdsTto/ufX2ous0Ft9U6qVWKiLdGxAkRsUXd/46+FBHn1jytVbG9qddQINubJL1Q0rrollsoVfBHREdS/7iIXZL+vYbjIkbK9mWSrpN0su17bL++7jmt0mmSXqXuCnJn79eL657UKh0v6Vrb31Z38bE9ItZF++M68zhJX7P9LUnfkPSZiPhczXOqRKp2TgBAshU/AIDgB4B0CH4ASIbgB4BkCH4ASIbgB4BkCH4ASOb/AbELXlfU8tRlAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1208880, 38) (1208880,)\n"
          ]
        }
      ],
      "source": [
        "for groupNum_train in building_meta_df['groupNum_train'].unique():\n",
        "    print('groupNum_train: ', groupNum_train)\n",
        "    X_test = create_X(test_df, groupNum_train=groupNum_train)\n",
        "    gc.collect()\n",
        "\n",
        "    exec('y_test= pred(X_test, models' + str(groupNum_train) + ')')\n",
        "\n",
        "    sns.distplot(y_test)\n",
        "    plt.show()\n",
        "\n",
        "    print(X_test.shape, y_test.shape)\n",
        "    sample_submission.loc[test_df[\"groupNum_train\"] ==\n",
        "                          groupNum_train, \"meter_reading\"] = np.expm1(y_test)\n",
        "\n",
        "    del X_test, y_test\n",
        "    gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Site-0 Correction "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://www.kaggle.com/c/ashrae-energy-prediction/discussion/119261#latest-684102\n",
        "sample_submission.loc[(test_df.building_id.isin(site_0_bids)) & (test_df.meter == 0), 'meter_reading'] = sample_submission[(\n",
        "    test_df.building_id.isin(site_0_bids)) & (test_df.meter == 0)]['meter_reading'] * 3.4118"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.log1p(sample_submission['meter_reading']).hist(bins=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not debug:\n",
        "    sample_submission.to_csv(\n",
        "        'submission_LSTM_RNN_firstRun.csv', index=False, float_format='%.4f')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not debug:\n",
        "\n",
        "  ! mkdir -p ~/.kaggle/ && \\\n",
        "    echo '{\"username\":\"joydipbhowmick\",\"key\":\"5bd4e6a1fec9fc7f8a93def26785a6d2\"}' > ~/.kaggle/kaggle.json && \\\n",
        "    chmod 600 ~/.kaggle/kaggle.json # Create a new direcory use the kaggle token key in that and make it read only to current user.\n",
        "  ! kaggle competitions submit -c ashrae-energy-prediction -f submission_RNN_Dense_layer.csv -m \"LSTM RNN Model No Blend First test run - still in debug mode\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ML_Final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
